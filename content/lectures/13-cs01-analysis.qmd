---
title: "13-cs01-analysis"
author: "Professor Shannon Ellis"
date: "2023-02-23"

format:
  html: 
    output-file: 13-cs01-analysis.html
    embed-resources: true
  revealjs:
    output-file: 13-cs01-analysis-slides.html
    slide-number: true
    chalkboard: false 
    preview-links: auto
    logo: images/cogs137-logo-hex.png
    css: slides.css
    footer: <https://cogs137.github.io/website/>
    scrollable: true
    embed-resources: true
    execute:
      echo: true
      eval: true
---

# CS01: Right-To-Carry (Analysis) {background-color="#92A86A"}

## Q&A {.smaller}

> Q: I'm curious about how different groups will approach this dataset differently, and hope that we can have some kind of showcase after this case study is completed!\
> A: I am too - sometimes students add another (related) question. Some find a new related dataset. Some go really deep on visualization. I like the idea of a showcase! Was not in my plan, but I think it should be!

> Q: I'm confused about...how to choose the best EDA. \
> A: The best EDA is the EDA that best helps you understand the datasets being used for analysis. So, while there's not "one plot to rule them all," a great EDA uses visualizations and data summaries that let the analyst really understand the data. Two EDAs can make different decisions and both be "best".

## Course Announcements {.smaller}

**Due Dates**:

-   Lecture Participation survey "due" after class
-   Lab06 due tomorrow (2/24; 11:59 PM)
-   HW03 due Mon (2/27; 11:59 PM)

. . .

**Notes**:

- [Final Project Groups survey](https://forms.gle/G9bxKRGtHrJ69Msr9) (link also on canvas; "due" Friday)
- Accept the GH repo for cs01; talk with group mates
- Midterm grades posted (Canvas) and feedback available (GitHub Issue)
  - Answer key on website
  - Regrades open until Sunday at 5PM (GitHub issue or Campuswire post)
- CS01 Data Wrangling: [Campuswire Post](https://campuswire.com/c/G78A1024C/feed/173)

## Agenda

- panel data & analysis
- modelling the LOTT and DONOGHUE data
- Multicollinearity
- VIF

# Questions  {background-color="#92A86A"}

1. What is the relationship between right to carry laws and violence rates in the US?
2. What is the effect of multicollinearity on coefficient estimates from linear regression models when analyzing right to carry laws and violence rates?

## Packages & Data

```{r, echo=FALSE, echo = FALSE, message=FALSE, warning=FALSE}
library(DT)

knitr::opts_chunk$set(echo=TRUE, warning=FALSE, message=FALSE) 
```

```{r packages-load}
# i've asked ITS to install those on datahub for you
# if that's not yet complete, you can install using install.packages()
library(tidyverse)
library(broom)
library(plm) 
library(car) 
library(rsample) 
library(GGally) 
library(ggcorrplot) 
```

. . .

This will only work if you finished the wrangling...

```{r}
load("data/wrangled/wrangled_data_rtc.rda")
```


# Panel Data {background-color="#92A86A"}

## Panel Data {.smaller}

- repeated measures for multiple panel members or individuals over time.
  - multiple units  (violent crime and other variables for each state)
  - multiple time points (multiple years)

. . . 

Lingo:

- $N$ individual panel members
- $T$ time points

. . . 

- **Balanced Panels**: At each time point ( $T$ ), there are data points for each individual( $N$ ). ( $n = N∗T$ )
- **Unbalanced Panels**: May be data points missing for some individuals ( $N$ ) at some time points ( $T$ ) ( $n$ observations $\lt N∗T$)

## Our Panel Data

In our case we have:

- $N$ = 44 states (in the data wrangling process we removed those who had adopted an RTC law before 1980)
- $T$ = 31 years (1980 - 2010)

Panel is balanced: $n=44∗31$, thus $n = 1364$


## Panel Linear Regression {.smaller}

$$Y_{it}=β_{0}+β_{1}X_{1it}+...+β_{K}X_{Kit}+e_{it}$$

- $i$ is the individual dimension (in our case individual states) 
- $t$ is the time dimension.

. . . 

Notes:

- Some explanatory variables $X_{it}$ will vary across individuals and time
- others will be fixed across the time of the study (or don't change over time)
- others still will be fixed across individuals but vary across time periods

. . .

[`r emo::ji("question")` Which are examples of variables in our analysis that likely fall into each of these categories?]{style="background-color: #ADD8E6"}


## Fixed Effects Panel Regression Analysis {.smaller}

- assumes that there are unknown or unobserved unique aspects about the individuals or heterogeneity among individuals (states) $a_i$ that are not explained by the independent variables but influence the outcome variable of interest (crime).
- they do not vary with time or in other words are fixed over time but may be **correlated** with independent variables $X_{it}$

. . . 

- The intercept can be different for each individual $\beta_{0i}$ (each state)
- Other coefficients are assumed to be the same across all the individuals.

. . . 

In our data...some of the unobserved qualities about the different states *may* be correlated with some of our independent variables (i.e.level of economic opportunity might be an unobserved feature about the states that influences violent crime rate (outcome) and would be possibly correlated with poverty rate and unemployment (predictors))


## Fixed Effects Panel Regression Analysis (Model) {.smaller}

These individual $a_i$ effects can be correlated with the independent variables $X$:

$$Y_{it}=\beta_{0}+\beta_{1}X_{1it}+...\beta_{K}X_{Kit}+ a_i +e_{it}$$
...or alternatively the individual effects can be absorbed into an *individual-specific intercept term* $\beta_{0i}$:

$$Y_{it}=\beta_{0i}+\beta_{1}X_{1it}+...\beta_{k}X_{kit} +e_{it}$$


## Panel Linear Model (`plm`) {.smaller}

- carry out panel linear models
- New object: `pdata.frame` (panel data frame); can indicate:  
  - which variable should be used to identify the individuals in our panel (`STATE`)
  - what variable should be used to identify the time periods in our panel (`YEAR`)
- Will be specified in `index` parameter: `index = c("Individual_Variable_NAME", "Time_Period_Variable_NAME")`


## `pdata.frame`

```{r}
d_panel_DONOHUE <- pdata.frame(DONOHUE_DF, index = c("STATE", "YEAR"))
class(d_panel_DONOHUE)
head(d_panel_DONOHUE, n = 3)
```


## Model Considerations: `effect` {.smaller}

There are three main options for the `effect` argument:

::: incremental
1. **individual**  - model for the effect of individual identity
2. **time** - model for the effect of time
3. **twoways** - meaning modeling for the effect of both individual identity and time  
:::

. . .

- speculate that there is an effect of individual `STATE` identity and time on violent crime rate (`effect = "twoways"`)
  - aka expect some states to have high rates of crime, and others to have low rates of crime
  - expect crime rates to change over time


## Model Considerations: `model` {.smaller}

::: incremental
1. **pooling** - standard pooled ordinary least squares regression model  
2. **within** - fixed effects model (variation between individuals is ignored, model compares individuals to themselves at different periods of time)  
3. **between** - fixed effects model (variation within individuals from one time point to another is ignored, model compares different individuals at each point of time)  
4. **random** - random effects (each state has a different intercept but force it to follow a normal distribution - requires more assumptions)
:::

. . . 

interested in how violence in each state varied over time: within `STATE` variation (`model = within`)

# Modelling  {background-color="#92A86A"}

## Model: `plm` (DONOHUE)

```{r}
DONOHUE_OUTPUT <- plm(Viol_crime_rate_1k_log ~
                      RTC_LAW +
                      White_Male_15_to_19_years +
                      White_Male_20_to_39_years +
                      Black_Male_15_to_19_years +
                      Black_Male_20_to_39_years +
                      Other_Male_15_to_19_years +
                      Other_Male_20_to_39_years +
                      Unemployment_rate +
                      Poverty_rate +
                      Population_log +
                      police_per_100k_lag,
                      effect = "twoways",
                      model = "within",
                      data = d_panel_DONOHUE)
```

. . .

[`r emo::ji("question")` What is our outcome variable here? What is our primary predictor of interest? Why are all the other variables included?]{style="background-color: #ADD8E6"}


## Model Output: DONOHUE {.smaller}


```{r}
DONOHUE_OUTPUT_TIDY <- tidy(DONOHUE_OUTPUT, conf.int = 0.95)
DONOHUE_OUTPUT_TIDY
DONOHUE_OUTPUT_TIDY$Analysis <- "Donohue"
```


## Formula: `as.formula()` (LOTT)

```{r}
LOTT_variables <- LOTT_DF |>
  select(RTC_LAW,
         contains(c("White", "Black", "Other")),
         Unemployment_rate,
         Poverty_rate,
         Population_log,
         police_per_100k_lag) |>
  colnames()

LOTT_fmla <- as.formula(paste("Viol_crime_rate_1k_log ~", paste(LOTT_variables, collapse = " + ")))
LOTT_fmla
```


## Model: `plm` (LOTT)

```{r}
d_panel_LOTT <- pdata.frame(LOTT_DF, index = c("STATE", "YEAR"))

LOTT_OUTPUT <- plm(LOTT_fmla,
                   model = "within",
                   effect = "twoways",
                   data = d_panel_LOTT)
```


## Model Output: LOTT {.smaller}

```{r}
LOTT_OUTPUT_TIDY <- tidy(LOTT_OUTPUT, conf.int = 0.95)
LOTT_OUTPUT_TIDY
LOTT_OUTPUT_TIDY$Analysis <- "Lott"
```

## RTC coefficient comparison {.smaller}

```{r}
comparing_analyses <- DONOHUE_OUTPUT_TIDY |>
  bind_rows(LOTT_OUTPUT_TIDY) |>
  filter(term == "RTC_LAWTRUE")

comparing_analyses
```

. . .

[`r emo::ji("brain")` With each analysis, what would your conclusion be to the question "What is the relationship between right to carry laws and violence rates in the US"?]{style="background-color: #ADD8E6"}



## RTC

::: panel-tabset

### Code
```{r, comparing, fig.show = "hide"}
ggplot(comparing_analyses) +
  geom_point(aes(x = Analysis, y = estimate)) +
  geom_errorbar(aes(x = Analysis, ymin = conf.low, ymax = conf.high), width = 0.25) +
  geom_hline(yintercept = 0, color = "red") +
  scale_y_continuous(
    breaks = seq(-0.2, 0.2, by = 0.05),
    labels = seq(-0.2, 0.2, by = 0.05),
    limits = c(-0.2, 0.2)
  ) +
  geom_segment(aes(x = 1, y = 0.125, xend = 1, yend = 0.175),
    arrow = arrow(angle = 45, ends = "last", type = "open"),
    size = 2, color = "green", lineend = "butt", linejoin = "mitre"
  ) +
  geom_segment(aes(x = 2, y = -0.125, xend = 2, yend = -0.175),
    arrow = arrow(angle = 45, ends = "last", type = "open"),
    size = 2, color = "red", lineend = "butt", linejoin = "mitre"
  ) +
  theme_minimal() +
  theme(
    axis.title.x = element_blank(),
    axis.text = element_text(size = 8, color = "black")
  ) +
  labs(
    title = "Effect estimate on ln(violent crimes per 100,000 people)",
    y = "  Effect estimate (95% CI)"
  )
```

### Plot

```{r ref.label="comparing", echo = FALSE, out.width="100%"}
```
:::

## Similar Data - different results

- The only difference between the two data frames rests in how the demographic variables were parameterized.
  - Donohue: Males only; ages 15 to 39
  - Lott: Males/Females; ages 10-65+

. . .

...so how did this occur?

# Multicollinearity  {background-color="#92A86A"}

## Multicollinearity 

- multicollinearity occurs when independent variables (predictors) are highly related to one another

. . .

- When *seemingly* independent variables are highly related to one another, the relationships estimated in an analysis may be distorted. 
- since linear regression aims to determine how a one unit change in a regressor influences a one unit change in the dependent variable, if the regressors are collinear...effect of each regressor cannot be accurately estimated

. . .

## Diagnosing Multicollinearity: Pairplots

::: panel-tabset

### Code
```{r correlation, fig.show = "hide"}
DONOHUE_DF |>
  select(RTC_LAW,
         Viol_crime_rate_1k_log,
         Unemployment_rate,
         Poverty_rate,
         Population_log) |>
  ggpairs(columns = c(2:5),
          lower = list(continuous = wrap("smooth_loess",
                                         color = "red",
                                         alpha = 0.5,
                                         size = 0.1)))
```

### Plot

```{r ref.label="correlation", echo = FALSE, out.width="80%"}
```


...not much correlation for non-demographic variables
- unemployment and poverty rate show some (as expeted)

:::


## Diagnosing Multicollinearity: Heatmaps

::: panel-tabset

### Code
```{r heatmap, fig.show = "hide"}
cor_DONOHUE_dem <- cor(DONOHUE_DF |> select(contains("_years")))

ggcorrplot(cor_DONOHUE_dem,
  tl.cex = 6,
  hc.order = TRUE,
  colors = c(
    "red",
    "white",
    "red"
  ),
  outline.color = "transparent",
  title = "Correlation Matrix: Donohue",
  legend.title = expression(rho)
)
```

### Plot
```{r ref.label="heatmap", echo = FALSE, out.width="80%"}
```

### Notes

- *strong* correlation within race
- race shows much stronger correlation than age
- suggests collinearity
:::

---

## Heatmap: Lott

::: panel-tabset

### Code
```{r heatmap-lott, fig.show = "hide"}
cor_LOTT_dem <- cor(LOTT_DF |> select(contains("_years")))

corr_mat_LOTT <- ggcorrplot(cor_LOTT_dem,
  tl.cex = 6,
  hc.order = TRUE,
  colors = c(
    "red",
    "white",
    "red"
  ),
  outline.color = "transparent",
  title = "Correlation Matrix: Lott",
  legend.title = expression(rho)
)

corr_mat_LOTT
```

### Plot

```{r ref.label="heatmap-lott", echo = FALSE, out.width="80%"}
```

:::


## Suggested multicollinearity

...so how do you find out for sure?

- look at the stability of the coefficient estimates under perturbations of the data
- we'll focus on `RTC_LAW`
- use resampling (here: remove one observation, see if estimates change == *LOOCV* - leave one out cross-validation): `rsample::loo_cv`


## LOOCV: splits (Donohue)

```{r, cache=TRUE}
## split data
set.seed(124)
DONOHUE_splits <- d_panel_DONOHUE |> loo_cv()
DONOHUE_splits
```


## LOOCV: get data (Donohue)

```{r, cache=TRUE}
DONOHUE_subsets <- map(pull(DONOHUE_splits, splits), training)
glimpse(DONOHUE_subsets[[1]])
```


## Function: bootstrapping (Donohue)

```{r}
fit_nls_on_bootstrap_DONOHUE <- function(subset) {
  plm(Viol_crime_rate_1k_log ~ RTC_LAW +
        White_Male_15_to_19_years +
        White_Male_20_to_39_years +
        Black_Male_15_to_19_years +
        Black_Male_20_to_39_years +
        Other_Male_15_to_19_years +
        Other_Male_20_to_39_years +
        Unemployment_rate +
        Poverty_rate +
        Population_log +
        police_per_100k_lag,
      data = data.frame(subset),
      index = c("STATE", "YEAR"),
      model = "within",
      effect = "twoways")
}
```


## Use the Function (Donohue)

```{r, cache=TRUE}
subsets_models_DONOHUE <- map(DONOHUE_subsets, fit_nls_on_bootstrap_DONOHUE)

subsets_models_DONOHUE <- subsets_models_DONOHUE |>
  map(tidy)

subsets_models_DONOHUE[[1]]
```

Note: This code takes a while to run. Suggestion to cache this code chunk!


## Save bootstrap output (Donohue)

```{r, cache=TRUE}
save(subsets_models_DONOHUE,
  file = "data/wrangled/DONOHUE_simulations.rda")
```


## LOOCV: splits (Lott)

```{r, cache=TRUE}
set.seed(124)
LOTT_splits <- d_panel_LOTT |> loo_cv()
LOTT_subsets <- map(pull(LOTT_splits, splits), training)
```


## Function: bootstrapping (Lott)

```{r}
fit_nls_on_bootstrap_LOTT <- function(split) {
  plm(LOTT_fmla,
      data = data.frame(split),
      index = c("STATE", "YEAR"),
      model = "within",
      effect = "twoways"
  )
}
```


## Use the Function (Lott)

```{r, cache=TRUE}
subsets_models_LOTT <- map(LOTT_subsets, fit_nls_on_bootstrap_LOTT)
subsets_models_LOTT <- subsets_models_LOTT |>
  map(tidy)
```

Note: This code takes a while to run. Suggestion to cache this code chunk!


## Save bootstrap output (Lott)

```{r}
save(subsets_models_LOTT,
  file = "data/wrangled/LOTT_simulations.rda")
```

## Visualize the results

```{r}
names(subsets_models_DONOHUE) <- paste0("DONOHUE_", seq_len(length(subsets_models_DONOHUE)))

names(subsets_models_LOTT) <-
  paste0("LOTT_", 1:length(subsets_models_LOTT))
```


## Combine simulation data {.smaller}

::: panel-tabset

### Code
```{r}
simulations_DONOHUE <- subsets_models_DONOHUE |>
  bind_rows(.id = "ID") |>
  mutate(Analysis = "Donohue")

simulations_LOTT <- subsets_models_LOTT |>
  bind_rows(.id = "ID") |>
  mutate(Analysis = "Lott")

simulations <- bind_rows(simulations_DONOHUE, simulations_LOTT)

# order for easier comparison
simulations <- simulations |>
  mutate(term = factor(term,
    levels = c(
      str_subset(unique(pull(simulations, term)), "years", negate = TRUE),
      sort(str_subset(unique(pull(simulations, term)), "years")))))
```

### Data
```{r}
head(simulations)
```
:::



## Simulation: Plot (coefficients)

::: panel-tabset

### Code

```{r, simulation, fig.show="hide"}
simulations |>
  ggplot(aes(x = term, y = estimate)) +
  geom_boxplot() +
  facet_grid(. ~ Analysis, scale = "free_x", space = "free", drop = TRUE) +
  labs(title = "Coefficient estimates",
       subtitle = "Estimates across leave-one-out analyses",
       x = "Term",
       y = "Coefficient",
       caption = "Results from simulations") +
  theme_linedraw() +
  theme(axis.title.x = element_blank(),
        axis.text.x = element_text(angle = 70, hjust = 1),
        strip.text.x = element_text(size = 14, face = "bold"),
        plot.title.position="plot")
```

### Plot

```{r ref.label="simulation", echo = FALSE, out.width="100%"}
```

:::

## Simulation: Plot (sd)

::: panel-tabset

### Code
```{r, sd, fig.show="hide"}
coeff_sd <- simulations |>
  group_by(Analysis, term) |>
  summarize("SD" = sd(estimate))

coeff_sd |>
  ggplot(aes(x = Analysis, y = SD)) +
  geom_jitter(width = 0.1, alpha = 0.5, size = 2) +
  labs(title = "Coefficient variability",
       subtitle = "SDs of coefficient estimates from leave-one-out analysis",
       x = "Term",
       y = "Coefficient Estimate \n Standard Deviations",
       caption = "Results from simulations") +
  theme_minimal() +
  theme(axis.title.x = element_blank(),
        axis.text.x = element_text(size = 8, color = "black"),
        axis.text.y = element_text(color = "black"),
        plot.title.position="plot")
```

### Plot

```{r ref.label="sd", echo = FALSE, out.width="100%"}
```

:::

# VIF: Variance Inflation Factor {background-color="#92A86A"}


## VIF: Evaluating presence and severity of multicollinearity

Variance Inflation Factor (**VIF**): index that measures how much the variance (the square of the estimate’s standard deviation) of an estimated regression coefficient is increased because of collinearity.


## Calculating VIF: {.smaller}

If our model is : $Y = β_0 + β_1X_1 + β_2X_2 + β_3X_3 + e$, then:

To calculate the VIF value for $X_1$, perform another OLS model, where $X_1$ is now the dependent variable explained by the other explanatory variables:

$$X_1 = β_0 +  β_2X_2 + β_3X_3 + e$$ 

. . . 

From this model : $$VIF = \frac{1}{1-R^{2}}$$ 

...where $R^2$ value is the proportion of variance in $X_1$ explained by the other variables ( $X_2$ and $X_3$)

. . . 

Repeat for each explanatory variable in the model.

. . . 
- the larger the VIF,  the more multicollinearity
- VIF of >=10 typically indicates problematic multicollinearity



## Calculating VIF (Donohue)

::: panel-tabset 

### Code
```{r}
# create model matrix
lm_DONOHUE_data <- as.data.frame(model.matrix(DONOHUE_OUTPUT))

# define model
lm_DONOHUE_data <- lm_DONOHUE_data |> 
  mutate(Viol_crime_rate_1k_log = plm::Within(pull(
    d_panel_DONOHUE, Viol_crime_rate_1k_log
  )), effect = "twoways")

# specify model
lm_DONOHUE <- lm(Viol_crime_rate_1k_log ~
RTC_LAWTRUE +
  White_Male_15_to_19_years +
  White_Male_20_to_39_years +
  Black_Male_15_to_19_years +
  Black_Male_20_to_39_years +
  Other_Male_15_to_19_years +
  Other_Male_20_to_39_years +
  Unemployment_rate +
  Poverty_rate +
  Population_log +
  police_per_100k_lag,
data = lm_DONOHUE_data
)

# calculate VIF
vif_DONOHUE <- vif(lm_DONOHUE)
```

### Table

```{r}
# combine into nice table
vif_DONOHUE <- vif_DONOHUE |>
  as_tibble() |>
  cbind(names(vif_DONOHUE)) |>
  as_tibble()
colnames(vif_DONOHUE) <- c("VIF", "Variable")

vif_DONOHUE |>
  arrange(desc(VIF))
```
:::

## Calculating VIF (Lott)

::: panel-tabset

### Code 
```{r}
lm_LOTT_data <- as.data.frame(model.matrix(LOTT_OUTPUT))
lm_LOTT_data <- lm_LOTT_data |>
  mutate(Viol_crime_rate_1k_log = plm::Within(pull(d_panel_LOTT, Viol_crime_rate_1k_log), effect = "twoways")) |>
  rename(RTC_LAW = RTC_LAWTRUE)
lm_LOTT <- lm(LOTT_fmla, data = lm_LOTT_data)

vif_LOTT <- vif(lm_LOTT)
vif_LOTT <- vif_LOTT |>
  as_tibble() |>
  cbind(names(vif_LOTT)) |>
  as_tibble()
colnames(vif_LOTT) <- c("VIF", "Variable")
```

### Table

```{r}
# clean up names
vif_LOTT |> 
  mutate(Variable = str_replace(string = Variable,
                                pattern = "RTC_LAW",
                                replacement = "RTC_LAWTRUE")) |>
  arrange(desc(VIF))
```
:::


## VIF Across Analyses {.smaller}

::: panel-tabset

### Code
```{r}
vif_DONOHUE <- vif_DONOHUE |>
  mutate(Analysis = "Donohue")
vif_LOTT <- vif_LOTT |>
  mutate(Analysis = "Lott")
vif_df <- bind_rows(vif_DONOHUE, vif_LOTT)
```

### Table
```{r, echo=FALSE}
datatable(vif_df)
```

:::


## VIF Plot

::: panel-tabset

### Code
```{r, vif, fig.show="hide"}
vif_df |>
  ggplot(aes(x = Analysis, y = VIF)) +
  geom_jitter(width = 0.1, alpha = 0.5, size = 2) +
  geom_hline(yintercept = 10, color = "red") +
  geom_text(aes(.75, 13, label = "typical cutoff of 10")) +
  coord_trans(y = "log10") +
  labs(title = "Variance inflation factors") +
  theme_minimal() +
  theme(axis.title.x = element_blank(),
        axis.text.x = element_text(color = "black"),
        axis.text.y = element_text(color = "black"))
```

### Plot

```{r ref.label="vif", echo = FALSE, out.width="100%"}
```
:::

## What to do?

- different model?
- different predictors in this model? 
- different parameterization of predictors?
- [article](https://link.springer.com/content/pdf/10.1007/s11135-006-9018-6.pdf) for a detailed discussion about what to consider when your model has variables with high VIF values


## Where to Go From Here

- complete the lab!
- start to work with your group through this analysis
- consider what model you'll want to use to answer the questions
- think about/consider extension for CS01

## Suggested Reading

- [Case Study from OCS](https://www.opencasestudies.org/ocs-bp-RTC-analysis/)
- [Wrangling for this case study](https://www.opencasestudies.org/ocs-bp-RTC-wrangling)

