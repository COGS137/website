---
title: "CS02: Right-To-Carry (Analysis)"
author: "Prof Ellis"
date: "2021-11-12"
output:
  xaringan::moon_reader:
    css: "slides.css"
    logo: img/cogs137-logo-hex.png
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r child = "setup.Rmd"}
```

```{r packages, echo=FALSE, message=FALSE, warning=FALSE}
# For nonsese...
library(emo)
library(DT)

knitr::opts_chunk$set(warning=FALSE, message=FALSE) 
```


## Course Announcements

- **lab07**: due tonight but accepted until Sunday night for full credit
- **hw04** due this Monday 11/15 (individually; wrangling of subset of data)
- **cs02** due next Monday 11/22 (as a group; full case study)
- heads up: No class Wed of Week 9 (day before Thanksgiving 11/24)

---

## Question

.question[What is the effect of multicollinearity on coefficient estimates from linear regression models when analyzing right to carry laws and violence rates?]

---

## Panel Data

- repeated measures for multiple panel members or individuals over time.
  - multiple units  (violent crime and other variables for each state)
  - multiple time points (multiple years)
--
Lingo:
- $N$ individual panel members
- $T$ time points

--

- **Balanced Panels**: At each time point ( $T$ ), there are data points for each individual( $N$ ). ( $n = N∗T$ )
- **Unbalanced Panels**: May be data points missing for some individuals ( $N$ ) at some time points ( $T$ ) ( $n$ observations $N∗T$)

---

## Our Panel Data

In our case we have:
$N$ = 44 states (in the data wrangling process we removed those who had adopted an RTC law before 1980)
$T$ = 31 years (1980 - 2010)

Panel is balanced: $n=44∗31$, thus $n = 1364$

---

## Panel Linear Regression

$$Y_{it}=β_{0}+β_{1}X_{1it}+...+β_{K}X_{Kit}+e_{it}$$

- $i$ is the individual dimension (in our case individual states) 
- $t$ is the time dimension.

--

Notes:
- Some explanatory variables $X_{it}$ will vary across individuals and time
- others will be fixed across the time of the study (or don't change over time)
- others still will be fixed across individuals but vary across time periods


---

## Fixed Effects Panel Regression Analysis
.small[
- assumes that there are unknown or unobserved unique aspects about the individuals or heterogeneity among individuals (states) $a_i$ that are not explained by the independent variables but influence the outcome variable of interest (crime).
- they do not vary with time or in other words are fixed over time but may be **correlated** with independent variables $X_{it}$
]

--

.small[
- The intercept can be different for each individual $\beta_{0i}$ (each state)
- Other coefficients are assumed to be the same across all the individuals.
]
--
.small[
In our data...some of the unobserved qualities about the different states *may* be correlated with some of our independent variables (i.e.level of economic opportunity might be an unobserved feature about the states that influences violent crime rate (outcome) and would be possibly correlated with poverty rate and unemployment (predictors))
]
---

## Fixed Effects Panel Regression Analysis (Model)

These individual $a_i$ effects can be correlated with the independent variables $X$:

$$Y_{it}=\beta_{0}+\beta_{1}X_{1it}+...\beta_{K}X_{Kit}+ a_i +e_{it}$$
...or alternatively the individual effects can be absorbed into an *individual-specific intercept term* $\beta_{0i}$:

$$Y_{it}=\beta_{0i}+\beta_{1}X_{1it}+...\beta_{k}X_{kit} +e_{it}$$
---

## Panel Linear Model (`plm`)

- carry out panel linear models
- New object: `pdata.frame` (panel data frame); can indicate:  
  - which variable should be used to identify the individuals in our panel (`STATE`)
  - what variable should be used to identify the time periods in our panel (`YEAR`)
- Will be specified in `index` parameter: `index=c("Individual_Variable_NAME", "Time_Period_Variable_NAME")`

---

# Packages & Data

```{r packages-load}
library(tidyverse)
library(broom)
library(plm) # I'll ask ITS to install these for you tonight
library(car) #
library(rsample) #
library(GGally) #
library(ggcorrplot) #
```

--

This will only work if you finished the wrangling...

```{r}
load("data/wrangled/wrangled_data_rtc.rda")
```

---

## `pdata.frame`

```{r}
d_panel_DONOHUE <- pdata.frame(DONOHUE_DF, index = c("STATE", "YEAR"))
class(d_panel_DONOHUE)
slice_head(d_panel_DONOHUE, n = 3)
```

---

## Model Considerations: `effect`

There are three main options for the `effect` argument:
1. .ocean[individual]  - model for the effect of individual identity
2. .ocean[time] - model for the effect of time
3. .ocean[twoways] - meaning modeling for the effect of both individual identity and time  

--

- speculate that there is an effect of individual `STATE` identity and time on violent crime rate (`effect = "twoways"`)
  - aka expect some states to have high rates of crime, and others to have low rates of crime
  - expect crime rates to change over time

---

## Model Considerations: `model`

1. .ocean[pooling] - standard pooled ordinary least squares regression model  
2. .ocean[within] - fixed effects model (variation between individuals is ignored, model compares individuals to themselves at different periods of time)  
3. .ocean[between] - fixed effects model (variation within individuals from one time point to another is ignored, model compares different individuals at each point of time)  
4. .ocean[random] - random effects (each state has a different intercept but force it to follow a normal distribution - requires more assumptions)


--

- interested in how violence in each state varied over time: within `STATE`variation (`model = within`)

---

## Model: `plm` (DONOHUE)

```{r}
DONOHUE_OUTPUT <- plm(Viol_crime_rate_1k_log ~
                      RTC_LAW +
                      White_Male_15_to_19_years +
                      White_Male_20_to_39_years +
                      Black_Male_15_to_19_years +
                      Black_Male_20_to_39_years +
                      Other_Male_15_to_19_years +
                      Other_Male_20_to_39_years +
                      Unemployment_rate +
                      Poverty_rate +
                      Population_log +
                      police_per_100k_lag,
                      effect = "twoways",
                      model = "within",
                      data = d_panel_DONOHUE)
```

---

## Model Output: DONOHUE


```{r}
DONOHUE_OUTPUT_TIDY <- tidy(DONOHUE_OUTPUT, conf.int = 0.95)
DONOHUE_OUTPUT_TIDY
DONOHUE_OUTPUT_TIDY$Analysis <- "Analysis Donohue"
```


---

## Formula: `as.formula()` (LOTT)

```{r}
LOTT_variables <- LOTT_DF |>
  select(RTC_LAW,
         contains(c("White", "Black", "Other")),
         Unemployment_rate,
         Poverty_rate,
         Population_log,
         police_per_100k_lag) |>
  colnames()
LOTT_fmla <- as.formula(paste("Viol_crime_rate_1k_log ~", paste(LOTT_variables, collapse = " + ")
))
LOTT_fmla
```

---
## Model: `plm` (LOTT)

```{r}
d_panel_LOTT <- pdata.frame(LOTT_DF, index = c("STATE", "YEAR"))

LOTT_OUTPUT <- plm(LOTT_fmla,
                   model = "within",
                   effect = "twoways",
                   data = d_panel_LOTT
)
```

---

## Model Output: LOTT

```{r}
LOTT_OUTPUT_TIDY <- tidy(LOTT_OUTPUT, conf.int = 0.95)
LOTT_OUTPUT_TIDY
LOTT_OUTPUT_TIDY$Analysis <- "Analysis Lott"
```

---

## **RTC coefficient comparison**


```{r}
comparing_analyses <- DONOHUE_OUTPUT_TIDY |>
  bind_rows(LOTT_OUTPUT_TIDY) |>
  filter(term == "RTC_LAWTRUE")
comparing_analyses
```

---

## RTC

.panelset[
.panel[.panel-name[Code]
```{r, comparing, fig.show = "hide"}
ggplot(comparing_analyses) +
  geom_point(aes(x = Analysis, y = estimate)) +
  geom_errorbar(aes(x = Analysis, ymin = conf.low, ymax = conf.high), width = 0.25) +
  geom_hline(yintercept = 0, color = "red") +
  scale_y_continuous(
    breaks = seq(-0.2, 0.2, by = 0.05),
    labels = seq(-0.2, 0.2, by = 0.05),
    limits = c(-0.2, 0.2)
  ) +
  geom_segment(aes(x = 1, y = 0.125, xend = 1, yend = 0.175),
    arrow = arrow(angle = 45, ends = "last", type = "open"),
    size = 2, color = "green", lineend = "butt", linejoin = "mitre"
  ) +
  geom_segment(aes(x = 2, y = -0.125, xend = 2, yend = -0.175),
    arrow = arrow(angle = 45, ends = "last", type = "open"),
    size = 2, color = "red", lineend = "butt", linejoin = "mitre"
  ) +
  theme_minimal() +
  theme(
    axis.title.x = element_blank(),
    axis.text = element_text(size = 8, color = "black")
  ) +
  labs(
    title = "Effect estimate on ln(violent crimes per 100,000 people)",
    y = "  Effect estimate (95% CI)"
  )
```
]
.panel[.panel-name[Plot]

```{r ref.label="comparing", echo = FALSE, out.width="100%"}
```
]]

---

## Similar Data - different results

- The only difference between the two data frames rests in how the demographic variables were parameterized.
  - Donohue: Males only; ages 15 to 39
  - Lott: Males/Females; ages 10-65+

--

...so how did this occur?

---

## Multicollinearity 

- multicollinearity occurs when independent variables (predictors) are highly related to one another

--

- When *seemingly* independent variables are highly related to one another, the relationships estimated in an analysis may be distorted. 
- since linear regression aims to determine how a one unit change in a regressor influences a one unit change in the dependent variable, if the regressors are collinear...effect of each regressor cannot be accurately estimated
-
---

## Diagnosing Multicollinearity: Pairplots

.panelset[
.panel[.panel-name[Code-1]
```{r correlation, fig.show = "hide"}
DONOHUE_DF |>
  select(RTC_LAW,
         Viol_crime_rate_1k_log,
         Unemployment_rate,
         Poverty_rate,
         Population_log) |>
  ggpairs(columns = c(2:5),
          lower = list(continuous = wrap("smooth_loess",
                                         color = "red",
                                         alpha = 0.5,
                                         size = 0.1)))
```
]
.panel[.panel-name[Plot]

```{r ref.label="correlation", echo = FALSE, out.width="80%"}
```

--

-...not much correlation for non-demographic variables
- unemployment and poverty rate show some (as expeted)
]]


---

## Diagnosing Multicollinearity: Heatmaps

.panelset[
.panel[.panel-name[Code]
```{r heatmap, fig.show = "hide"}
cor_DONOHUE_dem <- cor(DONOHUE_DF |> select(contains("_years")))

ggcorrplot(cor_DONOHUE_dem,
  tl.cex = 6,
  hc.order = TRUE,
  colors = c(
    "red",
    "white",
    "red"
  ),
  outline.color = "transparent",
  title = "Correlation Matrix, Analysis Donohue",
  legend.title = expression(rho)
)
```
]
.panel[.panel-name[Plot]

```{r ref.label="heatmap", echo = FALSE, out.width="80%"}
```
]
.panel[.panel-name[Notes]
- *strong* correlation within race
- race shows much stronger correlation than age
- suggests collinearity
]]

---

## Heatmap: Lott

.panelset[
.panel[.panel-name[Code]
```{r heatmap-lott, fig.show = "hide"}
cor_LOTT_dem <- cor(LOTT_DF |> select(contains("_years")))

corr_mat_LOTT <- ggcorrplot(cor_LOTT_dem,
  tl.cex = 6,
  hc.order = TRUE,
  colors = c(
    "red",
    "white",
    "red"
  ),
  outline.color = "transparent",
  title = "Correlation Matrix, Analysis Lott",
  legend.title = expression(rho)
)

corr_mat_LOTT
```
]
.panel[.panel-name[Plot]

```{r ref.label="heatmap-lott", echo = FALSE, out.width="80%"}
```
]]

---

## Suggested multicollinearity

...so how do you find out for sure?
- look at the stability of the coefficient estimates under perturbations of the data
- we'll focus on `RTC_LAW`
- use resampling (here: remove one observation, see if estimates change == *LOOCV* - leave one out cross-validation): `rsample::loo_cv`

---

## LOOCV: splits (Donohue)

```{r, cache=TRUE}
## split data
set.seed(124)
DONOHUE_splits <- d_panel_DONOHUE |> loo_cv()
DONOHUE_splits
```

---

## LOOCV: get data (Donohue)

```{r, cache=TRUE}
DONOHUE_subsets <- map(pull(DONOHUE_splits, splits), training)
glimpse(DONOHUE_subsets[[1]])
```

---

### Function: bootstrapping (Donohue)

```{r}
fit_nls_on_bootstrap_DONOHUE <- function(subset) {
  plm(Viol_crime_rate_1k_log ~ RTC_LAW +
        White_Male_15_to_19_years +
        White_Male_20_to_39_years +
        Black_Male_15_to_19_years +
        Black_Male_20_to_39_years +
        Other_Male_15_to_19_years +
        Other_Male_20_to_39_years +
        Unemployment_rate +
        Poverty_rate +
        Population_log +
        police_per_100k_lag,
      data = data.frame(subset),
      index = c("STATE", "YEAR"),
      model = "within",
      effect = "twoways")
}
```

---

### Use the Function (Donohue)

```{r, cache=TRUE}
subsets_models_DONOHUE <- map(DONOHUE_subsets, fit_nls_on_bootstrap_DONOHUE)

subsets_models_DONOHUE <- subsets_models_DONOHUE |>
  map(tidy)
```

Note: This code takes a while to run. Suggestion to cache this code chunk!
---

### Save bootstrap output (Donohue)

```{r, cache=TRUE}
save(subsets_models_DONOHUE,
  file = "data/wrangled/DONOHUE_simulations.rda")
```

---

## LOOCV: splits (Lott)

```{r, cache=TRUE}
set.seed(124)
LOTT_splits <- d_panel_LOTT |> loo_cv()
LOTT_subsets <- map(pull(LOTT_splits, splits), training)
```

---

### Function: bootstrapping (Lott)

```{r}
fit_nls_on_bootstrap_LOTT <- function(split) {
  plm(LOTT_fmla,
      data = data.frame(split),
      index = c("STATE", "YEAR"),
      model = "within",
      effect = "twoways"
  )
}
```

---

### Use the Function (Lott)

```{r, cache=TRUE}
subsets_models_LOTT <- map(LOTT_subsets, fit_nls_on_bootstrap_LOTT)
subsets_models_LOTT <- subsets_models_LOTT |>
  map(tidy)
```

Note: This code takes a while to run. Suggestion to cache this code chunk!

---

### Save bootstrap output (Lott)

```{r}
save(subsets_models_LOTT,
  file = "data/wrangled/LOTT_simulations.rda")
```

---

## Visualize the results

```{r}
names(subsets_models_DONOHUE) <- paste0("DONOHUE_", seq_len(length(subsets_models_DONOHUE)))

names(subsets_models_LOTT) <-
  paste0("LOTT_", 1:length(subsets_models_LOTT))
```

---

## Combine simulation data

.panelset[
.panel[.panel-name[Code]
```{r}
simulations_DONOHUE <- subsets_models_DONOHUE |>
  bind_rows(.id = "ID") |>
  mutate(Analysis = "Analysis Donohue")

simulations_LOTT <- subsets_models_LOTT |>
  bind_rows(.id = "ID") |>
  mutate(Analysis = "Analysis Lott")

simulations <- bind_rows(simulations_DONOHUE, simulations_LOTT)

# order for easier comparison
simulations <- simulations |>
  mutate(term = factor(term,
    levels = c(
      str_subset(unique(pull(simulations, term)), "years", negate = TRUE),
      sort(str_subset(unique(pull(simulations, term)), "years")))))
```
]
.panel[.panel-name[Data]
```{r}
head(simulations)
```
]]

---

## Simulation: Plot (coefficients)
.panelset[
.panel[.panel-name[Code]
```{r, simulation, fig.show="hide"}
simulations |>
  ggplot(aes(x = term, y = estimate)) +
  geom_boxplot() +
  facet_grid(. ~ Analysis, scale = "free_x", space = "free", drop = TRUE) +
  labs(title = "Coefficient estimates",
       subtitle = "Estimates across leave-one-out analyses",
       x = "Term",
       y = "Coefficient",
       caption = "Results from simulations") +
  theme_linedraw() +
  theme(axis.title.x = element_blank(),
        axis.text.x = element_text(angle = 70, hjust = 1),
        strip.text.x = element_text(size = 14, face = "bold"),
        plot.title.position="plot")
```
]
.panel[.panel-name[Plot]

```{r ref.label="simulation", echo = FALSE, out.width="100%"}
```
]]
---

## Simulation: Plot (sd)

.panelset[
.panel[.panel-name[Code]

```{r, sd, fig.show="hide"}
coeff_sd <- simulations |>
  group_by(Analysis, term) |>
  summarize("SD" = sd(estimate))

coeff_sd |>
  ggplot(aes(x = Analysis, y = SD)) +
  geom_jitter(width = 0.1, alpha = 0.5, size = 2) +
  labs(title = "Coefficient variability",
       subtitle = "SDs of coefficient estimates from leave-one-out analysis",
       x = "Term",
       y = "Coefficient Estimate \n Standard Deviations",
       caption = "Results from simulations") +
  theme_minimal() +
  theme(axis.title.x = element_blank(),
        axis.text.x = element_text(size = 8, color = "black"),
        axis.text.y = element_text(color = "black"),
        plot.title.position="plot")
```
]
.panel[.panel-name[Plot]

```{r ref.label="sd", echo = FALSE, out.width="100%"}
```
]]
---

## VIF: Evaluating presence and severity of multicollinearity

Variance Inflation Factor (**VIF**): index that measures how much the variance (the square of the estimate’s standard deviation) of an estimated regression coefficient is increased because of collinearity.

---

### Calculating VIF:
.small[
If our model is : $Y = β_0 + β_1X_1 + β_2X_2 + β_3X_3 + e $, then:

To calculate the VIF value for $X_1$, perform another OLS model, where $X_1$ is now the dependent variable explained by the other explanatory variables:

$$X_1 = β_0 +  β_2X_2 + β_3X_3 + e$$ 
]
--
.small[
From this model : $$VIF = \frac{1}{1-R^{2}}$$ 

...where $R^2$ value is the proportion of variance in $X_1$ explained by the other variables ($X_2$ and $X_3$)
]
--
.small[
Repeat for each explanatory variable in the model.
]
--
.small[
- the larger the VIF,  the more multicollinearity
- VIF of >=10 typically indicates problematic multicollinearity
]
---

## Calculating VIF (Donohue)

.panelset[
.panel[.panel-name[Code-1]
```{r}
# create model matrix
lm_DONOHUE_data <- as.data.frame(model.matrix(DONOHUE_OUTPUT))

# define model
lm_DONOHUE_data <- lm_DONOHUE_data |> 
  mutate(Viol_crime_rate_1k_log = plm::Within(pull(
    d_panel_DONOHUE, Viol_crime_rate_1k_log
  )), effect = "twoways")
```
]
.panel[.panel-name[2]
```{r}
# specify model
lm_DONOHUE <- lm(Viol_crime_rate_1k_log ~
RTC_LAWTRUE +
  White_Male_15_to_19_years +
  White_Male_20_to_39_years +
  Black_Male_15_to_19_years +
  Black_Male_20_to_39_years +
  Other_Male_15_to_19_years +
  Other_Male_20_to_39_years +
  Unemployment_rate +
  Poverty_rate +
  Population_log +
  police_per_100k_lag,
data = lm_DONOHUE_data
)

# calculate VIF
vif_DONOHUE <- vif(lm_DONOHUE)
```
]
.panel[.panel-name[3]
```{r}
# combine into nice table
vif_DONOHUE <- vif_DONOHUE |>
  as_tibble() |>
  cbind(names(vif_DONOHUE)) |>
  as_tibble()
colnames(vif_DONOHUE) <- c("VIF", "Variable")
vif_DONOHUE
```
]]
---

## Calculating VIF (Lott)

.panelset[
.panel[.panel-name[Code-1]
```{r}
lm_LOTT_data <- as.data.frame(model.matrix(LOTT_OUTPUT))
lm_LOTT_data <- lm_LOTT_data |>
  mutate(Viol_crime_rate_1k_log = plm::Within(pull(d_panel_LOTT, Viol_crime_rate_1k_log), effect = "twoways")) |>
  rename(RTC_LAW = RTC_LAWTRUE)
lm_LOTT <- lm(LOTT_fmla, data = lm_LOTT_data)
```
]
.panel[.panel-name[2]
```{r}
vif_LOTT <- vif(lm_LOTT)
vif_LOTT
vif_LOTT <- vif_LOTT |>
  as_tibble() |>
  cbind(names(vif_LOTT)) |>
  as_tibble()
colnames(vif_LOTT) <- c("VIF", "Variable")
```
]
.panel[.panel-name[3]
```{r}
# clean up names
vif_LOTT |> 
  mutate(Variable = str_replace(string = Variable,
                                pattern = "RTC_LAW",
                                replacement = "RTC_LAWTRUE"))
vif_LOTT
```
]]
---

**VIF Across Analyses**
.panelset[
.panel[.panel-name[Code]
```{r}
vif_DONOHUE <- vif_DONOHUE |>
  mutate(Analysis = "Analysis Donohue")
vif_LOTT <- vif_LOTT |>
  mutate(Analysis = "Analysis Lott")
vif_df <- bind_rows(vif_DONOHUE, vif_LOTT)
```
]
.panel[.panel-name[Table]
.small[
```{r, echo=FALSE}
datatable(vif_df)
```
]]]

---

### VIF Plot

.panelset[
.panel[.panel-name[Code]
```{r, vif, fig.show="hide"}
vif_df |>
  ggplot(aes(x = Analysis, y = VIF)) +
  geom_jitter(width = 0.1, alpha = 0.5, size = 2) +
  geom_hline(yintercept = 10, color = "red") +
  geom_text(aes(.75, 13, label = "typical cutoff of 10")) +
  coord_trans(y = "log10") +
  labs(title = "Variance inflation factors") +
  theme_minimal() +
  theme(axis.title.x = element_blank(),
        axis.text.x = element_text(color = "black"),
        axis.text.y = element_text(color = "black"))
```
]
.panel[.panel-name[Plot]

```{r ref.label="vif", echo = FALSE, out.width="100%"}
```
]]

---

### What to do?

- different model?
- different predictors in this model? 
- [article](https://link.springer.com/content/pdf/10.1007/s11135-006-9018-6.pdf) for a detailed discussion about what to consider when your model has variables with high VIF values


