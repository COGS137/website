<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Hypothesis testing</title>
    <meta charset="utf-8" />
    <meta name="author" content="Prof Ellis" />
    <meta name="date" content="2021-11-05" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/font-awesome/css/all.css" rel="stylesheet" />
    <link href="libs/font-awesome/css/v4-shims.css" rel="stylesheet" />
    <link rel="stylesheet" href="slides.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Hypothesis testing
### Prof Ellis
### 2021-11-05

---







## Announcements

- Tue OH moved to Tue 4-5:30pm
- Peer evals due Wed at 7pm -- must fill it out to receive your score
-

---

class: center, middle

# Hypothesis testing via simulation (for a single proportion)

---

## Packages


```r
library(tidyverse)
library(infer)
```


---

## Organ donors

People providing an organ for donation sometimes seek the help of a special "medical 
consultant". These consultants assist the patient in all aspects of the surgery, with 
the goal of reducing the possibility of complications during the medical procedure 
and recovery. Patients might choose a consultant based in part on the historical 
complication rate of the consultant's clients. 

One consultant tried to attract patients by noting that the average complication rate 
for liver donor surgeries in the US is about 10%, but her clients have only had 3 
complications in the 62 liver donor surgeries she has facilitated. She claims this is 
strong evidence that her work meaningfully contributes to reducing complications (and 
therefore she should be hired!).

---

## Data


```r
organ_donor &lt;- read_csv("data/organ-donor.csv")
organ_donor %&gt;%
  count(outcome)
```

```
## # A tibble: 2 x 2
##   outcome             n
##   &lt;chr&gt;           &lt;int&gt;
## 1 complication        3
## 2 no complication    59
```

---

## Parameter vs. statistic

A **parameter** for a hypothesis test is the "true" value of interest. We typically 
estimate the parameter using a **sample statistic** as a **point estimate**.

`\(p~\)`: true rate of complication

`\(\hat{p}~\)`: rate of complication in the sample = `\(\frac{3}{62}\)` = 
0.048

---

## Correlation vs. causation

.question[
ðŸ‘¤ Is it possible to assess the consultant's claim using the data?
]

--

No. The claim is that there is a causal connection, but the data are observational.
For example, maybe patients who can afford a medical consultant can afford better
medical care, which can also lead to a lower complication rate.

While it is not possible to assess the causal claim, it is still possible to test 
for an association using these data. For this question we ask, could the low 
complication rate of `\(\hat{p}\)` = 0.048 be due to chance?

---

## Two claims

- **Null hypothesis:** "There is nothing going on"

Complication rate for this consultant is no different than the US average of 10%

--

- **Alternative hypothesis:** "There is something going on"

Complication rate for this consultant is **lower** than the US average of 10%

---

## Hypothesis testing as a court trial

- **Null hypothesis**, `\(H_0\)`: Defendant is innocent

- **Alternative hypothesis**, `\(H_A\)`: Defendant is guilty

--

- **Present the evidence:** Collect data

--

- **Judge the evidence:** "Could these data plausibly have happened by chance if the null hypothesis were true?"
    * Yes: Fail to reject `\(H_0\)`
    * No: Reject `\(H_0\)`
    
---

## Hypothesis testing framework

- Start with a null hypothesis, `\(H_0\)`, that represents the status quo

- Set an alternative hypothesis, `\(H_A\)`, that represents the research question, 
i.e. what weâ€™re testing for

- Conduct a hypothesis test under the assumption that the null hypothesis is true and 
calculate a **p-value** (probability of observed or more extreme outcome given that the 
null hypothesis is true)
    - if the test results suggest that the data do not provide convincing evidence for 
    the alternative hypothesis, stick with the null hypothesis
    - if they do, then reject the null hypothesis in favor of the alternative

---

## Setting the hypotheses

.question[
ðŸ‘¥ Which of the following is the correct set of hypotheses?
]

(a) `\(H_0: p = 0.10\)`; `\(H_A: p \ne 0.10\)` &lt;br&gt;

(b) `\(H_0: p = 0.10\)`; `\(H_A: p &gt; 0.10\)` &lt;br&gt;

(c) `\(H_0: p = 0.10\)`; `\(H_A: p &lt; 0.10\)` &lt;br&gt;

(d) `\(H_0: \hat{p} = 0.10\)`; `\(H_A: \hat{p} \ne 0.10\)` &lt;br&gt;

(e) `\(H_0: \hat{p} = 0.10\)`; `\(H_A: \hat{p} &gt; 0.10\)` &lt;br&gt;

(f) `\(H_0: \hat{p} = 0.10\)`; `\(H_A: \hat{p} &lt; 0.10\)` &lt;br&gt;

---

## Simulating the null distribution

Since `\(H_0: p = 0.10\)`, we need to simulate a null distribution where the 
probability of success (complication) for each trial (patient) is 0.10.

.question[
ðŸ‘¥ Describe how you would simulate the null distribution for this study using a bag of 
chips. How many chips? What colors? What do the colors indicate? How many draws? 
&lt;b&gt;With replacement&lt;/b&gt; or &lt;b&gt;without replacement&lt;/b&gt;?
]

---

## What do we expect?

.question[
ðŸ‘¤ When sampling from the null distribution, what is the expected proportion of success 
(complications)?
]

---

## Simulation #1


```
## sim1
##    complication no complication 
##               3              59
```

```
## [1] 0.0483871
```

![](18-hyp-testing_files/figure-html/unnamed-chunk-3-1.png)&lt;!-- --&gt;

---

## Simulation #2


```
## sim2
##    complication no complication 
##               9              53
```

```
## [1] 0.1451613
```

![](18-hyp-testing_files/figure-html/unnamed-chunk-4-1.png)&lt;!-- --&gt;

---

## Simulation #3



```
## sim3
##    complication no complication 
##               8              54
```

```
## [1] 0.1290323
```

![](18-hyp-testing_files/figure-html/unnamed-chunk-5-1.png)&lt;!-- --&gt;

---

## This is getting boring...

We need a way to automate this process!

---

## Using `infer` to generate the null distribution

.small[

```r
null_dist &lt;- organ_donor %&gt;%
  specify(response = outcome, success = "complication") %&gt;%
  hypothesize(null = "point", p = c("complication" = 0.10, "no complication" = 0.90)) %&gt;% 
  generate(reps = 100, type = "simulate") %&gt;% 
  calculate(stat = "prop")
```
]


```
## # A tibble: 100 x 2
##    replicate  stat
##        &lt;dbl&gt; &lt;dbl&gt;
##  1         1 0.161
##  2         2 0.081
##  3         3 0.161
##  4         4 0.145
##  5         5 0.097
##  6         6 0.145
##  7         7 0.081
##  8         8 0.097
##  9         9 0.161
## 10        10 0.048
## # â€¦ with 90 more rows
```


---

## Visualizing the null distribution

.question[
ðŸ‘¤ What would you expect the center of the null distribution to be?
]

--


```r
ggplot(data = null_dist, mapping = aes(x = stat)) +
  geom_histogram(binwidth = 0.01) +
  labs(title = "Null distribution")
```

![](18-hyp-testing_files/figure-html/unnamed-chunk-8-1.png)&lt;!-- --&gt;


---

## Calculating the p-value, visually

.question[
ðŸ‘¥ What is the p-value, i.e. in what % of the 
simulations was the simulated sample proportion at least as extreme as the 
observed sample proportion?
]

![](18-hyp-testing_files/figure-html/unnamed-chunk-9-1.png)&lt;!-- --&gt;

---

## Calculating the p-value, directly


```r
null_dist %&gt;%
  filter(stat &lt;= (3/62)) %&gt;%
  summarise(p_value = n()/nrow(null_dist))
```

```
## # A tibble: 1 x 1
##   p_value
##     &lt;dbl&gt;
## 1    0.12
```


---

## Significance level

We often use 5% as the cutoff for whether the p-value is low enough that the data are 
unlikely to have come from the null model. This cutoff value is called the 
**significance level**, `\(\alpha\)`.

- If p-value &lt; `\(\alpha\)`, reject `\(H_0\)` in favor of `\(H_A\)`: The data provide convincing 
evidence for the alternative hypothesis.

- If p-value &gt; `\(\alpha\)`, fail to reject `\(H_0\)` in favor of `\(H_A\)`: The data do not provide 
convincing evidence for the alternative hypothesis.

---

## Conclusion

.question[
ðŸ‘¤ What is the conclusion of the hypothesis test?
]

--

Since the p-value is greater than the significance level, we fail to 
reject the null hypothesis. These data do not provide convincing evidence that this 
consultant incurs a lower complication rate than 10% (overall US complication rate).

---

## Let's get real

- 100 simulations is not sufficient

- We usually simulate around 15,000 times to get an accurate distribution

---

## Run the test

.small[

```r
null_dist &lt;- organ_donor %&gt;%
  specify(response = outcome, success = "complication") %&gt;%
  hypothesize(null = "point", p = c("complication" = 0.10, "no complication" = 0.90)) %&gt;% 
  generate(reps = 15000, type = "simulate") %&gt;% 
  calculate(stat = "prop", order = c("treatment", "control"))
```

```
## Warning: Statistic is not based on a difference or ratio; the `order` argument
## will be ignored. Check `?calculate` for details.
```
]

---

## Visualize and calculate

.small[

```r
ggplot(data = null_dist, mapping = aes(x = stat)) +
  geom_histogram(binwidth = 0.01) +
  geom_vline(xintercept = 3/62, color = "red")
```

![](18-hyp-testing_files/figure-html/unnamed-chunk-12-1.png)&lt;!-- --&gt;

```r
null_dist %&gt;%
  filter(stat &lt;= 3/62) %&gt;%
  summarise(p_value = n()/nrow(null_dist))
```

```
## # A tibble: 1 x 1
##   p_value
##     &lt;dbl&gt;
## 1   0.119
```
]

---

class: center, middle

# One vs. two sided hypothesis tests

---

## Types of alternative hypotheses

- One sided (one tailed) alternatives: The parameter is hypothesized to be less 
than or greater than the null value, &lt; or &gt;

--

- Two sided (two tailed) alternatives: The parameter is hypothesized to be not 
equal to the null value, `\(\ne\)`
    - Calculated as two times the tail area beyond the observed sample statistic
    - More objective, and hence more widely preferred
    
--

.question[
ðŸ‘¤ Average systolic blood pressure of people with 
Stage 1 Hypertension is 150 mm Hg. Suppose we want to use a hypothesis test to 
evaluate whether a new blood pressure medication has &lt;b&gt;an effect&lt;/b&gt; on the average 
blood pressure of heart patients. What are the hypotheses?
]

---

class: center, middle

# Testing for independence

---

## Is yawning contagious?

.question[
ðŸ‘¤ Do you think yawning is contagious?
]

.pull-left[
![empirical](img/09a/yawn1.png)
]
.pull-right[
![empirical](img/09a/yawn2.png)
]

---

## Is yawning contagious?

An experiment conducted by the MythBusters tested if a person can be subconsciously influenced into yawning if another person near them yawns.

https://www.youtube.com/watch?v=mrr_UjNLbhE

---

## Study description

In this study 50 people were randomly assigned to two groups: 34 to a group where a person near them yawned (treatment) and 16 to a control group where they didn't see someone yawn (control).


```r
mb_yawn &lt;- read_csv("data/mb-yawn.csv")
```


```r
mb_yawn %&gt;%
  count(group, outcome)
```

```
## # A tibble: 4 x 3
##   group     outcome      n
##   &lt;chr&gt;     &lt;chr&gt;    &lt;int&gt;
## 1 control   not yawn    12
## 2 control   yawn         4
## 3 treatment not yawn    24
## 4 treatment yawn        10
```

---

## Proportion of yawners

.small[

```r
mb_yawn %&gt;%
  count(group, outcome) %&gt;%
  group_by(group) %&gt;%
  mutate(p_hat = n / sum(n))
```

```
## # A tibble: 4 x 4
## # Groups:   group [2]
##   group     outcome      n p_hat
##   &lt;chr&gt;     &lt;chr&gt;    &lt;int&gt; &lt;dbl&gt;
## 1 control   not yawn    12 0.75 
## 2 control   yawn         4 0.25 
## 3 treatment not yawn    24 0.706
## 4 treatment yawn        10 0.294
```
]

- Proportion of yawners in the treatment group: `\(\frac{10}{34} = 0.2941\)`
- Proportion of yawners in the control group: `\(\frac{4}{16} = 0.25\)`
- Difference: `\(0.2941 - 0.25 = 0.0441\)`
- Our results match the ones calculated on the MythBusters episode.

---

## Independence?

.question[
ðŸ‘¤ Based on the proportions we calculated, 
do you think yawning is really contagious, i.e. are seeing someone yawn 
and yawning dependent?
]


```
## # A tibble: 4 x 4
## # Groups:   group [2]
##   group     outcome      n p_hat
##   &lt;chr&gt;     &lt;chr&gt;    &lt;int&gt; &lt;dbl&gt;
## 1 control   not yawn    12 0.75 
## 2 control   yawn         4 0.25 
## 3 treatment not yawn    24 0.706
## 4 treatment yawn        10 0.294
```

---

## Dependence, or another possible explanation?

- The observed differences might suggest that yawning is contagious, i.e. seeing someone yawn 
and yawning are dependent.

- But the differences are small enough that we might wonder if they might simple be **due to chance**.

- Perhaps if we were to repeat the experiment, we would see slightly different results.

- So we will do just that - well, somewhat - and see what happens.

- Instead of actually conducting the experiment many times, we will **simulate** our results.

---

## Two competing claims

- "There is nothing going on." 
Yawning and seeing someone yawn are **independent**, yawning is not contagious, observed difference in proportions is simply due to chance. `\(\rightarrow\)` Null hypothesis

- "There is something going on."
Yawning and seeing someone yawn are **dependent**, yawning is contagious, observed difference in proportions is not due to chance. `\(\rightarrow\)` Alternative hypothesis

---

## Simulation setup

1. A regular deck of cards is comprised of 52 cards: 4 aces, 4 of numbers 2-10, 4 jacks, 4 queens, and 4 kings.

2. Take out two aces from the deck of cards and set them aside.

3. The remaining 50 playing cards to represent each participant in the study:
    - 14 face cards (including the 2 aces) represent the people who yawn.
    - 36 non-face cards represent the people who don't yawn.

---

## Running the simulation

1. Shuffle the 50 cards at least 7 times&lt;sup&gt;1&lt;/sup&gt; to ensure that the cards counted out are from a random process.

2. Count out the top 16 cards and set them aside. These cards represent the people in the control group.

3. Out of the remaining 34 cards (treatment group) count the \red{number of face cards} (the number of people who yawned in the treatment group).

4. Calculate the difference in proportions of yawners (treatment - control), and plot it 
on the board.

5. Mark the difference you find on the dot plot on the board.

.footnote[
[1] http://www.dartmouth.edu/~chance/course/topics/winning_number.html
]

---

## Checking for independence

.question[
ðŸ‘¥ Do the simulation results suggest that yawning 
is contagious, i.e. does seeing someone yawn and yawning appear to be dependent?
]

.small[

```r
null_dist &lt;- mb_yawn %&gt;%
  specify(outcome ~ group, success = "yawn") %&gt;%
  hypothesize(null = "independence") %&gt;%
  generate(100, type = "permute") %&gt;%
  calculate(stat = "diff in props", order = c("treatment", "control"))
```
]

---

## Visualizing the null distribution

.question[
ðŸ‘¤ What would you expect the center of the 
null distribution to be?
]

--


```r
ggplot(data = null_dist, mapping = aes(x = stat)) +
  geom_histogram(binwidth = 0.05) +
  labs(title = "Null distribution")
```

![](18-hyp-testing_files/figure-html/unnamed-chunk-18-1.png)&lt;!-- --&gt;

---

## Calculating the p-value, visually

.question[
ðŸ‘¥ What is the p-value, i.e. in what % of the 
simulations was the simulated difference in sample proportion at least as extreme 
as the observed difference in sample proportions?
]

![](18-hyp-testing_files/figure-html/unnamed-chunk-19-1.png)&lt;!-- --&gt;

---

## Calculating the p-value, directly


```r
null_dist %&gt;%
  filter(stat &gt;= 0.0441) %&gt;%
  summarise(p_value = n()/nrow(null_dist))
```

```
## # A tibble: 1 x 1
##   p_value
##     &lt;dbl&gt;
## 1    0.49
```

---

## Conclusion

.question[
ðŸ‘¥ What is the conclusion of the hypothesis test?
]

&lt;br&gt;

--

.question[
ðŸ‘¤ Do you "buy" this conclusion?
]

## Recap: visualize and describe

.question[
When asked to visualize and describe distribution(s), how do you decide what visualizations to make?
]

--

- Make all possible visualizations for the relevant variables, e.g. 
    - for a single numerical variable, try a histogram as well as a box plot and a density plot.
    - for one numerical and one categorical variable, try density plots, violin plots, faceted histograms, and side-by-side box plots.

- This doesn't mean include **all** of these in your final write up. Try them out, see which one(s) help tell a story, and include that/those only in your write up. But you won't know without trying which one(s) to include.

---

## Recap: visualize and describe

.question[
When asked to visualize and describe distribution(s), how do you decide what to mention in your description?
]

--

- Shape, center, spread, and any unusual observations.

Simply stating features isn't sufficient, dig deeper to see why these features are apparent, e.g.

- if the distribution is bimodal, determine where the peaks are and try to figure out why these show up as two prominent peaks (are there two prominent groups in your data, what are they?)

- if there are outliers, and the observations are identifiable, identify the outliers and try to figure out why these observations stand out as outliers (the answer might be in the data, or might req)

---

## HW 3: Season and bike rentals

Prompt: Create a visualization displaying the relationship between bike rentals and season. Interpret the plot in context of the data.

---

## Option 1




```r
ggplot(data = bike, aes(x = cnt)) +
  geom_histogram(binwidth = 1000) +
  facet_grid(. ~ season)
```

![](18-hyp-testing_files/figure-html/bike-hist-facet-1.png)&lt;!-- --&gt;

---

## Option 2


```r
ggplot(data = bike, aes(x = cnt, color = season, fill = season)) +
  geom_density(alpha = 0.5)
```

![](18-hyp-testing_files/figure-html/bike-dens-1.png)&lt;!-- --&gt;

---

## Option 3

Daily bike rentals are highest on a typical summer day and lowest on a typical winter day. The variablity of daily bike rentals are somewhat consistent across seasons, but lowest in the summer. There is a high outlier in the winter, and low outlier in the fall.


```r
ggplot(data = bike, aes(x = season, y = cnt)) +
  geom_boxplot()
```

![](18-hyp-testing_files/figure-html/bike-box-1.png)&lt;!-- --&gt;

---

## Ok, but not satisfying

- The observations in this dataset are recognizable days.

- First, drill down and identify what they sre.

- Then, try to figure out why these observations stand out as outliers.

- It's possible you won't be able to, but you should try.

---

## High outlier in the winter


```r
bike %&gt;%
  filter(season == "winter") %&gt;%
  summarise(min = max(cnt), day_min = dteday[which.max(cnt)])
```

```
## # A tibble: 1 x 2
##     min day_min   
##   &lt;dbl&gt; &lt;date&gt;    
## 1  7836 2012-03-17
```

--

.question[
What happened on March 17, 2012 in Washington DC? If you don't know, google it!
]

---

![March 17, 2012](img/10a/dc-03-17-2012.png)
---

## Low outlier in the fall


```r
bike %&gt;%
  filter(season == "fall") %&gt;%
  summarise(min = min(cnt), day_min = dteday[which.min(cnt)])
```

```
## # A tibble: 1 x 2
##     min day_min   
##   &lt;dbl&gt; &lt;date&gt;    
## 1    22 2012-10-29
```

--

.question[
What happened on October 29, 2012 in Washington DC? If you don't know, google it!
]

---

![October 10, 2012](img/10a/dc-10-29-2012.png)

---

## Details matter

.question[
Which of the following is a more informative analysis?

(a) There is a high outlier in the winter, and low outlier in the fall.

(b) There is a low outlier in the winter, on St. Patrick's Day. And a low outlier in the fall, on the day Hurricane Sandy hit DC. 
]

---

## Interpreting regression coefficients

--

- For a model with a single predictor: "For each unit increase in `\(x\)`, `\(y\)` is expected to be higher/lower by `\(b_1\)`, on average."

--

- For a model with a multiple predictors: "**All else held constant**,for each unit increase in `\(x_1\)`, `\(y\)` is expected to be higher/lower by `\(b_1\)`, on average."

--

    - "All else" = all other variables **in** the model.

---

## 

.question[
Interpret the coefficient of holiday.
]


```
## # A tibble: 14 x 2
##    term                          estimate
##    &lt;chr&gt;                            &lt;dbl&gt;
##  1 (Intercept)                     2715. 
##  2 seasonsummer                    -277. 
##  3 seasonfall                       410. 
##  4 seasonwinter                   -1131. 
##  5 yr                              2014. 
##  6 holiday                        -1384. 
##  7 workingday                       120. 
##  8 weathersitmist                  -420. 
##  9 weathersitlight precipitation  -1907. 
## 10 temp_raw                         103. 
## 11 atemp_raw                         18.8
## 12 hum_raw                          -13.6
## 13 windspeed_raw                    -40.6
## 14 holiday:atemp_raw                 34.4
```

--

All else held constant, daily bike rentals are expected to be lower on holidays by 1384, on average, compared to non-holiday days.

---

## 

.question[
Discuss what makes for a good day to bike in DC.
]


```
## # A tibble: 14 x 2
##    term                          estimate
##    &lt;chr&gt;                            &lt;dbl&gt;
##  1 (Intercept)                     2715. 
##  2 seasonsummer                    -277. 
##  3 seasonfall                       410. 
##  4 seasonwinter                   -1131. 
##  5 yr                              2014. 
##  6 holiday                        -1384. 
##  7 workingday                       120. 
##  8 weathersitmist                  -420. 
##  9 weathersitlight precipitation  -1907. 
## 10 temp_raw                         103. 
## 11 atemp_raw                         18.8
## 12 hum_raw                          -13.6
## 13 windspeed_raw                    -40.6
## 14 holiday:atemp_raw                 34.4
```

--

With everything else being the same, Fall days are more popular for bike rentals than days in any other season. Alternatively, with everything else being constant, days with lower humidity are better for biking than days with higher humidity.

---

class: center, middle

# Simulation based inference review

---

## What do you want to do?

- Estimation -&gt; Confidence interval

- Decision -&gt; Hypothesis test

- First step: Ask the following questions

  1. How many variables?
  2. What type(s) of variable(s)?
  3. What is the research question?

---

## Data: NC births

The dataset is in the `openintro` package.


```r
glimpse(ncbirths)
```

```
## Rows: 1,000
## Columns: 13
## $ fage           &lt;int&gt; NA, NA, 19, 21, NA, NA, 18, 17, NA, 20, 30, NA, NA, NA,â€¦
## $ mage           &lt;int&gt; 13, 14, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16,â€¦
## $ mature         &lt;fct&gt; younger mom, younger mom, younger mom, younger mom, youâ€¦
## $ weeks          &lt;int&gt; 39, 42, 37, 41, 39, 38, 37, 35, 38, 37, 45, 42, 40, 38,â€¦
## $ premie         &lt;fct&gt; full term, full term, full term, full term, full term, â€¦
## $ visits         &lt;int&gt; 10, 15, 11, 6, 9, 19, 12, 5, 9, 13, 9, 8, 4, 12, 15, 7,â€¦
## $ marital        &lt;fct&gt; not married, not married, not married, not married, notâ€¦
## $ gained         &lt;int&gt; 38, 20, 38, 34, 27, 22, 76, 15, NA, 52, 28, 34, 12, 30,â€¦
## $ weight         &lt;dbl&gt; 7.63, 7.88, 6.63, 8.00, 6.38, 5.38, 8.44, 4.69, 8.81, 6â€¦
## $ lowbirthweight &lt;fct&gt; not low, not low, not low, not low, not low, low, not lâ€¦
## $ gender         &lt;fct&gt; male, male, female, male, female, male, male, male, malâ€¦
## $ habit          &lt;fct&gt; nonsmoker, nonsmoker, nonsmoker, nonsmoker, nonsmoker, â€¦
## $ whitemom       &lt;fct&gt; not white, not white, white, white, not white, not whitâ€¦
```

---

## Length of gestation

![](18-hyp-testing_files/figure-html/unnamed-chunk-25-1.png)&lt;!-- --&gt;


```
## # A tibble: 1 x 7
##     min  xbar   med     s    q1    q3   max
##   &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;
## 1    20  38.3    39  2.93    37    40    45
```


---

## Length of gestation

.question[
Assuming that this sample is representative of all births in NC, we are 95% confident that the average length of gestation for babies in NC is between ---- and ---- weeks.
]

--

**(1) How many variables?**

--

1 variable: length of gestation, `weeks`

--

**(2) What type(s) of variable(s)?**

--

Numerical

--

**(3) What is the research question?**

--

Estimate the average length of gestation `\(\rightarrow\)` confidence interval

---

## Simulation for CI for a mean

**Goal:** Use bootstrapping to estimate the sampling variability of the mean, i.e. the variability of means taken from the same population with the same sample size.

--

1. Take a bootstrap sample - a random sample taken with replacement from the 
original sample, of the same size as the original sample.

2. Calculate the mean of the bootstrap sample.

3. Repeat steps (1) and (2) many times to create a bootstrap distribution - 
a distribution of bootstrap means.

4. Calculate the bounds of the 95% confidence interval as the middle 95% 
of the bootstrap distribution.

---

## Set a seed first

From the documentation of `set.seed`:

- `set.seed` uses a single integer argument to set as many seeds as are required. There is no guarantee that different values of seed will seed the RNG differently, although any exceptions would be extremely rare.

- Initially, there is no seed; a new one is created from the current time and the process ID when one is required. Hence different sessions will give different simulation results, by default.


```r
set.seed(20180326)
```

---

## Computation for CI for a mean


```r
boot_means &lt;- ncbirths %&gt;%
  filter(!is.na(weeks)) %&gt;% # remove NAs
  specify(response = weeks) %&gt;%
  generate(reps = 1000, type = "bootstrap") %&gt;%
  calculate(stat = "mean")
ggplot(data = boot_means, aes(x = stat)) +
  geom_histogram(binwidth = 0.03)
```

![](18-hyp-testing_files/figure-html/unnamed-chunk-28-1.png)&lt;!-- --&gt;

---

## Length of gestation


```r
boot_means %&gt;%
  summarise(
    lower = quantile(stat, 0.025),
    upper = quantile(stat, 0.975)
  )
```

```
## # A tibble: 1 x 2
##   lower upper
##   &lt;dbl&gt; &lt;dbl&gt;
## 1  38.2  38.5
```

--

Assuming that this sample is representative of all births in NC, we are 95% confident that the average length of gestation for babies in NC is between 38.1 and 38.5 weeks.

---

## Length of gestation, revisited

.question[
The average length of human gestation is 280 days, or 40 weeks, from the first day of the woman's last menstrual period. Do these data provide convincing evidence that average length of gestation for women in NC is different than 40 weeks? Use a significance level of 5%.
]

--

`\(H_0: \mu = 40\)`  
`\(H_A: \mu \ne 40\)`

--

- We just said, "we are 95% confident that the average length of gestation for babies in NC is between 38.1 and 38.5 weeks".

- Since the null value is outside the CI, we would reject the null hypothesis in favor of the alternative.

- But an alternative, more direct, way of answering this question is using a hypothesis test.

---

## Simulation for HT for a mean

**Goal:** Use bootstrapping to generate a sampling distribution under the assumption of the null hypothesis being true. Then, calculate the p-value to make a decision on the hypotheses.

--

1. Take a bootstrap sample - a random sample taken with replacement from the 
original sample, of the same size as the original sample.

2. Calculate the mean of the bootstrap sample.

3. Repeat steps (1) and (2) many times to create a bootstrap distribution - 
a distribution of bootstrap means.

4. Shift the bootstrap distribution to be centered at the null value by subtracting/adding the difference between the center of the bootstrap distribution and the null value to each bootstrap mean.

5. Calculate the p-value as the proportion of simulations that yield a sample mean at least as extreme as the observed sample mean.

---

## Computation for HT for a mean


```r
boot_means_shifted &lt;- ncbirths %&gt;%
  filter(!is.na(weeks)) %&gt;% # remove NAs
  specify(response = weeks) %&gt;%
  hypothesize(null = "point", mu = 40) %&gt;% # hypothesize step
  generate(reps = 1000, type = "bootstrap") %&gt;%
  calculate(stat = "mean")
ggplot(data = boot_means_shifted, aes(x = stat)) +
  geom_histogram(binwidth = 0.03) +
  geom_vline(xintercept = 38.33, color = "red") +
  geom_vline(xintercept = 40 + (40 - 38.33), color = "red")
```

![](18-hyp-testing_files/figure-html/unnamed-chunk-30-1.png)&lt;!-- --&gt;

---

## Length of gestation


```r
boot_means_shifted %&gt;%
  filter(stat &lt;= 38.33) %&gt;%
  summarise(p_value = 2 * (n() / 1000))
```

```
## # A tibble: 1 x 1
##   p_value
##     &lt;dbl&gt;
## 1       0
```

--

Since p-value less than the significance level, we reject the null hypothesis. The data provide convincing evidence that the average length of gestation of births in NC is different than 40.

---

## Exercises

Go to RStudio Cloud, make a copy of **NC Births**, and answer the following questions.

1. Do these data provide convincing evidence of a difference in length in gestation between mature and younger moms? Use a significance level of 10%.

2. Estimate the difference in average lengths of gestation between mature and younger moms. Use a significance level equivalent to the hypothesis test above.

3. Do the results of the hypothesis test agree with the result of the confidence interval?

---

## `infer` structure


```r
df %&gt;%
  specify(response, explanatory) %&gt;% # explanatory optional
  generate(reps, type) %&gt;% # type: bootstrap, simulate, or permute
  calculate(stat)
```

- Always start with data frame
- Result is always a data frame with a variable called `stat`
   - See the documentation for `calculate` to see which `stat`istics can be calculated
- For hypothesis testing add a `hypothesize()` step between `specify()` and `generate()`
    - `null = "point"`, and then specify the null value
    - `null = "independence"`
    
    ---

# From last time - Testing for independence

---

## Study results


```r
mb_yawn &lt;- read_csv("data/mb-yawn.csv")
```

.small[

```r
mb_yawn %&gt;%
  count(group, outcome) %&gt;%
  group_by(group) %&gt;%
  mutate(p_hat = n / sum(n))
```

```
## # A tibble: 4 x 4
## # Groups:   group [2]
##   group     outcome      n p_hat
##   &lt;chr&gt;     &lt;chr&gt;    &lt;int&gt; &lt;dbl&gt;
## 1 control   not yawn    12 0.75 
## 2 control   yawn         4 0.25 
## 3 treatment not yawn    24 0.706
## 4 treatment yawn        10 0.294
```
]

Difference in proportions of yawners: 

`\(\hat{p}_{treatment} - \hat{p}_{control} = 0.2941 - 0.25 = 0.0441\)`

---

## Two competing claims

- "There is nothing going on." 
Yawning and seeing someone yawn are **independent**, yawning is not contagious, observed difference in proportions is simply due to chance. `\(\rightarrow\)` Null hypothesis

- "There is something going on."
Yawning and seeing someone yawn are **dependent**, yawning is contagious, observed difference in proportions is not due to chance. `\(\rightarrow\)` Alternative hypothesis

---

## Running the simulation

1. Shuffle the 50 cards at least 7 times&lt;sup&gt;1&lt;/sup&gt; to ensure that the cards counted out are from a random process.

2. Count out the top 16 cards and set them aside. These cards represent the people in the control group.

3. Out of the remaining 34 cards (treatment group) count the \red{number of face cards} (the number of people who yawned in the treatment group).

4. Calculate the difference in proportions of yawners (treatment - control), and plot it 
on the board.

5. Mark the difference you find on the dot plot on the board.

.footnote[
[1] http://www.dartmouth.edu/~chance/course/topics/winning_number.html
]

---

## Simulation by hand

.question[
ðŸ‘¥ Do the simulation results suggest that yawning 
is contagious, i.e. does seeing someone yawn and yawning appear to be dependent?
]

![yawn-sim-results](img/09b/yawn-sim-results.png)

---

## Simulation by computation


```r
null_dist &lt;- mb_yawn %&gt;%
  specify(response = outcome, explanatory = group, 
          success = "yawn") %&gt;%
  hypothesize(null = "independence") %&gt;%
  generate(100, type = "permute") %&gt;%
  calculate(stat = "diff in props", 
            order = c("treatment", "control"))
```

---

## Simulation by computation - 1

.small[
- Start with the data frame
- **Specify the variables**
    - **Since the response variable is categorical, specify the level which should be considered as "success"**


```r
mb_yawn %&gt;%
{{  specify(response = outcome, explanatory = group, 
          success = "yawn") }}
```
]

---

## Simulation by computation - 2

.small[
- Start with the data frame
- Specify the variables
    - Since the response variable is categorical, specify the level which should be considered as "success"
- **State the null hypothesis (yawning and whether or not you see someone yawn are independent)**


```r
mb_yawn %&gt;%
  specify(response = outcome, explanatory = group, 
          success = "yawn") %&gt;%
* hypothesize(null = "independence") 
```
]

---

## Simulation by computation - 3

.small[
- Start with the data frame
- Specify the variables
    - Since the response variable is categorical, specify the level which should be considered as "success"
- State the null hypothesis (yawning and whether or not you see someone yawn are independent)
- **Generate simulated differences via permutation**


```r
mb_yawn %&gt;%
  specify(response = outcome, explanatory = group, 
          success = "yawn") %&gt;%
  hypothesize(null = "independence") %&gt;%
* generate(100, type = "permute") 
```
]

---

## Simulation by computation - 4

.small[
- Start with the data frame
- Specify the variables
    - Since the response variable is categorical, specify the level which should be considered as "success"
- State the null hypothesis (yawning and whether or not you see someone yawn are independent)
- Generate simulated differences via permutation
- **Calculate the sample statistic of interest (difference in propotions)**
    - **Since the explanatory variable is categorical, specify the order in which the subtraction should occur for the calculation of the sample statistic, `\((\hat{p}_{treatment} - \hat{p}_{control})\)`.**
    

```r
mb_yawn %&gt;%
  specify(response = outcome, explanatory = group, 
          success = "yawn") %&gt;%
  hypothesize(null = "independence") %&gt;%
  generate(100, type = "permute") %&gt;%
{{ calculate(stat = "diff in props", 
           order = c("treatment", "control")) }}
```
]

---

## Simulation by computation - 0

.small[
- **Save the result**
- Start with the data frame
- Specify the variables
    - Since the response variable is categorical, specify the level which should be considered as "success"
- State the null hypothesis (yawning and whether or not you see someone yawn are independent)
- Generate simulated differences via permutation
- Calculate the sample statistic of interest (difference in propotions)
    - Since the explanatory variable is categorical, specify the order in which the subtraction should occur for the calculation of the sample statistic, `\((\hat{p}_{treatment} - \hat{p}_{control})\)`.
    

```r
*null_dist &lt;- mb_yawn %&gt;% 
  specify(response = outcome, explanatory = group, 
          success = "yawn") %&gt;%
  hypothesize(null = "independence") %&gt;%
  generate(100, type = "permute") %&gt;%
  calculate(stat = "diff in props", 
            order = c("treatment", "control"))
```
]

---

## Visualizing the null distribution

.question[
ðŸ‘¤ What would you expect the center of the 
null distribution to be?
]

--


```r
ggplot(data = null_dist, mapping = aes(x = stat)) +
  geom_histogram(binwidth = 0.05) +
  labs(title = "Null distribution")
```

![](18-hyp-testing_files/figure-html/unnamed-chunk-41-1.png)&lt;!-- --&gt;

---

## Calculating the p-value, visually

.question[
ðŸ‘¥ What is the p-value, i.e. in what % of the 
simulations was the simulated difference in sample proportion at least as extreme 
as the observed difference in sample proportions?
]

![](18-hyp-testing_files/figure-html/unnamed-chunk-42-1.png)&lt;!-- --&gt;

---

## Calculating the p-value, directly


```r
null_dist %&gt;%
  filter(stat &gt;= 0.0441) %&gt;%
  summarise(p_value = n()/nrow(null_dist))
```

```
## # A tibble: 1 x 1
##   p_value
##     &lt;dbl&gt;
## 1     0.5
```

---

## Conclusion

.question[
ðŸ‘¥ What is the conclusion of the hypothesis test?
]

&lt;br&gt;

--

.question[
ðŸ‘¤ Do you "buy" this conclusion?
]

---

class: center, middle

# Inference overview

---

## What do you want to do?

- Estimation -&gt; Confidence interval

- Decision -&gt; Hypothesis test

- First step: Ask the following questions

  1. How many variables?
  2. What types of variables?
  3. What is the research question?

---

class: center, middle

# Confidence intervals

---

## Confidence intervals

- Bootstrap

- Bounds: cutoff values for the middle XX% of the distribution

- Interpretation: We are XX% confident that the true population parameter is in the interval.

- Definition of confidence level: XX% of random samples of size n are expected to produce confidence intervals that contain the true population parameter.

- `infer::generate(reps, type = "bootstrap")`

---

## Confidence intervals exercises

.small[
.question[
ðŸ‘¥ Describe the simulation process for estimating the parameter assigned to your team.

- Note any assumptions you make in terms of sample size, observed sample statistic, etc.
- Imagine using index cards or chips to represent the data. 
- Specify whether the simulation type would be bootstrap, simulate, or permute.

&gt; **Panda Express, BME, get MECT, Duke Squirrels, Team Power:** single population median

&gt; **ACE, Kimchi Stew, Databaes, HJC, 23, 24/7, five squared:** single population proportion

&gt; **Team Untitled, R we done yet?, Blue Wombats, Cosmic:** difference between two population means

&gt; **InterstellR, Tequila Mockingbird, Sweeter than SugR:** difference between two population proportions

&gt; **The Data Wranglers, Git R Done, Migos, Six Squared:** single population standard deviation
]]

---

## Accuracy vs. precision

.question[
ðŸ‘¥ What happens to the width of the confidence interval as the confidence level increases? Why? Should we always prefer a confidence interval with a higher confidence level?
]

---

## Sample size and width of intervals

![](18-hyp-testing_files/figure-html/unnamed-chunk-44-1.png)&lt;!-- --&gt;


---

## Equivalency of confidence and significance levels

- Two sided alternative HT with `\(\alpha\)` `\(\rightarrow\)` `\(CL = 1 - \alpha\)`
- One sided alternative HT with `\(\alpha\)` `\(\rightarrow\)` `\(CL = 1 - (2 \times \alpha)\)`

![](18-hyp-testing_files/figure-html/unnamed-chunk-45-1.png)&lt;!-- --&gt;

---

## Interpretation of confidence intervals

.question[
ðŸ‘¤ Which of the following is more informative: 

&lt;ul&gt;
&lt;li&gt; The difference in price of a gallon of milk between Whole Foods and Harris Teeter is 30 cents.
&lt;li&gt; A gallon of milk costs 30 cents more at Whole Foods compared to Harris Teeter.
&lt;/ul&gt;
&lt;/div&gt;
]

--

.question[
ðŸ‘¤ What does your answer tell you about interpretation of confidence intervals for differences between two population parameters?
]

---

class: center, middle

# Hypothesis tests

---

## Hypothesis testing

- Set the hypotheses.

- Calculate the observed sample statistic.

- Calculate the p-value.

- Make a conclusion, about the hypotheses, in context of the data and the research question.

- `infer::hypothesize(null = "point")` and `infer::generate(reps, type = "simulate")` or `infer::generate(reps, type = "bootstrap")`

- `infer::hypothesize(null = "independence")` and `infer::generate(reps, type = "permute")`
  
---

## Hypothesis testing exercises

.small[
.question[
ðŸ‘¥
Describe the simulation process for tesing for the parameter assigned to your team.

- Note any assumptions you make in terms of sample size, observed sample statistic, etc.
- Imagine using index cards or chips to represent the data. 
- Specify whether the null hypothesis would be independence or point.
- Specify whether the simulation type would be bootstrap, simulate, or permute.

&gt; **Panda Express, BME, get MECT, Duke Squirrels, Team Power:** single standard deviation

&gt; **ACE, Kimchi Stew, Databaes, HJC, 23, 24/7, five squared:** single population mean

&gt; **Team Untitled, R we done yet?, Blue Wombats, Cosmic:** difference between two population proportions

&gt; **InterstellR, Tequila Mockingbird, Sweeter than SugR:** difference between two population medians

&gt; **The Data Wranglers, Git R Done, Migos, Six Squared:** single population median
]]

---

## Testing errors

- Type 1: Reject `\(H_0\)` when you shouldn't have
    + P(Type 1 error) = `\(\alpha\)`
    
- Type 2: Fail to reject `\(H_0\)` when you should have
    + P(Type 2 error) is harder to calculate, but increases as `\(\alpha\)` decreases

--

.question[
ðŸ‘¤ In a court of law

- Null hypothesis: Defendant is innocent
- Alternative hypothesis: Defendant is guilty

Which is worse: Type 1 or Type 2 error?
]

---

## Probabilities of testing errors

- P(Type 1 error) = `\(\alpha\)`

- P(Type 2 error) = 1 - Power

- Power = P(correctly rejecting the null hypothesis)

--

.question[
ðŸ‘¥ Fill in the blanks in terms of correctly/incorrectly rejecting/failing to reject the null hypothesis:

- `\(\alpha\)` is the probability of ______.
- 1 - Power is the probability of ______.
]
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
