[
  {
    "objectID": "LICENSE.html",
    "href": "LICENSE.html",
    "title": "Attribution-ShareAlike 4.0 International",
    "section": "",
    "text": "Creative Commons Corporation (“Creative Commons”) is not a law firm and does not provide legal services or legal advice. Distribution of Creative Commons public licenses does not create a lawyer-client or other relationship. Creative Commons makes its licenses and related information available on an “as-is” basis. Creative Commons gives no warranties regarding its licenses, any material licensed under their terms and conditions, or any related information. Creative Commons disclaims all liability for damages resulting from their use to the fullest extent possible."
  },
  {
    "objectID": "LICENSE.html#creative-commons-attribution-sharealike-4.0-international-public-license",
    "href": "LICENSE.html#creative-commons-attribution-sharealike-4.0-international-public-license",
    "title": "Attribution-ShareAlike 4.0 International",
    "section": "Creative Commons Attribution-ShareAlike 4.0 International Public License",
    "text": "Creative Commons Attribution-ShareAlike 4.0 International Public License\nBy exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution-ShareAlike 4.0 International Public License (“Public License”). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions.\n\nSection 1 – Definitions.\n\nAdapted Material means material subject to Copyright and Similar Rights that is derived from or based upon the Licensed Material and in which the Licensed Material is translated, altered, arranged, transformed, or otherwise modified in a manner requiring permission under the Copyright and Similar Rights held by the Licensor. For purposes of this Public License, where the Licensed Material is a musical work, performance, or sound recording, Adapted Material is always produced where the Licensed Material is synched in timed relation with a moving image.\nAdapter’s License means the license You apply to Your Copyright and Similar Rights in Your contributions to Adapted Material in accordance with the terms and conditions of this Public License.\nBY-SA Compatible License means a license listed at creativecommons.org/compatiblelicenses, approved by Creative Commons as essentially the equivalent of this Public License.\nCopyright and Similar Rights means copyright and/or similar rights closely related to copyright including, without limitation, performance, broadcast, sound recording, and Sui Generis Database Rights, without regard to how the rights are labeled or categorized. For purposes of this Public License, the rights specified in Section 2(b)(1)-(2) are not Copyright and Similar Rights.\nEffective Technological Measures means those measures that, in the absence of proper authority, may not be circumvented under laws fulfilling obligations under Article 11 of the WIPO Copyright Treaty adopted on December 20, 1996, and/or similar international agreements.\nExceptions and Limitations means fair use, fair dealing, and/or any other exception or limitation to Copyright and Similar Rights that applies to Your use of the Licensed Material.\nLicense Elements means the license attributes listed in the name of a Creative Commons Public License. The License Elements of this Public License are Attribution and ShareAlike.\nLicensed Material means the artistic or literary work, database, or other material to which the Licensor applied this Public License.\nLicensed Rights means the rights granted to You subject to the terms and conditions of this Public License, which are limited to all Copyright and Similar Rights that apply to Your use of the Licensed Material and that the Licensor has authority to license.\nLicensor means the individual(s) or entity(ies) granting rights under this Public License.\nShare means to provide material to the public by any means or process that requires permission under the Licensed Rights, such as reproduction, public display, public performance, distribution, dissemination, communication, or importation, and to make material available to the public including in ways that members of the public may access the material from a place and at a time individually chosen by them.\nSui Generis Database Rights means rights other than copyright resulting from Directive 96/9/EC of the European Parliament and of the Council of 11 March 1996 on the legal protection of databases, as amended and/or succeeded, as well as other essentially equivalent rights anywhere in the world.\nYou means the individual or entity exercising the Licensed Rights under this Public License. Your has a corresponding meaning.\n\n\n\nSection 2 – Scope.\n\nLicense grant.\n\nSubject to the terms and conditions of this Public License, the Licensor hereby grants You a worldwide, royalty-free, non-sublicensable, non-exclusive, irrevocable license to exercise the Licensed Rights in the Licensed Material to:\n\nreproduce and Share the Licensed Material, in whole or in part; and\nproduce, reproduce, and Share Adapted Material.\n\nExceptions and Limitations. For the avoidance of doubt, where Exceptions and Limitations apply to Your use, this Public License does not apply, and You do not need to comply with its terms and conditions.\nTerm. The term of this Public License is specified in Section 6(a).\nMedia and formats; technical modifications allowed. The Licensor authorizes You to exercise the Licensed Rights in all media and formats whether now known or hereafter created, and to make technical modifications necessary to do so. The Licensor waives and/or agrees not to assert any right or authority to forbid You from making technical modifications necessary to exercise the Licensed Rights, including technical modifications necessary to circumvent Effective Technological Measures. For purposes of this Public License, simply making modifications authorized by this Section 2(a)(4) never produces Adapted Material.\nDownstream recipients.\nA. Offer from the Licensor – Licensed Material. Every recipient of the Licensed Material automatically receives an offer from the Licensor to exercise the Licensed Rights under the terms and conditions of this Public License.\n\n__Additional offer from the Licensor – Adapted Material. Every recipient of Adapted Material from You automatically receives an offer from the Licensor to exercise the Licensed Rights in the Adapted Material under the conditions of the Adapter’s License You apply.\n\nC. No downstream restrictions. You may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, the Licensed Material if doing so restricts exercise of the Licensed Rights by any recipient of the Licensed Material.\nNo endorsement. Nothing in this Public License constitutes or may be construed as permission to assert or imply that You are, or that Your use of the Licensed Material is, connected with, or sponsored, endorsed, or granted official status by, the Licensor or others designated to receive attribution as provided in Section 3(a)(1)(A)(i).\n\nOther rights.\n\nMoral rights, such as the right of integrity, are not licensed under this Public License, nor are publicity, privacy, and/or other similar personality rights; however, to the extent possible, the Licensor waives and/or agrees not to assert any such rights held by the Licensor to the limited extent necessary to allow You to exercise the Licensed Rights, but not otherwise.\nPatent and trademark rights are not licensed under this Public License.\nTo the extent possible, the Licensor waives any right to collect royalties from You for the exercise of the Licensed Rights, whether directly or through a collecting society under any voluntary or waivable statutory or compulsory licensing scheme. In all other cases the Licensor expressly reserves any right to collect such royalties.\n\n\n\n\nSection 3 – License Conditions.\nYour exercise of the Licensed Rights is expressly made subject to the following conditions.\n\nAttribution.\n\nIf You Share the Licensed Material (including in modified form), You must:\n\nretain the following if it is supplied by the Licensor with the Licensed Material:\n\n\n\nidentification of the creator(s) of the Licensed Material and any others designated to receive attribution, in any reasonable manner requested by the Licensor (including by pseudonym if designated);\na copyright notice;\na notice that refers to this Public License;\na notice that refers to the disclaimer of warranties;\na URI or hyperlink to the Licensed Material to the extent reasonably practicable;\n\n\n\nindicate if You modified the Licensed Material and retain an indication of any previous modifications; and\nindicate the Licensed Material is licensed under this Public License, and include the text of, or the URI or hyperlink to, this Public License.\n\nYou may satisfy the conditions in Section 3(a)(1) in any reasonable manner based on the medium, means, and context in which You Share the Licensed Material. For example, it may be reasonable to satisfy the conditions by providing a URI or hyperlink to a resource that includes the required information.\nIf requested by the Licensor, You must remove any of the information required by Section 3(a)(1)(A) to the extent reasonably practicable.\n\nShareAlike.\n\nIn addition to the conditions in Section 3(a), if You Share Adapted Material You produce, the following conditions also apply.\n\nThe Adapter’s License You apply must be a Creative Commons license with the same License Elements, this version or later, or a BY-SA Compatible License.\nYou must include the text of, or the URI or hyperlink to, the Adapter’s License You apply. You may satisfy this condition in any reasonable manner based on the medium, means, and context in which You Share Adapted Material.\nYou may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, Adapted Material that restrict exercise of the rights granted under the Adapter’s License You apply.\n\n\n\nSection 4 – Sui Generis Database Rights.\nWhere the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material:\n\nfor the avoidance of doubt, Section 2(a)(1) grants You the right to extract, reuse, reproduce, and Share all or a substantial portion of the contents of the database;\nif You include all or a substantial portion of the database contents in a database in which You have Sui Generis Database Rights, then the database in which You have Sui Generis Database Rights (but not its individual contents) is Adapted Material, including for purposes of Section 3(b); and\nYou must comply with the conditions in Section 3(a) if You Share all or a substantial portion of the contents of the database.\n\nFor the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights.\n\n\nSection 5 – Disclaimer of Warranties and Limitation of Liability.\n\nUnless otherwise separately undertaken by the Licensor, to the extent possible, the Licensor offers the Licensed Material as-is and as-available, and makes no representations or warranties of any kind concerning the Licensed Material, whether express, implied, statutory, or other. This includes, without limitation, warranties of title, merchantability, fitness for a particular purpose, non-infringement, absence of latent or other defects, accuracy, or the presence or absence of errors, whether or not known or discoverable. Where disclaimers of warranties are not allowed in full or in part, this disclaimer may not apply to You.\nTo the extent possible, in no event will the Licensor be liable to You on any legal theory (including, without limitation, negligence) or otherwise for any direct, special, indirect, incidental, consequential, punitive, exemplary, or other losses, costs, expenses, or damages arising out of this Public License or use of the Licensed Material, even if the Licensor has been advised of the possibility of such losses, costs, expenses, or damages. Where a limitation of liability is not allowed in full or in part, this limitation may not apply to You.\nThe disclaimer of warranties and limitation of liability provided above shall be interpreted in a manner that, to the extent possible, most closely approximates an absolute disclaimer and waiver of all liability.\n\n\n\nSection 6 – Term and Termination.\n\nThis Public License applies for the term of the Copyright and Similar Rights licensed here. However, if You fail to comply with this Public License, then Your rights under this Public License terminate automatically.\nWhere Your right to use the Licensed Material has terminated under Section 6(a), it reinstates:\n\nautomatically as of the date the violation is cured, provided it is cured within 30 days of Your discovery of the violation; or\nupon express reinstatement by the Licensor.\n\nFor the avoidance of doubt, this Section 6(b) does not affect any right the Licensor may have to seek remedies for Your violations of this Public License.\nFor the avoidance of doubt, the Licensor may also offer the Licensed Material under separate terms or conditions or stop distributing the Licensed Material at any time; however, doing so will not terminate this Public License.\nSections 1, 5, 6, 7, and 8 survive termination of this Public License.\n\n\n\nSection 7 – Other Terms and Conditions.\n\nThe Licensor shall not be bound by any additional or different terms or conditions communicated by You unless expressly agreed.\nAny arrangements, understandings, or agreements regarding the Licensed Material not stated herein are separate from and independent of the terms and conditions of this Public License.t stated herein are separate from and independent of the terms and conditions of this Public License.\n\n\n\nSection 8 – Interpretation.\n\nFor the avoidance of doubt, this Public License does not, and shall not be interpreted to, reduce, limit, restrict, or impose conditions on any use of the Licensed Material that could lawfully be made without permission under this Public License.\nTo the extent possible, if any provision of this Public License is deemed unenforceable, it shall be automatically reformed to the minimum extent necessary to make it enforceable. If the provision cannot be reformed, it shall be severed from this Public License without affecting the enforceability of the remaining terms and conditions.\nNo term or condition of this Public License will be waived and no failure to comply consented to unless expressly agreed to by the Licensor.\nNothing in this Public License constitutes or may be interpreted as a limitation upon, or waiver of, any privileges and immunities that apply to the Licensor or You, including from the legal processes of any jurisdiction or authority.\n\n\nCreative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the “Licensor.” Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at creativecommons.org/policies, Creative Commons does not authorize the use of the trademark “Creative Commons” or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses.\nCreative Commons may be contacted at creativecommons.org"
  },
  {
    "objectID": "content/labs/03-lab-viz.html",
    "href": "content/labs/03-lab-viz.html",
    "title": "Lab 03 - Data Visualization",
    "section": "",
    "text": "A note on expectations: For each exercise, include any relevant output (tables, summary statistics, plots) in your answer along with text to guide the reader. Doing this is easy! Just place any relevant R code in a code chunk, any relevant text outside of code chunks, and hit Knit HTML.\nSome define statistics as the field that focuses on turning information into knowledge. The first step in that process is to summarize and describe raw information - the data. In this lab we explore data on college majors and earnings, specifically the data behind the FiveThirtyEight story “The Economic Guide To Picking A College Major”.\nThese data originally come from the American Community Survey (ACS) 2010-2012 Public Use Microdata Series. While outside the scope of this lab, if you are curious about how raw data from the ACS were cleaned and prepared, see the code FiveThirtyEight authors used.\nWe should also note that there are many considerations that go into picking a major. Earnings potential and employment prospects are two of them, and they are important, but they don’t tell the whole story. Keep this in mind as you analyze the data."
  },
  {
    "objectID": "content/labs/03-lab-viz.html#which-major-has-the-lowest-unemployment-rate",
    "href": "content/labs/03-lab-viz.html#which-major-has-the-lowest-unemployment-rate",
    "title": "Lab 03 - Data Visualization",
    "section": "Which major has the lowest unemployment rate?",
    "text": "Which major has the lowest unemployment rate?\nIn order to answer this question all we need to do is sort the data. We use the arrange function to do this, and sort it by the unemployment_rate variable. By default arrange sorts in ascending order, which is what we want here – we’re interested in the major with the lowest unemployment rate.\n\ncollege_recent_grads |>\n  arrange(unemployment_rate)\n\nThis gives us what we wanted, but not in an ideal form. First, the name of the major barely fits on the page. Second, some of the variables are not that useful (e.g. major_code, major_category) and some we might want front and center are not easily viewed (e.g. unemployment_rate).\nWe can use the select function to choose which variables to display, and in which order:\nNote that your output here likely has a whole bunch of decimal places in the unemployment variable? You likely don’t want all those values to be displayed.\nThere are two ways we can address this problem. One would be to round the unemployment_rate variable in the dataset or we can change the number of digits displayed, without touching the input data.\nBelow are instructions for how you would do both of these:\n\nRound unemployment_rate: We create a new variable with the mutate function. In this case, we’re overwriting the existing unemployment_rate variable, by rounding it to 4 decimal places.For example, the call to mutate would be: mutate(unemployment_rate = round(unemployment_rate, digits = 4))\nChange displayed number of digits without touching data: We can add an option to our R Markdown document to change the displayed number of digits in the output. To do so, add a new chunk, and set:\n\n\noptions(digits = 2)\n\nNote that the digits in options is scientific digits, and in round they are decimal places. If you’re thinking “Wouldn’t it be nice if they were consistent?”, you’re right…\nYou don’t need to do both of these; that would be redundant. The next exercise asks you to choose one.\n\nExercise 1\nWhich of these options, changing the input data or altering the number of digits displayed without touching the input data, is the better option? Explain your reasoning. Then, implement the option you chose."
  },
  {
    "objectID": "content/labs/03-lab-viz.html#which-major-has-the-highest-percentage-of-women",
    "href": "content/labs/03-lab-viz.html#which-major-has-the-highest-percentage-of-women",
    "title": "Lab 03 - Data Visualization",
    "section": "Which major has the highest percentage of women?",
    "text": "Which major has the highest percentage of women?\nTo answer such a question we need to arrange the data in descending order. For example, if earlier we were interested in the major with the highest unemployment rate, we would use the following:\n\n\nThe desc function specifies that we want unemployment_rate in descending order.\n\ncollege_recent_grads |>\n  arrange(desc(unemployment_rate)) |>\n  select(rank, major, unemployment_rate)\n\n\nExercise 2\nUsing what you’ve learned so far, arrange the data in descending order with respect to proportion of women in a major, and display only the major, the total number of people with major, and proportion of women. Show only the top 3 majors by adding head(3) at the end of the pipeline."
  },
  {
    "objectID": "content/labs/03-lab-viz.html#how-do-the-distributions-of-median-income-compare-across-major-categories",
    "href": "content/labs/03-lab-viz.html#how-do-the-distributions-of-median-income-compare-across-major-categories",
    "title": "Lab 03 - Data Visualization",
    "section": "How do the distributions of median income compare across major categories?",
    "text": "How do the distributions of median income compare across major categories?\n\n\nA percentile is a measure used in statistics indicating the value below which a given percentage of observations in a group of observations fall. For example, the 20th percentile is the value below which 20% of the observations may be found. (Source: Wikipedia\nThere are three types of incomes reported in this data frame: p25th, median, and p75th. These correspond to the 25th, 50th, and 75th percentiles of the income distribution of sampled individuals for a given major.\n\nExercise 3\nWhy do we often choose the median, rather than the mean, to describe the typical income of a group of people?\nThe question we want to answer “How do the distributions of median income compare across major categories?”. We need to do a few things to answer this question: First, we need to group the data by major_category. Then, we need a way to summarize the distributions of median income within these groups. This decision will depend on the shapes of these distributions. So first, we need to visualize the data.\nWe use the ggplot function to do this. The first argument is the data frame, and the next argument gives the mapping of the variables of the data to the aesthetic elements of the plot.\nLet’s start simple and take a look at the distribution of all median incomes, without considering the major categories.\n\nggplot(data = college_recent_grads, mapping = aes(x = median)) +\n  geom_histogram()\n\nAlong with the plot, we get a message:\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\nThis is telling us that we might want to reconsider the binwidth we chose for our histogram – or more accurately, the binwidth we didn’t specify. It’s good practice to always think in the context of the data and try out a few binwidths before settling on a binwidth. You might ask yourself: “What would be a meaningful difference in median incomes?” $1 is obviously too little, $10000 might be too high.\n\n\nExercise 4\nTry binwidths of $1000 and $5000 and choose one. Explain your reasoning for your choice. Note that the binwidth is an argument for the geom_histogram function. So to specify a binwidth of $1000, you would use geom_histogram(binwidth = 1000).\nWe can also calculate summary statistics for this distribution using the summarise function. Note here that you can calculate multiple summary statistics within a single summarise call:\n\ncollege_recent_grads |>\n  summarise(min = min(median), max = max(median),\n            mean = mean(median), med = median(median),\n            sd = sd(median), \n            q1 = quantile(median, probs = 0.25),\n            q3 = quantile(median, probs = 0.75))\n\n\n\nExercise 5\nBased on the shape of the histogram you created in the previous exercise, determine which of these summary statistics is useful for describing the distribution. Write up your description (remember shape, center, spread, any unusual observations) and include the summary statistic output as well.\nNext, we facet the plot by major category.\n\nggplot(data = college_recent_grads, mapping = aes(x = median)) +\n  geom_histogram() +\n  facet_wrap( ~ major_category, ncol = 4)\n\n\n\nExercise 6\nPlot the distribution of median income using a histogram, faceted by major_category. Use the binwidth you chose in the earlier exercise.\nNow that we’ve seen the shapes of the distributions of median incomes for each major category, we should have a better idea for which summary statistic to use to quantify the typical median income.\n\n\nExercise 7\nWhich major category has the highest typical (you’ll need to decide what this means) median income? Also note that we are looking for the highest statistic, so make sure if you arrange to do so in the correct direction.\n\n\nExercise 8\nWhich major category is the least popular in this sample?"
  },
  {
    "objectID": "content/labs/03-lab-viz.html#all-stem-fields-arent-the-same",
    "href": "content/labs/03-lab-viz.html#all-stem-fields-arent-the-same",
    "title": "Lab 03 - Data Visualization",
    "section": "All STEM fields aren’t the same",
    "text": "All STEM fields aren’t the same\nOne of the sections of the FiveThirtyEight story is “All STEM fields aren’t the same”. Let’s see if this is true.\nFirst, let’s create a new vector called stem_categories that lists the major categories that are considered STEM fields.\n\nstem_categories <- c(\"Biology & Life Science\",\n                     \"Computers & Mathematics\",\n                     \"Engineering\",\n                     \"Physical Sciences\")\n\nThen, we can use this to create a new variable in our data frame indicating whether a major is STEM or not.\n\ncollege_recent_grads <- college_recent_grads |>\n  mutate(major_type = case_when(major_category %in% stem_categories ~ \"stem\",\n                                TRUE ~ \"not stem\"))\n\nLet’s unpack this: with mutate we create a new variable called major_type, which is defined as \"stem\" if the major_category is in the vector called stem_categories we created earlier, and as \"not stem\" otherwise.\n%in% is a logical operator. Other logical operators that are commonly used are\n\n\n\nOperator\nOperation\n\n\n\n\nx < y\nless than\n\n\nx > y\ngreater than\n\n\nx <= y\nless than or equal to\n\n\nx >= y\ngreater than or equal to\n\n\nx != y\nnot equal to\n\n\nx == y\nequal to\n\n\nx %in% y\ncontains\n\n\nx | y\nor\n\n\nx & y\nand\n\n\n!x\nnot\n\n\n\nWe can use the logical operators to also filter our data for STEM majors whose median earnings is less than median for all majors’s median earnings, which we found to be $36,000 earlier.\n\ncollege_recent_grads |>\n  filter(\n    major_type == \"stem\",\n    median < 36000\n  )\n\n\nExercise 9\nWhich STEM majors have median salaries equal to or less than the median for all majors’ median earnings? Your output should only show the major name and median, 25th percentile, and 75th percentile earning for that major as and should be sorted such that the major with the highest median earning is on top."
  },
  {
    "objectID": "content/labs/03-lab-viz.html#what-types-of-majors-do-women-tend-to-major-in",
    "href": "content/labs/03-lab-viz.html#what-types-of-majors-do-women-tend-to-major-in",
    "title": "Lab 03 - Data Visualization",
    "section": "What types of majors do women tend to major in?",
    "text": "What types of majors do women tend to major in?\n\nExercise 10\nCreate a scatterplot of median income vs. proportion of women in that major, colored by whether the major is in a STEM field or not. Describe the association between these three variables."
  },
  {
    "objectID": "content/labs/04-lab-modelling.html",
    "href": "content/labs/04-lab-modelling.html",
    "title": "Lab 04 - Data Modelling course evaluations, Pt 1",
    "section": "",
    "text": "Many college courses conclude by giving students the opportunity to evaluate the course and the instructor anonymously. However, the use of these student evaluations as an indicator of course quality and teaching effectiveness is often criticized because these measures may reflect the influence of non-teaching related characteristics, such as the physical appearance of the instructor. The article titled, “Beauty in the classroom: instructors’ pulchritude and putative pedagogical productivity” (Hamermesh and Parker, 2005) found that instructors who are viewed to be better looking receive higher instructional ratings.\n\n\nDaniel S. Hamermesh, Amy Parker, Beauty in the classroom: instructors pulchritude and putative pedagogical productivity, Economics of Education Review, Volume 24, Issue 4, August 2005, Pages 369-376, ISSN 0272-7757, 10.1016/j.econedurev.2004.07.013. link.\nFor this assignment you will analyze the data from this study in order to learn what goes into a positive professor evaluation.\nThe data were gathered from end of semester student evaluations for a large sample of professors from the University of Texas at Austin. In addition, six students rated the professors’ physical appearance. (This is a slightly modified version of the original data set that was released as part of the replication data for Data Analysis Using Regression and Multilevel/Hierarchical Models (Gelman and Hill, 2007).) The result is a data frame where each row contains a different course and columns represent variables about the courses and professors."
  },
  {
    "objectID": "content/labs/04-lab-modelling.html#codebook",
    "href": "content/labs/04-lab-modelling.html#codebook",
    "title": "Lab 04 - Data Modelling course evaluations, Pt 1",
    "section": "Codebook",
    "text": "Codebook\n\n\n\n\n\n\n\nVariable name\nDescription\n\n\n\n\nscore\nAverage professor evaluation score: (1) very unsatisfactory - (5) excellent\n\n\nrank\nRank of professor: teaching, tenure track, tenure\n\n\nethnicity\nEthnicity of professor: not minority, minority\n\n\ngender\nGender of professor: female, male\n\n\nlanguage\nLanguage of school where professor received education: english or non-english\n\n\nage\nAge of professor\n\n\ncls_perc_eval\nPercent of students in class who completed evaluation\n\n\ncls_did_eval\nNumber of students in class who completed evaluation\n\n\ncls_students\nTotal number of students in class\n\n\ncls_level\nClass level: lower, upper\n\n\ncls_profs\nNumber of professors teaching sections in course in sample: single, multiple\n\n\ncls_credits\nNumber of credits of class: one credit (lab, PE, etc.), multi credit\n\n\nbty_f1lower\nBeauty rating of professor from lower level female: (1) lowest - (10) highest\n\n\nbty_f1upper\nBeauty rating of professor from upper level female: (1) lowest - (10) highest\n\n\nbty_f2upper\nBeauty rating of professor from upper level female: (1) lowest - (10) highest\n\n\nbty_m1lower\nBeauty rating of professor from lower level male: (1) lowest - (10) highest\n\n\nbty_m1upper\nBeauty rating of professor from upper level male: (1) lowest - (10) highest\n\n\nbty_m2upper\nBeauty rating of professor from upper level male: (1) lowest - (10) highest"
  },
  {
    "objectID": "content/labs/04-lab-modelling.html#part-1-data-manipulation",
    "href": "content/labs/04-lab-modelling.html#part-1-data-manipulation",
    "title": "Lab 04 - Data Modelling course evaluations, Pt 1",
    "section": "Part 1: Data Manipulation",
    "text": "Part 1: Data Manipulation\n\n\nThe rowwise function is useful for applying mathematical operations to each row.\n\nExercise 1\nCreate a new variable called bty_avg that is the average attractiveness score of the six students for each professor (bty_f1lower through bty_m2upper). Add this new variable to the evals data frame. Do this in one pipe, using the rowwise function. Since rowwise is new to you, incomplete code is given below to guide you in the right direction, however you will need to fill in the blanks.\n\n___ <- evals |>\n  rowwise() |>\n  ___(bty_avg = mean( c( ___ ) )) |>\n  ungroup()\n\nNote that we end the pipeline with ungroup() to remove the effect of the rowwise function from earlier in the pipeline. The rowwise function works a lot like group_by, except it groups the data frame one row at a time so that any operations applied to the data frame is done once per each row. This is helpful for finding the mean beauty score for each row. However in the remainder of the analysis we don’t want to, say, calculate summary statistics for each row, or fit a model for each row. Hence we need to undo the effect of rowwise, which we can do with ungroup."
  },
  {
    "objectID": "content/labs/04-lab-modelling.html#part-2-exploratory-data-analysis",
    "href": "content/labs/04-lab-modelling.html#part-2-exploratory-data-analysis",
    "title": "Lab 04 - Data Modelling course evaluations, Pt 1",
    "section": "Part 2: Exploratory Data Analysis",
    "text": "Part 2: Exploratory Data Analysis\n\nExercise 2\nVisualize the distribution of score. Is the distribution skewed? What does that tell you about how students rate courses? Is this what you expected to see? Why, or why not? Include any summary statistics and visualizations you use in your response.\n\n\nExercise 3\nVisualize and describe the relationship between score and the new variable you created, bty_avg.\n\n\nHint: See the help page for the function at http://ggplot2.tidyverse.org/reference/index.html.\n\n\nExercise 4\nReplot the scatterplot from Exercise 3, but this time use\ngeom_jitter()? What does “jitter” mean? What was misleading about the initial scatterplot?"
  },
  {
    "objectID": "content/labs/04-lab-modelling.html#part-3-linear-regression-with-a-numerical-predictor",
    "href": "content/labs/04-lab-modelling.html#part-3-linear-regression-with-a-numerical-predictor",
    "title": "Lab 04 - Data Modelling course evaluations, Pt 1",
    "section": "Part 3: Linear regression with a numerical predictor",
    "text": "Part 3: Linear regression with a numerical predictor\n\n\nLinear model is in the form \\(\\hat{y} = b_0 + b_1 x\\).\n\nExercise 5\nLet’s see if the apparent trend in the plot is something more than natural variation. Fit a linear model called m_bty to predict average professor evaluation score by average beauty rating (bty_avg). Based on the regression output, write the linear model.\n\n\nExercise 6\nReplot your visualization from Exercise 3, and add the regression line to this plot in orange color. Turn off the shading for the uncertainty of the line.\n\n\nExercise 7\nInterpret the slope of the linear model in context of the data.\n\n\nExercise 8\nInterpret the intercept of the linear model in context of the data. Comment on whether or not the intercept makes sense in this context.\n\n\nExercise 9\nDetermine the \\(R^2\\) of the model and interpret it in context of the data."
  },
  {
    "objectID": "content/labs/04-lab-modelling.html#part-4-linear-regression-with-a-categorical-predictor",
    "href": "content/labs/04-lab-modelling.html#part-4-linear-regression-with-a-categorical-predictor",
    "title": "Lab 04 - Data Modelling course evaluations, Pt 1",
    "section": "Part 4: Linear regression with a categorical predictor",
    "text": "Part 4: Linear regression with a categorical predictor\n\nExercise 10\nFit a new linear model called m_gen to predict average professor evaluation score based on gender of the professor. Based on the regression output, write the linear model and interpret the slope and intercept in context of the data.\n\n\nExercise 11\nWhat is the equation of the line corresponding to male professors? What is it for female professors?\n\n\nExercise 12\nFit a new linear model called m_rank to predict average professor evaluation score based on rank of the professor. Based on the regression output, write the linear model and interpret the slopes and intercept in context of the data.\n\n\nSee the course slides on using the forcats package for changing the order of levels.\n\n\nExercise 3\nCreate a new variable called rank_relevel where \"tenure track\" is the baseline level.\n\n\nExercise 14\nFit a new linear model called m_rank_relevel to predict average professor evaluation score based on rank_relevel of the professor. This is the new (releveled) variable you created in Exercise 13. Based on the regression output, write the linear model and interpret the slopes and intercept in context of the data. Also determine and interpret the \\(R^2\\) of the model.\n\n\nExercise 15\nCreate another new variable called tenure_eligible that labels \"teaching\" faculty as \"no\" and labels \"tenure track\" and \"tenured\" faculty as \"yes\".\n\n\nExercise 16\nFit a new linear model called m_tenure_eligible to predict average professor evaluation score based on tenure_eligibleness of the professor. This is the new (regrouped) variable you created in Exercise 15. Based on the regression output, write the linear model and interpret the slopes and intercept in context of the data. Also determine and interpret the \\(R^2\\) of the model."
  },
  {
    "objectID": "content/labs/05-lab-mlr.html",
    "href": "content/labs/05-lab-mlr.html",
    "title": "Lab 05 - Modelling course evaluations, Pt 2",
    "section": "",
    "text": "In this lab we revisit the professor evaluations data we modeled in an earlier lab. In the modelling lab we modeled evaluation scores using a single predictor at a time. However, this time we use multiple predictors to model evaluation scores.\nIf you don’t remember the data, review the modelling lab’s introduction before continuing to the exercises."
  },
  {
    "objectID": "content/labs/05-lab-mlr.html#part-1-simple-linear-regression",
    "href": "content/labs/05-lab-mlr.html#part-1-simple-linear-regression",
    "title": "Lab 05 - Modelling course evaluations, Pt 2",
    "section": "Part 1: Simple linear regression",
    "text": "Part 1: Simple linear regression\n\nExercise 2\n[Review from linear regression lab] Fit a linear model (one you have fit before): m_bty, predicting average professor evaluation score based on average beauty rating (bty_avg) only. Write the linear model, and note the \\(R^2\\) and the adjusted \\(R^2\\)."
  },
  {
    "objectID": "content/labs/05-lab-mlr.html#part-2-multiple-linear-regression",
    "href": "content/labs/05-lab-mlr.html#part-2-multiple-linear-regression",
    "title": "Lab 05 - Modelling course evaluations, Pt 2",
    "section": "Part 2: Multiple linear regression",
    "text": "Part 2: Multiple linear regression\n\nExercise 3\nFit a linear model: m_bty_gen, predicting average professor evaluation score based on average beauty rating (bty_avg) and gender. Write the linear model, and note the \\(R^2\\) and the adjusted \\(R^2\\).\n\n\nExercise 4\nInterpret the slopes and intercept of m_bty_gen in context of the data.\n\n\nExercise 5\nWhat percent of the variability in score is explained by the model m_bty_gen.\n\n\nExercise 6\nWhat is the equation of the line corresponding to just male professors?\n\n\nExercise 7\nFor two professors who received the same beauty rating, which gender tends to have the higher course evaluation score?\n\n\nExercise 8\nHow do the adjusted \\(R^2\\) values of m_bty_gen and m_bty compare? What does this tell us about how useful gender is in explaining the variability in evaluation scores when we already have information on the beauty score of the professor.\n\n\nExercise 9\nCompare the slopes of bty_avg under the two models (m_bty and m_bty_gen). Has the addition of gender to the model changed the parameter estimate (slope) for bty_avg?\n\n\nExercise 10\nCreate a new model called m_bty_rank with gender removed and rank added in. Write the equation of the linear model and interpret the slopes and intercept in context of the data."
  },
  {
    "objectID": "content/labs/05-lab-mlr.html#part-3-the-search-for-the-best-model",
    "href": "content/labs/05-lab-mlr.html#part-3-the-search-for-the-best-model",
    "title": "Lab 05 - Modelling course evaluations, Pt 2",
    "section": "Part 3: The search for the best model",
    "text": "Part 3: The search for the best model\nGoing forward, only consider the following variables as potential predictors: rank, ethnicity, gender, language, age, cls_perc_eval, cls_did_eval, cls_students, cls_level, cls_profs, cls_credits, bty_avg.\n\nExercise 11\nWhich variable, on its own, would you expect to be the worst predictor of evaluation scores? Why? Hint: Think about which variable would you expect to not have any association with the professor’s score.\n\n\nExercise 12\nCheck your suspicions from the previous exercise. Include the model output for that variable in your response.\n\n\nExercise 13\nSuppose you wanted to fit a full model with the variables listed above. If you are already going to include cls_perc_eval and cls_students, which variable should you not include as an additional predictor? Why?\n\n\nExercise 14\nFit a full model with all predictors listed above (except for the one you decided to exclude) in the previous question.\n\n\nExercise 15\nUsing backward-selection (meaning fit all predictors and remove those that are not needed in the model) with adjusted R-squared as the selection criterion, determine the best model. You do not need to show all steps in your answer, just the output for the final model. Also, write out the linear model for predicting score based on the final model you settle on.\n\n\nExercise 16\nInterpret the slopes of one numerical and one categorical predictor based on your final model.\n\n\nExercise 17\nBased on your final model, describe the characteristics of a professor and course at University of Texas at Austin that would be associated with a high evaluation score.\n\n\nExercise 18\nWould you be comfortable generalizing your conclusions to apply to professors generally (at any university)? Why or why not?"
  },
  {
    "objectID": "content/labs/02-lab-wrangling.html",
    "href": "content/labs/02-lab-wrangling.html",
    "title": "Lab 02 - Tooling",
    "section": "",
    "text": "Introduction\nIn the first lab, you got acquainted with RMarkdown documents, knitting, code chunks, and interacting with GitHub; however, most of the required code was provided for you. In this and subsequent labs, there will be less code provided, and it will be up to you to write the requisite code.\nThe goal of this lab is to get you comfortable working with tidy datasets and using dplyr to do so.\n\n\nGetting started\nTo get started, accept the lab02 assignment (link on Canvas), clone the repo (using SSH) into RStudio on datahub. And, then you’re ready to go!\n\n\nPackages\nThe only package required for completion of this lab is tidyverse, as dplyr (which you’ll be using a lot in this lab) is one of the packages in the tidyverse. Be sure to import the tidyverse prior to completing the lab.\n\n\nData\nFor this lab, we’ll be using the storms dataset from the dplyr package, which includes data about a subset of storms from 1975. The description from this dataset states “This data is a subset of the NOAA Atlantic hurricane database best track data, https://www.nhc.noaa.gov/data/#hurdat. The data includes the positions and attributes of 198 tropical storms, measured every six hours during the lifetime of a storm.”\nRemember that you can use ?storms to look up the documentation for the dataset. Be sure to read and understand what information is stored in each variable before proceeding. The instructions below are not very guided and will require that you have read and understood the information in the dataset first.\n\n\nExercises\nFor each of the following, write code using dplyr functions to determine the answers to each of the questions. Your responses should include the code, its output, and a few words that answer the question.\nNote that the final two questions are optional. Definitely give them a try, but it’s OK if you don’t have time to figure them out!\n\nExercise 1\nHow many unique hurricanes are included in this dataset?\n\n\nExercise 2\nWhich tropical storm affected the largest area experiencing tropical storm strength winds? And, what was the maximum sustained wind speed for that storm?\n\n\nExercise 3\nAmong all storms in this dataset, in which month are storms most common? Does this depend on the status of the storm? (In other words, are hurricanes more common in certain months than tropical depressions? or tropical storms?)\n\n\nExercise 4\nYour boss asks for the name, year, and status of all category 5 storms that have happened in the 2000s. Carry out the operations that would deliver what they’re looking for.\n\n\nExercise 5\nFilter these data to only include storms that occurred during your lifetime (your code and results may differ from your classmates!). Among storms that have occurred during your lifetime, what’s the mean and median air pressure across all measurements taken?\n\n\nExercise 6\n(optional challenge) Which decade (of the storms included in the dataset) had the largest number of unique reported storms?\n\n\nExercise 7\n(optional challenge) - Among the subset of storms occurring in your lifetime, which storm lasted the longest? Include your code and explain your answer.\nYay, you’re done! Knit your file, commit all remaining changes to your .Rmd and .html files, use the commit message “Done with Lab 2! 💪”, and push. Before you wrap up the assignment, make sure all documents are updated on your GitHub repo."
  },
  {
    "objectID": "content/labs/01-lab-intro-r.html",
    "href": "content/labs/01-lab-intro-r.html",
    "title": "Lab 01 - Tooling",
    "section": "",
    "text": "The main goal of this lab is to introduce you to R and RStudio, which we will be using throughout the course to learn and practice programming and analyze data.\n\n\nR is the name of the programming language itself and RStudio is a convenient interface.\nAn additional goal is to introduce you to git and GitHub, which is the collaboration and version control system that we will be using throughout the course.\n\n\ngit is a version control system (like “Track Changes” features from Microsoft Word on steroids) and GitHub is the home for your Git-based projects on the internet (like DropBox but much, much better).\nAs the labs progress, you are encouraged to explore beyond what the labs say directly; a willingness to experiment will make you a much better programmer. Before we get to that stage, however, you need to build some basic fluency in R. Today we begin with the fundamental building blocks of R and RStudio: the interface, reading in data, and basic commands.\nYou are encouraged to ask one another questions and work together, but each individual must turn in their own lab each week."
  },
  {
    "objectID": "content/labs/01-lab-intro-r.html#github-housekeeping",
    "href": "content/labs/01-lab-intro-r.html#github-housekeeping",
    "title": "Lab 01 - Tooling",
    "section": "GitHub Housekeeping",
    "text": "GitHub Housekeeping\n\n\n\n\n\n\nNote\n\n\n\nYour email address is the address tied to your GitHub account and your name should be first and last name.\n\n\nBefore we can get started we need to take care of some required housekeeping. Specifically, we need to configure your git so that RStudio can communicate with GitHub…and so you do not have to type in your username and password every time you want to communicate with GitHub from RStudio. These steps will be demo-ed during lab and you’ll have time to walk through the steps!\n\n\n\n\n\n\nNote\n\n\n\nIf you aren’t able to attend lab and get stuck here, there is a podcast recording from lecture on 9/29 from the COGS 137 Fa21 iteration where you can see these steps demo-ed.\n\n\n\nStep 1: Email and Username\nThe first step requires two pieces of information: your email address and your name.\nTo do so, follow these steps:\n\nGo to the Terminal pane\nType the following two lines of code, replacing the information in the quotation marks with your info:\n\n\ngit config --global user.email \"your email\"\ngit config --global user.name \"your name\"\n\nFor example, for me these are:\n\ngit config --global user.email \"sellis@ucsd.edu\"\ngit config --global user.name \"Shannon Ellis\"\n\nTo confirm that the changes have been implemented, run the following:\n\ngit config --global user.email\ngit config --global user.name\n\n\n\nStep 2: Generate ssh key\nIn the terminal, you’ll want to generate an ssh key by typing:\n\nssh-keygen\n\nAfter hitting enter/return to execute the above, you’ll press return/enter three times to bypass specifying a location and passphrase.\n\n\nStep 3: Copy your ssh key\nFrom the terminal type:\n\ncat ~/.ssh/id_rsa.pub\n\nYou’ll want to highlight and copy the full result of this command. It will start with ssh-rsa and end with dsmlp.login.ucsd.edu.\n\n\nStep 4: Let GitHub know your key\n\nIn your browser, navigate to https://github.com/settings/keys\nClick “New SSH Key”\nSet title to DSMLP\nPaste what you copied in step 3 into the “Key” box\nClick “Add SSH Key”\n\n\n\nStep 5: Finalize\nReturn to the terminal in RStudio and run the following command:\n\nssh git@github.com\n\nYou’ll then see a message like You've successfully authenticated, but GitHub does not provide shell access. At this point, you’re all set!\nThis will be the only time you have to do this. From here on out, you’ll be able to “communicate” with GitHub from RStudio without typing your username/password."
  },
  {
    "objectID": "content/labs/01-lab-intro-r.html#cloning-the-lab",
    "href": "content/labs/01-lab-intro-r.html#cloning-the-lab",
    "title": "Lab 01 - Tooling",
    "section": "Cloning the lab",
    "text": "Cloning the lab\nEach of your assignments will begin with the following steps. You saw these once in class and, they’re outlined in detail here again. Going forward each lab will start with a “Getting started” section but details will be a bit more sparse than this. You can always refer back to this lab for a detailed list of the steps involved for getting started with an assignment.\nClick on the assignment link for this week’s lab on the Canvas homepage. You will have to Accept before proceeding. Refresh the page and follow the link to the repo created for you. This repo contains a template you can build on to complete your lab.\n\n\n\n\n\n\n\nOn this page on GitHub, click the URL provided for you. This will bring you to your copy of the repo on GitHub. Click on the green <> Code button to clone the repo. Be sure that SSH is selected and copy this URL.\n\n\n\n\n\n\nImportant\n\n\n\nBe sure that any time you are copying a link from GitHub under the <>Code button, you select and use the ‘SSH’ URL as this is what will allow you to not have to type your username and password.\n\n\n\n\n\n\n\n\n\nGo to datahub and open RStudio. Go to File > New Project… and select to create a New Project from Version Control. On the following menu, select Git.\nCopy and paste the URL of your assignment repo into the “Repository URL” dialog box:\n\n\n\n\n\n\n\nHit Create Project. Open up lab-01.Rmd and continue through this lab. Your work/answers for this lab will be submitted in that document."
  },
  {
    "objectID": "content/labs/01-lab-intro-r.html#packages",
    "href": "content/labs/01-lab-intro-r.html#packages",
    "title": "Lab 01 - Tooling",
    "section": "Packages",
    "text": "Packages\nIn this lab we will work with two packages: datasauRus which contains the dataset, and tidyverse which is a collection of packages for doing data analysis in a “tidy” way.\nThese packages have already been installed for you. However, if they had not, you would need to run install.packages(\"tidyverse\") and install.packages(\"datasauRus\") before proceeding. Note that package installation happens a single time. But, any time you want to use a package (after it’s been installed), it has to be loaded, as we do below:\nIf you’d like to run your code in the Console as well you’ll also need to load the packages there. To do so, run the following in the console.\n\nlibrary(tidyverse) \nlibrary(datasauRus)\n\nYou should be able to Knit your document and see the results.\nNote that the packages are also loaded with the same commands in your R Markdown document."
  },
  {
    "objectID": "content/labs/01-lab-intro-r.html#yaml",
    "href": "content/labs/01-lab-intro-r.html#yaml",
    "title": "Lab 01 - Tooling",
    "section": "YAML:",
    "text": "YAML:\n\n\nThe top portion of your R Markdown file (between the three dashed lines) is called YAML. It stands for “Yet Another Markup Language”. It is a human-friendly data serialization standard for all programming languages. All you need to know is that this area is called the YAML (we will refer to it as such) and that it contains meta information about your document.\nOpen the R Markdown (Rmd) file in your project, change the author name to your name and knit the document. This will generate an HTML document."
  },
  {
    "objectID": "content/labs/01-lab-intro-r.html#commiting-changes",
    "href": "content/labs/01-lab-intro-r.html#commiting-changes",
    "title": "Lab 01 - Tooling",
    "section": "Commiting changes:",
    "text": "Commiting changes:\nThen Go to the Git pane in your RStudio on Datahub.\nIf you have made changes to your Rmd file, you should see it listed here. Click on it in this list and then click on Diff. This shows you the difference between the last committed state of the document and its current state that includes your changes. Be sure to also select your HTML document. Once you’re happy with these changes, write “Update author name” in the Commit message box and hit Commit.\n\n\n\n\n\n\n\nYou don’t have to commit after every change, this would get quite cumbersome. You should consider committing states that are meaningful to you for inspection, comparison, or restoration. In the first few assignments we will tell you exactly when to commit and in some cases, what commit message to use. As the quarter progresses, we will let you make these decisions."
  },
  {
    "objectID": "content/labs/01-lab-intro-r.html#pushing-changes",
    "href": "content/labs/01-lab-intro-r.html#pushing-changes",
    "title": "Lab 01 - Tooling",
    "section": "Pushing changes:",
    "text": "Pushing changes:\nNow that you have made an update and committed this change, it’s time to push these changes to the web! Or more specifically, to your repo on GitHub. Why? So that others can see your changes. And by others, we mean the course teaching team (your repos in this course are private to you and us, only).\nIn order to push your changes to GitHub, click on Push. Go check your repo on GitHub - you’ll see your updated documents there!\n\n\n\n\n\n\nThought exercise\n\n\n\nFor which of the above steps (changing project name, making updates to the document, committing, and pushing changes) do you need to have an internet connection? Discuss with your classmates."
  },
  {
    "objectID": "content/labs/01-lab-intro-r.html#data",
    "href": "content/labs/01-lab-intro-r.html#data",
    "title": "Lab 01 - Tooling",
    "section": "Data",
    "text": "Data\nThe data frame we will be working with today is called datasaurus_dozen2 and it’s in the datasauRus package. Actually, this single data frame contains 13 datasets, designed to show us why data visualization is important and how summary statistics alone can be misleading. The different datasets are maked by the dataset variable.\nTo find out more about the dataset, type the following in your Console: ?datasaurus_dozen. A question mark before the name of an object will always bring up its help file. This command must be ran in the Console.\n\nExercise 1\nBased on the help file, how many rows and how many columns does the datasaurus_dozen file have? What are the variables included in the data frame? Add your responses to your lab report. When you’re done, commit your changes with the commit message “Added answer for Ex 1”, and push.\nLet’s take a look at what these datasets are. To do so we can make a frequency table of the dataset variable:\n\ndatasaurus_dozen |>\n  count(dataset)\n\n# A tibble: 13 × 2\n   dataset        n\n   <chr>      <int>\n 1 away         142\n 2 bullseye     142\n 3 circle       142\n 4 dino         142\n 5 dots         142\n 6 h_lines      142\n 7 high_lines   142\n 8 slant_down   142\n 9 slant_up     142\n10 star         142\n11 v_lines      142\n12 wide_lines   142\n13 x_shape      142\n\n\nThe original Datasaurus (dino) was created by Alberto Cairo in this great blog post. The other Dozen were generated using simulated annealing and the process is described in the paper Same Stats, Different Graphs: Generating Datasets with Varied Appearance and Identical Statistics through Simulated Annealing by Justin Matejka and George Fitzmaurice.3 In the paper, the authors simulate a variety of datasets that the same summary statistics to the Datasaurus but have very different distributions."
  },
  {
    "objectID": "content/labs/01-lab-intro-r.html#data-visualization-and-summary",
    "href": "content/labs/01-lab-intro-r.html#data-visualization-and-summary",
    "title": "Lab 01 - Tooling",
    "section": "Data visualization and summary",
    "text": "Data visualization and summary\n\nExercise 2\nPlot y vs. x for the dino dataset. Then, calculate the correlation coefficient between x and y for this dataset.\nBelow is the code you will need to complete this exercise. Basically, the answer is already given, but you need to include relevant bits in your Rmd document and successfully knit it and view the results.\nStart with the datasaurus_dozen and pipe it into the filter function to filter for observations where dataset == \"dino\". Store the resulting filtered data frame as a new data frame called dino_data.\n\ndino_data <- datasaurus_dozen |>\n  filter(dataset == \"dino\")\n\nThere is a lot going on here, so let’s slow down and unpack it a bit.\nFirst, the pipe operator: |>, takes what comes before it and sends it as the first argument to what comes after it. So here, we’re saying filter the datasaurus_dozen data frame for observations where dataset == \"dino\".\nSecond, the assignment operator: <-, assigns the name dino_data to the filtered data frame.\nNext, we need to visualize these data. We will use the ggplot function for this. Its first argument is the data you’re visualizing. Next we define the aesthetic mappings. In other words, the columns of the data that get mapped to certain aesthetic features of the plot, e.g. the x axis will represent the variable called x and the y axis will represent the variable called y. Then, we add another layer to this plot where we define which geometric shapes we want to use to represent each observation in the data. In this case we want these to be points,m hence geom_point.\n\nggplot(data = dino_data, mapping = aes(x = x, y = y)) +\n  geom_point()\n\n\n\n\nIf this seems like a lot, it is. And you will learn about the philosophy of building data visualizations in layer in detail next week. For now, follow along with the code that is provided.\nFor the second part of this exercises, we need to calculate a summary statistic: the correlation coefficient. Correlation coefficient, often referred to as \\(r\\) in statistics, measures the linear association between two variables. You will see that some of the pairs of variables we plot do not have a linear relationship between them. This is exactly why we want to visualize first: visualize to assess the form of the relationship, and calculate \\(r\\) only if relevant. In this case, calculating a correlation coefficient really doesn’t make sense since the relationship between x and y is definitely not linear – it’s dinosaurial!\nBut, for illustrative purposes, let’s calculate correlation coefficient between x and y.\n\n\nStart with dino_data and calculate a summary statistic that we will call r as the correlation between x and y.\n\ndino_data |>\n  summarize(r = cor(x, y))\n\n# A tibble: 1 × 1\n        r\n    <dbl>\n1 -0.0645\n\n\nThis is a good place to pause, commit changes with the commit message “Added answer for Ex 2”, and push.\n\n\nExercise 3\nPlot y vs. x for the star dataset. You can (and should) reuse code we introduced above, just replace the dataset name with the desired dataset. Then, calculate the correlation coefficient between x and y for this dataset. How does this value compare to the r of dino?\nThis is another good place to pause, commit changes with the commit message “Added answer for Ex 3”, and push.\n\n\nExercise 4\nPlot y vs. x for the circle dataset. You can (and should) reuse code we introduced above, just replace the dataset name with the desired dataset. Then, calculate the correlation coefficient between x and y for this dataset. How does this value compare to the r of dino?\nYou should pause again, commit changes with the commit message “Added answer for Ex 4”, and push.\n\n\nFacet by the dataset variable, placing the plots in a 3 column grid, and don’t add a legend.\n\n\nExercise 5\nFinally, let’s plot all datasets at once. In order to do this we will make use of facetting.\n\nggplot(datasaurus_dozen, aes(x = x, y = y, color = dataset)) +\n  geom_point() +\n  facet_wrap(~ dataset, ncol = 3) +\n  theme(legend.position = \"none\")\n\nAnd we can use the group_by function to generate all the summary correlation coefficients.\n\ndatasaurus_dozen |>\n  group_by(dataset) |>\n  summarize(r = cor(x, y))\n\nYou’re done with the data analysis exercises, but we’d like you to do two more things:\n\n\n\n\n\nFigure 1: ?(caption)"
  },
  {
    "objectID": "content/labs/01-lab-intro-r.html#bonus-exercises",
    "href": "content/labs/01-lab-intro-r.html#bonus-exercises",
    "title": "Lab 01 - Tooling",
    "section": "Bonus Exercises",
    "text": "Bonus Exercises\nComplete these as time permits to further your experience with, comfort in, and understanding of R Markdown documents.\n\nResize your figures\nClick on the gear icon in on top of the R Markdown document, and select “Output Options…” in the dropdown menu. In the pop up dialogue box go to the Figures tab and change the height and width of the figures, and hit OK when done. Then, knit your document and see how you like the new sizes. Change and knit again and again until you’re happy with the figure sizes. Note that these values get saved in the YAML.\n\n\n\n\n\nFigure 2: ?(caption)\n\n\n\n\nYou can also use different figure sizes for different figures. To do so click on the gear icon within the chunk where you want to make a change. Changing the figure sizes added new options to these chunks: fig.width and fig.height. You can change them by defining different values directly in your R Markdown document as well.\n\n\n\n\n\n\n\nChange the look of your report\nOnce again click on the gear icon in on top of the R Markdown document, and select “Output Options…” in the dropdown menu. In the General tab of the pop up dialogue box try out different Syntax highlighting and theme options. Hit OK and knit your document to see how it looks. Play around with these until you’re happy with the look.\n\n\n\n\n\n\nNote\n\n\n\nNot sure how to use emojis on your computer? Maybe a classmate can help? Or you can ask your TA as well!"
  },
  {
    "objectID": "content/hw/hw-01.html",
    "href": "content/hw/hw-01.html",
    "title": "HW 01 - R Basics",
    "section": "",
    "text": "This assignment is meant to get you comfortable with 1) the format of homework assignments in this course and 2) writing R code in RStudio. The specific questions on this assignment will be simpler and should take you less time than those on future assignments. This assignment focuses on variables, operators, datasets, and dplyr basics.\n\nGetting started\nHere are the steps for getting started:\n\nStart by navigating to the hw01 GitHub URL (found on Canvas)\nClone this repo into RStudio on datahub\nMake any changes needed as outlined by the tasks you need to complete for the assignment\nPeriodically knit your file and take a look at the document generated\nCommit changes (for example, once per each new part)\nPush all your changes back to your GitHub repo\n\nYou can of course push multiple to GitHub times throughout the assignment. Your final push at the deadline will be used for grading. (This means even if you made mistakes before that on GitHub, you wouldn’t be penalized for them, so long as the final state of your work is correct).\n\n\n\n\n\n\nImportant\n\n\n\nYou’ll always want to knit your RMarkdown document to HTML and review that HTML document to ensure it includes all the information you want and looks as you intended, as we grade from the knit HTML. Both your .Rmd and .html files should be on GitHub."
  },
  {
    "objectID": "content/hw/hw-03.html",
    "href": "content/hw/hw-03.html",
    "title": "HW 03 - Bike rentals in DC",
    "section": "",
    "text": "Bike sharing systems take traditional bike rentals but automate the entire process (membership, rental, return, etc.). Through these systems, users are able to easily rent a bike from a particular position and return it at another position. There are hundreds of bike-sharing programs around the world comprising hundreds of thousands of bicycles. Today, there exists great interest in these (and other “alternative” transit) systems due to their important role in traffic, environmental, and health issues.\nApart from interesting real world applications of bike sharing systems, the characteristics of data being generated by these systems make them attractive for research. Opposed to other transport services such as bus or subway, the duration of travel, departure and arrival position is explicitly recorded in these systems. This feature turns bike sharing system into a virtual sensor network that can be used for sensing mobility in the city. Hence, it is expected that most of important events in the city could be detected via monitoring these data.\nSource: UCI Machine Learning Repository - Bike Sharing Dataset"
  },
  {
    "objectID": "content/hw/hw-03.html#getting-started",
    "href": "content/hw/hw-03.html#getting-started",
    "title": "HW 03 - Bike rentals in DC",
    "section": "Getting started",
    "text": "Getting started\nHere are the steps for getting started:\n\nStart with an assignment link that creates the GitHub repo with starter documents (link on Canvas).\nClone this repo into RStudio on datahub\nMake any changes needed as outlined by the tasks you need to complete for the assignment\nPeriodically commit changes (for example, once per each new part)\nPush all your changes back to your GitHub repo\nThis assignment will be graded from GitHub.\n\nYour final GitHub push prior to the deadline will be used for grading. (This means even if you made mistakes before that submission on GitHub, you won’t be penalized for them, so long as the final state of your work is correct)."
  },
  {
    "objectID": "content/hw/hw-03.html#data",
    "href": "content/hw/hw-03.html#data",
    "title": "HW 03 - Bike rentals in DC",
    "section": "Data",
    "text": "Data\nThe data include daily bike rental counts (by members and casual users) of Capital Bikeshare in Washington, DC in 2011 and 2012 as well as weather information on these days.\nThe original data sources are http://capitalbikeshare.com/system-data and http://www.freemeteo.com.\nThe codebook is below:\n\n\n\n\n\n\n\nVariable name\nDescription\n\n\n\n\ninstant\nrecord index\n\n\ndteday\ndate\n\n\nseason\nseason (1:winter, 2:spring, 3:summer, 4:fall)\n\n\nyr\nyear (0: 2011, 1:2012)\n\n\nmnth\nmonth (1 to 12)\n\n\nholiday\nweather day is holiday or not (extracted from http://dchr.dc.gov/page/holiday-schedule)\n\n\nweekday\nday of the week\n\n\nworkingday\nif day is neither weekend nor holiday is 1, otherwise is 0.\n\n\nweathersit\n1: Clear, Few clouds, Partly cloudy, Partly cloudy\n\n\n\n2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n\n\n\n3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n\n\n\n4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog\n\n\ntemp\nNormalized temperature in Celsius. The values are divided by 41 (max)\n\n\natemp\nNormalized feeling temperature in Celsius. The values are divided by 50 (max)\n\n\nhum\nNormalized humidity. The values are divided by 100 (max)\n\n\nwindspeed\nNormalized wind speed. The values are divided by 67 (max)\n\n\ncasual\nCount of casual users\n\n\nregistered\nCount of registered users\n\n\ncnt\nCount of total rental bikes including both casual and registered"
  },
  {
    "objectID": "content/hw/hw-03.html#setup",
    "href": "content/hw/hw-03.html#setup",
    "title": "HW 03 - Bike rentals in DC",
    "section": "Setup",
    "text": "Setup\nYou are free to utilize any packages in this homework. We think you’ll likely use tidyverse, tidymodels (…and maybe olsrr)"
  },
  {
    "objectID": "content/hw/hw-03.html#questions",
    "href": "content/hw/hw-03.html#questions",
    "title": "HW 03 - Bike rentals in DC",
    "section": "Questions",
    "text": "Questions\n\nData wrangling\n\nQuestion 1\nRecode the season variable to be a factor with meaningful level names as outlined in the codebook, with spring as the baseline level.\n\n\nQuestion 2\nRecode the binary variables holiday and workingday to be factors with levels no (0) and yes (1), with no as the baseline level.\n\n\nQuestion 3\nRecode the yr variable to be a factor with levels 2011 and 2012, with 2011 as the baseline level.\n\n\nQuestion 4\nRecode the weathersit variable as 1 - clear, 2 - mist, 3 - light precipitation, and 4 - heavy precipitation, with clear as the baseline.\n\n\nQuestion 5\nCalculate raw temperature, feeling temperature, humidity, and windspeed as their values given in the dataset multiplied by the maximum raw values stated in the codebook for each variable. Instead of writing over the existing variables, create new ones with concise but informative names.\n\n\nQuestion 6\nCheck that the sum of casual and registered adds up to cnt for each record.\n\n\n\nExploratory data analysis\n\nQuestion 7\nRecreate the following visualization, and interpret it in context of the data. Hint: You will need to use one of the variables you created above.\n\n\n\nQuestion 8\nCreate a visualization displaying the relationship between bike rentals and season. Interpret the plot in context of the data.\n\n\n\nModelling\n\nQuestion 9\nFit a linear model predicting total daily bike rentals from daily temperature. Write the linear model, interpret the slope and the intercept in context of the data, and determine and interpret the \\(R^2\\).\n\n\nQuestion 10\nFit another linear model predicting total daily bike rentals from daily feeling temperature. Write the linear model, interpret the slope and the intercept in context of the data, and determine and interpret the \\(R^2\\). Is temperature or feeling temperature a better predictor of bike rentals?\n\n\nQuestion 11\nFit a full model predicting total daily bike rentals from season, year, whether the day is holiday or not, whether the day is a workingday or not, the weather category, temperature, feeling temperature, humidity, and windspeed, as well as the interaction between at least one numerical and one categorical variable.\n\n\nQuestion 12\nPerform backward selection using adjusted \\(R^2\\) as the decision criterion to find the “best” model. Provide the model output for the final model.\n\n\nQuestion 13\nInterpret slope coefficients associated with two of the variables in your final model in context of the data. Note: If one of these is categorical with multiple levels, make sure you interpret all of the slope coefficients associated with the levels of the variable.\n\n\nQuestion 14\nBased on the final model you found in the previous question, discuss what makes for a good day to bike in DC (as measured by rental bikes being more in demand)."
  },
  {
    "objectID": "content/hw/hw-03.html#submission",
    "href": "content/hw/hw-03.html#submission",
    "title": "HW 03 - Bike rentals in DC",
    "section": "Submission",
    "text": "Submission\nBe sure to knit your file to HTML, look at the output HTML file to make sure everything looks as you expected, and then commit and push your final changes to GitHub. We will be grading from the HTML file. Before you wrap up the assignment, make sure all documents are updated on your GitHub repo."
  },
  {
    "objectID": "content/hw/hw-02.html",
    "href": "content/hw/hw-02.html",
    "title": "HW 02 - Data Visualization",
    "section": "",
    "text": "This assignment is meant to get you more comfortable with generating and customizing visualizations in R using ggplot2. The first section will guide you toward the visualizations you’re expected to generate, while the final two sections will be more open-ended. There are multiple distinct visualizations that could be totally “correct” for each question. You may make a different decision than your classmate and could both be correct.\nAlso, note that the final two parts of this assignment will take you way longer than you think they will. Definitely do not wait until the last minute to start this assignment."
  },
  {
    "objectID": "content/hw/hw-02.html#getting-started",
    "href": "content/hw/hw-02.html#getting-started",
    "title": "HW 02 - Data Visualization",
    "section": "Getting started",
    "text": "Getting started\nHere are the steps for getting started:\n\nStart with an assignment link that creates a repo on GitHub with starter documents (link on Canvas).\nClone this repo into RStudio on datahub\nMake any changes needed as outlined by the tasks you need to complete for the assignment\nPeriodically commit changes (for example, once per each new part)\nPush all your changes back to your GitHub repo\nThis assignment will be graded from GitHub.\n\nYour final GitHub push prior to the deadline will be used for grading. (This means even if you made mistakes before that submission on GitHub, you won’t be penalized for them, so long as the final state of your work is correct).\n\nImports\nThe following packages must be imported prior to completing this homework: tidyverse and palmerpenguins (Note: If you did not install palmerpenguins during lecture, you’ll have to run install.packages(\"palmerpenguins\") prior to importing it.)\n\n\nGround Rules\nFor this assignment, all visualizations must:\n\nbe completed using ggplot2\nhave an informative title and labeled axes\nfollow good visualization practices (discussed in class)"
  },
  {
    "objectID": "content/hw/hw-02.html#part-i-ggplot2",
    "href": "content/hw/hw-02.html#part-i-ggplot2",
    "title": "HW 02 - Data Visualization",
    "section": "Part I: ggplot2",
    "text": "Part I: ggplot2\nThis first section will continue to use the penguins dataset from the palmerpenguins package that was used during the ggplot2 lecture.\n\nQuestion 1\nGenerate a visualization that will allow readers to determine whether male or female penguins are larger (by mass).\n\n\nQuestion 2\nGenerate a barplot that visualizes how many penguins there are from each species on each island. Each island should be a different panel (in a 1 row x 3 columns visualization), and each chart should visualize the species count.\n\n\nQuestion 3\nGenerate a scatterplot that will allow the viewer to determine whether flipper length has differed over time. Be sure to color the points on this plot by species."
  },
  {
    "objectID": "content/hw/hw-02.html#part-ii-imitation-is-the-highest-form-of-flattery",
    "href": "content/hw/hw-02.html#part-ii-imitation-is-the-highest-form-of-flattery",
    "title": "HW 02 - Data Visualization",
    "section": "Part II: Imitation is the highest form of flattery",
    "text": "Part II: Imitation is the highest form of flattery\nIn class we learned a handful of ways to customize visualizations. Now, it’s your turn to apply what you learned by recreating someone else’s visualization.\n\nQuestion 4\nFor this question, find a visualization somewhere on the Internet and recreate the visualization as close as you can using ggplot2. To make this easier on yourself, you’ll likely want to find a visualization where the data are readily available. (To get started, FiveThirtyEight makes a lot of the data from their articles available and has many charts in their articles. You are not required to recreate a visualization from FiveThirtyEight; however, if you’re not sure where to start, you have this option.) Your answer should include an image of the original visualization, a reference to the original image (this could simply be a URL), and your code + recreation.\nNotes: - To insert an image in an RMarkdown document, you can use the syntax ![alt text](path/to/image.png). - The R/ggplot2 code to create your visualization cannot already exist on the internet. (For example, choosing to recreate a plot from the R Graph Gallery would not be an option b/c all the code is already there and you wouldn’t learn as much.)\n\n\nQuestion 5\nBriefly explain what you learned about ggplot2 in the process of re-creating this visualization.\n\n\nQuestion 6\nExplain how your visualization differs from the original (It’s OK if yours is not a perfect recreation!)"
  },
  {
    "objectID": "content/hw/hw-02.html#part-iii-take-a-sad-plot-and-make-it-better",
    "href": "content/hw/hw-02.html#part-iii-take-a-sad-plot-and-make-it-better",
    "title": "HW 02 - Data Visualization",
    "section": "Part III: Take a sad plot and make it better",
    "text": "Part III: Take a sad plot and make it better\n\nQuestion 7\nThis question was inspired by Alison Hill’s talk. The idea here is that there is a lot of data all around us and a whole bunch of visualizations. Some of them are really excellent, and some could be improved. Choose a visualization you’ve created in the past OR a visualization you’ve found out in the world that could benefit from a redesign and/or significant visual improvement. (This could be the same visualization you recreated above, but for most it will likely be a totally different visualization.) Your answer should include an image of the original visualization, a reference to the original image (this could simply be a URL), and your code + improved version.\nNote: If you’re unsure where to look for visualizations that would benefit from improvement, check out Flowing Data’s Ugly Charts or Reddit’s Data is ugly. You may need to recreate the dataset (meaning store the values from the visualization in a tibble) needed to generate the visualization prior to improving the design.\n\n\nQuestion 8\nBriefly explain what you learned about ggplot2 in the process of re-creating this visualization.\n\n\nQuestion 9\nExplain why you made the design and visualization choices you did for your improved version."
  },
  {
    "objectID": "content/hw/hw-02.html#submission",
    "href": "content/hw/hw-02.html#submission",
    "title": "HW 02 - Data Visualization",
    "section": "Submission",
    "text": "Submission\nBe sure to knit your file to HTML, look at the output HTML file to make sure everything looks as you expected, and then commit and push your final changes to GitHub. We will be grading from the HTML file. Before you wrap up the assignment, make sure all documents are updated on your GitHub repo."
  },
  {
    "objectID": "content/cs/cs01.html",
    "href": "content/cs/cs01.html",
    "title": "CS01: Right-To-Carry",
    "section": "",
    "text": "This is where you get to put together all you’ve learned so far this quarter into a full data science report! This report will include your analysis from top (the background and question) to bottom (your analysis, interpretation, and conclusions.)\nWe’ll be grading to see that you have: 1) all necessary code for each section of the project. 2) explanatory text that guides the reader from start to finish. 3) polished visualizations that allow the reader to both understand the data you’re working with an your conclusions.\nThis will be submitted and graded as a group. One submission per group."
  },
  {
    "objectID": "content/cs/cs01.html#getting-started",
    "href": "content/cs/cs01.html#getting-started",
    "title": "CS01: Right-To-Carry",
    "section": "Getting started",
    "text": "Getting started\nHere are the steps for getting started:\n\nThis will be completed in cs01 group repository that has been created for you and your group mates.\nMake any changes needed as outlined by the tasks you need to complete for the assignment\nPeriodically knit and commit changes (for example, once per each new part)1\nPush all your changes back to your GitHub repo\nThis case study will be graded from GitHub.\n\nYour final GitHub push prior to the deadline will be used for grading.\n\nImports\nYou are allowed to import whichever packages you like for this case study report."
  },
  {
    "objectID": "content/cs/cs01.html#case-study-report",
    "href": "content/cs/cs01.html#case-study-report",
    "title": "CS01: Right-To-Carry",
    "section": "Case Study Report",
    "text": "Case Study Report\nYour case study can be organized however you see best fit, but we’ll be looking for the following general sections:\n\nTitle\nAuthors\nBackground/Introduction\nQuestion(s)\nData Explanation\nData Import\nData Wrangling\nExploratory Data Analysis\nData Analysis\nResults\nDiscussion of results\nConclusion\n\nNow, you may want to combine some of these sections (i.e. include your results and discussion among your analysis code). That’s totally allowed, but we’ll be looking to see that your report includes sufficient information to understand what you did, why you did it, and what your results are.\n\nExtending the Analysis\nIn addition to getting the code presented in class working, adding explanatory text to your report, and generating polished visualizations, you and your group must “extend the analysis” presented in class in a meaningful way. Now “meaningful” is not a very-easily-measured term. A meaningful extension could be carrying out analysis to answer an additional sub-question beyond what was presented in class, or including a really extensive exploratory data analysis, or generating a really superb set of visualizations to convey your groups’ results, or finding a related dataset and incorporating it into your case study. To determine whether your extension is “meaningful,” you and your group should be able to answer “yes” to the question “Does our extension add something important to this report beyond what was presented in class?”\nThis extension should be included/weaved into your report, meaning it should only be “separated out” as its own section if it makes most sense for the story you’re telling."
  },
  {
    "objectID": "content/cs/cs01.html#group-feedback",
    "href": "content/cs/cs01.html#group-feedback",
    "title": "CS01: Right-To-Carry",
    "section": "Group Feedback",
    "text": "Group Feedback\nThere will be a form to submit upon submission of the case study to provide feedback about working with your group mates. This is meant to motivate not scare. Most groups work out really really well and everyone contributes to the best of their ability. However, if and when that doesn’t happen, I want to be sure I’m aware of the circumstances and follow up as necessary."
  },
  {
    "objectID": "content/labslides/03-lab-deck.html#agenda",
    "href": "content/labslides/03-lab-deck.html#agenda",
    "title": "Lab 03: Exploring & Visualizing Data",
    "section": "Agenda",
    "text": "Agenda\n\nTips:\n\nBriefly review a question regarding sorting.\nReview numeric vs categorical variable types.\n\nLab introduction:\n\nReview FiveThirtyEight article on college majors."
  },
  {
    "objectID": "content/labslides/03-lab-deck.html#lab-intro",
    "href": "content/labslides/03-lab-deck.html#lab-intro",
    "title": "Lab 03: Exploring & Visualizing Data",
    "section": "Lab Intro",
    "text": "Lab Intro\n\nLab instructions posted on the course website.\nThe Economic Guide To Picking A College Major by Ben Casselman"
  },
  {
    "objectID": "content/labslides/03-lab-deck.html#reminders",
    "href": "content/labslides/03-lab-deck.html#reminders",
    "title": "Lab 03: Exploring & Visualizing Data",
    "section": "Reminders",
    "text": "Reminders\n\nStart with library(tidyverse) (includes tidyr, readr, dplyr, etc.)\nClone using ‘SSH’ link from GitHub\nKnit to .html & push both .Rmd and .html to GitHub"
  },
  {
    "objectID": "content/labslides/03-lab-deck.html#tips",
    "href": "content/labslides/03-lab-deck.html#tips",
    "title": "Lab 03: Exploring & Visualizing Data",
    "section": "Tips",
    "text": "Tips\n\nBe ready to troubleshoot your document, since it will likely fail to knit on multiple occasions throughout the process. Read the error message carefully and take note of which line is preventing a successful knit.\nMake sure to keep track of your various chunks and to keep text and code in the right place.\nRemember that your R Markdown file is not aware of your project’s global environment and can only make use of variables, functions, etc. that you have loaded or defined in the document.\nRemind yourself how the pipe operator (|>) works.\nIf you’re unsure how a function works or what its arguments are, type ? in front of it and hit enter (?read_csv for instance). The “Help” tab will open and provide a summary of the function as well as some examples."
  },
  {
    "objectID": "content/labslides/02-lab-deck.html#reminders",
    "href": "content/labslides/02-lab-deck.html#reminders",
    "title": "Lab 02: Wrangling",
    "section": "Reminders",
    "text": "Reminders\n\nStart with library(tidyverse) (includes tidyr, readr, dplyr, etc.)\nClone using ‘SSH’ link from GitHub\nKnit to .html & push both .Rmd and .html to GitHub"
  },
  {
    "objectID": "content/labslides/02-lab-deck.html#starting-a-new-project",
    "href": "content/labslides/02-lab-deck.html#starting-a-new-project",
    "title": "Lab 02: Wrangling",
    "section": "Starting a new project",
    "text": "Starting a new project\n\nGo to Canvas to find the link for today’s lab: lab03-wi23.\nOn GitHub, click on the green Clone or download button, select use SSH (this might already be selected by default, and if it is, you’ll see the text Clone with SSH). Click on the clipboard icon to copy the repo URL.\nGo to RStudio on datahub. Create a New Project from Git Repo. You will need to click on the down arrow next to the New Project button to see this option.\nCopy and paste the URL of your assignment repo into the dialog box and hit OK.\nOpen the .Rmd file with your template in it. Be sure to update the author to your name."
  },
  {
    "objectID": "content/labslides/02-lab-deck.html#agenda",
    "href": "content/labslides/02-lab-deck.html#agenda",
    "title": "Lab 02: Wrangling",
    "section": "Agenda",
    "text": "Agenda\n\nLab 02 intro and demos: Introduce the lab, and work through the first question as a class.\nOn your own: Work on the rest of the lab “on your own”, but feel free to check in with classmates as much as you like."
  },
  {
    "objectID": "content/labslides/02-lab-deck.html#dplyr-review",
    "href": "content/labslides/02-lab-deck.html#dplyr-review",
    "title": "Lab 02: Wrangling",
    "section": "dplyr: Review",
    "text": "dplyr: Review\ndplyr provides a “Grammar of Data Manipulation” and is based on the concepts of functions as verbs that manipulate data frames.\n\nfilter: pick rows matching criteria\nslice: pick rows using index(es)\nselect: pick columns by name\npull: grab a column as a vector\nrename: rename specific columns\narrange: reorder rows\nmutate: add new variables\ntransmute: create new data frame with variables\ndistinct: filter for unique rows\nsample_n / sample_frac: randomly sample rows\nsummarize: reduce variables to values\n… (many more)"
  },
  {
    "objectID": "content/labslides/02-lab-deck.html#the-data",
    "href": "content/labslides/02-lab-deck.html#the-data",
    "title": "Lab 02: Wrangling",
    "section": "The Data",
    "text": "The Data\n\nstorms |>\n  slice(1:20)\n\n# A tibble: 20 × 13\n   name   year month   day  hour   lat  long status        categ…¹  wind press…²\n   <chr> <dbl> <dbl> <int> <dbl> <dbl> <dbl> <chr>         <ord>   <int>   <int>\n 1 Amy    1975     6    27     0  27.5 -79   tropical dep… -1         25    1013\n 2 Amy    1975     6    27     6  28.5 -79   tropical dep… -1         25    1013\n 3 Amy    1975     6    27    12  29.5 -79   tropical dep… -1         25    1013\n 4 Amy    1975     6    27    18  30.5 -79   tropical dep… -1         25    1013\n 5 Amy    1975     6    28     0  31.5 -78.8 tropical dep… -1         25    1012\n 6 Amy    1975     6    28     6  32.4 -78.7 tropical dep… -1         25    1012\n 7 Amy    1975     6    28    12  33.3 -78   tropical dep… -1         25    1011\n 8 Amy    1975     6    28    18  34   -77   tropical dep… -1         30    1006\n 9 Amy    1975     6    29     0  34.4 -75.8 tropical sto… 0          35    1004\n10 Amy    1975     6    29     6  34   -74.8 tropical sto… 0          40    1002\n11 Amy    1975     6    29    12  33.8 -73.8 tropical sto… 0          45    1000\n12 Amy    1975     6    29    18  33.8 -72.8 tropical sto… 0          50     998\n13 Amy    1975     6    30     0  34.3 -71.6 tropical sto… 0          50     998\n14 Amy    1975     6    30     6  35.6 -70.8 tropical sto… 0          55     998\n15 Amy    1975     6    30    12  35.9 -70.5 tropical sto… 0          60     987\n16 Amy    1975     6    30    18  36.2 -70.2 tropical sto… 0          60     987\n17 Amy    1975     7     1     0  36.2 -69.8 tropical sto… 0          60     984\n18 Amy    1975     7     1     6  36.2 -69.4 tropical sto… 0          60     984\n19 Amy    1975     7     1    12  36.2 -68.3 tropical sto… 0          60     984\n20 Amy    1975     7     1    18  36.7 -67.2 tropical sto… 0          60     984\n# … with 2 more variables: tropicalstorm_force_diameter <int>,\n#   hurricane_force_diameter <int>, and abbreviated variable names ¹​category,\n#   ²​pressure"
  },
  {
    "objectID": "content/labslides/02-lab-deck.html#the-data-documentation",
    "href": "content/labslides/02-lab-deck.html#the-data-documentation",
    "title": "Lab 02: Wrangling",
    "section": "The Data: Documentation",
    "text": "The Data: Documentation\nFrom the console…\n\n?storms\n\n\n\n\nhttps://cogs137.github.io/website/"
  },
  {
    "objectID": "content/labslides/05-lab-deck.html#agenda",
    "href": "content/labslides/05-lab-deck.html#agenda",
    "title": "Lab 05: Modelling course evals (Pt. 2)",
    "section": "Agenda",
    "text": "Agenda\n\nDocumentation\nLab 05: Modelling course evaluations\nGetting started with lab"
  },
  {
    "objectID": "content/labslides/05-lab-deck.html#documentation",
    "href": "content/labslides/05-lab-deck.html#documentation",
    "title": "Lab 05: Modelling course evals (Pt. 2)",
    "section": "Documentation",
    "text": "Documentation\nDemo on how to utilize/read/understand R Documentation"
  },
  {
    "objectID": "content/labslides/05-lab-deck.html#reminder-data-come-from",
    "href": "content/labslides/05-lab-deck.html#reminder-data-come-from",
    "title": "Lab 05: Modelling course evals (Pt. 2)",
    "section": "Reminder: Data come from…",
    "text": "Reminder: Data come from…\n“Beauty in the classroom: instructors’ pulchritude and putative pedagogical productivity”\nDaniel S. Hamermesh, Amy Parker, Beauty in the classroom: instructors pulchritude and putative pedagogical productivity, Economics of Education Review, Volume 24, Issue 4, August 2005. http://www.sciencedirect.com/science/article/pii/S0272775704001165"
  },
  {
    "objectID": "content/labslides/05-lab-deck.html#some-notes-on-this-lab",
    "href": "content/labslides/05-lab-deck.html#some-notes-on-this-lab",
    "title": "Lab 05: Modelling course evals (Pt. 2)",
    "section": "Some notes on this lab",
    "text": "Some notes on this lab\n\nThis is an extension of lab04. It may be worth briefly looking over that lab and/or the answer key to get that fresh in your mind prior to beginning this lab.\nThere are three parts. Ideally, you’d get through Exercise 12. We’ll be looking to see you’ve fit and interpreted models with multiple predictors.\n\n\n\n\nhttps://cogs137.github.io/website/"
  },
  {
    "objectID": "content/labslides/01-lab-deck.html#agenda",
    "href": "content/labslides/01-lab-deck.html#agenda",
    "title": "Lab 01: Tooling",
    "section": "Agenda",
    "text": "Agenda\n\nLab structure: Lab structure overview.\nLab 01 intro and demos: Introduce the lab, and work through the first section as a class.\nOn your own: Work on the rest of the lab “on your own”, but feel free to check in with classmates as much as you like."
  },
  {
    "objectID": "content/labslides/01-lab-deck.html#lab-strucuture-1",
    "href": "content/labslides/01-lab-deck.html#lab-strucuture-1",
    "title": "Lab 01: Tooling",
    "section": "Lab strucuture",
    "text": "Lab strucuture\n\n5-10 minute introduction (a bit longer today)\nUse the remaining time to work through the lab exercises and fill out your lab report\n\nSubmit: on your own\nWorking: always allowed to work together\n\nLab instructions posted on the course website on the left panel under “Labs”\n\nLet’s go find today’s lab!"
  },
  {
    "objectID": "content/labslides/01-lab-deck.html#tips",
    "href": "content/labslides/01-lab-deck.html#tips",
    "title": "Lab 01: Tooling",
    "section": "Tips",
    "text": "Tips\n\nYou do not have to finish the lab in class; you have until midnight to submit. But, you might choose to get through portions that you think will be challenging (which initially might be the coding component) in class when staff can help you on the spot, and leave the narrative writing until later.\nDo not pressure each other to finish early; use the time wisely to really learn the material and produce a quality lab.\nWhen working with others, do not split up lab among classmates, work on it together in its entirety.\nSometimes you may not finish the entire lab…and that’s ok! When this happens or you’re unsure about what you turn in, be sure to go back and check your thoughts/work against the posted answer key."
  },
  {
    "objectID": "content/labslides/01-lab-deck.html#goals",
    "href": "content/labslides/01-lab-deck.html#goals",
    "title": "Lab 01: Tooling",
    "section": "Goals",
    "text": "Goals\n\nIntroduce you to Git and GitHub: collaboration and version control system that we will be using throughout the course\n\nGit is a version control system – like “Track Changes” features from Microsoft Word/Google Docs on steroids\nGitHub is the home for your git-based projects on the internet\nConnect your RStudio on datahub to your GitHub account\n\nIntroduce you to R and RStudio:\n\nR is the name of the programming language itself\nRStudio is a convenient interface"
  },
  {
    "objectID": "content/labslides/01-lab-deck.html#getting-started-github-datahub",
    "href": "content/labslides/01-lab-deck.html#getting-started-github-datahub",
    "title": "Lab 01: Tooling",
    "section": "Getting started: GitHub & datahub",
    "text": "Getting started: GitHub & datahub\nFirst, put away computers, and watch me do it:\n\nDemo of the process\nSteps are spelled out in the “GitHub Housekeeping” portion of the lab"
  },
  {
    "objectID": "content/labslides/01-lab-deck.html#getting-started-assignment-retrieval",
    "href": "content/labslides/01-lab-deck.html#getting-started-assignment-retrieval",
    "title": "Lab 01: Tooling",
    "section": "Getting started: Assignment Retrieval",
    "text": "Getting started: Assignment Retrieval\nFirst, put away computers, and watch me do it:\n\nClick on the assignment link on Canvas for today’s lab to create your GitHub repository (which we’ll refer to as “repo” going forward) for the lab. This repo contains a template you can build on to complete your lab.\nOn GitHub, accept the assignment. Click on the clipboard icon to copy the repo URL.\nGo to datahub. and open RStudio. Go to File > New Project… and select to create a New Project from Version Control. On the following menu, select Git.\nCopy and paste the URL of your assignment repo into the “Repository URL” dialog box.\nHit Create Project.\n\nNow it’s your turn! Place a green sticky on your laptop when you’re done with this part (you can continue if you like). Place a pink sticky if you have questions."
  },
  {
    "objectID": "content/lab-ans/lab03-viz-ans.html",
    "href": "content/lab-ans/lab03-viz-ans.html",
    "title": "Lab 03 - Data Visualization (Ans)",
    "section": "",
    "text": "library(tidyverse)"
  },
  {
    "objectID": "content/lab-ans/lab03-viz-ans.html#which-major-has-the-lowest-unemployment-rate",
    "href": "content/lab-ans/lab03-viz-ans.html#which-major-has-the-lowest-unemployment-rate",
    "title": "Lab 03 - Data Visualization (Ans)",
    "section": "Which major has the lowest unemployment rate?",
    "text": "Which major has the lowest unemployment rate?\n\ncollege_recent_grads |>\n  arrange(unemployment_rate) |>\n  select(rank, major, unemployment_rate)\n\n# A tibble: 173 × 3\n    rank major                                      unemployment_rate\n   <dbl> <chr>                                                  <dbl>\n 1    53 Mathematics And Computer Science                     0      \n 2    74 Military Technologies                                0      \n 3    84 Botany                                               0      \n 4   113 Soil Science                                         0      \n 5   121 Educational Administration And Supervision           0      \n 6    15 Engineering Mechanics Physics And Science            0.00633\n 7    20 Court Reporting                                      0.0117 \n 8   120 Mathematics Teacher Education                        0.0162 \n 9     1 Petroleum Engineering                                0.0184 \n10    65 General Agriculture                                  0.0196 \n# … with 163 more rows\n\n\nDisplay only 4 decimal places using mutate and round:\n\ncollege_recent_grads |>\n  arrange(unemployment_rate) |>\n  select(rank, major, unemployment_rate) |>\n  mutate(unemployment_rate = round(unemployment_rate, digits = 4))\n\n# A tibble: 173 × 3\n    rank major                                      unemployment_rate\n   <dbl> <chr>                                                  <dbl>\n 1    53 Mathematics And Computer Science                      0     \n 2    74 Military Technologies                                 0     \n 3    84 Botany                                                0     \n 4   113 Soil Science                                          0     \n 5   121 Educational Administration And Supervision            0     \n 6    15 Engineering Mechanics Physics And Science             0.0063\n 7    20 Court Reporting                                       0.0117\n 8   120 Mathematics Teacher Education                         0.0162\n 9     1 Petroleum Engineering                                 0.0184\n10    65 General Agriculture                                   0.0196\n# … with 163 more rows\n\n\nDisplay 2 scientific digits using options:\n\noptions(digits = 2)\n\n\nExercise 1\nWhich of these options, changing the input data or altering the number of digits displayed without touching the input data, is the better option? Explain your reasoning. Then, implement the option you chose.\nI prefer the options approach because it will enforce consistency each time we display variables, without having to make the call to round each time (without changing the underlying data)."
  },
  {
    "objectID": "content/lab-ans/lab03-viz-ans.html#which-major-has-the-highest-percentage-of-women",
    "href": "content/lab-ans/lab03-viz-ans.html#which-major-has-the-highest-percentage-of-women",
    "title": "Lab 03 - Data Visualization (Ans)",
    "section": "Which major has the highest percentage of women?",
    "text": "Which major has the highest percentage of women?\n\nExercise 2\nUsing what you’ve learned so far, arrange the data in descending order with respect to proportion of women in a major, and display only the major, the total number of people with major, and proportion of women. Show only the top 3 majors by adding head(3) at the end of the pipeline.\nThe sharewomen column lists the proportion of women in each major. So we can arrange our data in descending order using desc(sharewomen), then select the columns we want: major, total, and sharewomen. We then just display the top 3 majors using head(3).\n\ncollege_recent_grads |>\n  arrange(desc(sharewomen)) |>\n  select(major, total, sharewomen) |>\n  head(3)\n\n# A tibble: 3 × 3\n  major                                         total sharewomen\n  <chr>                                         <dbl>      <dbl>\n1 Early Childhood Education                     37589      0.969\n2 Communication Disorders Sciences And Services 38279      0.968\n3 Medical Assisting Services                    11123      0.928"
  },
  {
    "objectID": "content/lab-ans/lab03-viz-ans.html#how-do-the-distributions-of-median-income-compare-across-major-categories",
    "href": "content/lab-ans/lab03-viz-ans.html#how-do-the-distributions-of-median-income-compare-across-major-categories",
    "title": "Lab 03 - Data Visualization (Ans)",
    "section": "How do the distributions of median income compare across major categories?",
    "text": "How do the distributions of median income compare across major categories?\n\nExercise 3\nWhy do we often choose the median, rather than the mean, to describe the typical income of a group of people?\nThe mean is more affected by the presence of outliers and by the skew of the distribution. Thus, the presence of a single person with very high income can increase the mean substantively, such that it’s no longer a good impression of the overall distribution. In contrast, the median (or the “middle number”) tells us the income exactly in the middle of the distribution.\n\n\nExercise 4\nTry binwidths of $1000 and $5000 and choose one. Explain your reasoning for your choice. Note that the binwidth is an argument for the geom_histogram function. So to specify a binwidth of $1000, you would use geom_histogram(binwidth = 1000).\n\nggplot(data = college_recent_grads, mapping = aes(x = median)) +\n  geom_histogram(binwidth=5000)\n\n\n\n\nI ended up choosing binwidth=5000. When binwidth=1000, there were too many small differences in income that were thus not grouped together, and it was harder to see the overall shape of the distribution.\nWe can also calculate summary statistics for this distribution using the summarise function:\n\ncollege_recent_grads |>\n  summarise(min = min(median), max = max(median),\n            mean = mean(median), med = median(median),\n            sd = sd(median), \n            q1 = quantile(median, probs = 0.25),\n            q3 = quantile(median, probs = 0.75))\n\n# A tibble: 1 × 7\n    min    max   mean   med     sd    q1    q3\n  <dbl>  <dbl>  <dbl> <dbl>  <dbl> <dbl> <dbl>\n1 22000 110000 40151. 36000 11470. 33000 45000\n\n\n\n\nExercise 5\nBased on the shape of the histogram you created in the previous exercise, determine which of these summary statistics is useful for describing the distribution. Write up your description (remember shape, center, spread, any unusual observations) and include the summary statistic output as well.\nThe underlying distribution of median incomes is somewhat right-skewed, with at least 1-2 majors making a lot of money. Because of this, I’m going to use the median median income.\nIt would be probably be fine to use the mean median income as well—judging by the distribution of median incomes in each major_category, which are relatively normal-ish.\n\n\nExercise 6\nPlot the distribution of median income using a histogram, faceted by major_category. Use the binwidth you chose in the earlier exercise.\n\nggplot(data = college_recent_grads, mapping = aes(x = median)) +\n  geom_histogram(binwidth = 5000) +\n  facet_wrap( ~ major_category, ncol = 4)\n\n\n\n\n\n\nExercise 7\nWhich major category has the highest typical (you’ll need to decide what this means) median income? Use the partial code below, filling it in with the appropriate statistic and function. Also note that we are looking for the highest statistic, so make sure to arrange in the correct direction.\n\ncollege_recent_grads |>\n  group_by(major_category) |>\n  summarise(median = median(median)) |>\n  arrange(desc(median))\n\n# A tibble: 16 × 2\n   major_category                      median\n   <chr>                                <dbl>\n 1 Engineering                          57000\n 2 Computers & Mathematics              45000\n 3 Business                             40000\n 4 Physical Sciences                    39500\n 5 Social Science                       38000\n 6 Biology & Life Science               36300\n 7 Law & Public Policy                  36000\n 8 Agriculture & Natural Resources      35000\n 9 Communications & Journalism          35000\n10 Health                               35000\n11 Industrial Arts & Consumer Services  35000\n12 Interdisciplinary                    35000\n13 Education                            32750\n14 Humanities & Liberal Arts            32000\n15 Arts                                 30750\n16 Psychology & Social Work             30000\n\n\nEngineering.\n\n\nExercise 8\nWhich major category is the least popular in this sample? To answer this question we use a new function called count, which first groups the data and then counts the number of observations in each category (see below). Add to the pipeline appropriately to arrange the results so that the major with the lowest observations is on top.\n\ncollege_recent_grads |>\n  count(major_category) |>\n  arrange(desc(-n))\n\n# A tibble: 16 × 2\n   major_category                          n\n   <chr>                               <int>\n 1 Interdisciplinary                       1\n 2 Communications & Journalism             4\n 3 Law & Public Policy                     5\n 4 Industrial Arts & Consumer Services     7\n 5 Arts                                    8\n 6 Psychology & Social Work                9\n 7 Social Science                          9\n 8 Agriculture & Natural Resources        10\n 9 Physical Sciences                      10\n10 Computers & Mathematics                11\n11 Health                                 12\n12 Business                               13\n13 Biology & Life Science                 14\n14 Humanities & Liberal Arts              15\n15 Education                              16\n16 Engineering                            29"
  },
  {
    "objectID": "content/lab-ans/lab03-viz-ans.html#all-stem-fields-arent-the-same",
    "href": "content/lab-ans/lab03-viz-ans.html#all-stem-fields-arent-the-same",
    "title": "Lab 03 - Data Visualization (Ans)",
    "section": "All STEM fields aren’t the same",
    "text": "All STEM fields aren’t the same\nFirst, let’s create a new vector called stem_categories that lists the major categories that are considered STEM fields.\n\nstem_categories <- c(\"Biology & Life Science\",\n                     \"Computers & Mathematics\",\n                     \"Engineering\",\n                     \"Physical Sciences\")\n\nThen, we can use this to create a new variable in our data frame indicating whether a major is STEM or not.\n\ncollege_recent_grads <- college_recent_grads |>\n  mutate(major_type = case_when(\n    major_category %in% stem_categories ~ \"stem\",\n    TRUE ~ \"not stem\"\n  ))\n\nWe can use the logical operators to also filter our data for STEM majors whose median earnings is less than median for all majors’s median earnings, which we found to be $36,000 earlier.\n\ncollege_recent_grads |>\n  filter(\n    major_type == \"stem\",\n    median < median(college_recent_grads$median)\n  )\n\n# A tibble: 10 × 22\n    rank major_code major   major…¹  total sampl…²    men  women share…³ emplo…⁴\n   <dbl>      <dbl> <chr>   <chr>    <dbl>   <dbl>  <dbl>  <dbl>   <dbl>   <dbl>\n 1    93       1301 Enviro… Biolog…  25965     225  10787  15178   0.585   20859\n 2    98       5098 Multi-… Physic…  62052     427  27015  35037   0.565   46138\n 3   102       3608 Physio… Biolog…  22060      99   8422  13638   0.618   14643\n 4   106       2001 Commun… Comput…  18035     208  11431   6604   0.366   14779\n 5   109       3611 Neuros… Biolog…  13663      53   4944   8719   0.638    9087\n 6   111       5002 Atmosp… Physic…   4043      32   2744   1299   0.321    3431\n 7   123       3699 Miscel… Biolog…  10706      63   4747   5959   0.557    7767\n 8   124       3600 Biology Biolog… 280709    1370 111762 168947   0.602  182295\n 9   133       3604 Ecology Biolog…   9154      86   3878   5276   0.576    7585\n10   169       3609 Zoology Biolog…   8409      47   3050   5359   0.637    6259\n# … with 12 more variables: employed_fulltime <dbl>, employed_parttime <dbl>,\n#   employed_fulltime_yearround <dbl>, unemployed <dbl>,\n#   unemployment_rate <dbl>, p25th <dbl>, median <dbl>, p75th <dbl>,\n#   college_jobs <dbl>, non_college_jobs <dbl>, low_wage_jobs <dbl>,\n#   major_type <chr>, and abbreviated variable names ¹​major_category,\n#   ²​sample_size, ³​sharewomen, ⁴​employed\n\n\n\nExercise 9\nWhich STEM majors have median salaries equal to or less than the median for all majors’s median earnings? Your output should only show the major name and median, 25th percentile, and 75th percentile earning for that major as and should be sorted such that the major with the highest median earning is on top.\n\ncollege_recent_grads |>\n  filter(\n    major_type == \"stem\",\n    median < median(college_recent_grads$median)\n  ) |>\n  select(major, median, p25th, p75th) |>\n  arrange(desc(median))\n\n# A tibble: 10 × 4\n   major                                 median p25th p75th\n   <chr>                                  <dbl> <dbl> <dbl>\n 1 Environmental Science                  35600 25000 40200\n 2 Multi-Disciplinary Or General Science  35000 24000 50000\n 3 Physiology                             35000 20000 50000\n 4 Communication Technologies             35000 25000 45000\n 5 Neuroscience                           35000 30000 44000\n 6 Atmospheric Sciences And Meteorology   35000 28000 50000\n 7 Miscellaneous Biology                  33500 23000 48000\n 8 Biology                                33400 24000 45000\n 9 Ecology                                33000 23000 42000\n10 Zoology                                26000 20000 39000"
  },
  {
    "objectID": "content/lab-ans/lab03-viz-ans.html#what-types-of-majors-do-women-tend-to-major-in",
    "href": "content/lab-ans/lab03-viz-ans.html#what-types-of-majors-do-women-tend-to-major-in",
    "title": "Lab 03 - Data Visualization (Ans)",
    "section": "What types of majors do women tend to major in?",
    "text": "What types of majors do women tend to major in?\n\nExercise 10\nCreate a scatterplot of median income vs. proportion of women in that major, colored by whether the major is in a STEM field or not. Describe the association between these three variables.\n\ncollege_recent_grads |>\n  drop_na(sharewomen) |> ## This will drop rows for which sharewomen has NA value\n  ggplot(aes(x = median,\n             y = sharewomen,\n             color = major_type)) +\n  geom_point(alpha = .6) +\n  labs(x = \"Median income for major\",\n       y = \"Share of women in major\",\n       color = \"STEM major?\")\n\n\n\n\nIn general, there appears to be a negative relationship between median income and the proportion of women (sharewomen) in a major. Both variables are also correlated with major_type: stem majors tend to have a lower proportion of women (and lower median income), while not stem majors have a higher proportion (and higher median income).\n(Note that the negative relationship with median income is somewhat clearer if log(median) is used instead.)"
  },
  {
    "objectID": "content/lab-ans/lab04-modelling-ans.html",
    "href": "content/lab-ans/lab04-modelling-ans.html",
    "title": "Lab 04 - Modelling (Ans)",
    "section": "",
    "text": "library(tidyverse)\nlibrary(tidymodels)\n\n\n\n\n\nevals <- read_csv(\"data/evals-mod.csv\")"
  },
  {
    "objectID": "content/lab-ans/lab04-modelling-ans.html#part-1",
    "href": "content/lab-ans/lab04-modelling-ans.html#part-1",
    "title": "Lab 04 - Modelling (Ans)",
    "section": "Part 1",
    "text": "Part 1\n\nExercise 1\nFirst, we use rowwise to group evals by each row. We then use mutate to compute a new variable (bty_avg) corresponding to the average of the six beauty scores.\nFinally, we ungroup so that the dataframe isn’t still grouped by each row.\n\nevals <- evals |>\n  rowwise() |>\n  mutate(bty_avg = mean( c( bty_f1lower, bty_f1upper,\n                            bty_f2upper, bty_m1lower,\n                            bty_m1upper, bty_m2upper) )) |>\n  ungroup()"
  },
  {
    "objectID": "content/lab-ans/lab04-modelling-ans.html#part-2",
    "href": "content/lab-ans/lab04-modelling-ans.html#part-2",
    "title": "Lab 04 - Modelling (Ans)",
    "section": "Part 2",
    "text": "Part 2\n\nExercise 2\nThe distribution is slightly left-skewed, i.e., many scores are on the higher side (between 4-5) with a longer tail going to the left.\nThis is further corroborrated by the fact that the mean is lower than the median. Given that the mean is more affected by skew than the median, this is what we’d expect with negatively skewed data.\n\nevals |>\n  ggplot(aes(x = score))+\n  geom_histogram() +\n  theme_bw()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\nevals |>\n  summarise(mean = mean(score),\n            median = median(score),\n            sd = sd(score))\n\n# A tibble: 1 × 3\n   mean median    sd\n  <dbl>  <dbl> <dbl>\n1  4.17    4.3 0.544\n\n\n\n\nExercise 3\nIt seems like there’s a slight positive relationship between bty_avg and score, though it’s hard to tell given that many points overlap and form “bands” along particular values (e.g., many teachers have the same score).\n\nevals |>\n  ggplot(aes(x = bty_avg,\n             y = score))+\n  geom_point() +\n  theme_bw()\n\n\n\n\n\n\nExercise 4\nOne way to deal with the above is to add jitter to the plot, which reveals that certain clusters of points were either larger or smaller than initially thought. (Another apprpoach would be to change the alpha of geom_point, allowing us to detect denser clusters.)\n\nevals |>\n  ggplot(aes(x = bty_avg,\n             y = score))+\n  geom_jitter() +\n  theme_bw()"
  },
  {
    "objectID": "content/lab-ans/lab04-modelling-ans.html#part-3",
    "href": "content/lab-ans/lab04-modelling-ans.html#part-3",
    "title": "Lab 04 - Modelling (Ans)",
    "section": "Part 3",
    "text": "Part 3\n\nExercise 5\nAccording to the model, the linear equation would be as follows:\n\\(\\hat{y} = 3.88 + 0.07*X\\)\nWhere \\(X\\) is bty_avg.\nWe use broom::tidy to transform the model object into a tidy dataframe.\n\nm_bty <- linear_reg() |>\n  set_engine(\"lm\") |>\n  fit(score ~ bty_avg, data = evals)\n\nm_bty |>\n  tidy() |>\n  select(term, estimate)\n\n# A tibble: 2 × 2\n  term        estimate\n  <chr>          <dbl>\n1 (Intercept)   3.88  \n2 bty_avg       0.0666\n\n\n\n\nExercise 6\n\nevals |>\n  ggplot(aes(x = bty_avg,\n             y = score))+\n  geom_point() +\n  geom_smooth(method = \"lm\", \n              color = \"orange\",\n              se = FALSE) +\n  theme_bw()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\nExercise 7\nProfessors with higher average beauty ratings also tend to receive higher teaching scores.\nThe slope is approximately 0.07, which means that for every 1-unit increase in beauty rating (i.e., from 4 to 5), we can expect that a professor will receive .07 higher teaching scores (with a ~0.02 standard error).\n\nm_bty |>\n  tidy() |>\n  filter(term == \"bty_avg\") |>\n  select(term, estimate, std.error)\n\n# A tibble: 1 × 3\n  term    estimate std.error\n  <chr>      <dbl>     <dbl>\n1 bty_avg   0.0666    0.0163\n\n\n\n\nExercise 8\nThe intercept is 3.88. This is the estimated score for professors with a beauty score of 0, i.e., it is the value of \\(\\hat{y}\\) when the regression line crosses \\(x = 0\\).\nThis may or may not make sense; given that possible beauty scores ranged from 1-6, it is a little strange to imagine a scenario where the beauty score is 0 (and it would be even stranger to imagine scenarios where the beauty scores is negative).\nOn the other hand, it is not inconsistent with other features of the data: the mean score, for example, is 4.17, so it makes sense that the intercept of a linear model would be slightly lower than the mean, allowing the explanatory variable to account for increases in score throughout the data.\n\nm_bty |>\n  tidy() |>\n  filter(term == \"(Intercept)\") |>\n  select(term, estimate, std.error)\n\n# A tibble: 1 × 3\n  term        estimate std.error\n  <chr>          <dbl>     <dbl>\n1 (Intercept)     3.88    0.0761\n\n\n\n\nExercise 9\nHere, we identify the \\(R^2\\) of the model using glance, which identifies model-level characteristics.\nThe value is 0.0350, which means that our explanatory variable accounts for roughly 3.5% of the variance in our response variable.\n\nm_bty |>\n  glance() |>\n  select(r.squared)\n\n# A tibble: 1 × 1\n  r.squared\n      <dbl>\n1    0.0350"
  },
  {
    "objectID": "content/lab-ans/lab04-modelling-ans.html#part-4",
    "href": "content/lab-ans/lab04-modelling-ans.html#part-4",
    "title": "Lab 04 - Modelling (Ans)",
    "section": "Part 4",
    "text": "Part 4\n\nExercise 10\nThe linear equation would be as follows:\n\\(\\hat{y} = 4.09 + 0.142*X\\)\nWhere \\(X = 1\\) for male professors and \\(X = 0\\) for female professors. In other words, the intercept corresponds to the mean score for female professors, while the slope tells us the difference in mean between the female average and the male average.\n\nm_gen <- linear_reg() |>\n  set_engine(\"lm\") |>\n  fit( score ~ gender, data = evals)\n\nm_gen |>\n  tidy()\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic p.value\n  <chr>          <dbl>     <dbl>     <dbl>   <dbl>\n1 (Intercept)    4.09     0.0387    106.   0      \n2 gendermale     0.142    0.0508      2.78 0.00558\n\n\n\n\nExercise 11\nAs specified above, the slope coefficient for the \\(X\\) term signifies the difference in means between male and female professors.\n\n\nExercise 12\nHere, the model equation would look as follows:\n\\(\\hat{y} = 4.28 + -0.13*X_1 + -0.145*X_2\\)\nWhere \\(X_1 = 1\\) for tenure track professors and 0 for all else, and \\(X_2 = 1\\) for tenured professors and 0 for all else.\nIn other words: the intercept tells us the mean for teaching professors, and the two slope coefficients tell us the difference between that mean and the two other levels of rank.\n\ntable(evals$rank)\n\n\n    teaching tenure track      tenured \n         102          108          253 \n\nm_rank <- linear_reg() |>\n  set_engine(\"lm\") |>\n  fit(score ~ rank, data = evals)\n\nm_rank |>\n  tidy()\n\n# A tibble: 3 × 5\n  term             estimate std.error statistic   p.value\n  <chr>               <dbl>     <dbl>     <dbl>     <dbl>\n1 (Intercept)         4.28     0.0537     79.9  1.02e-271\n2 ranktenure track   -0.130    0.0748     -1.73 8.37e-  2\n3 ranktenured        -0.145    0.0636     -2.28 2.28e-  2\n\n\n\n\nExercise 13\nHere, we use the factor command (within mutate) to reorder the levels of rank such that tenure track is the first level.\n\nevals <- evals |>\n  mutate(rank_relevel = fct_relevel(factor(rank), c(\"tenure track\",\n                                                    \"teaching\",\n                                                    \"tenured\")))\n\n\n\nExercise 14\nThis model has the same structure as the previous model using rank, but it has reordered the levels of rank (for rank_relevel) such that tenure track is now first.\nThis means that the intercept should now be interpreted as the mean score for tenure track professors, and the coefficients represent the difference in means for teaching and tenured professors, respectively.\n\\(\\hat{y} = 4.15 + 0.13*X_1 + -0.0155*X_2\\)\nWhere \\(X_1 = 1\\) for teaching professors and 0 for all else; and \\(X_2 = 1\\) for tenured professors and 0 for all else.\nWe can compare tehse to the coefficients for the previous model, where teaching was the baseline: in both cases, we see that the difference between teaching and tenure track is 0.13 (just in opposite directions, depending on the baseline).\nThe \\(R^2\\) of the model is 0.0116 in both cases. In other words, the model explains approximately 1.16% of the variance in score.\n\nm_rank_relevel <- linear_reg() |>\n  set_engine(\"lm\") |>\n  fit(score ~ rank_relevel, data = evals)\n\n\nm_rank_relevel |>\n  tidy()\n\n# A tibble: 3 × 5\n  term                 estimate std.error statistic   p.value\n  <chr>                   <dbl>     <dbl>     <dbl>     <dbl>\n1 (Intercept)            4.15      0.0521    79.7   2.58e-271\n2 rank_relevelteaching   0.130     0.0748     1.73  8.37e-  2\n3 rank_releveltenured   -0.0155    0.0623    -0.249 8.04e-  1\n\nm_rank_relevel |>\n  glance() |>\n  select(r.squared)\n\n# A tibble: 1 × 1\n  r.squared\n      <dbl>\n1    0.0116\n\n\n\n\nExercise 15\n\nevals <- evals |>\n  mutate(tenure_eligible = case_when(\n    rank == \"teaching\" ~ \"no\",\n    TRUE ~ \"yes\"\n  ))\n\n## Double check\ntable(evals$rank, evals$tenure_eligible)\n\n              \n                no yes\n  teaching     102   0\n  tenure track   0 108\n  tenured        0 253\n\n\n\n\nExercise 16\nThe linear equation is as follows:\n\\(\\hat{y} = 4.28 + -0.141*X_1\\)\nWhere \\(X_1 = 1\\) for tenure eligible professors and \\(X_1 = 0\\) for non-tenure-eligible professors.\nThus, this means that the mean score for non-tenure-eligible professors is 4.28, and professors that are tenure eligible can expect a score that’s -0.141 lower, on average.\n\nm_tenure_eligible <- linear_reg() |>\n  set_engine(\"lm\") |>\n  fit(score ~ tenure_eligible, data = evals)\n\nm_tenure_eligible |>\n  tidy()\n\n# A tibble: 2 × 5\n  term               estimate std.error statistic   p.value\n  <chr>                 <dbl>     <dbl>     <dbl>     <dbl>\n1 (Intercept)           4.28     0.0536     79.9  2.72e-272\n2 tenure_eligibleyes   -0.141    0.0607     -2.32 2.10e-  2\n\n\nWe can also calculate the \\(R^2\\), and we see that it is 0.0115. In other words, the model explains approximately 1.15% of the variance in score.\n\nm_tenure_eligible |>\n  glance()\n\n# A tibble: 1 × 12\n  r.squ…¹ adj.r…² sigma stati…³ p.value    df logLik   AIC   BIC devia…⁴ df.re…⁵\n    <dbl>   <dbl> <dbl>   <dbl>   <dbl> <dbl>  <dbl> <dbl> <dbl>   <dbl>   <int>\n1  0.0115 0.00935 0.541    5.36  0.0210     1  -372.  750.  762.    135.     461\n# … with 1 more variable: nobs <int>, and abbreviated variable names\n#   ¹​r.squared, ²​adj.r.squared, ³​statistic, ⁴​deviance, ⁵​df.residual"
  },
  {
    "objectID": "content/lab-ans/lab02-wrangling-ans.html",
    "href": "content/lab-ans/lab02-wrangling-ans.html",
    "title": "Lab 02 - Wrangling (Ans)",
    "section": "",
    "text": "Load packages\n\nlibrary(tidyverse) \n\n\n\nExercise 1\nHow many unique hurricanes are included in this dataset?\n(Note the specific value may differ based on the version of the dataset you’re using, but the code would not change.)\n\nn_unique <- storms |> \n  filter(status == \"hurricane\") |>\n  distinct(name, year, .keep_all = TRUE) |>\n  count() |>\n  pull(n)\n\n# OR\n\nstorms |> \n  filter(status == \"hurricane\") |>\n  group_by(year, name) |> \n  count() |>\n  nrow()\n\n[1] 246\n\n# ChatGPT answer\n# idea is correct; code is not\n# n_distinct(storms, name)\n\nThere are 246 unique hurricanes.\n(Note that we need to group by name and year, as certain storms have the same name…in different years.)\n\n\nExercise 2\nNote: If you used storms on datahub, the ts_diameter column has missing information and were likely unable to complete this question. Otherwise…this would have been the approach…\nWhich tropical storm affected the largest area experiencing tropical storm strength winds? And, what was the maximum sustained wind speed for that storm?\n\nstorms |> \n  filter(status == \"tropical storm\", \n         !is.na(ts_diameter)) |> \n  slice_max(ts_diameter)\n\nOR\n\nstorms |>\n  filter(status == \"tropical storm\",\n         !is.na(ts_diameter)) |> \n  filter(ts_diameter == max(ts_diameter, na.rm=TRUE))\n\n# ChatGPT answer is way off\n\nSandy (2012) had the largest area affected.\n\n\nExercise 3\nAmong all storms in this dataset, in which month are storms most common? Does this depend on the status of the storm? (In other words, are hurricanes more common in certain months than tropical depressions? or tropical storms?)\n\n# most common month\nstorms |> \n  distinct(name, year, .keep_all=TRUE) |>\n  group_by(month) |>\n  summarise(n = n()) |> # could alternatively use count() here\n  arrange(desc(n))\n\n# A tibble: 10 × 2\n   month     n\n   <dbl> <int>\n 1     9   173\n 2     8   124\n 3    10    85\n 4     7    59\n 5     6    27\n 6    11    27\n 7     5     9\n 8    12     5\n 9     1     2\n10     4     1\n\n# ChatGPT is close but missing uniqueness of the storm (would still get the correct answer)\n\nSeptember is the most common month.\n\n# depend on status?\nstorms |> \n  group_by(status, month) |>\n  summarise(n = n()) |> # could alternatively use count() here\n  slice_max(n)\n\n`summarise()` has grouped output by 'status'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 3 × 3\n# Groups:   status [3]\n  status              month     n\n  <chr>               <dbl> <int>\n1 hurricane               9  1793\n2 tropical depression     9  1085\n3 tropical storm          9  2016\n\n\nIt does not depend on status. September is the most common for all three storm types.\n\n\nExercise 4\nYour boss asks for the name, year, and status of all category 5 storms that have happened in the 2000s. Carry out the operations that would deliver what they’re looking for.\n\nstorms |>\n  filter(category == 5,\n         between(year, 2000, 2009)) |>\n  select(name, year, status) |>\n  distinct(name, year, .keep_all=TRUE)\n\n# A tibble: 8 × 3\n  name     year status   \n  <chr>   <dbl> <chr>    \n1 Isabel   2003 hurricane\n2 Ivan     2004 hurricane\n3 Emily    2005 hurricane\n4 Katrina  2005 hurricane\n5 Rita     2005 hurricane\n6 Wilma    2005 hurricane\n7 Dean     2007 hurricane\n8 Felix    2007 hurricane\n\n# ChatGPT answer\n# incorrect b/c it mixes up status and category\n# also missing the equal to aspect for an inclusive decade\n# storms %>%\n#   filter(year >= 2000, year < 2010, status == \"5\") %>%\n#   select(name, year, status)\n\n\n\nExercise 5\nFilter these data to only include storms that occurred during your lifetime (your code and results may differ from your classmates!). Among storms that have occurred during your lifetime, what’s the mean and median air pressure across all measurements taken?\n\nmy_storms <- storms |>\n  filter(between(year, 1988, 2023)) # alternatively filter(year >= 1988)\n\nmy_storms |>\n  summarise(median_pressure = median(pressure),\n            mean_pressure = mean(pressure))\n\n# A tibble: 1 × 2\n  median_pressure mean_pressure\n            <int>         <dbl>\n1             999          991.\n\n# ChatGPT did well here\n\n\nMedian: 999 millibars\nMean: 991 millibars\n\n\n\nExercise 6\nWhich decade (of the storms included in the dataset) had the largest number of unique reported storms?\n\nstorms |> \n  distinct(name, year) |>\n  mutate(decade = year - year %% 10) |> # there are MANY different ways to approach this!\n  group_by(decade) |>\n  count()\n\n# A tibble: 6 × 2\n# Groups:   decade [6]\n  decade     n\n   <dbl> <int>\n1   1970    19\n2   1980    70\n3   1990   105\n4   2000   148\n5   2010   144\n6   2020    26\n\n# ChatGPT answer\n# incorrect b/c of the distinct name/near piece missing\n# would get correct decade but not the correct answer\n# storms %>%\n#   mutate(decade = floor(year/10)*10) %>%\n#   group_by(decade) %>%\n#   summarise(unique_storms = n_distinct(name)) %>%\n#   arrange(desc(unique_storms)) %>%\n#   top_n(1)\n\nThe 2000s.\n(Note: we want to be sure to only count each storm once. Could also arrange by desc(n) to have 2000 at top.)\n\n\nExercise 7\nAmong the subset of storms occurring in your lifetime, which storm lasted the longest? Include your code and explain your answer.\n\nmy_storms |>  \n  group_by(name, year) |> \n  count() |> \n  arrange(desc(n))\n\n# A tibble: 444 × 3\n# Groups:   name, year [444]\n   name       year     n\n   <chr>     <dbl> <int>\n 1 Nadine     2012    89\n 2 Kyle       2002    81\n 3 Alberto    2000    79\n 4 Ivan       2004    78\n 5 Georges    1998    71\n 6 Jeanne     2004    66\n 7 Dorian     2019    64\n 8 Josephine  1990    62\n 9 Emily      1993    60\n10 Maria      2017    60\n# … with 434 more rows\n\n\nNadine lasted the longest (unless you were born after 2012).\n(Note: The logic here is that storms are reported every six hours, per the description of the dataset, so the storm that has the most rows/entries would have lasted the longest)"
  },
  {
    "objectID": "content/exams/midterm_wi23.html",
    "href": "content/exams/midterm_wi23.html",
    "title": "COGS 137 - Winter 2023 - Midterm",
    "section": "",
    "text": "Your solutions must be written up in the R Markdown (Rmd) file called midterm-01.Rmd. This file must include your code and write up (written explanation) for each task.\nBe sure to knit your file to HTML prior to submission and include both the .Rmd and .html files on GitHub. Your “submission” will be whatever is in your exam repository at the deadline.\nIf you cannot figure out the code for a question and this is causing you to not be able to knit your file, set the code chunk to eval = FALSE (but leave your code there - chance for partial credit!) and then knit.\nThis exam is open book, open internet, closed other people. You may use any online or book-based resource you would like, but you must include citations for any code that you use. You may not consult with anyone else about this exam, including any other humans on the internet or one another.\nYou have until 11:59pm on Monday, Feb 13th to complete this exam and turn it in via your personal Github repo - late work will not be accepted. Technical difficulties are not an excuse for late work - do not wait until the last minute to knit / commit / push.\nThere will be no Campuswire posts about questions on the exam. If you are unsure of something, include a note in your exam. We’ll consider this in grading. However, if you think there is a mistake in the exam or are having technical issues, please DM or email Prof Ellis as soon as possible.\nEach question requires a (brief) narrative as well as a (brief) description of your approach. You can use comments in your code, but do not extensively count on these. I should be able to suppress all the code in your document and still be able to read and make sense of your answers to the questions.\nEven if the answer seems obvious from the R output, make sure to state it in your narrative as well. For example, if the question is asking what is 2 + 2, and you have the following in your document, you should additionally have a sentence that states “2 + 2 is 4.” You just want us to be clear that you know the answer to the question.\n\n2 + 2\n# 4"
  },
  {
    "objectID": "content/exams/midterm_wi23.html#academic-integrity",
    "href": "content/exams/midterm_wi23.html#academic-integrity",
    "title": "COGS 137 - Winter 2023 - Midterm",
    "section": "Academic Integrity",
    "text": "Academic Integrity\nBe sure to complete the AI statement in the exam you submit itself.\nA note on sharing / reusing code: I am well aware that a huge volume of code is available on the web to solve any number of problems. For this exam you are allowed to make use of any online resources (e.g. StackOverflow) but you must explicitly cite where you obtained any code you directly use (or use as inspiration). You are also not allowed to ask a question on an external forum, you can only use answers to questions that have already been answered. Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism. All communication with classmates is explicitly forbidden."
  },
  {
    "objectID": "content/exams/midterm_wi23.html#grading-and-feedback",
    "href": "content/exams/midterm_wi23.html#grading-and-feedback",
    "title": "COGS 137 - Winter 2023 - Midterm",
    "section": "Grading and feedback",
    "text": "Grading and feedback\nThis exam is worth 14% of your grade. You will be graded on the correctness of your code, correctness of your answers, the clarity of your explanations, and the overall organization of your document. (There’s no one “right” organization but the template gets you started on a well-organized exam. We should be able to easily navigate your midterm to find what we’re looking for.) Organization + Clarity in written communication - 1pt"
  },
  {
    "objectID": "content/exams/midterm_wi23.html#logistics",
    "href": "content/exams/midterm_wi23.html#logistics",
    "title": "COGS 137 - Winter 2023 - Midterm",
    "section": "Logistics",
    "text": "Logistics\nAnswer the questions in the document called midterm-01.Rmd. Add your code and narrative in the spaces below each question. Add code chunks as needed. Use as many lines as you need, but keep your narrative concise. Be sure to knit your file to HTML and view the file prior to turning it in."
  },
  {
    "objectID": "content/exams/midterm_wi23.html#packages",
    "href": "content/exams/midterm_wi23.html#packages",
    "title": "COGS 137 - Winter 2023 - Midterm",
    "section": "Packages",
    "text": "Packages\nYou will need the tidyverse and tidymodels packages for this midterm. If working on datahub, these package has been installed, but you will need to load them. You are allowed, but not required, to use additional packages."
  },
  {
    "objectID": "content/exams/midterm_wi23.html#the-data",
    "href": "content/exams/midterm_wi23.html#the-data",
    "title": "COGS 137 - Winter 2023 - Midterm",
    "section": "The data",
    "text": "The data\nThe data we’ll be using come from The Axios and Harris Poll and have been provided by the TidyTuesday team.\nThe data are stored in two different files in the data/ folder: poll.csv and reputation.csv. You’ll want to read each table in and understand what each variable represents prior to completing the exam.\nEach variable and the data overall are described in detail here. You should click on that link to see what information is stored in each column in the datasets. But briefly, these two files include data about the 100 “most visible” brands in America. Specifically, reputation.csv includes information from the 2022 poll about these 100 stores across different reputation categories. poll.csv includes information about the same 100 stores but includes information about their rankings across multiple years."
  },
  {
    "objectID": "content/exams/midterm_wi23.html#questions",
    "href": "content/exams/midterm_wi23.html#questions",
    "title": "COGS 137 - Winter 2023 - Midterm",
    "section": "Questions",
    "text": "Questions\n\nQuestion 1 (0.5 points)\nHow many different industries (industry variable) are represented in these data?\n\n\nQuestion 2 (0.5 points)\n\nWhich company had the lowest overall ranking in 2022?\nAnd for which category (from the name variable) did this organization score lowest?\n\n\n\nQuestion 3 (1 point)\nWhich company in the reputation.csv dataset has the “best” average (mean) rank across all seven categories?\n\n\nQuestion 4 (1 point)\nWhich company had the biggest increase in rank from 2021 to 2022?\n\n\nQuestion 5 (1.5 points)\nFor the industry with only a single “most visible” company in the dataset, has their RQ score been increasing or decreasing overall since 2017?\n\n\nQuestion 6 (2 points)\nHow many companies from each industry category are represented in the 2022 ‘100 Most Visible’ companies in America data? Generate a visualization to display the answer to this question. Be sure to follow best visualization practices discussed in class.\n\n\nQuestion 7 (2 points)\nOf industries that have at least 5 companies in the dataset, which industry has the highest median 2022 rank? Generate a visualization that allows you to answer this question. Be sure to follow best practices.\n\n\nQuestion 8 (2 points)\nYour boss is curious about how much rankings change from one year to the next. To answer this question, they ask you to determine how well 2021 rankings explain the following year’s 2022 rankings. Generate a linear model to answer this question. Be sure to include your interpretation of the model (in other words your answer to the question “how well do 2021 rankings explain 2022’s rankings?”)\n\n\nQuestion 9 (2.5 points)\nRecreate the plot included below using the data you’ve been working with. Once you have created the visualization, in no more than one paragraph, describe what you think the point of this visualization might be."
  },
  {
    "objectID": "content/exams/practice-exam.html",
    "href": "content/exams/practice-exam.html",
    "title": "COGS 137 - Winter 2023 - Practice Midterm",
    "section": "",
    "text": "There will be rules spelled out on the real midterm. Be sure to read them before taking the real exam. There will also be an academic integrity statement for you to complete. Replace the ____________ with your name below on the real deal.\n\n\n\n\n\n\nNote\n\n\n\nThis is the midterm from the last time this course was offered. Linear regression was not covered prior to the midterm the last time this course was offered. There will be a question or two on linear regression and the interpretation of linear models on this year’s midterm."
  },
  {
    "objectID": "content/exams/practice-exam.html#academic-integrity-statement",
    "href": "content/exams/practice-exam.html#academic-integrity-statement",
    "title": "COGS 137 - Winter 2023 - Practice Midterm",
    "section": "Academic Integrity Statement",
    "text": "Academic Integrity Statement\nI, ____________, hereby state that I have not communicated with or gained information in any way from my classmates or anyone during this exam, and that all work is my own.\nA note on sharing / reusing code: We are well aware that a huge volume of code is available on the web to solve any number of problems. For this exam you are allowed to make use of any online resources (e.g. StackOverflow) but you must explicitly cite where you obtained any code you directly use (or use as inspiration). You are also not allowed to ask a question on an external forum, you can only use answers to questions that have already been answered. Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism. All communication with classmates is explicitly forbidden."
  },
  {
    "objectID": "content/exams/practice-exam.html#getting-help",
    "href": "content/exams/practice-exam.html#getting-help",
    "title": "COGS 137 - Winter 2023 - Practice Midterm",
    "section": "Getting help",
    "text": "Getting help\nBecause we cannot be available to all students across the entire length of the (real) exam, there will be no questions of instructional staff about the exam. If you find wording confusing or are unsure, note that in your answer and explain how you interpreted it. This will be taken into consideration during grading. If you are having technical difficulties or think there is an error on the exam, DM or email Prof Ellis immediately and she’ll work with you as soon as possible."
  },
  {
    "objectID": "content/exams/practice-exam.html#grading-and-feedback",
    "href": "content/exams/practice-exam.html#grading-and-feedback",
    "title": "COGS 137 - Winter 2023 - Practice Midterm",
    "section": "Grading and feedback",
    "text": "Grading and feedback\nThe (real) exam is worth 16% of your grade. You will be graded on the correctness of your code, correctness of your answers (often there are multiple “correct” answers, by design), the clarity of your explanations, and the overall organization of your document. (There’s no one “right” organization, but we should be able to easily navigate your midterm to find what we’re looking for.)"
  },
  {
    "objectID": "content/exams/practice-exam.html#logistics",
    "href": "content/exams/practice-exam.html#logistics",
    "title": "COGS 137 - Winter 2023 - Practice Midterm",
    "section": "Logistics",
    "text": "Logistics\nAnswer the questions in the document called practice-exam.Rmd. Add your code and narrative in the spaces below each question. Add code chunks as needed. Use as many lines as you need, but keep your narrative concise. Be sure to knit your file to HTML and view the file prior to turning it in."
  },
  {
    "objectID": "content/exams/practice-exam.html#packages",
    "href": "content/exams/practice-exam.html#packages",
    "title": "COGS 137 - Winter 2023 - Practice Midterm",
    "section": "Packages",
    "text": "Packages\nYou will need the tidyverse package for this (practice) midterm. (For the real deal, you’ll need tidyverse and tidymodels.) If working on datahub, this package has been installed, but you will need to load it. No other packages are required, but if for some reason you want to load in another package, you are permitted to do so."
  },
  {
    "objectID": "content/exams/practice-exam.html#the-data",
    "href": "content/exams/practice-exam.html#the-data",
    "title": "COGS 137 - Winter 2023 - Practice Midterm",
    "section": "The data",
    "text": "The data\nThe dataset you’ll be working with on this practice midterm is all about beach volleyball. The full dataset is explained in detail here and includes match-level data from 76,756 volleyball matches. You should click on that link to see what information is stored in each column in this dataset and what information is included in each column.\nBriefly, what you’ll use for this midterm is a subset of the full dataset, including only the 11,699 observations (rows) from 2018 and 2019 but all of the original columns. Each row summarizes the results from a single, distinct match played in a volleyball tournament.\nTo briefly describe beach volleyball, it is a sport played 2 on 2, so each match involves only 4 players. These data include matches from two different volleyball circuits, the international FIVB and the US-centric AVP. You will not need to know much at all about this sport to complete this midterm, and anything you need to know will be explained.\nThe data are stored in data/vb_matches.csv. You’ll need to read the dataset in prior to answering any questions on the midterm."
  },
  {
    "objectID": "content/exams/practice-exam.html#questions",
    "href": "content/exams/practice-exam.html#questions",
    "title": "COGS 137 - Winter 2023 - Practice Midterm",
    "section": "Questions",
    "text": "Questions\nQuestion 1 (0.75 points) - How many FIVB and AVP matches are included in this dataset?\nQuestion 2 (0.75 points) - Find the match with the longest duration.\na.  Where was this tournament played (City & Country)?\nb.  How long did the match last?\nc.  Who were the two winners? </br>\nQuestion 3 (1.5 points) - Across all tournaments included in this dataset, which teams have won the most tournaments? Your response should include both the winning players, their gender, and the number of tournaments they’ve won in descending order. Who has the most wins? How many men’s and how many women’s teams are in the top 10? Note: “winning a tournament” is indicated by winning either a “Gold Medal” (FIVB) or “Finals” (AVP) match, specified in the bracket column.\nQuestion 4 (1.5 points) - Of only the AVP tournaments included in this dataset, how many different cities hosted tournaments in 2018 and 2019? And, which cities (if any) hosted a tournament in both 2018 and 2019? Note that tournaments are named for the city hosting the tournament.\nQuestion 5 (2.5 points) - Prof Ellis plays a lot of women’s beach volleyball and is only 5’5” (65 inches). Despite not having the sheer talent or raw athletic ability to make it as a professional volleyball player, she wonders if she ever had a chance at her height. (Reminder: there are 4 players in each match whose height should be considered.) To help her out, answer each of the following:\na.  Who was the shortest women's player to compete in a tournament in 2018/2019?\nb.  How tall are they?\nc.  Did they *win* a tournament in 2018 or 2019? </br>\nQuestion 6 (3 points) - Which country has hosted the most FIVB tournaments? Did this differ by year? Generate a visualization that shows how many FIVB tournaments each country hosted. Allow viewer to visualize this by year. And, be sure each tournament is only counted once (regardless of how many games were played).\nQuestion 7 (3 points) - Recreate the plot included below using the data you’ve been working with. Once you have created the visualization, in no more than one paragraph, describe what you think the point of this visualization might be. (Hint: The visualization uses the variable avg_team_height, which is not included in the provided data frame. You will have to create avg_team_height yourself, by determining the average (mean) team height for each winning team.)\n\n\n\n\n\n\n\nNote\n\n\n\nQ7 had a typo when this course was offered previously leading to students spending wayyyyy longer than intended on this exam. That typo has been fixed for this practice midterm.\n\n\nQuestion 8 (1 pts) - If you were in charge of designing the plot you just recreated in the plot above, what changes would you make to improve its effectiveness as a visualization? (You do not have to write any code for this question, just explain the different design/viz choices you would make.)"
  },
  {
    "objectID": "content/exams/practice-exam-ans.html",
    "href": "content/exams/practice-exam-ans.html",
    "title": "COGS 137 - Winter 2023 - Practice Midterm (Answers)",
    "section": "",
    "text": "There will be rules spelled out on the real midterm. Be sure to read them before taking the real exam. There will also be an academic integrity statement for you to complete. Replace the ____________ with your name below on the real deal."
  },
  {
    "objectID": "content/exams/practice-exam-ans.html#academic-integrity-statement",
    "href": "content/exams/practice-exam-ans.html#academic-integrity-statement",
    "title": "COGS 137 - Winter 2023 - Practice Midterm (Answers)",
    "section": "Academic Integrity Statement",
    "text": "Academic Integrity Statement\nI, ____________, hereby state that I have not communicated with or gained information in any way from my classmates or anyone during this exam, and that all work is my own.\nA note on sharing / reusing code: We are well aware that a huge volume of code is available on the web to solve any number of problems. For this exam you are allowed to make use of any online resources (e.g. StackOverflow) but you must explicitly cite where you obtained any code you directly use (or use as inspiration). You are also not allowed to ask a question on an external forum, you can only use answers to questions that have already been answered. Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism. All communication with classmates is explicitly forbidden."
  },
  {
    "objectID": "content/exams/practice-exam-ans.html#getting-help",
    "href": "content/exams/practice-exam-ans.html#getting-help",
    "title": "COGS 137 - Winter 2023 - Practice Midterm (Answers)",
    "section": "Getting help",
    "text": "Getting help\nBecause we cannot be available to all students across the entire length of the (real) exam, there will be no questions of instructional staff about the exam. If you find wording confusing or are unsure, note that in your answer and explain how you interpreted it. This will be taken into consideration during grading. If you are having technical difficulties or think there is an error on the exam, DM or email Prof Ellis immediately and she’ll work with you as soon as possible."
  },
  {
    "objectID": "content/exams/practice-exam-ans.html#grading-and-feedback",
    "href": "content/exams/practice-exam-ans.html#grading-and-feedback",
    "title": "COGS 137 - Winter 2023 - Practice Midterm (Answers)",
    "section": "Grading and feedback",
    "text": "Grading and feedback\nThe (real) exam is worth 16% of your grade. You will be graded on the correctness of your code, correctness of your answers (often there are multiple “correct” answers, by design), the clarity of your explanations, and the overall organization of your document. (There’s no one “right” organization, but we should be able to easily navigate your midterm to find what we’re looking for.)"
  },
  {
    "objectID": "content/exams/practice-exam-ans.html#logistics",
    "href": "content/exams/practice-exam-ans.html#logistics",
    "title": "COGS 137 - Winter 2023 - Practice Midterm (Answers)",
    "section": "Logistics",
    "text": "Logistics\nAnswer the questions in the document called practice-exam.Rmd. Add your code and narrative in the spaces below each question. Add code chunks as needed. Use as many lines as you need, but keep your narrative concise. Be sure to knit your file to HTML and view the file prior to turning it in."
  },
  {
    "objectID": "content/exams/practice-exam-ans.html#packages",
    "href": "content/exams/practice-exam-ans.html#packages",
    "title": "COGS 137 - Winter 2023 - Practice Midterm (Answers)",
    "section": "Packages",
    "text": "Packages\nYou will need the tidyverse package for this (practice) midterm. (For the real deal, you’ll need tidyverse and tidymodels.) If working on datahub, this package has been installed, but you will need to load it. No other packages are required, but if for some reason you want to load in another package, you are permitted to do so."
  },
  {
    "objectID": "content/exams/practice-exam-ans.html#the-data",
    "href": "content/exams/practice-exam-ans.html#the-data",
    "title": "COGS 137 - Winter 2023 - Practice Midterm (Answers)",
    "section": "The data",
    "text": "The data\nThe dataset you’ll be working with on this practice midterm is all about beach volleyball. The full dataset is explained in detail here and includes match-level data from 76,756 volleyball matches. You should click on that link to see what information is stored in each column in this dataset and what information is included in each column.\nBriefly, what you’ll use for this midterm is a subset of the full dataset, including only the 11,699 observations (rows) from 2018 and 2019 but all of the original columns. Each row summarizes the results from a single, distinct match played in a volleyball tournament.\nTo briefly describe beach volleyball, it is a sport played 2 on 2, so each match involves only 4 players. These data include matches from two different volleyball circuits, the international FIVB and the US-centric AVP. You will not need to know much at all about this sport to complete this midterm, and anything you need to know will be explained.\nThe data are stored in data/vb_matches.csv. You’ll need to read the dataset in prior to answering any questions on the midterm.\n\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n\n\n✔ ggplot2 3.4.0     ✔ purrr   1.0.0\n✔ tibble  3.1.8     ✔ dplyr   1.0.9\n✔ tidyr   1.2.1     ✔ stringr 1.5.0\n✔ readr   2.1.3     ✔ forcats 0.5.2\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\ndf <- read_csv('data/vb_matches.csv')\n\nRows: 11699 Columns: 65\n\n\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (17): circuit, tournament, country, gender, w_player1, w_p1_country, w_...\ndbl  (42): year, match_num, w_p1_age, w_p1_hgt, w_p2_age, w_p2_hgt, l_p1_age...\ndate  (5): date, w_p1_birthdate, w_p2_birthdate, l_p1_birthdate, l_p2_birthdate\ntime  (1): duration\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "content/exams/practice-exam-ans.html#questions",
    "href": "content/exams/practice-exam-ans.html#questions",
    "title": "COGS 137 - Winter 2023 - Practice Midterm (Answers)",
    "section": "Questions",
    "text": "Questions\nQuestion 1 (0.75 points) - How many FIVB and AVP matches are included in this dataset?\n\ndf |> \n  group_by(circuit) |>\n  count()\n\n# A tibble: 2 × 2\n# Groups:   circuit [2]\n  circuit     n\n  <chr>   <int>\n1 AVP      2656\n2 FIVB     9043\n\n\n\n2656 AVP\n9043 FIVB\n\nQuestion 2 (0.75 points) - Find the match with the longest duration. a. Where was this tournament played (City & Country)? b. How long did the match last? c. Who were the two winners?\n\ndf |> \n  slice(which.max(duration))\n\n# A tibble: 1 × 65\n  circuit tournament country   year date       gender match…¹ w_pla…² w_p1_bir…³\n  <chr>   <chr>      <chr>    <dbl> <date>     <chr>    <dbl> <chr>   <date>    \n1 AVP     Austin     United …  2018 2018-05-17 M           37 Nathan… 1991-06-15\n# … with 56 more variables: w_p1_age <dbl>, w_p1_hgt <dbl>, w_p1_country <chr>,\n#   w_player2 <chr>, w_p2_birthdate <date>, w_p2_age <dbl>, w_p2_hgt <dbl>,\n#   w_p2_country <chr>, w_rank <chr>, l_player1 <chr>, l_p1_birthdate <date>,\n#   l_p1_age <dbl>, l_p1_hgt <dbl>, l_p1_country <chr>, l_player2 <chr>,\n#   l_p2_birthdate <date>, l_p2_age <dbl>, l_p2_hgt <dbl>, l_p2_country <chr>,\n#   l_rank <chr>, score <chr>, duration <time>, bracket <chr>, round <chr>,\n#   w_p1_tot_attacks <dbl>, w_p1_tot_kills <dbl>, w_p1_tot_errors <dbl>, …\n\n\n\nAustin, USA\n1h 42 min\nNathan Yang & Steven Irvin\n\n\nQuestion 3 (1.5 points) - Across all tournaments included in this dataset, which teams have won the most tournaments? Your response should include both the winning players, their gender, and the number of tournaments they’ve won in descending order. Who has the most wins? How many men’s and how many women’s teams are in the top 10?\nNote: “winning a tournament” is indicated by winning either a “Gold Medal” (FIVB) or “Finals” (AVP) match, specified in the bracket column.\n\ndf |> \n  filter(bracket %in% c(\"Gold Medal\", \"Finals\")) |> \n  group_by(w_player1, w_player2, gender) |>\n  count() |> \n  arrange(desc(n)) |>\n  head(10)\n\n# A tibble: 10 × 4\n# Groups:   w_player1, w_player2, gender [10]\n   w_player1              w_player2                 gender     n\n   <chr>                  <chr>                     <chr>  <int>\n 1 Alix Klineman          \"April Ross\"              W         11\n 2 Anders Mol             \"Christian Sorum\"         M         10\n 3 Melissa Humana-Paredes \"Sarah Pavan\"             W          6\n 4 Nick Lucena            \"Phil Dalhausser\"         M          6\n 5 Jake Gibb              \"Taylor Crabb\"            M          5\n 6 Jingzhe Wang           \"Shuhui Wen\"              W          5\n 7 Agatha Bednarczuk      \"Eduarda \\\"Duda\\\" Lisboa\" W          4\n 8 Aleksandrs Samoilovs   \"Janis Smedins\"           M          4\n 9 Betsi Flint            \"Emily Day\"               W          4\n10 Alexander Brouwer      \"Robert Meeuwsen\"         M          3\n\n\n\nAlix Klineman and April Ross have won the most tournaments\nThere are 5 men’s teams and 5 women’s teams\n\nQuestion 4 (1.5 points) - Of only the AVP tournaments included in this dataset, how many different cities hosted tournaments in 2018 and 2019? And, which cities (if any) hosted a tournament in both 2018 and 2019?\nNote that tournaments are named for the city hosting the tournament.\n\n# distinct locations\ndf |> \n  filter(circuit == 'AVP') |>\n  distinct(tournament)\n\n# A tibble: 9 × 1\n  tournament      \n  <chr>           \n1 Austin          \n2 New York        \n3 Seattle         \n4 San Francisco   \n5 Hermosa Beach   \n6 Manhattan Beach \n7 Chicago         \n8 Waikiki         \n9 Huntington Beach\n\n\n\n9 distinct locations\n\n\nlocations <- df |> \n  filter(circuit == 'AVP') |>\n  group_by(year, date) |> \n    distinct(tournament) \n\ndf |>\n  filter(circuit == \"AVP\") |>\n  group_by(year, date) |>\n  distinct(tournament) |>\n  group_by(tournament) |>\n  count() |>\n  filter(n > 1)\n\n# A tibble: 6 × 2\n# Groups:   tournament [6]\n  tournament          n\n  <chr>           <int>\n1 Austin              2\n2 Chicago             2\n3 Hermosa Beach       2\n4 Manhattan Beach     2\n5 New York            2\n6 Seattle             2\n\n\n\n6 locations were duplicates between 2018 and 2019, including Chicago, Manhattan Beach, Hermosa Beach, Seattle, New York, and Austin\n\nQuestion 5 (2.5 points) - Prof Ellis plays a lot of women’s beach volleyball and is only 5’5” (65 inches). Despite not having the sheer talent or raw athletic ability to make it as a professional volleyball player, she wonders if she ever had a chance at her height. To help her out, answer each of the following: a. Who was the shortest women’s player to compete in a tournament in 2018/2019? b. How tall are they? c. Did they win a tournament in 2018 or 2019?\nReminder: there are 4 players in each match whose height should be considered.\n\n# find shortest in each column\ndf |>\n  filter(gender == \"W\") |>\n  summarize(min_p1 = min(w_p1_hgt, na.rm=TRUE), \n            min_p2  = min(w_p2_hgt, na.rm=TRUE), \n            min_l_p1 = min(l_p1_hgt, na.rm=TRUE),\n            min_l_p2 = min(l_p2_hgt, na.rm=TRUE))\n\n# A tibble: 1 × 4\n  min_p1 min_p2 min_l_p1 min_l_p2\n   <dbl>  <dbl>    <dbl>    <dbl>\n1     63     64       62       61\n\n# determine the shortest player\ndf |> filter(l_p2_hgt == 61)\n\n# A tibble: 2 × 65\n  circuit tournament  country  year date       gender match…¹ w_pla…² w_p1_bir…³\n  <chr>   <chr>       <chr>   <dbl> <date>     <chr>    <dbl> <chr>   <date>    \n1 FIVB    Visakhapat… India    2019 2019-02-28 W            7 Meliss… 1995-01-27\n2 FIVB    Visakhapat… India    2019 2019-02-28 W           16 Ekater… 1990-11-06\n# … with 56 more variables: w_p1_age <dbl>, w_p1_hgt <dbl>, w_p1_country <chr>,\n#   w_player2 <chr>, w_p2_birthdate <date>, w_p2_age <dbl>, w_p2_hgt <dbl>,\n#   w_p2_country <chr>, w_rank <chr>, l_player1 <chr>, l_p1_birthdate <date>,\n#   l_p1_age <dbl>, l_p1_hgt <dbl>, l_p1_country <chr>, l_player2 <chr>,\n#   l_p2_birthdate <date>, l_p2_age <dbl>, l_p2_hgt <dbl>, l_p2_country <chr>,\n#   l_rank <chr>, score <chr>, duration <time>, bracket <chr>, round <chr>,\n#   w_p1_tot_attacks <dbl>, w_p1_tot_kills <dbl>, w_p1_tot_errors <dbl>, …\n\n\nPerumal Yogeshwari was the shortest to compete (at 61 inches). By deduction, since this is the l_p2 column, we know that she did not win any tournaments.\nQuestion 6 (3 pts) - Which country has hosted the most FIVB tournaments? Did this differ by year? Generate a visualization that shows how many FIVB tournaments each country hosted. Allow viewer to visualize this by year. And, be sure each tournament is only counted once (regardless of how many games were played).\n\ndf |>\n  filter(circuit == 'FIVB') |>\n  distinct(tournament, year, .keep_all = TRUE) |>\n  ggplot(aes(y=fct_infreq(country))) + \n  geom_bar() + \n  facet_wrap(~year) +\n  labs(y=NULL,\n       x=\"Count\",\n       title = \"Number of FIVB tournaments hosted by each country\") + \n  theme_bw() +\n  theme(plot.title.position = \"plot\")\n\n\n\n\nQuestion 7 (3 pts) - Recreate the plot included below using the data you’ve been working with. Once you have created the visualization, in no more than one paragraph, describe what you think the point of this visualization might be.\nHint: The visualization uses the variable avg_team_height, which is not included in the provided data frame. You will have to create avg_team_height yourself, be determining the average (mean) team height for each winning team.\n\n\ndf |>\n  filter(circuit == 'AVP') |>\n  mutate(avg_team_height = (w_p1_hgt + w_p2_hgt)/2) |>\n  ggplot(aes(x = fct_infreq(w_p1_country), y = avg_team_height, fill=w_p1_country)) +\n  geom_boxplot() + \n  facet_wrap(~gender, \n             scales=\"free_y\", \n             nrow=2) +\n  labs(y = 'Average Team Height (in)',\n       x = 'Country',\n       title = 'Average team heights for AVP match winners in 2018 and 2019') +\n  theme(plot.title.position = \"plot\") +\n  guides(fill=\"none\") \n\nWarning: Removed 1288 rows containing non-finite values (`stat_boxplot()`).\n\n\n\n\n\nVisualizes which countries have the tallest winning teams on average. For men, we see that players from the Netherlands are quite tall. For Women, it’s the US and Canada.\n\nQuestion 8 (1 pts) - If you were in charge of designing the plot you just recreated in the plot above, what changes would you make to improve its effectiveness as a visualization? (You do not have to write any code for this question, just explain the different design/viz choices you would make.)\n\n\nswap axes\naccurate/more informative labelling labeling\nmeaningful ordering of countries (geography?)\nimproved color choices (flag colors?)\nincrease text size\nremove background\netc."
  },
  {
    "objectID": "content/lectures/10-mlr-slides.html#qa",
    "href": "content/lectures/10-mlr-slides.html#qa",
    "title": "10-mlr",
    "section": "Q&A",
    "text": "Q&A\n\nQ: I didn’t know we don’t have to complete all parts of the lab to get credit - how does it work if we’re graded on effort? Do we still get a full score?\nA: We grade on concerted effort. Meaning, we look at everyone’s labs, and using a rubric relative to what we expect a student could complete in ~1h of work, we grade and give full credit if it looks like at least an hour of time was spent. Now, sometimes it’s hard to judge this as students work at different speeds. If you ever receive less than full credit (2) but feel you made a concerted effort that week in lab, reach out and we’ll chat about it!\n\n\nQ: I am still confused about when are we supposed to use jitter on our scatterplot.\nA: When points on a plot are on top of one another and you can’t tell how many observations are actually plotted, jittering is something to consider. You can alternatively use transparency (alpha) or scale the points relative to how many observations are present at each point. There’s no “you must jitter now” rule, but there are times to consider it."
  },
  {
    "objectID": "content/lectures/10-mlr-slides.html#course-announcements",
    "href": "content/lectures/10-mlr-slides.html#course-announcements",
    "title": "10-mlr",
    "section": "Course Announcements",
    "text": "Course Announcements\nDue Dates:\n\nLab 05 due Friday (2/17; 11:59 PM)\nmid-course survey (optional for EC) due Fri (2/17; 11:59 PM)\nLecture Participation survey “due” after class\n\n\n\nHW03 will be available tomorrow (Wed); due (2/27) <- that’s a change"
  },
  {
    "objectID": "content/lectures/10-mlr-slides.html#agenda",
    "href": "content/lectures/10-mlr-slides.html#agenda",
    "title": "10-mlr",
    "section": "Agenda",
    "text": "Agenda\n\nMultiple Linear Regression\n\nMultiple predictors\nMain vs interaction effects\nModel comparison\nBackward selection"
  },
  {
    "objectID": "content/lectures/10-mlr-slides.html#packages-data",
    "href": "content/lectures/10-mlr-slides.html#packages-data",
    "title": "10-mlr",
    "section": "Packages & Data",
    "text": "Packages & Data\n\nlibrary(tidyverse)\nlibrary(tidymodels)\n\n\nData: Paris Paintings\n\npp <- read_csv(\"https://raw.githubusercontent.com/COGS137/datasets/main/paris_paintings.csv\", \n               na = c(\"n/a\", \"\", \"NA\")) |> \n  mutate(log_price = log(price))\n\n\nNumber of observations: 3393\nNumber of variables: 62"
  },
  {
    "objectID": "content/lectures/10-mlr-slides.html#multiple-predictors",
    "href": "content/lectures/10-mlr-slides.html#multiple-predictors",
    "title": "10-mlr",
    "section": "Multiple predictors",
    "text": "Multiple predictors\n\nResponse variable: log_price\nExplanatory variables: Width and height\n\n\n\nlin_mod <- linear_reg() |>\n  set_engine(\"lm\")\n\npp_fit <- lin_mod |>\n  fit(log_price ~ Width_in + Height_in, data = pp)\ntidy(pp_fit)\n\n# A tibble: 3 × 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)   4.77     0.0579      82.4  0       \n2 Width_in      0.0269   0.00373      7.22 6.58e-13\n3 Height_in    -0.0133   0.00395     -3.36 7.93e- 4"
  },
  {
    "objectID": "content/lectures/10-mlr-slides.html#linear-model-with-multiple-predictors",
    "href": "content/lectures/10-mlr-slides.html#linear-model-with-multiple-predictors",
    "title": "10-mlr",
    "section": "Linear model with multiple predictors",
    "text": "Linear model with multiple predictors\n\n\n# A tibble: 3 × 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)   4.77     0.0579      82.4  0       \n2 Width_in      0.0269   0.00373      7.22 6.58e-13\n3 Height_in    -0.0133   0.00395     -3.36 7.93e- 4\n\n\n\n\\[\\widehat{log\\_price} = 4.77 + 0.0269 \\times width - 0.0133 \\times height\\]\n\n❓ How do we interpret this model?"
  },
  {
    "objectID": "content/lectures/10-mlr-slides.html#price-surface-area-and-living-artist",
    "href": "content/lectures/10-mlr-slides.html#price-surface-area-and-living-artist",
    "title": "10-mlr",
    "section": "Price, surface area, and living artist",
    "text": "Price, surface area, and living artist\n\nExplore the relationship between price of paintings and surface area, conditioned on whether or not the artist is still living\nFirst visualize and explore, then model\n\n\n\nBut first, prep the data:\n\n\npp <- pp |>\n  mutate(artistliving = case_when(artistliving == 0 ~ \"Deceased\", \n                                  TRUE ~ \"Living\"))\n\npp |>\n  count(artistliving)\n\n# A tibble: 2 × 2\n  artistliving     n\n  <chr>        <int>\n1 Deceased      2937\n2 Living         456"
  },
  {
    "objectID": "content/lectures/10-mlr-slides.html#typical-surface-area",
    "href": "content/lectures/10-mlr-slides.html#typical-surface-area",
    "title": "10-mlr",
    "section": "Typical surface area",
    "text": "Typical surface area\n\nPlotCode\n\n\n\n\n\n\n\nTypical surface area appears to be less than 1000 square inches (~ 80cm x 80cm). There are very few paintings that have surface area above 5000 square inches.\n\n\n\nggplot(data = pp, aes(x = Surface, fill = artistliving)) +\n  geom_histogram(binwidth = 500) + \n  facet_grid(artistliving ~ .) +\n  scale_fill_manual(values = c(\"#E48957\", \"#071381\")) +\n  guides(fill = \"none\") +\n  labs(x = \"Surface area\", y = NULL) +\n  geom_vline(xintercept = 1000) +\n  geom_vline(xintercept = 5000, linetype = \"dashed\", color = \"gray\")"
  },
  {
    "objectID": "content/lectures/10-mlr-slides.html#narrowing-the-scope",
    "href": "content/lectures/10-mlr-slides.html#narrowing-the-scope",
    "title": "10-mlr",
    "section": "Narrowing the scope",
    "text": "Narrowing the scope\n\nPlotCode\n\n\nFor simplicity let’s focus on the paintings with Surface < 5000:\n\n\n\n\n\n\n\n\npp_Surf_lt_5000 <- pp |>\n  filter(Surface < 5000)\n\nggplot(data = pp_Surf_lt_5000, \n       aes(y = log_price, x = Surface, color = artistliving, shape = artistliving)) +\n  geom_point(alpha = 0.5) +\n  labs(color = \"Artist\", shape = \"Artist\") +\n  scale_color_manual(values = c(\"#E48957\", \"#071381\"))"
  },
  {
    "objectID": "content/lectures/10-mlr-slides.html#facet-to-get-a-better-look",
    "href": "content/lectures/10-mlr-slides.html#facet-to-get-a-better-look",
    "title": "10-mlr",
    "section": "Facet to get a better look",
    "text": "Facet to get a better look\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(data = pp_Surf_lt_5000, \n       aes(y = log_price, x = Surface, color = artistliving, shape = artistliving)) +\n  geom_point(alpha = 0.5) +\n  facet_wrap(~artistliving) +\n  scale_color_manual(values = c(\"#E48957\", \"#071381\")) +\n  labs(color = \"Artist\", shape = \"Artist\")"
  },
  {
    "objectID": "content/lectures/10-mlr-slides.html#two-ways-to-model",
    "href": "content/lectures/10-mlr-slides.html#two-ways-to-model",
    "title": "10-mlr",
    "section": "Two ways to model",
    "text": "Two ways to model\n\nMain effects: Assuming relationship between surface and logged price does not vary by whether or not the artist is living.\nInteraction effects: Assuming relationship between surface and logged price varies by whether or not the artist is living."
  },
  {
    "objectID": "content/lectures/10-mlr-slides.html#interacting-explanatory-variables",
    "href": "content/lectures/10-mlr-slides.html#interacting-explanatory-variables",
    "title": "10-mlr",
    "section": "Interacting explanatory variables",
    "text": "Interacting explanatory variables\n\nIncluding an interaction effect in the model allows for different slopes, i.e.  nonparallel lines.\nThis implies that the regression coefficient for an explanatory variable would change as another explanatory variable changes.\nThis can be accomplished by adding an interaction variable: the product of two explanatory variables."
  },
  {
    "objectID": "content/lectures/10-mlr-slides.html#two-ways-to-model-1",
    "href": "content/lectures/10-mlr-slides.html#two-ways-to-model-1",
    "title": "10-mlr",
    "section": "Two ways to model",
    "text": "Two ways to model\n\n\n\nMain effects: Assuming relationship between surface and logged price does not vary by whether or not the artist is living\nInteraction effects: Assuming relationship between surface and logged price varies by whether or not the artist is living\n\n\n\n\n\n\n\n\n\n\n❓ Which does your intuition/knowledge of the data suggest is more appropriate?\nPut a green sticky if you think main; pink if you think interaction."
  },
  {
    "objectID": "content/lectures/10-mlr-slides.html#fit-model-with-main-effects",
    "href": "content/lectures/10-mlr-slides.html#fit-model-with-main-effects",
    "title": "10-mlr",
    "section": "Fit model with main effects",
    "text": "Fit model with main effects\n\nResponse variable: log_price\nExplanatory variables: Surface area and artistliving\n\n\npp_main_fit <- lin_mod |>\n  fit(log_price ~ Surface + artistliving, data = pp_Surf_lt_5000)\ntidy(pp_main_fit)\n\n# A tibble: 3 × 5\n  term               estimate std.error statistic  p.value\n  <chr>                 <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)        4.88     0.0424       115.   0       \n2 Surface            0.000265 0.0000415      6.39 1.85e-10\n3 artistlivingLiving 0.137    0.0970         1.41 1.57e- 1\n\n\n\n\\[\\widehat{log\\_price} = 4.88 + 0.000265 \\times surface + 0.137 \\times artistliving\\]"
  },
  {
    "objectID": "content/lectures/10-mlr-slides.html#solving-the-model",
    "href": "content/lectures/10-mlr-slides.html#solving-the-model",
    "title": "10-mlr",
    "section": "Solving the model",
    "text": "Solving the model\n\nNon-living artist: Plug in 0 for artistliving\n\n\\(\\widehat{log\\_price} = 4.88 + 0.000265 \\times surface + 0.137 \\times 0\\)\n\\(= 4.88 + 0.000265 \\times surface\\)\n\n\nLiving artist: Plug in 1 for artistliving\n\n\\(\\widehat{log\\_price} = 4.88 + 0.000265 \\times surface + 0.137 \\times 1\\)\n\\(= 5.017 + 0.000265 \\times surface\\)"
  },
  {
    "objectID": "content/lectures/10-mlr-slides.html#visualizing-main-effects",
    "href": "content/lectures/10-mlr-slides.html#visualizing-main-effects",
    "title": "10-mlr",
    "section": "Visualizing main effects",
    "text": "Visualizing main effects\n\n\n\nSame slope: Rate of change in price as the surface area increases does not vary between paintings by living and non-living artists.\nDifferent intercept: Paintings by living artists are consistently more expensive than paintings by non-living artists."
  },
  {
    "objectID": "content/lectures/10-mlr-slides.html#interpreting-main-effects",
    "href": "content/lectures/10-mlr-slides.html#interpreting-main-effects",
    "title": "10-mlr",
    "section": "Interpreting main effects",
    "text": "Interpreting main effects\n\ntidy(pp_main_fit) |> \n  mutate(exp_estimate = exp(estimate)) |>\n  select(term, estimate, exp_estimate)\n\n# A tibble: 3 × 3\n  term               estimate exp_estimate\n  <chr>                 <dbl>        <dbl>\n1 (Intercept)        4.88           132.  \n2 Surface            0.000265         1.00\n3 artistlivingLiving 0.137            1.15\n\n\n\n\nAll else held constant, for each additional square inch in painting’s surface area, the price of the painting is predicted, on average, to be higher by a factor of 1.\nAll else held constant, paintings by a living artist are predicted, on average, to be higher by a factor of 1.15 compared to paintings by an artist who is no longer alive.\nPaintings that are by an artist who is not alive and that have a surface area of 0 square inches are predicted, on average, to be 132 livres."
  },
  {
    "objectID": "content/lectures/10-mlr-slides.html#main-vs.-interaction-effects",
    "href": "content/lectures/10-mlr-slides.html#main-vs.-interaction-effects",
    "title": "10-mlr",
    "section": "Main vs. interaction effects",
    "text": "Main vs. interaction effects\n\nThe way we specified our main effects model only lets artistliving affect the intercept.\nModel implicitly assumes that paintings with living and deceased artists have the same slope and only allows for different intercepts.\n\n\n❓ What seems more appropriate in this case?\n\nSame slope and same intercept for both colors\nSame slope and different intercept for both colors\nDifferent slope and different intercept for both colors"
  },
  {
    "objectID": "content/lectures/10-mlr-slides.html#interaction-surface-artistliving",
    "href": "content/lectures/10-mlr-slides.html#interaction-surface-artistliving",
    "title": "10-mlr",
    "section": "Interaction: Surface * artistliving",
    "text": "Interaction: Surface * artistliving"
  },
  {
    "objectID": "content/lectures/10-mlr-slides.html#fit-model-with-interaction-effects",
    "href": "content/lectures/10-mlr-slides.html#fit-model-with-interaction-effects",
    "title": "10-mlr",
    "section": "Fit model with interaction effects",
    "text": "Fit model with interaction effects\n\nResponse variable: log_price\nExplanatory variables: Surface area, artistliving, and their interaction\n\n\npp_int_fit <- lin_mod |>\n  fit(log_price ~ Surface * artistliving, data = pp_Surf_lt_5000)\ntidy(pp_int_fit)\n\n# A tibble: 4 × 5\n  term                        estimate std.error statistic    p.value\n  <chr>                          <dbl>     <dbl>     <dbl>      <dbl>\n1 (Intercept)                 4.91     0.0432       114.   0         \n2 Surface                     0.000206 0.0000442      4.65 0.00000337\n3 artistlivingLiving         -0.126    0.119         -1.06 0.289     \n4 Surface:artistlivingLiving  0.000479 0.000126       3.81 0.000139"
  },
  {
    "objectID": "content/lectures/10-mlr-slides.html#linear-model-with-interaction-effects",
    "href": "content/lectures/10-mlr-slides.html#linear-model-with-interaction-effects",
    "title": "10-mlr",
    "section": "Linear model with interaction effects",
    "text": "Linear model with interaction effects\n\n\n# A tibble: 4 × 5\n  term                        estimate std.error statistic    p.value\n  <chr>                          <dbl>     <dbl>     <dbl>      <dbl>\n1 (Intercept)                 4.91     0.0432       114.   0         \n2 Surface                     0.000206 0.0000442      4.65 0.00000337\n3 artistlivingLiving         -0.126    0.119         -1.06 0.289     \n4 Surface:artistlivingLiving  0.000479 0.000126       3.81 0.000139  \n\n\n\\[\\widehat{log\\_price} = 4.91 + 0.00021 \\times surface - 0.126 \\times artistliving\\] \\[+ ~ 0.00048 \\times surface * artistliving\\]"
  },
  {
    "objectID": "content/lectures/10-mlr-slides.html#interpretation-of-interaction-effects",
    "href": "content/lectures/10-mlr-slides.html#interpretation-of-interaction-effects",
    "title": "10-mlr",
    "section": "Interpretation of interaction effects",
    "text": "Interpretation of interaction effects\n\n\nRate of change in price as the surface area of the painting increases does vary between paintings by living and non-living artists (different slopes)\nSome paintings by living artists are more expensive than paintings by non-living artists, and some are not (different intercept).\n\n\n\n\n\n\n\nNon-living artist: \\(\\widehat{log\\_price} = 4.91 + 0.00021 \\times surface\\) \\(- 0.126 \\times 0 + 0.00048 \\times surface \\times 0\\) \\(= 4.91 + 0.00021 \\times surface\\)\nLiving artist: \\(\\widehat{log\\_price} = 4.91 + 0.00021 \\times surface\\) \\(- 0.126 \\times 1 + 0.00048 \\times surface \\times 1\\) \\(= 4.91 + 0.00021 \\times surface\\) \\(- 0.126 + 0.00048 \\times surface\\) \\(= 4.784 + 0.00069 \\times surface\\)"
  },
  {
    "objectID": "content/lectures/10-mlr-slides.html#r-squared",
    "href": "content/lectures/10-mlr-slides.html#r-squared",
    "title": "10-mlr",
    "section": "R-squared",
    "text": "R-squared\n\n\\(R^2\\) is the percentage of variability in the response variable explained by the regression model.\n\n\nglance(pp_main_fit)$r.squared\n\n[1] 0.01320884\n\nglance(pp_int_fit)$r.squared\n\n[1] 0.0176922\n\n\n\n\nClearly the model with interactions has a higher \\(R^2\\).\n\n\n\n\nHowever using \\(R^2\\) for model selection in models with multiple explanatory variables is not a good idea as \\(R^2\\) increases when any variable is added to the model."
  },
  {
    "objectID": "content/lectures/10-mlr-slides.html#adjusted-r-squared",
    "href": "content/lectures/10-mlr-slides.html#adjusted-r-squared",
    "title": "10-mlr",
    "section": "Adjusted R-squared",
    "text": "Adjusted R-squared\nIt appears that adding the interaction actually increased adjusted \\(R^2\\), so we should indeed use the model with the interactions.\n\nglance(pp_main_fit)$adj.r.squared\n\n[1] 0.01258977\n\nglance(pp_int_fit)$adj.r.squared\n\n[1] 0.01676753"
  },
  {
    "objectID": "content/lectures/10-mlr-slides.html#third-order-interactions",
    "href": "content/lectures/10-mlr-slides.html#third-order-interactions",
    "title": "10-mlr",
    "section": "Third order interactions",
    "text": "Third order interactions\n\nCan you? Yes\nShould you? Probably not if you want to interpret these interactions in context of the data."
  },
  {
    "objectID": "content/lectures/10-mlr-slides.html#in-pursuit-of-occams-razor",
    "href": "content/lectures/10-mlr-slides.html#in-pursuit-of-occams-razor",
    "title": "10-mlr",
    "section": "In pursuit of Occam’s razor",
    "text": "In pursuit of Occam’s razor\n\n\nOccam’s Razor states that among competing hypotheses that predict equally well, the one with the fewest assumptions should be selected.\nModel selection follows this principle.\nWe only want to add another variable to the model if the addition of that variable brings something valuable in terms of predictive power to the model.\nIn other words, we prefer the simplest best model, i.e. parsimonious model."
  },
  {
    "objectID": "content/lectures/10-mlr-slides.html#backward-selection",
    "href": "content/lectures/10-mlr-slides.html#backward-selection",
    "title": "10-mlr",
    "section": "Backward selection",
    "text": "Backward selection\nFor this demo, we’ll ignore interaction effects…and just model main effects to start:\n\npp_full <-  lin_mod |>\n  fit(log_price ~ Width_in + Height_in + Surface + artistliving, data=pp) \n\nglance(pp_full)$adj.r.squared\n\n[1] 0.02570141\n\n\n\n\\(R^2\\) (full): 0.0257014`\n\n\nRemove artistliving\n\npp_noartist <- lin_mod |>\n  fit(log_price ~ Width_in + Height_in + Surface, data=pp) \n\nglance(pp_noartist)$adj.r.squared\n\n[1] 0.02579859\n\n\n\n\n\\(R^2\\) (full): 0.0257\n\\(R^2\\) (no artistliving): 0.0258\n\n…Improved variance explained\n\nRemove Surface\n\npp_noartist_nosurface <- lin_mod |>\n  fit(log_price ~ Width_in + Height_in, data=pp) \n\nglance(pp_noartist_nosurface)$adj.r.squared\n\n[1] 0.02231559\n\n\n\n\n\\(R^2\\) (full): 0.0257\n\\(R^2\\) (no artistliving): 0.0258\n\\(R^2\\) (no artistliving or Surface): 0.0223\n\n\n\n…no longer gaining improvement, so we stick with: log_price ~ Width_in + Height_in + Surface"
  },
  {
    "objectID": "content/lectures/10-mlr-slides.html#other-approach",
    "href": "content/lectures/10-mlr-slides.html#other-approach",
    "title": "10-mlr",
    "section": "Other approach:",
    "text": "Other approach:\n\n# requires package installation: \n# install.packages(\"olsrr\")\nlibrary(olsrr)\n\n\nStep 1: Fit model (w/o tidymodels)\n\n# fit the model (not using tidymodels)\nmod <- lm(log_price ~ Width_in + Height_in + Surface + artistliving, data=pp_Surf_lt_5000)\n\n\n\nStep 2: Determine which variables to remove\n\nols_step_backward_p(mod)\n\n\n                             Elimination Summary                               \n------------------------------------------------------------------------------\n        Variable                      Adj.                                        \nStep      Removed       R-Square    R-Square     C(p)        AIC         RMSE     \n------------------------------------------------------------------------------\n   1    artistliving      0.0261      0.0251    3.8495    12603.7727    1.8315    \n------------------------------------------------------------------------------\n\n\n…specifies that artistliving should be removed\n\n\nStep 2 (alternate): Compare all possible models…\n\nols_step_all_possible(mod) |>\n  arrange(desc(adjr))\n\n   Index N                              Predictors     R-Square Adj. R-Square\n1     11 3              Width_in Height_in Surface 0.0260749939  0.0251349118\n2     15 4 Width_in Height_in Surface artistliving 0.0263412027  0.0250876993\n3      5 2                      Width_in Height_in 0.0256902566  0.0250634893\n4     12 3         Width_in Height_in artistliving 0.0259732581  0.0250330779\n5      6 2                        Width_in Surface 0.0249136264  0.0242863596\n6     13 3           Width_in Surface artistliving 0.0251787948  0.0242378477\n7      7 2                   Width_in artistliving 0.0212864021  0.0206568018\n8      1 1                                Width_in 0.0209415833  0.0206267736\n9      8 2                    Surface artistliving 0.0132088377  0.0125897717\n10     2 1                                 Surface 0.0125899681  0.0122803381\n11    14 3          Height_in Surface artistliving 0.0130836930  0.0121310711\n12     9 2                       Height_in Surface 0.0126782901  0.0120431523\n13    10 2                  Height_in artistliving 0.0062698155  0.0056305552\n14     3 1                               Height_in 0.0058797727  0.0055601199\n15     4 1                            artistliving 0.0005531617  0.0002397573\n   Mallow's Cp\n1     3.849487\n2     5.000000\n3     3.077206\n4     4.174132\n5     5.555476\n6     6.709309\n7    17.130153\n8    16.230489\n9    51.971190\n10   52.001268\n11   45.305459\n12   44.599123\n13   65.048926\n14   64.293574\n15   91.485605"
  },
  {
    "objectID": "content/lectures/10-mlr-slides.html#recap",
    "href": "content/lectures/10-mlr-slides.html#recap",
    "title": "10-mlr",
    "section": "Recap",
    "text": "Recap\n\nCan you model and interpret linear models with multiple predictors?\nCan you explain the difference in a model with main effects vs. interaction effects?\nCan you compare different models and determine how to proceed?\nCan you carry out and explain backward selection?"
  },
  {
    "objectID": "content/lectures/10-mlr-slides.html#suggested-reading",
    "href": "content/lectures/10-mlr-slides.html#suggested-reading",
    "title": "10-mlr",
    "section": "Suggested Reading",
    "text": "Suggested Reading\nIntroduction to Modern Statistics Chapter 8: Linear Regression with Multiple Predictors\n\n\n\nhttps://cogs137.github.io/website/"
  },
  {
    "objectID": "content/lectures/10-mlr.html",
    "href": "content/lectures/10-mlr.html",
    "title": "10-mlr",
    "section": "",
    "text": "Q: I didn’t know we don’t have to complete all parts of the lab to get credit - how does it work if we’re graded on effort? Do we still get a full score?\nA: We grade on concerted effort. Meaning, we look at everyone’s labs, and using a rubric relative to what we expect a student could complete in ~1h of work, we grade and give full credit if it looks like at least an hour of time was spent. Now, sometimes it’s hard to judge this as students work at different speeds. If you ever receive less than full credit (2) but feel you made a concerted effort that week in lab, reach out and we’ll chat about it!\n\n\nQ: I am still confused about when are we supposed to use jitter on our scatterplot.\nA: When points on a plot are on top of one another and you can’t tell how many observations are actually plotted, jittering is something to consider. You can alternatively use transparency (alpha) or scale the points relative to how many observations are present at each point. There’s no “you must jitter now” rule, but there are times to consider it.\n\n\n\n\nDue Dates:\n\nLab 05 due Friday (2/17; 11:59 PM)\nmid-course survey (optional for EC) due Fri (2/17; 11:59 PM)\nLecture Participation survey “due” after class\n\n\n\nHW03 will be available tomorrow (Wed); due (2/27) <- that’s a change\n\n\n\n\n\n\nMultiple Linear Regression\n\nMultiple predictors\nMain vs interaction effects\nModel comparison\nBackward selection\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(tidymodels)\n\n\nData: Paris Paintings\n\npp <- read_csv(\"https://raw.githubusercontent.com/COGS137/datasets/main/paris_paintings.csv\", \n               na = c(\"n/a\", \"\", \"NA\")) |> \n  mutate(log_price = log(price))\n\n\nNumber of observations: 3393\nNumber of variables: 62"
  },
  {
    "objectID": "content/lectures/10-mlr.html#multiple-predictors",
    "href": "content/lectures/10-mlr.html#multiple-predictors",
    "title": "10-mlr",
    "section": "Multiple predictors",
    "text": "Multiple predictors\n\nResponse variable: log_price\nExplanatory variables: Width and height\n\n\n\nlin_mod <- linear_reg() |>\n  set_engine(\"lm\")\n\npp_fit <- lin_mod |>\n  fit(log_price ~ Width_in + Height_in, data = pp)\ntidy(pp_fit)\n\n# A tibble: 3 × 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)   4.77     0.0579      82.4  0       \n2 Width_in      0.0269   0.00373      7.22 6.58e-13\n3 Height_in    -0.0133   0.00395     -3.36 7.93e- 4"
  },
  {
    "objectID": "content/lectures/10-mlr.html#linear-model-with-multiple-predictors",
    "href": "content/lectures/10-mlr.html#linear-model-with-multiple-predictors",
    "title": "10-mlr",
    "section": "Linear model with multiple predictors",
    "text": "Linear model with multiple predictors\n\n\n# A tibble: 3 × 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)   4.77     0.0579      82.4  0       \n2 Width_in      0.0269   0.00373      7.22 6.58e-13\n3 Height_in    -0.0133   0.00395     -3.36 7.93e- 4\n\n\n\n\\[\\widehat{log\\_price} = 4.77 + 0.0269 \\times width - 0.0133 \\times height\\]\n\n❓ How do we interpret this model?"
  },
  {
    "objectID": "content/lectures/10-mlr.html#price-surface-area-and-living-artist",
    "href": "content/lectures/10-mlr.html#price-surface-area-and-living-artist",
    "title": "10-mlr",
    "section": "Price, surface area, and living artist",
    "text": "Price, surface area, and living artist\n\nExplore the relationship between price of paintings and surface area, conditioned on whether or not the artist is still living\nFirst visualize and explore, then model\n\n\n\nBut first, prep the data:\n\n\npp <- pp |>\n  mutate(artistliving = case_when(artistliving == 0 ~ \"Deceased\", \n                                  TRUE ~ \"Living\"))\n\npp |>\n  count(artistliving)\n\n# A tibble: 2 × 2\n  artistliving     n\n  <chr>        <int>\n1 Deceased      2937\n2 Living         456"
  },
  {
    "objectID": "content/lectures/10-mlr.html#typical-surface-area",
    "href": "content/lectures/10-mlr.html#typical-surface-area",
    "title": "10-mlr",
    "section": "Typical surface area",
    "text": "Typical surface area\n\nPlotCode\n\n\n\n\n\n\n\nTypical surface area appears to be less than 1000 square inches (~ 80cm x 80cm). There are very few paintings that have surface area above 5000 square inches.\n\n\n\nggplot(data = pp, aes(x = Surface, fill = artistliving)) +\n  geom_histogram(binwidth = 500) + \n  facet_grid(artistliving ~ .) +\n  scale_fill_manual(values = c(\"#E48957\", \"#071381\")) +\n  guides(fill = \"none\") +\n  labs(x = \"Surface area\", y = NULL) +\n  geom_vline(xintercept = 1000) +\n  geom_vline(xintercept = 5000, linetype = \"dashed\", color = \"gray\")"
  },
  {
    "objectID": "content/lectures/10-mlr.html#narrowing-the-scope",
    "href": "content/lectures/10-mlr.html#narrowing-the-scope",
    "title": "10-mlr",
    "section": "Narrowing the scope",
    "text": "Narrowing the scope\n\nPlotCode\n\n\nFor simplicity let’s focus on the paintings with Surface < 5000:\n\n\n\n\n\n\n\n\npp_Surf_lt_5000 <- pp |>\n  filter(Surface < 5000)\n\nggplot(data = pp_Surf_lt_5000, \n       aes(y = log_price, x = Surface, color = artistliving, shape = artistliving)) +\n  geom_point(alpha = 0.5) +\n  labs(color = \"Artist\", shape = \"Artist\") +\n  scale_color_manual(values = c(\"#E48957\", \"#071381\"))"
  },
  {
    "objectID": "content/lectures/10-mlr.html#facet-to-get-a-better-look",
    "href": "content/lectures/10-mlr.html#facet-to-get-a-better-look",
    "title": "10-mlr",
    "section": "Facet to get a better look",
    "text": "Facet to get a better look\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(data = pp_Surf_lt_5000, \n       aes(y = log_price, x = Surface, color = artistliving, shape = artistliving)) +\n  geom_point(alpha = 0.5) +\n  facet_wrap(~artistliving) +\n  scale_color_manual(values = c(\"#E48957\", \"#071381\")) +\n  labs(color = \"Artist\", shape = \"Artist\")"
  },
  {
    "objectID": "content/lectures/10-mlr.html#two-ways-to-model",
    "href": "content/lectures/10-mlr.html#two-ways-to-model",
    "title": "10-mlr",
    "section": "Two ways to model",
    "text": "Two ways to model\n\nMain effects: Assuming relationship between surface and logged price does not vary by whether or not the artist is living.\nInteraction effects: Assuming relationship between surface and logged price varies by whether or not the artist is living."
  },
  {
    "objectID": "content/lectures/10-mlr.html#interacting-explanatory-variables",
    "href": "content/lectures/10-mlr.html#interacting-explanatory-variables",
    "title": "10-mlr",
    "section": "Interacting explanatory variables",
    "text": "Interacting explanatory variables\n\nIncluding an interaction effect in the model allows for different slopes, i.e.  nonparallel lines.\nThis implies that the regression coefficient for an explanatory variable would change as another explanatory variable changes.\nThis can be accomplished by adding an interaction variable: the product of two explanatory variables."
  },
  {
    "objectID": "content/lectures/10-mlr.html#two-ways-to-model-1",
    "href": "content/lectures/10-mlr.html#two-ways-to-model-1",
    "title": "10-mlr",
    "section": "Two ways to model",
    "text": "Two ways to model\n\n\n\nMain effects: Assuming relationship between surface and logged price does not vary by whether or not the artist is living\nInteraction effects: Assuming relationship between surface and logged price varies by whether or not the artist is living\n\n\n\n\n\n\n\n\n\n\n❓ Which does your intuition/knowledge of the data suggest is more appropriate?\nPut a green sticky if you think main; pink if you think interaction."
  },
  {
    "objectID": "content/lectures/10-mlr.html#fit-model-with-main-effects",
    "href": "content/lectures/10-mlr.html#fit-model-with-main-effects",
    "title": "10-mlr",
    "section": "Fit model with main effects",
    "text": "Fit model with main effects\n\nResponse variable: log_price\nExplanatory variables: Surface area and artistliving\n\n\npp_main_fit <- lin_mod |>\n  fit(log_price ~ Surface + artistliving, data = pp_Surf_lt_5000)\ntidy(pp_main_fit)\n\n# A tibble: 3 × 5\n  term               estimate std.error statistic  p.value\n  <chr>                 <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)        4.88     0.0424       115.   0       \n2 Surface            0.000265 0.0000415      6.39 1.85e-10\n3 artistlivingLiving 0.137    0.0970         1.41 1.57e- 1\n\n\n\n\\[\\widehat{log\\_price} = 4.88 + 0.000265 \\times surface + 0.137 \\times artistliving\\]"
  },
  {
    "objectID": "content/lectures/10-mlr.html#solving-the-model",
    "href": "content/lectures/10-mlr.html#solving-the-model",
    "title": "10-mlr",
    "section": "Solving the model",
    "text": "Solving the model\n\nNon-living artist: Plug in 0 for artistliving\n\n\\(\\widehat{log\\_price} = 4.88 + 0.000265 \\times surface + 0.137 \\times 0\\)\n\\(= 4.88 + 0.000265 \\times surface\\)\n\n\nLiving artist: Plug in 1 for artistliving\n\n\\(\\widehat{log\\_price} = 4.88 + 0.000265 \\times surface + 0.137 \\times 1\\)\n\\(= 5.017 + 0.000265 \\times surface\\)"
  },
  {
    "objectID": "content/lectures/10-mlr.html#visualizing-main-effects",
    "href": "content/lectures/10-mlr.html#visualizing-main-effects",
    "title": "10-mlr",
    "section": "Visualizing main effects",
    "text": "Visualizing main effects\n\n\n\nSame slope: Rate of change in price as the surface area increases does not vary between paintings by living and non-living artists.\nDifferent intercept: Paintings by living artists are consistently more expensive than paintings by non-living artists."
  },
  {
    "objectID": "content/lectures/10-mlr.html#interpreting-main-effects",
    "href": "content/lectures/10-mlr.html#interpreting-main-effects",
    "title": "10-mlr",
    "section": "Interpreting main effects",
    "text": "Interpreting main effects\n\ntidy(pp_main_fit) |> \n  mutate(exp_estimate = exp(estimate)) |>\n  select(term, estimate, exp_estimate)\n\n# A tibble: 3 × 3\n  term               estimate exp_estimate\n  <chr>                 <dbl>        <dbl>\n1 (Intercept)        4.88           132.  \n2 Surface            0.000265         1.00\n3 artistlivingLiving 0.137            1.15\n\n\n\n\nAll else held constant, for each additional square inch in painting’s surface area, the price of the painting is predicted, on average, to be higher by a factor of 1.\nAll else held constant, paintings by a living artist are predicted, on average, to be higher by a factor of 1.15 compared to paintings by an artist who is no longer alive.\nPaintings that are by an artist who is not alive and that have a surface area of 0 square inches are predicted, on average, to be 132 livres."
  },
  {
    "objectID": "content/lectures/10-mlr.html#main-vs.-interaction-effects",
    "href": "content/lectures/10-mlr.html#main-vs.-interaction-effects",
    "title": "10-mlr",
    "section": "Main vs. interaction effects",
    "text": "Main vs. interaction effects\n\nThe way we specified our main effects model only lets artistliving affect the intercept.\nModel implicitly assumes that paintings with living and deceased artists have the same slope and only allows for different intercepts.\n\n\n❓ What seems more appropriate in this case?\n\nSame slope and same intercept for both colors\nSame slope and different intercept for both colors\nDifferent slope and different intercept for both colors"
  },
  {
    "objectID": "content/lectures/10-mlr.html#interaction-surface-artistliving",
    "href": "content/lectures/10-mlr.html#interaction-surface-artistliving",
    "title": "10-mlr",
    "section": "Interaction: Surface * artistliving",
    "text": "Interaction: Surface * artistliving"
  },
  {
    "objectID": "content/lectures/10-mlr.html#fit-model-with-interaction-effects",
    "href": "content/lectures/10-mlr.html#fit-model-with-interaction-effects",
    "title": "10-mlr",
    "section": "Fit model with interaction effects",
    "text": "Fit model with interaction effects\n\nResponse variable: log_price\nExplanatory variables: Surface area, artistliving, and their interaction\n\n\npp_int_fit <- lin_mod |>\n  fit(log_price ~ Surface * artistliving, data = pp_Surf_lt_5000)\ntidy(pp_int_fit)\n\n# A tibble: 4 × 5\n  term                        estimate std.error statistic    p.value\n  <chr>                          <dbl>     <dbl>     <dbl>      <dbl>\n1 (Intercept)                 4.91     0.0432       114.   0         \n2 Surface                     0.000206 0.0000442      4.65 0.00000337\n3 artistlivingLiving         -0.126    0.119         -1.06 0.289     \n4 Surface:artistlivingLiving  0.000479 0.000126       3.81 0.000139"
  },
  {
    "objectID": "content/lectures/10-mlr.html#linear-model-with-interaction-effects",
    "href": "content/lectures/10-mlr.html#linear-model-with-interaction-effects",
    "title": "10-mlr",
    "section": "Linear model with interaction effects",
    "text": "Linear model with interaction effects\n\n\n# A tibble: 4 × 5\n  term                        estimate std.error statistic    p.value\n  <chr>                          <dbl>     <dbl>     <dbl>      <dbl>\n1 (Intercept)                 4.91     0.0432       114.   0         \n2 Surface                     0.000206 0.0000442      4.65 0.00000337\n3 artistlivingLiving         -0.126    0.119         -1.06 0.289     \n4 Surface:artistlivingLiving  0.000479 0.000126       3.81 0.000139  \n\n\n\\[\\widehat{log\\_price} = 4.91 + 0.00021 \\times surface - 0.126 \\times artistliving\\] \\[+ ~ 0.00048 \\times surface * artistliving\\]"
  },
  {
    "objectID": "content/lectures/10-mlr.html#interpretation-of-interaction-effects",
    "href": "content/lectures/10-mlr.html#interpretation-of-interaction-effects",
    "title": "10-mlr",
    "section": "Interpretation of interaction effects",
    "text": "Interpretation of interaction effects\n\n\nRate of change in price as the surface area of the painting increases does vary between paintings by living and non-living artists (different slopes)\nSome paintings by living artists are more expensive than paintings by non-living artists, and some are not (different intercept).\n\n\n\n\n\n\n\nNon-living artist: \\(\\widehat{log\\_price} = 4.91 + 0.00021 \\times surface\\) \\(- 0.126 \\times 0 + 0.00048 \\times surface \\times 0\\) \\(= 4.91 + 0.00021 \\times surface\\)\nLiving artist: \\(\\widehat{log\\_price} = 4.91 + 0.00021 \\times surface\\) \\(- 0.126 \\times 1 + 0.00048 \\times surface \\times 1\\) \\(= 4.91 + 0.00021 \\times surface\\) \\(- 0.126 + 0.00048 \\times surface\\) \\(= 4.784 + 0.00069 \\times surface\\)"
  },
  {
    "objectID": "content/lectures/10-mlr.html#r-squared",
    "href": "content/lectures/10-mlr.html#r-squared",
    "title": "10-mlr",
    "section": "R-squared",
    "text": "R-squared\n\n\\(R^2\\) is the percentage of variability in the response variable explained by the regression model.\n\n\nglance(pp_main_fit)$r.squared\n\n[1] 0.01320884\n\nglance(pp_int_fit)$r.squared\n\n[1] 0.0176922\n\n\n\n\nClearly the model with interactions has a higher \\(R^2\\).\n\n\n\n\nHowever using \\(R^2\\) for model selection in models with multiple explanatory variables is not a good idea as \\(R^2\\) increases when any variable is added to the model."
  },
  {
    "objectID": "content/lectures/10-mlr.html#adjusted-r-squared",
    "href": "content/lectures/10-mlr.html#adjusted-r-squared",
    "title": "10-mlr",
    "section": "Adjusted R-squared",
    "text": "Adjusted R-squared\nIt appears that adding the interaction actually increased adjusted \\(R^2\\), so we should indeed use the model with the interactions.\n\nglance(pp_main_fit)$adj.r.squared\n\n[1] 0.01258977\n\nglance(pp_int_fit)$adj.r.squared\n\n[1] 0.01676753"
  },
  {
    "objectID": "content/lectures/10-mlr.html#third-order-interactions",
    "href": "content/lectures/10-mlr.html#third-order-interactions",
    "title": "10-mlr",
    "section": "Third order interactions",
    "text": "Third order interactions\n\nCan you? Yes\nShould you? Probably not if you want to interpret these interactions in context of the data."
  },
  {
    "objectID": "content/lectures/10-mlr.html#in-pursuit-of-occams-razor",
    "href": "content/lectures/10-mlr.html#in-pursuit-of-occams-razor",
    "title": "10-mlr",
    "section": "In pursuit of Occam’s razor",
    "text": "In pursuit of Occam’s razor\n\n\nOccam’s Razor states that among competing hypotheses that predict equally well, the one with the fewest assumptions should be selected.\nModel selection follows this principle.\nWe only want to add another variable to the model if the addition of that variable brings something valuable in terms of predictive power to the model.\nIn other words, we prefer the simplest best model, i.e. parsimonious model."
  },
  {
    "objectID": "content/lectures/10-mlr.html#backward-selection",
    "href": "content/lectures/10-mlr.html#backward-selection",
    "title": "10-mlr",
    "section": "Backward selection",
    "text": "Backward selection\nFor this demo, we’ll ignore interaction effects…and just model main effects to start:\n\npp_full <-  lin_mod |>\n  fit(log_price ~ Width_in + Height_in + Surface + artistliving, data=pp) \n\nglance(pp_full)$adj.r.squared\n\n[1] 0.02570141\n\n\n\n\\(R^2\\) (full): 0.0257014`\n\n\n\nRemove artistliving\n\npp_noartist <- lin_mod |>\n  fit(log_price ~ Width_in + Height_in + Surface, data=pp) \n\nglance(pp_noartist)$adj.r.squared\n\n[1] 0.02579859\n\n\n\n\n\\(R^2\\) (full): 0.0257\n\\(R^2\\) (no artistliving): 0.0258\n\n…Improved variance explained\n\n\n\nRemove Surface\n\npp_noartist_nosurface <- lin_mod |>\n  fit(log_price ~ Width_in + Height_in, data=pp) \n\nglance(pp_noartist_nosurface)$adj.r.squared\n\n[1] 0.02231559\n\n\n\n\n\\(R^2\\) (full): 0.0257\n\\(R^2\\) (no artistliving): 0.0258\n\\(R^2\\) (no artistliving or Surface): 0.0223\n\n\n\n…no longer gaining improvement, so we stick with: log_price ~ Width_in + Height_in + Surface"
  },
  {
    "objectID": "content/lectures/10-mlr.html#other-approach",
    "href": "content/lectures/10-mlr.html#other-approach",
    "title": "10-mlr",
    "section": "Other approach:",
    "text": "Other approach:\n\n# requires package installation: \n# install.packages(\"olsrr\")\nlibrary(olsrr)\n\n\nStep 1: Fit model (w/o tidymodels)\n\n# fit the model (not using tidymodels)\nmod <- lm(log_price ~ Width_in + Height_in + Surface + artistliving, data=pp_Surf_lt_5000)\n\n\n\nStep 2: Determine which variables to remove\n\nols_step_backward_p(mod)\n\n\n                             Elimination Summary                               \n------------------------------------------------------------------------------\n        Variable                      Adj.                                        \nStep      Removed       R-Square    R-Square     C(p)        AIC         RMSE     \n------------------------------------------------------------------------------\n   1    artistliving      0.0261      0.0251    3.8495    12603.7727    1.8315    \n------------------------------------------------------------------------------\n\n\n…specifies that artistliving should be removed\n\n\nStep 2 (alternate): Compare all possible models…\n\nols_step_all_possible(mod) |>\n  arrange(desc(adjr))\n\n   Index N                              Predictors     R-Square Adj. R-Square\n1     11 3              Width_in Height_in Surface 0.0260749939  0.0251349118\n2     15 4 Width_in Height_in Surface artistliving 0.0263412027  0.0250876993\n3      5 2                      Width_in Height_in 0.0256902566  0.0250634893\n4     12 3         Width_in Height_in artistliving 0.0259732581  0.0250330779\n5      6 2                        Width_in Surface 0.0249136264  0.0242863596\n6     13 3           Width_in Surface artistliving 0.0251787948  0.0242378477\n7      7 2                   Width_in artistliving 0.0212864021  0.0206568018\n8      1 1                                Width_in 0.0209415833  0.0206267736\n9      8 2                    Surface artistliving 0.0132088377  0.0125897717\n10     2 1                                 Surface 0.0125899681  0.0122803381\n11    14 3          Height_in Surface artistliving 0.0130836930  0.0121310711\n12     9 2                       Height_in Surface 0.0126782901  0.0120431523\n13    10 2                  Height_in artistliving 0.0062698155  0.0056305552\n14     3 1                               Height_in 0.0058797727  0.0055601199\n15     4 1                            artistliving 0.0005531617  0.0002397573\n   Mallow's Cp\n1     3.849487\n2     5.000000\n3     3.077206\n4     4.174132\n5     5.555476\n6     6.709309\n7    17.130153\n8    16.230489\n9    51.971190\n10   52.001268\n11   45.305459\n12   44.599123\n13   65.048926\n14   64.293574\n15   91.485605"
  },
  {
    "objectID": "content/lectures/10-mlr.html#recap",
    "href": "content/lectures/10-mlr.html#recap",
    "title": "10-mlr",
    "section": "Recap",
    "text": "Recap\n\nCan you model and interpret linear models with multiple predictors?\nCan you explain the difference in a model with main effects vs. interaction effects?\nCan you compare different models and determine how to proceed?\nCan you carry out and explain backward selection?"
  },
  {
    "objectID": "content/lectures/10-mlr.html#suggested-reading",
    "href": "content/lectures/10-mlr.html#suggested-reading",
    "title": "10-mlr",
    "section": "Suggested Reading",
    "text": "Suggested Reading\nIntroduction to Modern Statistics Chapter 8: Linear Regression with Multiple Predictors"
  },
  {
    "objectID": "content/lectures/03-tidyr-slides.html#qa",
    "href": "content/lectures/03-tidyr-slides.html#qa",
    "title": "03-tidyr",
    "section": "Q&A",
    "text": "Q&A\n\nQ: The most confusing part for the “transmute” part of the lecture. Does this remove the column from the original dataframe or does it just separate it but it remains in the dataframe\nA: The original dataframe is not changed. It just creates a new dataframe. Nothing in dplyr will change your original dataframe, unless you explicitly assign it back to the same variable name.\n\n\nQ: It’s a totally new language for me and it’s kind of hard to write the function correctly and quickly at first\nA: That’s expected. You’re not alone!\n\n\nQ: I’m not sure when it would be ideal to use Select vs Transmute, as in today’s lecture\nA: When you want to extract existing columns, select! When you want to create a new column in a new dataframe, transmute!\n\n\nQ: Pulls - when are they necessary?\nA: dplyr pulls are necessary when you have values in a dataframe, but you want them in a typical vector…or you want to pull a single value.\n\n\nQ: If we don’t finish the notes on a given day, do I have to learn them on my own?\nA: Nope! We’ll pick up there on the next class day."
  },
  {
    "objectID": "content/lectures/03-tidyr-slides.html#course-announcements",
    "href": "content/lectures/03-tidyr-slides.html#course-announcements",
    "title": "03-tidyr",
    "section": "Course Announcements",
    "text": "Course Announcements\nDue Dates:\n\nLab 02 due Friday (1/20; 11:59 PM)\nHW01 due Monday (1/23; 11:59 PM)\nLecture Participation survey “due” after class\n\nNotes (1/19):\n\nHW01 available - let’s try this again\n\nQ2 can delete expect_true(true_var) and expect_false(false_var) from testing (they should only be in Q3)\n\nStaff office hours updated (see Canvas or website)"
  },
  {
    "objectID": "content/lectures/03-tidyr-slides.html#student-survey",
    "href": "content/lectures/03-tidyr-slides.html#student-survey",
    "title": "03-tidyr",
    "section": "Student Survey",
    "text": "Student Survey\n\n88% know Python; 20% know R; most (but not all!) have programmed before\nReasons for taking course: learn R, add to resume, analyze data, improve data science skills\n\n\nWhat y’all do outside of school:\n\nsports: soccer, rugby, vball, basketball, surfing, skating, etc.\nindoor activities: reading, gaming, cook, crochet, art, write, youtube, tiktok\nwork\nsleep\n\n\n\nMy favorite boring facts:\n\nI love cupcakes\nI like drinking tea\nI’ve never had a nosebleed\nI can sleep for up to 16-17 hours if I forget to set an alarm\nI don’t cook"
  },
  {
    "objectID": "content/lectures/03-tidyr-slides.html#tidy-data",
    "href": "content/lectures/03-tidyr-slides.html#tidy-data",
    "title": "03-tidyr",
    "section": "Tidy Data",
    "text": "Tidy Data\nThe opinionated tidyverse is named as such b/c it assumes/necessitates your data be “tidy”.\n\n\nTidy datasets are all alike, but every messy dataset is messy in its own way. —- Hadley Wickham\n\n\n\n\nEach variable must have its own column.\nEach observation must have its own row.\nEach value must have its own cell.\n\n\n\n\nSource: https://r4ds.had.co.nz/tidy-data.html"
  },
  {
    "objectID": "content/lectures/03-tidyr-slides.html#tidy-or-not",
    "href": "content/lectures/03-tidyr-slides.html#tidy-or-not",
    "title": "03-tidyr",
    "section": "Tidy or not?",
    "text": "Tidy or not?\n❓ Given the rules discussed, is the cat_lovers dataset tidy?\n\ncat_lovers <- read_csv(\"https://raw.githubusercontent.com/COGS137/datasets/main/cat-lovers.csv\")\ncat_lovers |> datatable()\n\n\n\n\n\n\n\n❓ Given the rules discussed, is the bike dataset tidy?\n\nbike <- read_csv2(\"https://raw.githubusercontent.com/COGS137/datasets/main/nc_bike_crash.csv\", \n                  na = c(\"NA\", \"\", \".\"))\nbike |> datatable()"
  },
  {
    "objectID": "content/lectures/03-tidyr-slides.html#summary-tables",
    "href": "content/lectures/03-tidyr-slides.html#summary-tables",
    "title": "03-tidyr",
    "section": "Summary tables",
    "text": "Summary tables\n❓ Which is a dataset? Which is a summary table?"
  },
  {
    "objectID": "content/lectures/03-tidyr-slides.html#your-turn",
    "href": "content/lectures/03-tidyr-slides.html#your-turn",
    "title": "03-tidyr",
    "section": "Your Turn",
    "text": "Your Turn\nThere are four representations of the same data/information provided in the tidyr packages: table1, table2, table3, and the combination of table4a and table4b. Given what we’ve discussed, which is the best (tidiest) way to represent these data?\n\n\nPut a green sticky on the front of your computer when you’re done. Put a pink if you want help/have a question."
  },
  {
    "objectID": "content/lectures/03-tidyr-slides.html#common-issues",
    "href": "content/lectures/03-tidyr-slides.html#common-issues",
    "title": "03-tidyr",
    "section": "Common issues",
    "text": "Common issues\n\nOne variable might be spread across multiple columns.\nOne observation might be scattered across multiple rows.\n\n\nSolution: pivoting!"
  },
  {
    "objectID": "content/lectures/03-tidyr-slides.html#pivoting",
    "href": "content/lectures/03-tidyr-slides.html#pivoting",
    "title": "03-tidyr",
    "section": "Pivoting",
    "text": "Pivoting\n\npivot_longerpivot_widerlong vs. wide\n\n\nFor when some of the column names are not names of variables, but values of a variable…\n\ntable4a\n\n# A tibble: 3 × 3\n  country     `1999` `2000`\n* <chr>        <int>  <int>\n1 Afghanistan    745   2666\n2 Brazil       37737  80488\n3 China       212258 213766\n\n\n\ntable4a |> \n  pivot_longer(c(`1999`, `2000`), names_to = \"year\", values_to = \"cases\")\n\n# A tibble: 6 × 3\n  country     year   cases\n  <chr>       <chr>  <int>\n1 Afghanistan 1999     745\n2 Afghanistan 2000    2666\n3 Brazil      1999   37737\n4 Brazil      2000   80488\n5 China       1999  212258\n6 China       2000  213766\n\n\n❓ Why are there backticks around the years? (Note: we have not discussed this yet)\n\n\nFor when an observation is scattered across multiple rows…\n\ntable2\n\n# A tibble: 12 × 4\n   country      year type            count\n   <chr>       <int> <chr>           <int>\n 1 Afghanistan  1999 cases             745\n 2 Afghanistan  1999 population   19987071\n 3 Afghanistan  2000 cases            2666\n 4 Afghanistan  2000 population   20595360\n 5 Brazil       1999 cases           37737\n 6 Brazil       1999 population  172006362\n 7 Brazil       2000 cases           80488\n 8 Brazil       2000 population  174504898\n 9 China        1999 cases          212258\n10 China        1999 population 1272915272\n11 China        2000 cases          213766\n12 China        2000 population 1280428583\n\n\n\ntable2 |>\n    pivot_wider(names_from = type, values_from = count)\n\n# A tibble: 6 × 4\n  country      year  cases population\n  <chr>       <int>  <int>      <int>\n1 Afghanistan  1999    745   19987071\n2 Afghanistan  2000   2666   20595360\n3 Brazil       1999  37737  172006362\n4 Brazil       2000  80488  174504898\n5 China        1999 212258 1272915272\n6 China        2000 213766 1280428583\n\n\n❓ Why aren’t there quotes around column names here…but there were in pivot_longer? (Note: we have not discussed this yet.)\n\n\n\nwide data contains values that do not repeat in the first column.\nlong format contains values that do repeat in the first column.\n\nBoth are good/helpful! We’ll return to this idea and discuss more during dataviz next week.\nBriefly:\n\nwide data: analysis\nlong data: plotting"
  },
  {
    "objectID": "content/lectures/03-tidyr-slides.html#separating-uniting",
    "href": "content/lectures/03-tidyr-slides.html#separating-uniting",
    "title": "03-tidyr",
    "section": "Separating & Uniting",
    "text": "Separating & Uniting\n\nseparateunite\n\n\nFor when multiple pieces of information are stored in a single column…\n\ntable3\n\n# A tibble: 6 × 3\n  country      year rate             \n* <chr>       <int> <chr>            \n1 Afghanistan  1999 745/19987071     \n2 Afghanistan  2000 2666/20595360    \n3 Brazil       1999 37737/172006362  \n4 Brazil       2000 80488/174504898  \n5 China        1999 212258/1272915272\n6 China        2000 213766/1280428583\n\n\n\ntable3 |> \n  separate(rate, into = c(\"cases\", \"population\"))\n\n# A tibble: 6 × 4\n  country      year cases  population\n  <chr>       <int> <chr>  <chr>     \n1 Afghanistan  1999 745    19987071  \n2 Afghanistan  2000 2666   20595360  \n3 Brazil       1999 37737  172006362 \n4 Brazil       2000 80488  174504898 \n5 China        1999 212258 1272915272\n6 China        2000 213766 1280428583\n\n\n…but…but…cases and population should be numeric…\n\ntable3 |> \n  separate(rate, into = c(\"cases\", \"population\"), convert = TRUE)\n\n# A tibble: 6 × 4\n  country      year  cases population\n  <chr>       <int>  <int>      <int>\n1 Afghanistan  1999    745   19987071\n2 Afghanistan  2000   2666   20595360\n3 Brazil       1999  37737  172006362\n4 Brazil       2000  80488  174504898\n5 China        1999 212258 1272915272\n6 China        2000 213766 1280428583\n\n\n\n\nUnite is the opposite…it combines data stored across multiple columns.\nThe general syntax is:\n\ndf |>\n  unite(new_col, first_col, second_col)"
  },
  {
    "objectID": "content/lectures/03-tidyr-slides.html#joins",
    "href": "content/lectures/03-tidyr-slides.html#joins",
    "title": "03-tidyr",
    "section": "Joins",
    "text": "Joins\nIf we look at table4a, it’s missing the population information. That’s stored in a separate table…table4b\n\ntable4b\n\n# A tibble: 3 × 3\n  country         `1999`     `2000`\n* <chr>            <int>      <int>\n1 Afghanistan   19987071   20595360\n2 Brazil       172006362  174504898\n3 China       1272915272 1280428583\n\n\n…which is also in the “wide” format\n\n…so we pivot both tables longer\n\ntidy4a <- table4a |> \n  pivot_longer(c(`1999`, `2000`), names_to = \"year\", values_to = \"cases\")\n\ntidy4b <- table4b |> \n  pivot_longer(c(`1999`, `2000`), names_to = \"year\", values_to = \"population\")\n\ntidy4b\n\n# A tibble: 6 × 3\n  country     year  population\n  <chr>       <chr>      <int>\n1 Afghanistan 1999    19987071\n2 Afghanistan 2000    20595360\n3 Brazil      1999   172006362\n4 Brazil      2000   174504898\n5 China       1999  1272915272\n6 China       2000  1280428583\n\n\n\n\n…but how do we get them into a single tidy dataset?\n\n\nA join!\n\nleft_join(tidy4a, tidy4b)\n\n# A tibble: 6 × 4\n  country     year   cases population\n  <chr>       <chr>  <int>      <int>\n1 Afghanistan 1999     745   19987071\n2 Afghanistan 2000    2666   20595360\n3 Brazil      1999   37737  172006362\n4 Brazil      2000   80488  174504898\n5 China       1999  212258 1272915272\n6 China       2000  213766 1280428583\n\n\n\n\n\nSource: R4DS"
  },
  {
    "objectID": "content/lectures/03-tidyr-slides.html#the-data-nycflights13",
    "href": "content/lectures/03-tidyr-slides.html#the-data-nycflights13",
    "title": "03-tidyr",
    "section": "The Data: nycflights13",
    "text": "The Data: nycflights13\n\nlibrary(nycflights13)\n\n\nairlines : links airline to two letter code\nairports : ID’ed by FAA code\nplanes : ID’ed by tailnum\nairport : weather each hour; id’ed by two letter airport code\n\n\n\n\n\nImage Source: https://r4ds.had.co.nz/relational-data.html)\n\n\n\n\n\nflights connects to planes via a single variable, tailnum.\nflights connects to airlines through the carrier variable.\nflights connects to airports in two ways: via the origin and dest variables.\nflights connects to weather via origin (the location), and year, month, day and hour (the time)."
  },
  {
    "objectID": "content/lectures/03-tidyr-slides.html#mutating-joins",
    "href": "content/lectures/03-tidyr-slides.html#mutating-joins",
    "title": "03-tidyr",
    "section": "Mutating Joins",
    "text": "Mutating Joins\nmutating joins - add new variables to a data frame from matching observations in another\n\nFor simplicity, we’ll work with only a handful of columns…\n\nflights |> \n  select(year:day, hour, tailnum, carrier) |> \n  left_join(airlines, by = \"carrier\")\n\n# A tibble: 336,776 × 7\n    year month   day  hour tailnum carrier name                    \n   <int> <int> <int> <dbl> <chr>   <chr>   <chr>                   \n 1  2013     1     1     5 N14228  UA      United Air Lines Inc.   \n 2  2013     1     1     5 N24211  UA      United Air Lines Inc.   \n 3  2013     1     1     5 N619AA  AA      American Airlines Inc.  \n 4  2013     1     1     5 N804JB  B6      JetBlue Airways         \n 5  2013     1     1     6 N668DN  DL      Delta Air Lines Inc.    \n 6  2013     1     1     5 N39463  UA      United Air Lines Inc.   \n 7  2013     1     1     6 N516JB  B6      JetBlue Airways         \n 8  2013     1     1     6 N829AS  EV      ExpressJet Airlines Inc.\n 9  2013     1     1     6 N593JB  B6      JetBlue Airways         \n10  2013     1     1     6 N3ALAA  AA      American Airlines Inc.  \n# … with 336,766 more rows\n\n\nThere is now a new column name…coming from the airlines data frame.\n\n\nleft_join:\n\nkeeps all rows in first df (here: flights)\nadds all matching information from second df (here: airlines); adds NAs for any observations not in airlines\n\n\n\nOther joins:\nright_join: keeps all observations in second df full_join: keeps all observations in either df\n\n\n\n\n\nImage Source: https://r4ds.had.co.nz/relational-data.html\n\n\n\n\ninner_join:\n\ntakes only rows in both dfs\n\n\n\n\nImage Source: https://r4ds.had.co.nz/relational-data.html"
  },
  {
    "objectID": "content/lectures/03-tidyr-slides.html#suggested-reading",
    "href": "content/lectures/03-tidyr-slides.html#suggested-reading",
    "title": "03-tidyr",
    "section": "Suggested Reading",
    "text": "Suggested Reading\nR4DS:\n\nChapter 12: Tidy Data\nChapter 13: Relational Data\n\n\n\n\nhttps://cogs137.github.io/website/"
  },
  {
    "objectID": "content/lectures/03-tidyr.html",
    "href": "content/lectures/03-tidyr.html",
    "title": "03-tidyr",
    "section": "",
    "text": "Q: The most confusing part for the “transmute” part of the lecture. Does this remove the column from the original dataframe or does it just separate it but it remains in the dataframe\nA: The original dataframe is not changed. It just creates a new dataframe. Nothing in dplyr will change your original dataframe, unless you explicitly assign it back to the same variable name.\n\n\nQ: It’s a totally new language for me and it’s kind of hard to write the function correctly and quickly at first\nA: That’s expected. You’re not alone!\n\n\nQ: I’m not sure when it would be ideal to use Select vs Transmute, as in today’s lecture\nA: When you want to extract existing columns, select! When you want to create a new column in a new dataframe, transmute!\n\n\nQ: Pulls - when are they necessary?\nA: dplyr pulls are necessary when you have values in a dataframe, but you want them in a typical vector…or you want to pull a single value.\n\n\nQ: If we don’t finish the notes on a given day, do I have to learn them on my own?\nA: Nope! We’ll pick up there on the next class day.\n\n\n\n\nDue Dates:\n\nLab 02 due Friday (1/20; 11:59 PM)\nHW01 due Monday (1/23; 11:59 PM)\nLecture Participation survey “due” after class\n\nNotes (1/19):\n\nHW01 available - let’s try this again\n\nQ2 can delete expect_true(true_var) and expect_false(false_var) from testing (they should only be in Q3)\n\nStaff office hours updated (see Canvas or website)\n\n\n\n\n\n88% know Python; 20% know R; most (but not all!) have programmed before\nReasons for taking course: learn R, add to resume, analyze data, improve data science skills\n\n\nWhat y’all do outside of school:\n\nsports: soccer, rugby, vball, basketball, surfing, skating, etc.\nindoor activities: reading, gaming, cook, crochet, art, write, youtube, tiktok\nwork\nsleep\n\n\n\nMy favorite boring facts:\n\nI love cupcakes\nI like drinking tea\nI’ve never had a nosebleed\nI can sleep for up to 16-17 hours if I forget to set an alarm\nI don’t cook\n\n\n\n\n\nThe opinionated tidyverse is named as such b/c it assumes/necessitates your data be “tidy”.\n\n\nTidy datasets are all alike, but every messy dataset is messy in its own way. —- Hadley Wickham\n\n\n\n\nEach variable must have its own column.\nEach observation must have its own row.\nEach value must have its own cell.\n\n\n\nSource: https://r4ds.had.co.nz/tidy-data.html\n\n\n\n\n❓ Given the rules discussed, is the cat_lovers dataset tidy?\n\ncat_lovers <- read_csv(\"https://raw.githubusercontent.com/COGS137/datasets/main/cat-lovers.csv\")\n\nRows: 60 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): name, number_of_cats, handedness\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ncat_lovers |> datatable()\n\n\n\n\n\n\n\n❓ Given the rules discussed, is the bike dataset tidy?\n\nbike <- read_csv2(\"https://raw.githubusercontent.com/COGS137/datasets/main/nc_bike_crash.csv\", \n                  na = c(\"NA\", \"\", \".\"))\n\nℹ Using \"','\" as decimal and \"'.'\" as grouping mark. Use `read_delim()` for more control.\n\n\nRows: 5716 Columns: 54\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\nchr  (44): AmbulanceR, BikeAge_Gr, Bike_Alc_D, Bike_Dir, Bike_Injur, Bike_Po...\ndbl   (8): FID, OBJECTID, Bike_Age, Crash_Hour, Crash_Ty_1, Crash_Year, Drvr...\ndttm  (1): Crash_Time\ndate  (1): Crash_Date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nbike |> datatable()\n\nWarning in instance$preRenderHook(instance): It seems your data is too\nbig for client-side DataTables. You may consider server-side processing:\nhttps://rstudio.github.io/DT/server.html\n\n\n\n\n\n\n\n\n\n\n\n❓ Which is a dataset? Which is a summary table?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThere are four representations of the same data/information provided in the tidyr packages: table1, table2, table3, and the combination of table4a and table4b. Given what we’ve discussed, which is the best (tidiest) way to represent these data?\n\n\nPut a green sticky on the front of your computer when you’re done. Put a pink if you want help/have a question.\n\n\n\n\nOne variable might be spread across multiple columns.\nOne observation might be scattered across multiple rows.\n\n\nSolution: pivoting!\n\n\n\n\n\npivot_longerpivot_widerlong vs. wide\n\n\nFor when some of the column names are not names of variables, but values of a variable…\n\ntable4a\n\n# A tibble: 3 × 3\n  country     `1999` `2000`\n* <chr>        <int>  <int>\n1 Afghanistan    745   2666\n2 Brazil       37737  80488\n3 China       212258 213766\n\n\n\ntable4a |> \n  pivot_longer(c(`1999`, `2000`), names_to = \"year\", values_to = \"cases\")\n\n# A tibble: 6 × 3\n  country     year   cases\n  <chr>       <chr>  <int>\n1 Afghanistan 1999     745\n2 Afghanistan 2000    2666\n3 Brazil      1999   37737\n4 Brazil      2000   80488\n5 China       1999  212258\n6 China       2000  213766\n\n\n❓ Why are there backticks around the years? (Note: we have not discussed this yet)\n\n\nFor when an observation is scattered across multiple rows…\n\ntable2\n\n# A tibble: 12 × 4\n   country      year type            count\n   <chr>       <int> <chr>           <int>\n 1 Afghanistan  1999 cases             745\n 2 Afghanistan  1999 population   19987071\n 3 Afghanistan  2000 cases            2666\n 4 Afghanistan  2000 population   20595360\n 5 Brazil       1999 cases           37737\n 6 Brazil       1999 population  172006362\n 7 Brazil       2000 cases           80488\n 8 Brazil       2000 population  174504898\n 9 China        1999 cases          212258\n10 China        1999 population 1272915272\n11 China        2000 cases          213766\n12 China        2000 population 1280428583\n\n\n\ntable2 |>\n    pivot_wider(names_from = type, values_from = count)\n\n# A tibble: 6 × 4\n  country      year  cases population\n  <chr>       <int>  <int>      <int>\n1 Afghanistan  1999    745   19987071\n2 Afghanistan  2000   2666   20595360\n3 Brazil       1999  37737  172006362\n4 Brazil       2000  80488  174504898\n5 China        1999 212258 1272915272\n6 China        2000 213766 1280428583\n\n\n❓ Why aren’t there quotes around column names here…but there were in pivot_longer? (Note: we have not discussed this yet.)\n\n\n\nwide data contains values that do not repeat in the first column.\nlong format contains values that do repeat in the first column.\n\nBoth are good/helpful! We’ll return to this idea and discuss more during dataviz next week.\nBriefly:\n\nwide data: analysis\nlong data: plotting\n\n\n\n\n\n\n\n\nseparateunite\n\n\nFor when multiple pieces of information are stored in a single column…\n\ntable3\n\n# A tibble: 6 × 3\n  country      year rate             \n* <chr>       <int> <chr>            \n1 Afghanistan  1999 745/19987071     \n2 Afghanistan  2000 2666/20595360    \n3 Brazil       1999 37737/172006362  \n4 Brazil       2000 80488/174504898  \n5 China        1999 212258/1272915272\n6 China        2000 213766/1280428583\n\n\n\ntable3 |> \n  separate(rate, into = c(\"cases\", \"population\"))\n\n# A tibble: 6 × 4\n  country      year cases  population\n  <chr>       <int> <chr>  <chr>     \n1 Afghanistan  1999 745    19987071  \n2 Afghanistan  2000 2666   20595360  \n3 Brazil       1999 37737  172006362 \n4 Brazil       2000 80488  174504898 \n5 China        1999 212258 1272915272\n6 China        2000 213766 1280428583\n\n\n…but…but…cases and population should be numeric…\n\ntable3 |> \n  separate(rate, into = c(\"cases\", \"population\"), convert = TRUE)\n\n# A tibble: 6 × 4\n  country      year  cases population\n  <chr>       <int>  <int>      <int>\n1 Afghanistan  1999    745   19987071\n2 Afghanistan  2000   2666   20595360\n3 Brazil       1999  37737  172006362\n4 Brazil       2000  80488  174504898\n5 China        1999 212258 1272915272\n6 China        2000 213766 1280428583\n\n\n\n\nUnite is the opposite…it combines data stored across multiple columns.\nThe general syntax is:\n\ndf |>\n  unite(new_col, first_col, second_col)\n\n\n\n\n\n\n\nIf we look at table4a, it’s missing the population information. That’s stored in a separate table…table4b\n\ntable4b\n\n# A tibble: 3 × 3\n  country         `1999`     `2000`\n* <chr>            <int>      <int>\n1 Afghanistan   19987071   20595360\n2 Brazil       172006362  174504898\n3 China       1272915272 1280428583\n\n\n…which is also in the “wide” format\n\n…so we pivot both tables longer\n\ntidy4a <- table4a |> \n  pivot_longer(c(`1999`, `2000`), names_to = \"year\", values_to = \"cases\")\n\ntidy4b <- table4b |> \n  pivot_longer(c(`1999`, `2000`), names_to = \"year\", values_to = \"population\")\n\ntidy4b\n\n# A tibble: 6 × 3\n  country     year  population\n  <chr>       <chr>      <int>\n1 Afghanistan 1999    19987071\n2 Afghanistan 2000    20595360\n3 Brazil      1999   172006362\n4 Brazil      2000   174504898\n5 China       1999  1272915272\n6 China       2000  1280428583\n\n\n\n\n…but how do we get them into a single tidy dataset?\n\n\nA join!\n\nleft_join(tidy4a, tidy4b)\n\nJoining, by = c(\"country\", \"year\")\n\n\n# A tibble: 6 × 4\n  country     year   cases population\n  <chr>       <chr>  <int>      <int>\n1 Afghanistan 1999     745   19987071\n2 Afghanistan 2000    2666   20595360\n3 Brazil      1999   37737  172006362\n4 Brazil      2000   80488  174504898\n5 China       1999  212258 1272915272\n6 China       2000  213766 1280428583\n\n\n\n\nSource: R4DS\n\n\n\n\n\nlibrary(nycflights13)\n\n\nairlines : links airline to two letter code\nairports : ID’ed by FAA code\nplanes : ID’ed by tailnum\nairport : weather each hour; id’ed by two letter airport code\n\n\n\n\n\nImage Source: https://r4ds.had.co.nz/relational-data.html)\n\n\n\n\n\nflights connects to planes via a single variable, tailnum.\nflights connects to airlines through the carrier variable.\nflights connects to airports in two ways: via the origin and dest variables.\nflights connects to weather via origin (the location), and year, month, day and hour (the time).\n\n\n\n\n\nmutating joins - add new variables to a data frame from matching observations in another\n\nFor simplicity, we’ll work with only a handful of columns…\n\nflights |> \n  select(year:day, hour, tailnum, carrier) |> \n  left_join(airlines, by = \"carrier\")\n\n# A tibble: 336,776 × 7\n    year month   day  hour tailnum carrier name                    \n   <int> <int> <int> <dbl> <chr>   <chr>   <chr>                   \n 1  2013     1     1     5 N14228  UA      United Air Lines Inc.   \n 2  2013     1     1     5 N24211  UA      United Air Lines Inc.   \n 3  2013     1     1     5 N619AA  AA      American Airlines Inc.  \n 4  2013     1     1     5 N804JB  B6      JetBlue Airways         \n 5  2013     1     1     6 N668DN  DL      Delta Air Lines Inc.    \n 6  2013     1     1     5 N39463  UA      United Air Lines Inc.   \n 7  2013     1     1     6 N516JB  B6      JetBlue Airways         \n 8  2013     1     1     6 N829AS  EV      ExpressJet Airlines Inc.\n 9  2013     1     1     6 N593JB  B6      JetBlue Airways         \n10  2013     1     1     6 N3ALAA  AA      American Airlines Inc.  \n# … with 336,766 more rows\n\n\nThere is now a new column name…coming from the airlines data frame.\n\n\nleft_join:\n\nkeeps all rows in first df (here: flights)\nadds all matching information from second df (here: airlines); adds NAs for any observations not in airlines\n\n\n\nOther joins:\nright_join: keeps all observations in second df full_join: keeps all observations in either df\n\n\n\n\n\nImage Source: https://r4ds.had.co.nz/relational-data.html\n\n\n\n\ninner_join:\n\ntakes only rows in both dfs\n\n\n\n\nImage Source: https://r4ds.had.co.nz/relational-data.html"
  },
  {
    "objectID": "content/lectures/03-tidyr.html#suggested-reading",
    "href": "content/lectures/03-tidyr.html#suggested-reading",
    "title": "03-tidyr",
    "section": "Suggested Reading",
    "text": "Suggested Reading\nR4DS:\n\nChapter 12: Tidy Data\nChapter 13: Relational Data"
  },
  {
    "objectID": "content/lectures/00-welcome-slides.html#agenda",
    "href": "content/lectures/00-welcome-slides.html#agenda",
    "title": "00-welcome",
    "section": "Agenda",
    "text": "Agenda\n\nDescribe what this class is\nDescribe how the class will run\nGo over the tooling for this course: R, RStudio, GitHub"
  },
  {
    "objectID": "content/lectures/00-welcome-slides.html#what-is-r",
    "href": "content/lectures/00-welcome-slides.html#what-is-r",
    "title": "00-welcome",
    "section": "What is R?",
    "text": "What is R?\n : R is a statistical programming language.\nWhile R has most/all of the functionality of YFPL (your favorite programming language), it was designed for the specific use of analyzing data."
  },
  {
    "objectID": "content/lectures/00-welcome-slides.html#what-is-data-science",
    "href": "content/lectures/00-welcome-slides.html#what-is-data-science",
    "title": "00-welcome",
    "section": "What is data science?",
    "text": "What is data science?\n: Data science is the scientific process of using data to answer interesting questions and/or solve important problems."
  },
  {
    "objectID": "content/lectures/00-welcome-slides.html#practical-data-science-in-r",
    "href": "content/lectures/00-welcome-slides.html#practical-data-science-in-r",
    "title": "00-welcome",
    "section": "Practical Data Science in R",
    "text": "Practical Data Science in R\n\n\nProgram at the introductory level in the R statistical programming language\nEmploy the tidyverse suite of packages to interact with, wrangle, visualize, and model data\nExplain & apply statistical concepts (estimation, linear regression, logistic regression, etc.) for data analysis\nCommunicate data science projects through effective visualization, oral presentation, and written reports"
  },
  {
    "objectID": "content/lectures/00-welcome-slides.html#who-am-i",
    "href": "content/lectures/00-welcome-slides.html#who-am-i",
    "title": "00-welcome",
    "section": "Who am I?",
    "text": "Who am I?\nShannon Ellis: Associate Teaching Professor, Mom & wife, volleyball-obsessed, and baking & cooking lover\n   sellis@ucsd.edu     shanellis.com     Peterson Hall 104     Tu/Th 2-3:20PM (Lab: Fri 1-1:50PM)"
  },
  {
    "objectID": "content/lectures/00-welcome-slides.html#who-all-is-involved",
    "href": "content/lectures/00-welcome-slides.html#who-all-is-involved",
    "title": "00-welcome",
    "section": "Who all is involved?",
    "text": "Who all is involved?\n\n\n\nInstructor\nShannon Ellis\nsellis@ucsd.edu\nWed 2-3\nVirtual (see canvas)\n\n\n\n\n\nTh 12:50-1:50\nCSB 243\n\n\nTA\nShubham Kulkarni\n\nTime TBD\nLocation TBD\n\n\nIAs\nChristian Kim\n\nTime TBD\nLocation TBD"
  },
  {
    "objectID": "content/lectures/00-welcome-slides.html#what-is-this-course",
    "href": "content/lectures/00-welcome-slides.html#what-is-this-course",
    "title": "00-welcome",
    "section": "What is this course?",
    "text": "What is this course?\nEverything you want to know about the course, and everything you will need for the course will be posted at: https://cogs137.github.io/website/\n\n\nIs this an intro CS course? No.\nWill we be doing computing? Yes.\nWhat computing language will we learn? R.\nIs this an intro stats course? No.\nWill we be doing stats? Yes.\nAre there any prerequisites? Yes, an intro statistics course!"
  },
  {
    "objectID": "content/lectures/00-welcome-slides.html#soi-dont-have-to-know-how-to-program-already",
    "href": "content/lectures/00-welcome-slides.html#soi-dont-have-to-know-how-to-program-already",
    "title": "00-welcome",
    "section": "So…I don’t have to know how to program already?",
    "text": "So…I don’t have to know how to program already?\n\n\n\n\nNope! The first few weeks of the course will be all about getting comfortable using the R programming language!\n After that, we’ll focus on delving into interesting statistical analyses through case studies.\n\n\n\nArtwork by @allison_horst"
  },
  {
    "objectID": "content/lectures/00-welcome-slides.html#the-general-plan",
    "href": "content/lectures/00-welcome-slides.html#the-general-plan",
    "title": "00-welcome",
    "section": "The General Plan",
    "text": "The General Plan\n\nWeeks 1-4: Learn to program in the tidyverse in R\nWeeks 5-10: Communication, Data Analysis, Statistics, & Case Studies\n\nCS01: Right to Carry\nCS02: Vaping Behaviors"
  },
  {
    "objectID": "content/lectures/00-welcome-slides.html#the-nitty-gritty",
    "href": "content/lectures/00-welcome-slides.html#the-nitty-gritty",
    "title": "00-welcome",
    "section": "The Nitty Gritty",
    "text": "The Nitty Gritty\n\nLectureIn-personWaitlistLab & OHMaterials\n\n\nClass Meetings\n\nInteractive\nLectures & lots of learn-by-doing\nBring your laptop to class every day\n\n\n\nIn-person, synchronous learning\n\nI will be teaching (so long as I’m healthy and have child care) in person.\nLectures will be podcast.\nAttendance will be incentivized using a daily participation survey.\nIf you’re not feeling well, please stay home. I will do the same.\nExam will be take-home.\n\n\n\nThe (Dreaded) Waitlist\n\nCourse enrollment is supposed to be 50 for this course\nThere are 72 people currently enrolled\nI don’t control the waitlist (cogsadvising@ucsd.edu does)\nI’d anticipate our staff adding 3-5 people from the waitlist (but cannot guarantee this)\n\n\n\nLab & Office Hours\n\nMy office hours begin week 1; TA/IA OH begin week 2\nLab will start this Fri (week 1)\nI will hang out after class today for questions/concerns from students\n\n\n\nCourse Materials\n\nTextbooks are free and available online\nCourse platforms:\n\nWebsite : schedule, policies, due dates, etc.\nGitHub : retrieving assignments, labs, exams, etc.\ndatahub : completing assignments, labs, exams etc.\nGradescope : submitting assignments\nCanvas : grades, course-specific links\nCampuswire : Q&A"
  },
  {
    "objectID": "content/lectures/00-welcome-slides.html#diversity-inclusion",
    "href": "content/lectures/00-welcome-slides.html#diversity-inclusion",
    "title": "00-welcome",
    "section": "Diversity & Inclusion:",
    "text": "Diversity & Inclusion:\nGoal: every student be well-served by this course\n\nPhilosophy: The diversity of students in this class is a huge asset to our learning community; our differences provide opportunities for learning and understanding.\n\n\nPlan: Present course materials that are conscious of and respectful to diversity (gender identity, sexuality, disability, age, socioeconomic status, ethnicity, race, nationality, religion, politics, and culture)\n\n\nBut… if I ever fall short or if you ever have suggestions for improvement, please do share with me! There is also an anonymous Google Form if you’re more comfortable there."
  },
  {
    "objectID": "content/lectures/00-welcome-slides.html#a-new-ish-course",
    "href": "content/lectures/00-welcome-slides.html#a-new-ish-course",
    "title": "00-welcome",
    "section": "A new-ish course!",
    "text": "A new-ish course!\n\nOffered once previously\nIf something doesn’t make sense, tell me!\nIf you’ve got feedback/suggestions, I’m all ears!\n\n\nDifferences since last iteration:\n\nLess…pretty much everything\nNew website/lecture platform (quarto)\nTu/Th and not early in the morning\nGroup mates differ\nIncreased focus on communication\nMultiple final project options\nSlightly larger class & slightly smaller staff\nI’m a mom & just coming back from parental leave"
  },
  {
    "objectID": "content/lectures/00-welcome-slides.html#how-to-get-help",
    "href": "content/lectures/00-welcome-slides.html#how-to-get-help",
    "title": "00-welcome",
    "section": "How to get help",
    "text": "How to get help\n\nLab\nOffice Hours\nCampuswire\n\n\nA few guidelines:\n1. No duplicates.\n2. Public posts are best.\n3. Posts should include your question, what you've tried so far, & resources used.\n4. Helping others is encouraged.\n5. No assignment code in public posts.\n6. We're not robots."
  },
  {
    "objectID": "content/lectures/00-welcome-slides.html#the-r-community",
    "href": "content/lectures/00-welcome-slides.html#the-r-community",
    "title": "00-welcome",
    "section": " The R Community",
    "text": "The R Community\n\n\n\nR Rollercoaster\n\n\n\nArtwork by @allison_horst"
  },
  {
    "objectID": "content/lectures/00-welcome-slides.html#academic-integrity",
    "href": "content/lectures/00-welcome-slides.html#academic-integrity",
    "title": "00-welcome",
    "section": "Academic integrity",
    "text": "Academic integrity\nDon’t cheat.\n\nTeamwork is allowed, but you should be able to answer “Yes” to each of the following: - Can I explain each piece of code and each analysis carried out in what I’m submitting? - Could I reproduce this code/analysis on my own?\n\n\nThe Internet is a great resource. - Cite your sources.\n\n\nTeamwork is not allowed on your midterm. - It is open-notes and open-Google - You cannot discuss the questions on the exam with anyone."
  },
  {
    "objectID": "content/lectures/00-welcome-slides.html#course-components",
    "href": "content/lectures/00-welcome-slides.html#course-components",
    "title": "00-welcome",
    "section": "Course components:",
    "text": "Course components:\n\n\nLabs (8): Individual submission; graded on effort\nHomework (4): Individual submission; graded on correctness\nExam (1): Individual completion & submission, take-home midterm\nCase Studies (2): Team submission, technical analysis report\nFinal Project (1) : Team submission, due Thurs of finals week"
  },
  {
    "objectID": "content/lectures/00-welcome-slides.html#grading",
    "href": "content/lectures/00-welcome-slides.html#grading",
    "title": "00-welcome",
    "section": "Grading",
    "text": "Grading\nYour final grade will be comprised of the following:\n\n\n\nAssignment (#)\n% of grade\n\n\n\n\nLabs (8)\n16%\n\n\nHomework (4)\n32%\n\n\nMidterm (1)\n15%\n\n\nCase Study Projects* (2)\n20%\n\n\nFinal project* (1)\n17%\n\n\n\n* indicates group submission"
  },
  {
    "objectID": "content/lectures/00-welcome-slides.html#latemissed-work-policy",
    "href": "content/lectures/00-welcome-slides.html#latemissed-work-policy",
    "title": "00-welcome",
    "section": "Late/missed work policy",
    "text": "Late/missed work policy\n\nHomework and case study projects: accepted up to 3 days (72 hours) after the assigned deadline for a 25% deduction\nNo late deadlines for labs, the exam, or the final project\n\n\n\nNote: Prof Ellis is a reasonable person; reach out to her if you have an extenuating circumstance at any point in the quarter."
  },
  {
    "objectID": "content/lectures/00-welcome-slides.html#datahub",
    "href": "content/lectures/00-welcome-slides.html#datahub",
    "title": "00-welcome",
    "section": "Datahub",
    "text": "Datahub\nDatahub is a platform hosted by UCSD that gives students access to computational resources.\nThis means that while you’ll be typing on your keyboard, you’ll be using UCSD’s computers in this class.\nWebsite: https://datahub.ucsd.edu/\n\nLaunch Environment\nWhen working on “stuff” for this course, select the COGS 137 environment.\n\n\n\ndatahub"
  },
  {
    "objectID": "content/lectures/00-welcome-slides.html#toolkit",
    "href": "content/lectures/00-welcome-slides.html#toolkit",
    "title": "00-welcome",
    "section": "Toolkit",
    "text": "Toolkit\n\ntoolkit\nScriptability \\(\\rightarrow\\) R\nLiterate programming (code, narrative, output in one place) \\(\\rightarrow\\) R Markdown\nVersion control \\(\\rightarrow\\) Git / GitHub"
  },
  {
    "objectID": "content/lectures/00-welcome-slides.html#r-and-rstudio",
    "href": "content/lectures/00-welcome-slides.html#r-and-rstudio",
    "title": "00-welcome",
    "section": "R and RStudio",
    "text": "R and RStudio\n\nR/RStudioTourTryR packages\n\n\nR & RStudio\n\nR is a statistical programming language\nRStudio is a convenient interface for R (an integreated development environment, IDE)\n\n\n\n\n[DEMO]\n\nConcepts introduced:\n\nConsole\nUsing R as a calculator\nEnvironment\nLoading and viewing a data frame\nAccessing a variable in a data frame\nR functions\n\n\n\nYour Turn\n\nLogin to datahub\nCarry out a mathematical operation in the console\nView the airquality dataframe\nAccess a column from the airquality dataframe\nCalculate the median for one of the numeric columns\n\nPut a green sticky on the front of your computer when you’re done. Put a pink if you want help/have a question.\n\n\n\nPackages are the fundamental units of reproducible R code. They include reusable R functions, the documentation that describes how to use them, and sample data 1\nAs of Jan 2023, there are ~18,979 R packages available on CRAN (the Comprehensive R Archive Network)2\nWe’re going to work with a small (but important) subset of these!\n\n\n\n\nWickham and Bryan, R PackagesCRAN contributed packages"
  },
  {
    "objectID": "content/lectures/00-welcome-slides.html#what-is-the-tidyverse",
    "href": "content/lectures/00-welcome-slides.html#what-is-the-tidyverse",
    "title": "00-welcome",
    "section": "What is the Tidyverse?",
    "text": "What is the Tidyverse?\n\n\n\n\n\ntidyverse.org\n\n\nThe tidyverse is an opinionated collection of R packages designed for data science.\nAll packages share an underlying philosophy and a common syntax."
  },
  {
    "objectID": "content/lectures/00-welcome-slides.html#rstudio-projects3",
    "href": "content/lectures/00-welcome-slides.html#rstudio-projects3",
    "title": "00-welcome",
    "section": "RStudio Projects1",
    "text": "RStudio Projects1\n\nBuilt-in functionality to keep all files for a single project organized\n\nRStudio Projects Documentation"
  },
  {
    "objectID": "content/lectures/00-welcome-slides.html#r-markdown",
    "href": "content/lectures/00-welcome-slides.html#r-markdown",
    "title": "00-welcome",
    "section": "R Markdown",
    "text": "R Markdown\n\nFully reproducible reports – each time you knit, the document is executed from top to bottom\nSimple markdown syntax for text\nCode goes in chunks, defined by three backticks, narrative goes outside of chunks"
  },
  {
    "objectID": "content/lectures/00-welcome-slides.html#r-markdown-tips",
    "href": "content/lectures/00-welcome-slides.html#r-markdown-tips",
    "title": "00-welcome",
    "section": "R Markdown tips",
    "text": "R Markdown tips\n\nKeep the R Markdown cheat sheet and Markdown Quick Reference (Help -> Markdown Quick Reference) handy, we’ll refer to it often as the course progresses\nThe workspace of your R Markdown document is separate from the Console\n\n\n\n[DEMO]"
  },
  {
    "objectID": "content/lectures/00-welcome-slides.html#how-will-we-use-r-markdown",
    "href": "content/lectures/00-welcome-slides.html#how-will-we-use-r-markdown",
    "title": "00-welcome",
    "section": "How will we use R Markdown?",
    "text": "How will we use R Markdown?\n\nEvery lab / project / homework / notes / etc. is an R Markdown document\nYou’ll always have a template R Markdown document to start with\nThe amount of scaffolding in the template will decrease over the quarter"
  },
  {
    "objectID": "content/lectures/00-welcome-slides.html#collaboration-git-github",
    "href": "content/lectures/00-welcome-slides.html#collaboration-git-github",
    "title": "00-welcome",
    "section": "Collaboration: Git & GitHub",
    "text": "Collaboration: Git & GitHub\n\nThe statistical programming language we’ll use is R\nThe software we use to interface with R is RStudio\nBut how do I get you the course materials that you can build on for your assignments?\n\nHint: I’m not going to email you documents, that would be a mess!"
  },
  {
    "objectID": "content/lectures/00-welcome-slides.html#version-control",
    "href": "content/lectures/00-welcome-slides.html#version-control",
    "title": "00-welcome",
    "section": "Version control",
    "text": "Version control\n\nWe introduced GitHub as a platform for collaboration\nBut it’s much more than that…\nIt’s actually designed for version control"
  },
  {
    "objectID": "content/lectures/00-welcome-slides.html#versioning",
    "href": "content/lectures/00-welcome-slides.html#versioning",
    "title": "00-welcome",
    "section": "Versioning",
    "text": "Versioning\n\nLego versions"
  },
  {
    "objectID": "content/lectures/00-welcome-slides.html#versioning-1",
    "href": "content/lectures/00-welcome-slides.html#versioning-1",
    "title": "00-welcome",
    "section": "Versioning",
    "text": "Versioning\nwith human readable messages\n\nLego versions with commit messages"
  },
  {
    "objectID": "content/lectures/00-welcome-slides.html#why-do-we-need-version-control",
    "href": "content/lectures/00-welcome-slides.html#why-do-we-need-version-control",
    "title": "00-welcome",
    "section": "Why do we need version control?",
    "text": "Why do we need version control?\n\nPhD Comics"
  },
  {
    "objectID": "content/lectures/00-welcome-slides.html#git-and-github-tips",
    "href": "content/lectures/00-welcome-slides.html#git-and-github-tips",
    "title": "00-welcome",
    "section": "Git and GitHub tips",
    "text": "Git and GitHub tips\n\nGit is a version control system – like “Track Changes” features from Microsoft Word on steroids. GitHub is the home for your Git-based projects on the internet – like DropBox but much, much better).\n\n\n\nThere are millions of git commands – ok, that’s an exaggeration, but there are a lot of them – and very few people know them all. 99% of the time you will use git to add, commit, push, and pull.\n\n\n\n\nWe will be doing Git things and interfacing with GitHub through RStudio, but if you google for help you might come across methods for doing these things in the command line – skip that and move on to the next resource unless you feel comfortable trying it out.\n\n\n\n\nResource: happygitwithr.com: book for working with git in R; Some content is beyond the scope of this course, but it’s a good resource"
  },
  {
    "objectID": "content/lectures/00-welcome-slides.html#lets-take-a-tour-git-github",
    "href": "content/lectures/00-welcome-slides.html#lets-take-a-tour-git-github",
    "title": "00-welcome",
    "section": "Let’s take a tour – Git / GitHub",
    "text": "Let’s take a tour – Git / GitHub\nWe’ll cover this time permitting, you’ll see it again in lab this week\nConcepts introduced:\n\nConnect an R project to Github repository\nWorking with a local and remote repository\nCommitting, Pushing and Pulling\n\nThere is a bit more of GitHub that we’ll use in this class, but for today this is enough."
  },
  {
    "objectID": "content/lectures/00-welcome-slides.html#recap",
    "href": "content/lectures/00-welcome-slides.html#recap",
    "title": "00-welcome",
    "section": "Recap",
    "text": "Recap\nCan you answer these questions?\n\nWhat is R vs RStudio?\nWhat are RStudio Projects?\nWhat is version control, and why do we care?\nWhat is git vs GitHub (and do I need to care)?"
  },
  {
    "objectID": "content/lectures/00-welcome-slides.html#additional-git-resources",
    "href": "content/lectures/00-welcome-slides.html#additional-git-resources",
    "title": "00-welcome",
    "section": "Additional git Resources",
    "text": "Additional git Resources\nVersion Control (git and GitHub):\n\nGetting Started with git\nGitHub Guide\nGitHub Desktop App Tutorial\nGit Command Line Resource\nUsing git from the command line\n\nInstalling and using git (Part 1), by COGS 108 TA Ganesh (youtube, 22min tutorial)\nmerge conflicts and branching (Part 2), by IA Shubham Kulkarni (youtube, 8min tutorial)\n\nUsing git with GitHub Desktop, by COGS 108 TA Sidharth Suresh (youtube, 13min tutorial)\nGIT & GITHUB TUTORIAL, from edureka!\n\nwith notes from COGS 18/108 TA Holly(Yueying) Dong"
  },
  {
    "objectID": "content/lectures/00-welcome-slides.html#slides-to-pdf",
    "href": "content/lectures/00-welcome-slides.html#slides-to-pdf",
    "title": "00-welcome",
    "section": "Slides to PDF",
    "text": "Slides to PDF\n\nToggle into Print View using the E key (or using the Navigation Menu)\nOpen the in-browser print dialog (CTRL/CMD+P).\nChange the Destination setting to Save as PDF.\nChange the Layout to Landscape.\nChange the Margins to None.\nEnable the Background graphics option.\nClick Save 🎉\n\n\n\nInstructions from quarto documentation"
  },
  {
    "objectID": "content/lectures/00-welcome-slides.html#whos-in-this-class",
    "href": "content/lectures/00-welcome-slides.html#whos-in-this-class",
    "title": "00-welcome",
    "section": "Who’s in this class?",
    "text": "Who’s in this class?\n\nroster <- read_sheet('10_NsXld_swxoTL_01pCklRKR95OH5XoNlRzTl7L5XXs')\n\nggplot(roster, aes(x = College)) +\n  geom_bar() +\n  labs(title = \"COGS 137\") +\n  theme_bw(base_size = 14) + \n  theme(plot.title.position = \"plot\")\n\n\n\n\n\n\nNote: This code will not run for you because you don’t have access to the roster for this course."
  },
  {
    "objectID": "content/lectures/00-welcome-slides.html#whos-in-this-class-1",
    "href": "content/lectures/00-welcome-slides.html#whos-in-this-class-1",
    "title": "00-welcome",
    "section": "Who’s in this class?",
    "text": "Who’s in this class?\n\nroster |>\n  mutate(major = substr(Major, 1, 2)) |>\n  ggplot(aes(fct_infreq(major))) + \n  geom_bar() +\n  labs(title = \"COGS 137\",\n       x = \"Major\") +\n  theme_bw(base_size = 12) + \n  theme(plot.title.position = \"plot\")"
  },
  {
    "objectID": "content/lectures/00-welcome-slides.html#whos-in-this-class-2",
    "href": "content/lectures/00-welcome-slides.html#whos-in-this-class-2",
    "title": "00-welcome",
    "section": "Who’s in this class?",
    "text": "Who’s in this class?\n\nroster |>\n  ggplot(aes(fct_relevel(Level, \"JR\", \"SR\"))) +\n  geom_bar() +\n  labs(title = \"COGS 137\",\n       x = \"Level\") +\n  theme_bw(base_size = 14) + \n  theme(plot.title.position = \"plot\")"
  },
  {
    "objectID": "content/lectures/00-welcome-slides.html#id-like-to-know-more",
    "href": "content/lectures/00-welcome-slides.html#id-like-to-know-more",
    "title": "00-welcome",
    "section": "I’d like to know more!",
    "text": "I’d like to know more!\n(optional) Student Survey - complete by Monday at 11:59 PM for small amount of extra credit\n\n(optional) Daily Post-Lecture Feedback\n\nopportunity to reflect on learning\nopportunity to ask questions (I will read and answer these.)\nopportunity for extra credit on final project\n\n\n\n\n\nhttps://cogs137.github.io/website/\n\n\n\nNote: Links to both surveys are also on Canvas."
  },
  {
    "objectID": "content/lectures/00-welcome.html",
    "href": "content/lectures/00-welcome.html",
    "title": "00-welcome",
    "section": "",
    "text": "Practical Data Science in R\nPlease take one green sticky and one pink sticky as they come around. If you’re able, try and save these. We’ll use them most classes. (But, I’ll always have extra!)\n\n\n\n\n\n\n\n\nDescribe what this class is\nDescribe how the class will run\nGo over the tooling for this course: R, RStudio, GitHub\n\n\n\n\n : R is a statistical programming language.\nWhile R has most/all of the functionality of YFPL (your favorite programming language), it was designed for the specific use of analyzing data.\n\n\n\n: Data science is the scientific process of using data to answer interesting questions and/or solve important problems.\n\n\n\n\n\nProgram at the introductory level in the R statistical programming language\nEmploy the tidyverse suite of packages to interact with, wrangle, visualize, and model data\nExplain & apply statistical concepts (estimation, linear regression, logistic regression, etc.) for data analysis\nCommunicate data science projects through effective visualization, oral presentation, and written reports\n\n\n\n\n\nShannon Ellis: Associate Teaching Professor, Mom & wife, volleyball-obsessed, and baking & cooking lover\n   sellis@ucsd.edu     shanellis.com     Peterson Hall 104     Tu/Th 2-3:20PM (Lab: Fri 1-1:50PM)\n\n\n\n\n\n\nInstructor\nShannon Ellis\nsellis@ucsd.edu\nWed 2-3\nVirtual (see canvas)\n\n\n\n\n\nTh 12:50-1:50\nCSB 243\n\n\nTA\nShubham Kulkarni\n\nTime TBD\nLocation TBD\n\n\nIAs\nChristian Kim\n\nTime TBD\nLocation TBD\n\n\n\n\n\n\nEverything you want to know about the course, and everything you will need for the course will be posted at: https://cogs137.github.io/website/\n\n\nIs this an intro CS course? No.\nWill we be doing computing? Yes.\nWhat computing language will we learn? R.\nIs this an intro stats course? No.\nWill we be doing stats? Yes.\nAre there any prerequisites? Yes, an intro statistics course!\n\n\n\n\n\n\n\n\n\nNope! The first few weeks of the course will be all about getting comfortable using the R programming language!\n After that, we’ll focus on delving into interesting statistical analyses through case studies.\n\n\n\nArtwork by @allison_horst"
  },
  {
    "objectID": "content/lectures/00-welcome.html#the-general-plan",
    "href": "content/lectures/00-welcome.html#the-general-plan",
    "title": "00-welcome",
    "section": "The General Plan",
    "text": "The General Plan\n\nWeeks 1-4: Learn to program in the tidyverse in R\nWeeks 5-10: Communication, Data Analysis, Statistics, & Case Studies\n\nCS01: Right to Carry\nCS02: Vaping Behaviors"
  },
  {
    "objectID": "content/lectures/00-welcome.html#the-nitty-gritty",
    "href": "content/lectures/00-welcome.html#the-nitty-gritty",
    "title": "00-welcome",
    "section": "The Nitty Gritty",
    "text": "The Nitty Gritty\n\nLectureIn-personWaitlistLab & OHMaterials\n\n\nClass Meetings\n\nInteractive\nLectures & lots of learn-by-doing\nBring your laptop to class every day\n\n\n\nIn-person, synchronous learning\n\nI will be teaching (so long as I’m healthy and have child care) in person.\nLectures will be podcast.\nAttendance will be incentivized using a daily participation survey.\nIf you’re not feeling well, please stay home. I will do the same.\nExam will be take-home.\n\n\n\nThe (Dreaded) Waitlist\n\nCourse enrollment is supposed to be 50 for this course\nThere are 72 people currently enrolled\nI don’t control the waitlist (cogsadvising@ucsd.edu does)\nI’d anticipate our staff adding 3-5 people from the waitlist (but cannot guarantee this)\n\n\n\nLab & Office Hours\n\nMy office hours begin week 1; TA/IA OH begin week 2\nLab will start this Fri (week 1)\nI will hang out after class today for questions/concerns from students\n\n\n\nCourse Materials\n\nTextbooks are free and available online\nCourse platforms:\n\nWebsite : schedule, policies, due dates, etc.\nGitHub : retrieving assignments, labs, exams, etc.\ndatahub : completing assignments, labs, exams etc.\nGradescope : submitting assignments\nCanvas : grades, course-specific links\nCampuswire : Q&A"
  },
  {
    "objectID": "content/lectures/00-welcome.html#diversity-inclusion",
    "href": "content/lectures/00-welcome.html#diversity-inclusion",
    "title": "00-welcome",
    "section": "Diversity & Inclusion:",
    "text": "Diversity & Inclusion:\nGoal: every student be well-served by this course\n\nPhilosophy: The diversity of students in this class is a huge asset to our learning community; our differences provide opportunities for learning and understanding.\n\n\nPlan: Present course materials that are conscious of and respectful to diversity (gender identity, sexuality, disability, age, socioeconomic status, ethnicity, race, nationality, religion, politics, and culture)\n\n\nBut… if I ever fall short or if you ever have suggestions for improvement, please do share with me! There is also an anonymous Google Form if you’re more comfortable there."
  },
  {
    "objectID": "content/lectures/00-welcome.html#a-new-ish-course",
    "href": "content/lectures/00-welcome.html#a-new-ish-course",
    "title": "00-welcome",
    "section": "A new-ish course!",
    "text": "A new-ish course!\n\nOffered once previously\nIf something doesn’t make sense, tell me!\nIf you’ve got feedback/suggestions, I’m all ears!\n\n\nDifferences since last iteration:\n\nLess…pretty much everything\nNew website/lecture platform (quarto)\nTu/Th and not early in the morning\nGroup mates differ\nIncreased focus on communication\nMultiple final project options\nSlightly larger class & slightly smaller staff\nI’m a mom & just coming back from parental leave"
  },
  {
    "objectID": "content/lectures/00-welcome.html#how-to-get-help",
    "href": "content/lectures/00-welcome.html#how-to-get-help",
    "title": "00-welcome",
    "section": "How to get help",
    "text": "How to get help\n\nLab\nOffice Hours\nCampuswire\n\n\nA few guidelines:\n1. No duplicates.\n2. Public posts are best.\n3. Posts should include your question, what you've tried so far, & resources used.\n4. Helping others is encouraged.\n5. No assignment code in public posts.\n6. We're not robots."
  },
  {
    "objectID": "content/lectures/00-welcome.html#the-r-community",
    "href": "content/lectures/00-welcome.html#the-r-community",
    "title": "00-welcome",
    "section": " The R Community",
    "text": "The R Community\n\n\n\nR Rollercoaster\n\n\n\nArtwork by @allison_horst"
  },
  {
    "objectID": "content/lectures/00-welcome.html#academic-integrity",
    "href": "content/lectures/00-welcome.html#academic-integrity",
    "title": "00-welcome",
    "section": "Academic integrity",
    "text": "Academic integrity\nDon’t cheat.\n\nTeamwork is allowed, but you should be able to answer “Yes” to each of the following: - Can I explain each piece of code and each analysis carried out in what I’m submitting? - Could I reproduce this code/analysis on my own?\n\n\nThe Internet is a great resource. - Cite your sources.\n\n\nTeamwork is not allowed on your midterm. - It is open-notes and open-Google - You cannot discuss the questions on the exam with anyone."
  },
  {
    "objectID": "content/lectures/00-welcome.html#course-components",
    "href": "content/lectures/00-welcome.html#course-components",
    "title": "00-welcome",
    "section": "Course components:",
    "text": "Course components:\n\n\nLabs (8): Individual submission; graded on effort\nHomework (4): Individual submission; graded on correctness\nExam (1): Individual completion & submission, take-home midterm\nCase Studies (2): Team submission, technical analysis report\nFinal Project (1) : Team submission, due Thurs of finals week"
  },
  {
    "objectID": "content/lectures/00-welcome.html#grading",
    "href": "content/lectures/00-welcome.html#grading",
    "title": "00-welcome",
    "section": "Grading",
    "text": "Grading\nYour final grade will be comprised of the following:\n\n\n\nAssignment (#)\n% of grade\n\n\n\n\nLabs (8)\n16%\n\n\nHomework (4)\n32%\n\n\nMidterm (1)\n15%\n\n\nCase Study Projects* (2)\n20%\n\n\nFinal project* (1)\n17%\n\n\n\n* indicates group submission"
  },
  {
    "objectID": "content/lectures/00-welcome.html#latemissed-work-policy",
    "href": "content/lectures/00-welcome.html#latemissed-work-policy",
    "title": "00-welcome",
    "section": "Late/missed work policy",
    "text": "Late/missed work policy\n\nHomework and case study projects: accepted up to 3 days (72 hours) after the assigned deadline for a 25% deduction\nNo late deadlines for labs, the exam, or the final project\n\n\n\nNote: Prof Ellis is a reasonable person; reach out to her if you have an extenuating circumstance at any point in the quarter."
  },
  {
    "objectID": "content/lectures/00-welcome.html#datahub",
    "href": "content/lectures/00-welcome.html#datahub",
    "title": "00-welcome",
    "section": "Datahub",
    "text": "Datahub\nDatahub is a platform hosted by UCSD that gives students access to computational resources.\nThis means that while you’ll be typing on your keyboard, you’ll be using UCSD’s computers in this class.\nWebsite: https://datahub.ucsd.edu/\n\nLaunch Environment\nWhen working on “stuff” for this course, select the COGS 137 environment.\n\n\n\ndatahub"
  },
  {
    "objectID": "content/lectures/00-welcome.html#toolkit",
    "href": "content/lectures/00-welcome.html#toolkit",
    "title": "00-welcome",
    "section": "Toolkit",
    "text": "Toolkit\n\n\n\ntoolkit\n\n\n\nScriptability \\(\\rightarrow\\) R\nLiterate programming (code, narrative, output in one place) \\(\\rightarrow\\) R Markdown\nVersion control \\(\\rightarrow\\) Git / GitHub"
  },
  {
    "objectID": "content/lectures/00-welcome.html#r-and-rstudio",
    "href": "content/lectures/00-welcome.html#r-and-rstudio",
    "title": "00-welcome",
    "section": "R and RStudio",
    "text": "R and RStudio\n\nR/RStudioTourTryR packages\n\n\nR & RStudio\n\nR is a statistical programming language\nRStudio is a convenient interface for R (an integreated development environment, IDE)\n\n\n\n\n[DEMO]\n\nConcepts introduced:\n\nConsole\nUsing R as a calculator\nEnvironment\nLoading and viewing a data frame\nAccessing a variable in a data frame\nR functions\n\n\n\nYour Turn\n\nLogin to datahub\nCarry out a mathematical operation in the console\nView the airquality dataframe\nAccess a column from the airquality dataframe\nCalculate the median for one of the numeric columns\n\nPut a green sticky on the front of your computer when you’re done. Put a pink if you want help/have a question.\n\n\n\nPackages are the fundamental units of reproducible R code. They include reusable R functions, the documentation that describes how to use them, and sample data 1\nAs of Jan 2023, there are ~18,979 R packages available on CRAN (the Comprehensive R Archive Network)2\nWe’re going to work with a small (but important) subset of these!"
  },
  {
    "objectID": "content/lectures/00-welcome.html#what-is-the-tidyverse",
    "href": "content/lectures/00-welcome.html#what-is-the-tidyverse",
    "title": "00-welcome",
    "section": "What is the Tidyverse?",
    "text": "What is the Tidyverse?\n\n\n\n\n\ntidyverse.org\n\n\nThe tidyverse is an opinionated collection of R packages designed for data science.\nAll packages share an underlying philosophy and a common syntax."
  },
  {
    "objectID": "content/lectures/00-welcome.html#rstudio-projects3",
    "href": "content/lectures/00-welcome.html#rstudio-projects3",
    "title": "00-welcome",
    "section": "RStudio Projects3",
    "text": "RStudio Projects3\n\nBuilt-in functionality to keep all files for a single project organized"
  },
  {
    "objectID": "content/lectures/00-welcome.html#r-markdown",
    "href": "content/lectures/00-welcome.html#r-markdown",
    "title": "00-welcome",
    "section": "R Markdown",
    "text": "R Markdown\n\nFully reproducible reports – each time you knit, the document is executed from top to bottom\nSimple markdown syntax for text\nCode goes in chunks, defined by three backticks, narrative goes outside of chunks"
  },
  {
    "objectID": "content/lectures/00-welcome.html#r-markdown-tips",
    "href": "content/lectures/00-welcome.html#r-markdown-tips",
    "title": "00-welcome",
    "section": "R Markdown tips",
    "text": "R Markdown tips\n\nKeep the R Markdown cheat sheet and Markdown Quick Reference (Help -> Markdown Quick Reference) handy, we’ll refer to it often as the course progresses\nThe workspace of your R Markdown document is separate from the Console\n\n\n\n[DEMO]"
  },
  {
    "objectID": "content/lectures/00-welcome.html#how-will-we-use-r-markdown",
    "href": "content/lectures/00-welcome.html#how-will-we-use-r-markdown",
    "title": "00-welcome",
    "section": "How will we use R Markdown?",
    "text": "How will we use R Markdown?\n\nEvery lab / project / homework / notes / etc. is an R Markdown document\nYou’ll always have a template R Markdown document to start with\nThe amount of scaffolding in the template will decrease over the quarter"
  },
  {
    "objectID": "content/lectures/00-welcome.html#collaboration-git-github",
    "href": "content/lectures/00-welcome.html#collaboration-git-github",
    "title": "00-welcome",
    "section": "Collaboration: Git & GitHub",
    "text": "Collaboration: Git & GitHub\n\nThe statistical programming language we’ll use is R\nThe software we use to interface with R is RStudio\nBut how do I get you the course materials that you can build on for your assignments?\n\nHint: I’m not going to email you documents, that would be a mess!"
  },
  {
    "objectID": "content/lectures/00-welcome.html#version-control",
    "href": "content/lectures/00-welcome.html#version-control",
    "title": "00-welcome",
    "section": "Version control",
    "text": "Version control\n\nWe introduced GitHub as a platform for collaboration\nBut it’s much more than that…\nIt’s actually designed for version control"
  },
  {
    "objectID": "content/lectures/00-welcome.html#versioning",
    "href": "content/lectures/00-welcome.html#versioning",
    "title": "00-welcome",
    "section": "Versioning",
    "text": "Versioning\n\n\n\nLego versions"
  },
  {
    "objectID": "content/lectures/00-welcome.html#versioning-1",
    "href": "content/lectures/00-welcome.html#versioning-1",
    "title": "00-welcome",
    "section": "Versioning",
    "text": "Versioning\nwith human readable messages\n\n\n\nLego versions with commit messages"
  },
  {
    "objectID": "content/lectures/00-welcome.html#why-do-we-need-version-control",
    "href": "content/lectures/00-welcome.html#why-do-we-need-version-control",
    "title": "00-welcome",
    "section": "Why do we need version control?",
    "text": "Why do we need version control?\n\n\n\nPhD Comics"
  },
  {
    "objectID": "content/lectures/00-welcome.html#git-and-github-tips",
    "href": "content/lectures/00-welcome.html#git-and-github-tips",
    "title": "00-welcome",
    "section": "Git and GitHub tips",
    "text": "Git and GitHub tips\n\nGit is a version control system – like “Track Changes” features from Microsoft Word on steroids. GitHub is the home for your Git-based projects on the internet – like DropBox but much, much better).\n\n\n\nThere are millions of git commands – ok, that’s an exaggeration, but there are a lot of them – and very few people know them all. 99% of the time you will use git to add, commit, push, and pull.\n\n\n\n\nWe will be doing Git things and interfacing with GitHub through RStudio, but if you google for help you might come across methods for doing these things in the command line – skip that and move on to the next resource unless you feel comfortable trying it out.\n\n\n\nResource: happygitwithr.com: book for working with git in R; Some content is beyond the scope of this course, but it’s a good resource"
  },
  {
    "objectID": "content/lectures/00-welcome.html#lets-take-a-tour-git-github",
    "href": "content/lectures/00-welcome.html#lets-take-a-tour-git-github",
    "title": "00-welcome",
    "section": "Let’s take a tour – Git / GitHub",
    "text": "Let’s take a tour – Git / GitHub\nWe’ll cover this time permitting, you’ll see it again in lab this week\nConcepts introduced:\n\nConnect an R project to Github repository\nWorking with a local and remote repository\nCommitting, Pushing and Pulling\n\nThere is a bit more of GitHub that we’ll use in this class, but for today this is enough."
  },
  {
    "objectID": "content/lectures/00-welcome.html#recap",
    "href": "content/lectures/00-welcome.html#recap",
    "title": "00-welcome",
    "section": "Recap",
    "text": "Recap\nCan you answer these questions?\n\nWhat is R vs RStudio?\nWhat are RStudio Projects?\nWhat is version control, and why do we care?\nWhat is git vs GitHub (and do I need to care)?"
  },
  {
    "objectID": "content/lectures/00-welcome.html#additional-git-resources",
    "href": "content/lectures/00-welcome.html#additional-git-resources",
    "title": "00-welcome",
    "section": "Additional git Resources",
    "text": "Additional git Resources\n\nVersion Control (git and GitHub):\n\nGetting Started with git\nGitHub Guide\nGitHub Desktop App Tutorial\nGit Command Line Resource\nUsing git from the command line\n\nInstalling and using git (Part 1), by COGS 108 TA Ganesh (youtube, 22min tutorial)\nmerge conflicts and branching (Part 2), by IA Shubham Kulkarni (youtube, 8min tutorial)\n\nUsing git with GitHub Desktop, by COGS 108 TA Sidharth Suresh (youtube, 13min tutorial)\nGIT & GITHUB TUTORIAL, from edureka!\n\nwith notes from COGS 18/108 TA Holly(Yueying) Dong"
  },
  {
    "objectID": "content/lectures/00-welcome.html#slides-to-pdf",
    "href": "content/lectures/00-welcome.html#slides-to-pdf",
    "title": "00-welcome",
    "section": "Slides to PDF",
    "text": "Slides to PDF\n\nToggle into Print View using the E key (or using the Navigation Menu)\nOpen the in-browser print dialog (CTRL/CMD+P).\nChange the Destination setting to Save as PDF.\nChange the Layout to Landscape.\nChange the Margins to None.\nEnable the Background graphics option.\nClick Save 🎉\n\n\n\nInstructions from quarto documentation"
  },
  {
    "objectID": "content/lectures/00-welcome.html#whos-in-this-class",
    "href": "content/lectures/00-welcome.html#whos-in-this-class",
    "title": "00-welcome",
    "section": "Who’s in this class?",
    "text": "Who’s in this class?\n\nroster <- read_sheet('10_NsXld_swxoTL_01pCklRKR95OH5XoNlRzTl7L5XXs')\n\nggplot(roster, aes(x = College)) +\n  geom_bar() +\n  labs(title = \"COGS 137\") +\n  theme_bw(base_size = 14) + \n  theme(plot.title.position = \"plot\")\n\n\n\n\n\n\nNote: This code will not run for you because you don’t have access to the roster for this course."
  },
  {
    "objectID": "content/lectures/00-welcome.html#whos-in-this-class-1",
    "href": "content/lectures/00-welcome.html#whos-in-this-class-1",
    "title": "00-welcome",
    "section": "Who’s in this class?",
    "text": "Who’s in this class?\n\nroster |>\n  mutate(major = substr(Major, 1, 2)) |>\n  ggplot(aes(fct_infreq(major))) + \n  geom_bar() +\n  labs(title = \"COGS 137\",\n       x = \"Major\") +\n  theme_bw(base_size = 12) + \n  theme(plot.title.position = \"plot\")"
  },
  {
    "objectID": "content/lectures/00-welcome.html#whos-in-this-class-2",
    "href": "content/lectures/00-welcome.html#whos-in-this-class-2",
    "title": "00-welcome",
    "section": "Who’s in this class?",
    "text": "Who’s in this class?\n\nroster |>\n  ggplot(aes(fct_relevel(Level, \"JR\", \"SR\"))) +\n  geom_bar() +\n  labs(title = \"COGS 137\",\n       x = \"Level\") +\n  theme_bw(base_size = 14) + \n  theme(plot.title.position = \"plot\")"
  },
  {
    "objectID": "content/lectures/00-welcome.html#id-like-to-know-more",
    "href": "content/lectures/00-welcome.html#id-like-to-know-more",
    "title": "00-welcome",
    "section": "I’d like to know more!",
    "text": "I’d like to know more!\n(optional) Student Survey - complete by Monday at 11:59 PM for small amount of extra credit\n\n(optional) Daily Post-Lecture Feedback\n\nopportunity to reflect on learning\nopportunity to ask questions (I will read and answer these.)\nopportunity for extra credit on final project\n\n\n\n\n\nNote: Links to both surveys are also on Canvas."
  },
  {
    "objectID": "content/lectures/07-linear-models-slides.html#qa",
    "href": "content/lectures/07-linear-models-slides.html#qa",
    "title": "07-linear-models",
    "section": "Q&A",
    "text": "Q&A\n\nQ: Do you recommend review some statistics before attending lectures?\nA: This is very much up to you. It certainly wouldn’t hurt! There will be readings connected to each lecture; these are a great place to start. It can be helpful to work through these readings and the exercises either before or after lecture!\n\n\nQ: I am still not quite sure how to do HW part 2 and 3, do we download data into the folder, read the file, and plot it?\nA: Yup! That’s one approach. The other approach (if the data are not available for download) would be to create the dataset on your own, estimating the values as best you can from the plot and creating a dataframe/tibble containing that information directly in your code (similar to what you did in HW01)….and then plot from there."
  },
  {
    "objectID": "content/lectures/07-linear-models-slides.html#course-announcements",
    "href": "content/lectures/07-linear-models-slides.html#course-announcements",
    "title": "07-linear-models",
    "section": "Course Announcements",
    "text": "Course Announcements\nDue Dates:\n\nLab 04 due tomorrow (2/3; 11:59 PM)\nLecture Participation survey “due” after class\nHW02 due Monday (2/6; 11:59 PM)\n\n\n\nMidterm Exam\n\npractice exam(s) will be released tomorrow; answers posted next week\nwill cover material through “Effective Communication”\nwill be released/posted next Friday after lab\nwill be due Monday Feb 13th at 11:59 PM\nwill be an Rmd document and submitted via GitHub (like everything so far)\nwill be commpleted individually (open Notes; open Google)"
  },
  {
    "objectID": "content/lectures/07-linear-models-slides.html#agenda",
    "href": "content/lectures/07-linear-models-slides.html#agenda",
    "title": "07-linear-models",
    "section": "Agenda",
    "text": "Agenda\n\nLinear Models\n\nQuantitative Predictor\nCategorical Predictor (2 & >2 levels)\nresiduals\ndata transformations"
  },
  {
    "objectID": "content/lectures/07-linear-models-slides.html#data-paris-paintings",
    "href": "content/lectures/07-linear-models-slides.html#data-paris-paintings",
    "title": "07-linear-models",
    "section": "Data: Paris Paintings",
    "text": "Data: Paris Paintings\n\npp <- read_csv(\"https://raw.githubusercontent.com/COGS137/datasets/main/paris_paintings.csv\", \n               na = c(\"n/a\", \"\", \"NA\"))\n\n\nNumber of observations: 3393\nNumber of variables: 61"
  },
  {
    "objectID": "content/lectures/07-linear-models-slides.html#goal-predict-height-from-width",
    "href": "content/lectures/07-linear-models-slides.html#goal-predict-height-from-width",
    "title": "07-linear-models",
    "section": "Goal: Predict height from width",
    "text": "Goal: Predict height from width\n\\[\\widehat{height}_{i} = \\beta_0 + \\beta_1 \\times width_{i}\\]"
  },
  {
    "objectID": "content/lectures/07-linear-models-slides.html#tidymodels-1",
    "href": "content/lectures/07-linear-models-slides.html#tidymodels-1",
    "title": "07-linear-models",
    "section": "tidymodels",
    "text": "tidymodels\n\nNOT a core tidyverse package\nfollows the structure of a tidyverse package\n\n\n\n# should already be installed for you on datahub\nlibrary(tidymodels)"
  },
  {
    "objectID": "content/lectures/07-linear-models-slides.html#step-1-specify-model",
    "href": "content/lectures/07-linear-models-slides.html#step-1-specify-model",
    "title": "07-linear-models",
    "section": "Step 1: Specify model",
    "text": "Step 1: Specify model\n\nlinear_reg()\n\nLinear Regression Model Specification (regression)\n\nComputational engine: lm"
  },
  {
    "objectID": "content/lectures/07-linear-models-slides.html#step-2-set-model-fitting-engine",
    "href": "content/lectures/07-linear-models-slides.html#step-2-set-model-fitting-engine",
    "title": "07-linear-models",
    "section": "Step 2: Set model fitting engine",
    "text": "Step 2: Set model fitting engine\n\nlinear_reg() |>\n  set_engine(\"lm\") # lm: linear model\n\nLinear Regression Model Specification (regression)\n\nComputational engine: lm"
  },
  {
    "objectID": "content/lectures/07-linear-models-slides.html#step-3-fit-model-estimate-parameters",
    "href": "content/lectures/07-linear-models-slides.html#step-3-fit-model-estimate-parameters",
    "title": "07-linear-models",
    "section": "Step 3: Fit model & estimate parameters",
    "text": "Step 3: Fit model & estimate parameters\n… using formula syntax\n\nlinear_reg() |>\n  set_engine(\"lm\") |>\n  fit(Height_in ~ Width_in, data = pp)\n\nparsnip model object\n\n\nCall:\nstats::lm(formula = Height_in ~ Width_in, data = data)\n\nCoefficients:\n(Intercept)     Width_in  \n     3.6214       0.7808"
  },
  {
    "objectID": "content/lectures/07-linear-models-slides.html#a-closer-look-at-model-output",
    "href": "content/lectures/07-linear-models-slides.html#a-closer-look-at-model-output",
    "title": "07-linear-models",
    "section": "A closer look at model output",
    "text": "A closer look at model output\n\n\nparsnip model object\n\n\nCall:\nstats::lm(formula = Height_in ~ Width_in, data = data)\n\nCoefficients:\n(Intercept)     Width_in  \n     3.6214       0.7808  \n\n\n\\[\\widehat{height}_{i} = 3.6214 + 0.7808 \\times width_{i}\\]"
  },
  {
    "objectID": "content/lectures/07-linear-models-slides.html#a-tidy-look-at-model-output",
    "href": "content/lectures/07-linear-models-slides.html#a-tidy-look-at-model-output",
    "title": "07-linear-models",
    "section": "A tidy look at model output",
    "text": "A tidy look at model output\n\nlinear_reg() |>\n  set_engine(\"lm\") |>\n  fit(Height_in ~ Width_in, data = pp) |>\n  tidy()\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)    3.62    0.254        14.3 8.82e-45\n2 Width_in       0.781   0.00950      82.1 0       \n\n\n\\[\\widehat{height}_{i} = 3.62 + 0.781 \\times width_{i}\\]"
  },
  {
    "objectID": "content/lectures/07-linear-models-slides.html#slope-and-intercept",
    "href": "content/lectures/07-linear-models-slides.html#slope-and-intercept",
    "title": "07-linear-models",
    "section": "Slope and intercept",
    "text": "Slope and intercept\n\\[\\widehat{height}_{i} = 3.62 + 0.781 \\times width_{i}\\]\n\n\nSlope: For each additional inch the painting is wider, the height is expected to be higher, on average, by 0.781 inches.\n\n\n\n\nIntercept: Paintings that are 0 inches wide are expected to be 3.62 inches high, on average. (Does this make sense?)"
  },
  {
    "objectID": "content/lectures/07-linear-models-slides.html#correlation-does-not-imply-causation",
    "href": "content/lectures/07-linear-models-slides.html#correlation-does-not-imply-causation",
    "title": "07-linear-models",
    "section": "Correlation does not imply causation",
    "text": "Correlation does not imply causation\nRemember this when interpreting model coefficients\n\n\n\n\n\n\n\nSource: XKCD, Cell phones"
  },
  {
    "objectID": "content/lectures/07-linear-models-slides.html#linear-model-with-a-single-predictor",
    "href": "content/lectures/07-linear-models-slides.html#linear-model-with-a-single-predictor",
    "title": "07-linear-models",
    "section": "Linear model with a single predictor",
    "text": "Linear model with a single predictor\n\nWe’re interested in \\(\\beta_0\\) (population parameter for the intercept) and \\(\\beta_1\\) (population parameter for the slope) in the following model:\n\n\\[\\hat{y}_{i} = \\beta_0 + \\beta_1~x_{i}\\]\n\n\nTough luck, you can’t have them…\n\n\n\n\nSo we use sample statistics to estimate them:\n\n\\[\\hat{y}_{i} = b_0 + b_1~x_{i}\\]"
  },
  {
    "objectID": "content/lectures/07-linear-models-slides.html#least-squares-regression",
    "href": "content/lectures/07-linear-models-slides.html#least-squares-regression",
    "title": "07-linear-models",
    "section": "Least squares regression",
    "text": "Least squares regression\n\nThe regression line minimizes the sum of squared residuals.\n\n\n\nIf \\(e_i = y_i - \\hat{y}_i\\), then, the regression line minimizes \\(\\sum_{i = 1}^n e_i^2\\)."
  },
  {
    "objectID": "content/lectures/07-linear-models-slides.html#visualizing-residuals",
    "href": "content/lectures/07-linear-models-slides.html#visualizing-residuals",
    "title": "07-linear-models",
    "section": "Visualizing residuals",
    "text": "Visualizing residuals"
  },
  {
    "objectID": "content/lectures/07-linear-models-slides.html#visualizing-residuals-cont.",
    "href": "content/lectures/07-linear-models-slides.html#visualizing-residuals-cont.",
    "title": "07-linear-models",
    "section": "Visualizing residuals (cont.)",
    "text": "Visualizing residuals (cont.)"
  },
  {
    "objectID": "content/lectures/07-linear-models-slides.html#visualizing-residuals-cont.-1",
    "href": "content/lectures/07-linear-models-slides.html#visualizing-residuals-cont.-1",
    "title": "07-linear-models",
    "section": "Visualizing residuals (cont.)",
    "text": "Visualizing residuals (cont.)"
  },
  {
    "objectID": "content/lectures/07-linear-models-slides.html#properties-of-least-squares-regression",
    "href": "content/lectures/07-linear-models-slides.html#properties-of-least-squares-regression",
    "title": "07-linear-models",
    "section": "Properties of least squares regression",
    "text": "Properties of least squares regression\n\nThe regression line goes through the center of mass point, the coordinates corresponding to average \\(x\\) and average \\(y\\), \\((\\bar{x}, \\bar{y})\\):\n\n\\[\\bar{y} = b_0 + b_1 \\bar{x} ~ \\rightarrow ~ b_0 = \\bar{y} - b_1 \\bar{x}\\]\n\n\nThe slope has the same sign as the correlation coefficient: \\(b_1 = r \\frac{s_y}{s_x}\\)\n\n\n\n\nThe sum of the residuals is zero: \\(\\sum_{i = 1}^n e_i = 0\\)\n\n\n\n\nThe residuals and \\(x\\) values are uncorrelated"
  },
  {
    "objectID": "content/lectures/07-linear-models-slides.html#categorical-predictor-with-2-levels",
    "href": "content/lectures/07-linear-models-slides.html#categorical-predictor-with-2-levels",
    "title": "07-linear-models",
    "section": "Categorical predictor with 2 levels",
    "text": "Categorical predictor with 2 levels\n\n\n\n\n# A tibble: 3,393 × 3\n   name      Height_in landsALL\n   <chr>         <dbl>    <dbl>\n 1 L1764-2          37        0\n 2 L1764-3          18        0\n 3 L1764-4          13        1\n 4 L1764-5a         14        1\n 5 L1764-5b         14        1\n 6 L1764-6           7        0\n 7 L1764-7a          6        0\n 8 L1764-7b          6        0\n 9 L1764-8          15        0\n10 L1764-9a          9        0\n11 L1764-9b          9        0\n12 L1764-10a        16        1\n13 L1764-10b        16        1\n14 L1764-10c        16        1\n15 L1764-11         20        0\n16 L1764-12a        14        1\n17 L1764-12b        14        1\n18 L1764-13a        15        1\n19 L1764-13b        15        1\n20 L1764-14         37        0\n# … with 3,373 more rows\n\n\n\n\nlandsALL = 0: No landscape features\nlandsALL = 1: Some landscape features"
  },
  {
    "objectID": "content/lectures/07-linear-models-slides.html#height-landscape-features",
    "href": "content/lectures/07-linear-models-slides.html#height-landscape-features",
    "title": "07-linear-models",
    "section": "Height & landscape features",
    "text": "Height & landscape features\n\nm_ht_lands <- linear_reg() |>\n  set_engine(\"lm\") |>\n  fit(Height_in ~ factor(landsALL), data = pp)\n\nm_ht_lands |> tidy()\n\n# A tibble: 2 × 5\n  term              estimate std.error statistic  p.value\n  <chr>                <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)          22.7      0.328      69.1 0       \n2 factor(landsALL)1    -5.65     0.532     -10.6 7.97e-26"
  },
  {
    "objectID": "content/lectures/07-linear-models-slides.html#height-landscape-features-1",
    "href": "content/lectures/07-linear-models-slides.html#height-landscape-features-1",
    "title": "07-linear-models",
    "section": "Height & landscape features",
    "text": "Height & landscape features\n\\[\\widehat{Height_{in}} = 22.7 - 5.645~landsALL\\]\n\nSlope: Paintings with landscape features are expected, on average, to be 5.645 inches shorter than paintings that without landscape features\n\nCompares baseline level (landsALL = 0) to the other level (landsALL = 1)\n\nIntercept: Paintings that don’t have landscape features are expected, on average, to be 22.7 inches tall"
  },
  {
    "objectID": "content/lectures/07-linear-models-slides.html#categorical-predictor-with-2-levels-1",
    "href": "content/lectures/07-linear-models-slides.html#categorical-predictor-with-2-levels-1",
    "title": "07-linear-models",
    "section": "Categorical predictor with >2 levels",
    "text": "Categorical predictor with >2 levels\n\n\n\n\n# A tibble: 3,393 × 3\n   name      Height_in school_pntg\n   <chr>         <dbl> <chr>      \n 1 L1764-2          37 F          \n 2 L1764-3          18 I          \n 3 L1764-4          13 D/FL       \n 4 L1764-5a         14 F          \n 5 L1764-5b         14 F          \n 6 L1764-6           7 I          \n 7 L1764-7a          6 F          \n 8 L1764-7b          6 F          \n 9 L1764-8          15 I          \n10 L1764-9a          9 D/FL       \n11 L1764-9b          9 D/FL       \n12 L1764-10a        16 X          \n13 L1764-10b        16 X          \n14 L1764-10c        16 X          \n15 L1764-11         20 D/FL       \n16 L1764-12a        14 D/FL       \n17 L1764-12b        14 D/FL       \n18 L1764-13a        15 D/FL       \n19 L1764-13b        15 D/FL       \n20 L1764-14         37 F          \n# … with 3,373 more rows\n\n\n\n\nschool from which painting came (details in a few slides)"
  },
  {
    "objectID": "content/lectures/07-linear-models-slides.html#relationship-between-height-and-school",
    "href": "content/lectures/07-linear-models-slides.html#relationship-between-height-and-school",
    "title": "07-linear-models",
    "section": "Relationship between height and school",
    "text": "Relationship between height and school\n\nlinear_reg() |>\n  set_engine(\"lm\") |>\n  fit(Height_in ~ school_pntg, data = pp) |>\n  tidy()\n\n# A tibble: 7 × 5\n  term            estimate std.error statistic p.value\n  <chr>              <dbl>     <dbl>     <dbl>   <dbl>\n1 (Intercept)        14.0       10.0     1.40  0.162  \n2 school_pntgD/FL     2.33      10.0     0.232 0.816  \n3 school_pntgF       10.2       10.0     1.02  0.309  \n4 school_pntgG        1.65      11.9     0.139 0.889  \n5 school_pntgI       10.3       10.0     1.02  0.306  \n6 school_pntgS       30.4       11.4     2.68  0.00744\n7 school_pntgX        2.87      10.3     0.279 0.780"
  },
  {
    "objectID": "content/lectures/07-linear-models-slides.html#dummy-variables",
    "href": "content/lectures/07-linear-models-slides.html#dummy-variables",
    "title": "07-linear-models",
    "section": "Dummy variables",
    "text": "Dummy variables\n\n\n# A tibble: 7 × 5\n  term            estimate std.error statistic p.value\n  <chr>              <dbl>     <dbl>     <dbl>   <dbl>\n1 (Intercept)        14.0       10.0     1.40  0.162  \n2 school_pntgD/FL     2.33      10.0     0.232 0.816  \n3 school_pntgF       10.2       10.0     1.02  0.309  \n4 school_pntgG        1.65      11.9     0.139 0.889  \n5 school_pntgI       10.3       10.0     1.02  0.306  \n6 school_pntgS       30.4       11.4     2.68  0.00744\n7 school_pntgX        2.87      10.3     0.279 0.780  \n\n\n\nWhen the categorical explanatory variable has many levels, they’re encoded to dummy variables\nEach coefficient describes the expected difference between heights in that particular school compared to the baseline level"
  },
  {
    "objectID": "content/lectures/07-linear-models-slides.html#categorical-predictor-with-3-levels",
    "href": "content/lectures/07-linear-models-slides.html#categorical-predictor-with-3-levels",
    "title": "07-linear-models",
    "section": "Categorical predictor with 3+ levels",
    "text": "Categorical predictor with 3+ levels\n\n\n\n\n\n\n\nschool_pntg\nD_FL\nF\nG\nI\nS\nX\n\n\n\n\nA\n0\n0\n0\n0\n0\n0\n\n\nD/FL\n1\n0\n0\n0\n0\n0\n\n\nF\n0\n1\n0\n0\n0\n0\n\n\nG\n0\n0\n1\n0\n0\n0\n\n\nI\n0\n0\n0\n1\n0\n0\n\n\nS\n0\n0\n0\n0\n1\n0\n\n\nX\n0\n0\n0\n0\n0\n1\n\n\n\n\n\n\n\n\n\n\n# A tibble: 3,393 × 3\n   name      Height_in school_pntg\n   <chr>         <dbl> <chr>      \n 1 L1764-2          37 F          \n 2 L1764-3          18 I          \n 3 L1764-4          13 D/FL       \n 4 L1764-5a         14 F          \n 5 L1764-5b         14 F          \n 6 L1764-6           7 I          \n 7 L1764-7a          6 F          \n 8 L1764-7b          6 F          \n 9 L1764-8          15 I          \n10 L1764-9a          9 D/FL       \n11 L1764-9b          9 D/FL       \n12 L1764-10a        16 X          \n13 L1764-10b        16 X          \n14 L1764-10c        16 X          \n15 L1764-11         20 D/FL       \n16 L1764-12a        14 D/FL       \n17 L1764-12b        14 D/FL       \n18 L1764-13a        15 D/FL       \n19 L1764-13b        15 D/FL       \n20 L1764-14         37 F          \n# … with 3,373 more rows"
  },
  {
    "objectID": "content/lectures/07-linear-models-slides.html#the-linear-model-with-multiple-predictors",
    "href": "content/lectures/07-linear-models-slides.html#the-linear-model-with-multiple-predictors",
    "title": "07-linear-models",
    "section": "The linear model with multiple predictors",
    "text": "The linear model with multiple predictors\n\nPopulation model:\n\n\\[ \\hat{y} = \\beta_0 + \\beta_1~x_1 + \\beta_2~x_2 + \\cdots + \\beta_k~x_k \\]\n\n\nSample model that we use to estimate the population model:\n\n\\[ \\hat{y} = b_0 + b_1~x_1 + b_2~x_2 + \\cdots + b_k~x_k \\]"
  },
  {
    "objectID": "content/lectures/07-linear-models-slides.html#relationship-bw-height-and-school",
    "href": "content/lectures/07-linear-models-slides.html#relationship-bw-height-and-school",
    "title": "07-linear-models",
    "section": "Relationship b/w height and school",
    "text": "Relationship b/w height and school\n\n\n# A tibble: 7 × 5\n  term            estimate std.error statistic p.value\n  <chr>              <dbl>     <dbl>     <dbl>   <dbl>\n1 (Intercept)        14.0       10.0     1.40  0.162  \n2 school_pntgD/FL     2.33      10.0     0.232 0.816  \n3 school_pntgF       10.2       10.0     1.02  0.309  \n4 school_pntgG        1.65      11.9     0.139 0.889  \n5 school_pntgI       10.3       10.0     1.02  0.306  \n6 school_pntgS       30.4       11.4     2.68  0.00744\n7 school_pntgX        2.87      10.3     0.279 0.780  \n\n\n\nAustrian school (A) paintings are expected, on average, to be 14 inches tall.\nDutch/Flemish school (D/FL) paintings are expected, on average, to be 2.33 inches taller than Austrian school paintings.\nFrench school (F) paintings are expected, on average, to be 10.2 inches taller than Austrian school paintings.\nGerman school (G) paintings are expected, on average, to be 1.65 inches taller than Austrian school paintings.\nItalian school (I) paintings are expected, on average, to be 10.3 inches taller than Austrian school paintings.\nSpanish school (S) paintings are expected, on average, to be 30.4 inches taller than Austrian school paintings.\nPaintings whose school is unknown (X) are expected, on average, to be 2.87 inches taller than Austrian school paintings. ]"
  },
  {
    "objectID": "content/lectures/07-linear-models-slides.html#predict-height-from-width",
    "href": "content/lectures/07-linear-models-slides.html#predict-height-from-width",
    "title": "07-linear-models",
    "section": "Predict height from width",
    "text": "Predict height from width\n❓ On average, how tall are paintings that are 60 inches wide? \\[\\widehat{Height_{in}} = 3.62 + 0.78~Width_{in}\\]\n\n\n3.62 + 0.78 * 60\n\n[1] 50.42\n\n\n“On average, we expect paintings that are 60 inches wide to be 50.42 inches high.”\nWarning: We “expect” this to happen, but there will be some variability. (We’ll learn about measuring the variability around the prediction later.)"
  },
  {
    "objectID": "content/lectures/07-linear-models-slides.html#prediction-vs.-extrapolation",
    "href": "content/lectures/07-linear-models-slides.html#prediction-vs.-extrapolation",
    "title": "07-linear-models",
    "section": "Prediction vs. extrapolation",
    "text": "Prediction vs. extrapolation\n❓ On average, how tall are paintings that are 400 inches wide? \\[\\widehat{Height_{in}} = 3.62 + 0.78~Width_{in}\\]"
  },
  {
    "objectID": "content/lectures/07-linear-models-slides.html#watch-out-for-extrapolation",
    "href": "content/lectures/07-linear-models-slides.html#watch-out-for-extrapolation",
    "title": "07-linear-models",
    "section": "Watch out for extrapolation!",
    "text": "Watch out for extrapolation!\n\n“When those blizzards hit the East Coast this winter, it proved to my satisfaction that global warming was a fraud. That snow was freezing cold. But in an alarming trend, temperatures this spring have risen. Consider this: On February 6th it was 10 degrees. Today it hit almost 80. At this rate, by August it will be 220 degrees. So clearly folks the climate debate rages on.”1  Stephen Colbert, April 6th, 2010\n\nIntroduction to Modern Statistics. “Extrapolation is treacherous.”"
  },
  {
    "objectID": "content/lectures/07-linear-models-slides.html#measuring-the-strength-of-the-fit",
    "href": "content/lectures/07-linear-models-slides.html#measuring-the-strength-of-the-fit",
    "title": "07-linear-models",
    "section": "Measuring the strength of the fit",
    "text": "Measuring the strength of the fit\n\nThe strength of the fit of a linear model is most commonly evaluated using \\(R^2\\).\nIt tells us what percent of variability in the response variable is explained by the model.\nThe remainder of the variability is explained by variables not included in the model.\n\\(R^2\\) is sometimes called the coefficient of determination."
  },
  {
    "objectID": "content/lectures/07-linear-models-slides.html#obtaining-r2-in-r",
    "href": "content/lectures/07-linear-models-slides.html#obtaining-r2-in-r",
    "title": "07-linear-models",
    "section": "Obtaining \\(R^2\\) in R",
    "text": "Obtaining \\(R^2\\) in R\n\nHeight vs. width\n\n\nglance(m_ht_wt)\n\n# A tibble: 1 × 12\n  r.squared adj.r.sq…¹ sigma stati…² p.value    df  logLik    AIC    BIC devia…³\n      <dbl>      <dbl> <dbl>   <dbl>   <dbl> <dbl>   <dbl>  <dbl>  <dbl>   <dbl>\n1     0.683      0.683  8.30   6749.       0     1 -11083. 22173. 22191. 216055.\n# … with 2 more variables: df.residual <int>, nobs <int>, and abbreviated\n#   variable names ¹​adj.r.squared, ²​statistic, ³​deviance\n\nglance(m_ht_wt)$r.squared # extract R-squared\n\n[1] 0.6829468\n\n\nRoughly 68% of the variability in heights of paintings can be explained by their widths.\n\n\nHeight vs. landscape features\n\n\nglance(m_ht_lands)$r.squared\n\n[1] 0.03456724"
  },
  {
    "objectID": "content/lectures/07-linear-models-slides.html#data-paris-paintings-1",
    "href": "content/lectures/07-linear-models-slides.html#data-paris-paintings-1",
    "title": "07-linear-models",
    "section": "Data: Paris Paintings",
    "text": "Data: Paris Paintings"
  },
  {
    "objectID": "content/lectures/07-linear-models-slides.html#price-vs.-width",
    "href": "content/lectures/07-linear-models-slides.html#price-vs.-width",
    "title": "07-linear-models",
    "section": "Price vs. width",
    "text": "Price vs. width\n❓ Describe the relationship between price and width of paintings whose width is less than 100in."
  },
  {
    "objectID": "content/lectures/07-linear-models-slides.html#price-vs.-width-1",
    "href": "content/lectures/07-linear-models-slides.html#price-vs.-width-1",
    "title": "07-linear-models",
    "section": "Price vs. width",
    "text": "Price vs. width\n❓ Which plot shows a more linear relationship?"
  },
  {
    "objectID": "content/lectures/07-linear-models-slides.html#price-vs.-width-residuals",
    "href": "content/lectures/07-linear-models-slides.html#price-vs.-width-residuals",
    "title": "07-linear-models",
    "section": "Price vs. width, residuals",
    "text": "Price vs. width, residuals\n❓ Which plot shows a residuals that are uncorrelated with predicted values from the model?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n❓What’s the unit of residuals?"
  },
  {
    "objectID": "content/lectures/07-linear-models-slides.html#transforming-the-data",
    "href": "content/lectures/07-linear-models-slides.html#transforming-the-data",
    "title": "07-linear-models",
    "section": "Transforming the data",
    "text": "Transforming the data\n\nWe saw that price has a right-skewed distribution, and the relationship between price and width of painting is non-linear.\n\n\n\nIn these situations a transformation applied to the response variable may be useful.\n\n\n\n\nIn order to decide which transformation to use, we should examine the distribution of the response variable.\n\n\n\n\nThe extremely right skewed distribution suggests that a log transformation may be useful.\n\nlog = natural log, \\(ln\\)\nDefault base of the log function in R is the natural log:  log(x, base = exp(1))"
  },
  {
    "objectID": "content/lectures/07-linear-models-slides.html#logged-price-vs.-width",
    "href": "content/lectures/07-linear-models-slides.html#logged-price-vs.-width",
    "title": "07-linear-models",
    "section": "Logged price vs. width",
    "text": "Logged price vs. width\n❓ How do we interpret the slope of this model?"
  },
  {
    "objectID": "content/lectures/07-linear-models-slides.html#interpreting-models-with-log-transformation",
    "href": "content/lectures/07-linear-models-slides.html#interpreting-models-with-log-transformation",
    "title": "07-linear-models",
    "section": "Interpreting models with log transformation",
    "text": "Interpreting models with log transformation\n\nm_lprice_wt <- lm(log(price) ~ Width_in, data = pp_wt_lt_100)\nm_lprice_wt |>\n  tidy() |>\n  select(term, estimate) |>\n  mutate(estimate = round(estimate, 3))\n\n# A tibble: 2 × 2\n  term        estimate\n  <chr>          <dbl>\n1 (Intercept)    4.67 \n2 Width_in       0.019"
  },
  {
    "objectID": "content/lectures/07-linear-models-slides.html#linear-model-with-log-transformation",
    "href": "content/lectures/07-linear-models-slides.html#linear-model-with-log-transformation",
    "title": "07-linear-models",
    "section": "Linear model with log transformation",
    "text": "Linear model with log transformation\n\\[ \\widehat{log(price)} = 4.67 + 0.02 Width \\]\n\n\nFor each additional inch the painting is wider, the log price of the painting is expected to be higher, on average, by 0.02 livres.\n\n\n\n\nwhich is not a very useful statement…"
  },
  {
    "objectID": "content/lectures/07-linear-models-slides.html#working-with-logs",
    "href": "content/lectures/07-linear-models-slides.html#working-with-logs",
    "title": "07-linear-models",
    "section": "Working with logs",
    "text": "Working with logs\n\nSubtraction and logs: \\(log(a) − log(b) = log(a / b)\\)\n\n\n\nNatural logarithm: \\(e^{log(x)} = x\\)\n\n\n\n\nWe can use these identities to “undo” the log transformation"
  },
  {
    "objectID": "content/lectures/07-linear-models-slides.html#interpreting-models-with-log-transformation-1",
    "href": "content/lectures/07-linear-models-slides.html#interpreting-models-with-log-transformation-1",
    "title": "07-linear-models",
    "section": "Interpreting models with log transformation",
    "text": "Interpreting models with log transformation\nThe slope coefficient for the log transformed model is 0.02, meaning the log price difference between paintings whose widths are one inch apart is predicted to be 0.02 log livres.\n\n\\[ log(\\text{price for width x+1}) - log(\\text{price for width x}) = 0.02 \\]\n\n\n\\[ log\\left(\\frac{\\text{price for width x+1}}{\\text{price for width x}}\\right) = 0.02 \\]\n\n\n\\[ e^{log\\left(\\frac{\\text{price for width x+1}}{\\text{price for width x}}\\right)} = e^{0.02} \\]\n\n\n\\[ \\frac{\\text{price for width x+1}}{\\text{price for width x}} \\approx 1.02 \\]\n\n\nFor each additional inch the painting is wider, the price of the painting is expected to be higher, on average, by a factor of 1.02."
  },
  {
    "objectID": "content/lectures/07-linear-models-slides.html#shortcuts-in-r",
    "href": "content/lectures/07-linear-models-slides.html#shortcuts-in-r",
    "title": "07-linear-models",
    "section": "Shortcuts in R",
    "text": "Shortcuts in R\n\nm_lprice_wt |>\n  tidy() |>\n  select(term, estimate) |>\n  mutate(estimate = round(estimate, 3))\n\n# A tibble: 2 × 2\n  term        estimate\n  <chr>          <dbl>\n1 (Intercept)    4.67 \n2 Width_in       0.019\n\n\n\nm_lprice_wt |>\n  tidy() |>\n  select(term, estimate) |>\n  mutate(estimate = round(exp(estimate), 3))\n\n# A tibble: 2 × 2\n  term        estimate\n  <chr>          <dbl>\n1 (Intercept)   107.  \n2 Width_in        1.02"
  },
  {
    "objectID": "content/lectures/07-linear-models-slides.html#recap-log-transformations",
    "href": "content/lectures/07-linear-models-slides.html#recap-log-transformations",
    "title": "07-linear-models",
    "section": "Recap: Log Transformations",
    "text": "Recap: Log Transformations\n\nNon-constant variance is one of the most common model violations, however it is usually fixable by transforming the response (y) variable.\n\n\n\nThe most common transformation when the response variable is right skewed is the log transform: \\(log(y)\\), especially useful when the response variable is (extremely) right skewed.\n\n\n\n\nThis transformation is also useful for variance stabilization.\n\n\n\n\nWhen using a log transformation on the response variable the interpretation of the slope changes: “For each unit increase in x, y is expected on average to be higher/lower  by a factor of \\(e^{b_1}\\).”\n\n\n\n\nAnother useful transformation is the square root: \\(\\sqrt{y}\\), especially useful when the response variable is counts."
  },
  {
    "objectID": "content/lectures/07-linear-models-slides.html#aside-when-y-0",
    "href": "content/lectures/07-linear-models-slides.html#aside-when-y-0",
    "title": "07-linear-models",
    "section": "Aside: when \\(y = 0\\)",
    "text": "Aside: when \\(y = 0\\)\nIn some cases the value of the response variable might be 0, and\n\nlog(0)\n\n[1] -Inf\n\n\n\nThe trick is to add a very small number to the value of the response variable for these cases so that the log function can still be applied:\n\nlog(0 + 0.00001)\n\n[1] -11.51293"
  },
  {
    "objectID": "content/lectures/07-linear-models-slides.html#recap",
    "href": "content/lectures/07-linear-models-slides.html#recap",
    "title": "07-linear-models",
    "section": "Recap",
    "text": "Recap\n\nCan I carry out linear regression using the tidymodels approach?\nCan I interpret and explain the results from a linear model with a single predictor?\nDo I understand the limitations of modelling data w/ linear regression?\nCan I describe and implement the use of a dummy variable in linear regression?\nCan I determine when logistic transformation may be appropriate? Can I interpret these results?"
  },
  {
    "objectID": "content/lectures/07-linear-models-slides.html#suggested-reading",
    "href": "content/lectures/07-linear-models-slides.html#suggested-reading",
    "title": "07-linear-models",
    "section": "Suggested Reading",
    "text": "Suggested Reading\n\nR4DS Chapter 24: Model Building\nIntroduction to Modern Statistics Chapter 7: Linear Regression with a Single Predictor\n\n\n\n\nhttps://cogs137.github.io/website/"
  },
  {
    "objectID": "content/lectures/07-linear-models.html",
    "href": "content/lectures/07-linear-models.html",
    "title": "07-linear-models",
    "section": "",
    "text": "Q: Do you recommend review some statistics before attending lectures?\nA: This is very much up to you. It certainly wouldn’t hurt! There will be readings connected to each lecture; these are a great place to start. It can be helpful to work through these readings and the exercises either before or after lecture!\n\n\nQ: I am still not quite sure how to do HW part 2 and 3, do we download data into the folder, read the file, and plot it?\nA: Yup! That’s one approach. The other approach (if the data are not available for download) would be to create the dataset on your own, estimating the values as best you can from the plot and creating a dataframe/tibble containing that information directly in your code (similar to what you did in HW01)….and then plot from there.\n\n\n\n\nDue Dates:\n\nLab 04 due tomorrow (2/3; 11:59 PM)\nLecture Participation survey “due” after class\nHW02 due Monday (2/6; 11:59 PM)\n\n\n\nMidterm Exam\n\npractice exam(s) will be released tomorrow; answers posted next week\nwill cover material through “Effective Communication”\nwill be released/posted next Friday after lab\nwill be due Monday Feb 13th at 11:59 PM\nwill be an Rmd document and submitted via GitHub (like everything so far)\nwill be commpleted individually (open Notes; open Google)\n\n\n\n\n\n\n\nLinear Models\n\nQuantitative Predictor\nCategorical Predictor (2 & >2 levels)\nresiduals\ndata transformations"
  },
  {
    "objectID": "content/lectures/07-linear-models.html#data-paris-paintings",
    "href": "content/lectures/07-linear-models.html#data-paris-paintings",
    "title": "07-linear-models",
    "section": "Data: Paris Paintings",
    "text": "Data: Paris Paintings\n\npp <- read_csv(\"https://raw.githubusercontent.com/COGS137/datasets/main/paris_paintings.csv\", \n               na = c(\"n/a\", \"\", \"NA\"))\n\n\nNumber of observations: 3393\nNumber of variables: 61"
  },
  {
    "objectID": "content/lectures/07-linear-models.html#goal-predict-height-from-width",
    "href": "content/lectures/07-linear-models.html#goal-predict-height-from-width",
    "title": "07-linear-models",
    "section": "Goal: Predict height from width",
    "text": "Goal: Predict height from width\n\\[\\widehat{height}_{i} = \\beta_0 + \\beta_1 \\times width_{i}\\]"
  },
  {
    "objectID": "content/lectures/07-linear-models.html#tidymodels-1",
    "href": "content/lectures/07-linear-models.html#tidymodels-1",
    "title": "07-linear-models",
    "section": "tidymodels",
    "text": "tidymodels\n\nNOT a core tidyverse package\nfollows the structure of a tidyverse package\n\n\n\n\n\n\n\n# should already be installed for you on datahub\nlibrary(tidymodels)"
  },
  {
    "objectID": "content/lectures/07-linear-models.html#step-1-specify-model",
    "href": "content/lectures/07-linear-models.html#step-1-specify-model",
    "title": "07-linear-models",
    "section": "Step 1: Specify model",
    "text": "Step 1: Specify model\n\nlinear_reg()\n\nLinear Regression Model Specification (regression)\n\nComputational engine: lm"
  },
  {
    "objectID": "content/lectures/07-linear-models.html#step-2-set-model-fitting-engine",
    "href": "content/lectures/07-linear-models.html#step-2-set-model-fitting-engine",
    "title": "07-linear-models",
    "section": "Step 2: Set model fitting engine",
    "text": "Step 2: Set model fitting engine\n\nlinear_reg() |>\n  set_engine(\"lm\") # lm: linear model\n\nLinear Regression Model Specification (regression)\n\nComputational engine: lm"
  },
  {
    "objectID": "content/lectures/07-linear-models.html#step-3-fit-model-estimate-parameters",
    "href": "content/lectures/07-linear-models.html#step-3-fit-model-estimate-parameters",
    "title": "07-linear-models",
    "section": "Step 3: Fit model & estimate parameters",
    "text": "Step 3: Fit model & estimate parameters\n… using formula syntax\n\nlinear_reg() |>\n  set_engine(\"lm\") |>\n  fit(Height_in ~ Width_in, data = pp)\n\nparsnip model object\n\n\nCall:\nstats::lm(formula = Height_in ~ Width_in, data = data)\n\nCoefficients:\n(Intercept)     Width_in  \n     3.6214       0.7808"
  },
  {
    "objectID": "content/lectures/07-linear-models.html#a-closer-look-at-model-output",
    "href": "content/lectures/07-linear-models.html#a-closer-look-at-model-output",
    "title": "07-linear-models",
    "section": "A closer look at model output",
    "text": "A closer look at model output\n\n\nparsnip model object\n\n\nCall:\nstats::lm(formula = Height_in ~ Width_in, data = data)\n\nCoefficients:\n(Intercept)     Width_in  \n     3.6214       0.7808  \n\n\n\\[\\widehat{height}_{i} = 3.6214 + 0.7808 \\times width_{i}\\]"
  },
  {
    "objectID": "content/lectures/07-linear-models.html#a-tidy-look-at-model-output",
    "href": "content/lectures/07-linear-models.html#a-tidy-look-at-model-output",
    "title": "07-linear-models",
    "section": "A tidy look at model output",
    "text": "A tidy look at model output\n\nlinear_reg() |>\n  set_engine(\"lm\") |>\n  fit(Height_in ~ Width_in, data = pp) |>\n  tidy()\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)    3.62    0.254        14.3 8.82e-45\n2 Width_in       0.781   0.00950      82.1 0       \n\n\n\\[\\widehat{height}_{i} = 3.62 + 0.781 \\times width_{i}\\]"
  },
  {
    "objectID": "content/lectures/07-linear-models.html#slope-and-intercept",
    "href": "content/lectures/07-linear-models.html#slope-and-intercept",
    "title": "07-linear-models",
    "section": "Slope and intercept",
    "text": "Slope and intercept\n\\[\\widehat{height}_{i} = 3.62 + 0.781 \\times width_{i}\\]\n\n\nSlope: For each additional inch the painting is wider, the height is expected to be higher, on average, by 0.781 inches.\n\n\n\n\nIntercept: Paintings that are 0 inches wide are expected to be 3.62 inches high, on average. (Does this make sense?)"
  },
  {
    "objectID": "content/lectures/07-linear-models.html#correlation-does-not-imply-causation",
    "href": "content/lectures/07-linear-models.html#correlation-does-not-imply-causation",
    "title": "07-linear-models",
    "section": "Correlation does not imply causation",
    "text": "Correlation does not imply causation\nRemember this when interpreting model coefficients\n\n\n\n\n\n\n\nSource: XKCD, Cell phones"
  },
  {
    "objectID": "content/lectures/07-linear-models.html#linear-model-with-a-single-predictor",
    "href": "content/lectures/07-linear-models.html#linear-model-with-a-single-predictor",
    "title": "07-linear-models",
    "section": "Linear model with a single predictor",
    "text": "Linear model with a single predictor\n\nWe’re interested in \\(\\beta_0\\) (population parameter for the intercept) and \\(\\beta_1\\) (population parameter for the slope) in the following model:\n\n\\[\\hat{y}_{i} = \\beta_0 + \\beta_1~x_{i}\\]\n\n\nTough luck, you can’t have them…\n\n\n\n\nSo we use sample statistics to estimate them:\n\n\\[\\hat{y}_{i} = b_0 + b_1~x_{i}\\]"
  },
  {
    "objectID": "content/lectures/07-linear-models.html#least-squares-regression",
    "href": "content/lectures/07-linear-models.html#least-squares-regression",
    "title": "07-linear-models",
    "section": "Least squares regression",
    "text": "Least squares regression\n\nThe regression line minimizes the sum of squared residuals.\n\n\n\nIf \\(e_i = y_i - \\hat{y}_i\\), then, the regression line minimizes \\(\\sum_{i = 1}^n e_i^2\\)."
  },
  {
    "objectID": "content/lectures/07-linear-models.html#visualizing-residuals",
    "href": "content/lectures/07-linear-models.html#visualizing-residuals",
    "title": "07-linear-models",
    "section": "Visualizing residuals",
    "text": "Visualizing residuals"
  },
  {
    "objectID": "content/lectures/07-linear-models.html#visualizing-residuals-cont.",
    "href": "content/lectures/07-linear-models.html#visualizing-residuals-cont.",
    "title": "07-linear-models",
    "section": "Visualizing residuals (cont.)",
    "text": "Visualizing residuals (cont.)"
  },
  {
    "objectID": "content/lectures/07-linear-models.html#visualizing-residuals-cont.-1",
    "href": "content/lectures/07-linear-models.html#visualizing-residuals-cont.-1",
    "title": "07-linear-models",
    "section": "Visualizing residuals (cont.)",
    "text": "Visualizing residuals (cont.)"
  },
  {
    "objectID": "content/lectures/07-linear-models.html#properties-of-least-squares-regression",
    "href": "content/lectures/07-linear-models.html#properties-of-least-squares-regression",
    "title": "07-linear-models",
    "section": "Properties of least squares regression",
    "text": "Properties of least squares regression\n\nThe regression line goes through the center of mass point, the coordinates corresponding to average \\(x\\) and average \\(y\\), \\((\\bar{x}, \\bar{y})\\):\n\n\\[\\bar{y} = b_0 + b_1 \\bar{x} ~ \\rightarrow ~ b_0 = \\bar{y} - b_1 \\bar{x}\\]\n\n\nThe slope has the same sign as the correlation coefficient: \\(b_1 = r \\frac{s_y}{s_x}\\)\n\n\n\n\nThe sum of the residuals is zero: \\(\\sum_{i = 1}^n e_i = 0\\)\n\n\n\n\nThe residuals and \\(x\\) values are uncorrelated"
  },
  {
    "objectID": "content/lectures/07-linear-models.html#categorical-predictor-with-2-levels",
    "href": "content/lectures/07-linear-models.html#categorical-predictor-with-2-levels",
    "title": "07-linear-models",
    "section": "Categorical predictor with 2 levels",
    "text": "Categorical predictor with 2 levels\n\n\n\n\n# A tibble: 3,393 × 3\n   name      Height_in landsALL\n   <chr>         <dbl>    <dbl>\n 1 L1764-2          37        0\n 2 L1764-3          18        0\n 3 L1764-4          13        1\n 4 L1764-5a         14        1\n 5 L1764-5b         14        1\n 6 L1764-6           7        0\n 7 L1764-7a          6        0\n 8 L1764-7b          6        0\n 9 L1764-8          15        0\n10 L1764-9a          9        0\n11 L1764-9b          9        0\n12 L1764-10a        16        1\n13 L1764-10b        16        1\n14 L1764-10c        16        1\n15 L1764-11         20        0\n16 L1764-12a        14        1\n17 L1764-12b        14        1\n18 L1764-13a        15        1\n19 L1764-13b        15        1\n20 L1764-14         37        0\n# … with 3,373 more rows\n\n\n\n\nlandsALL = 0: No landscape features\nlandsALL = 1: Some landscape features"
  },
  {
    "objectID": "content/lectures/07-linear-models.html#height-landscape-features",
    "href": "content/lectures/07-linear-models.html#height-landscape-features",
    "title": "07-linear-models",
    "section": "Height & landscape features",
    "text": "Height & landscape features\n\nm_ht_lands <- linear_reg() |>\n  set_engine(\"lm\") |>\n  fit(Height_in ~ factor(landsALL), data = pp)\n\nm_ht_lands |> tidy()\n\n# A tibble: 2 × 5\n  term              estimate std.error statistic  p.value\n  <chr>                <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)          22.7      0.328      69.1 0       \n2 factor(landsALL)1    -5.65     0.532     -10.6 7.97e-26"
  },
  {
    "objectID": "content/lectures/07-linear-models.html#height-landscape-features-1",
    "href": "content/lectures/07-linear-models.html#height-landscape-features-1",
    "title": "07-linear-models",
    "section": "Height & landscape features",
    "text": "Height & landscape features\n\\[\\widehat{Height_{in}} = 22.7 - 5.645~landsALL\\]\n\nSlope: Paintings with landscape features are expected, on average, to be 5.645 inches shorter than paintings that without landscape features\n\nCompares baseline level (landsALL = 0) to the other level (landsALL = 1)\n\nIntercept: Paintings that don’t have landscape features are expected, on average, to be 22.7 inches tall"
  },
  {
    "objectID": "content/lectures/07-linear-models.html#categorical-predictor-with-2-levels-1",
    "href": "content/lectures/07-linear-models.html#categorical-predictor-with-2-levels-1",
    "title": "07-linear-models",
    "section": "Categorical predictor with >2 levels",
    "text": "Categorical predictor with >2 levels\n\n\n\n\n# A tibble: 3,393 × 3\n   name      Height_in school_pntg\n   <chr>         <dbl> <chr>      \n 1 L1764-2          37 F          \n 2 L1764-3          18 I          \n 3 L1764-4          13 D/FL       \n 4 L1764-5a         14 F          \n 5 L1764-5b         14 F          \n 6 L1764-6           7 I          \n 7 L1764-7a          6 F          \n 8 L1764-7b          6 F          \n 9 L1764-8          15 I          \n10 L1764-9a          9 D/FL       \n11 L1764-9b          9 D/FL       \n12 L1764-10a        16 X          \n13 L1764-10b        16 X          \n14 L1764-10c        16 X          \n15 L1764-11         20 D/FL       \n16 L1764-12a        14 D/FL       \n17 L1764-12b        14 D/FL       \n18 L1764-13a        15 D/FL       \n19 L1764-13b        15 D/FL       \n20 L1764-14         37 F          \n# … with 3,373 more rows\n\n\n\n\nschool from which painting came (details in a few slides)"
  },
  {
    "objectID": "content/lectures/07-linear-models.html#relationship-between-height-and-school",
    "href": "content/lectures/07-linear-models.html#relationship-between-height-and-school",
    "title": "07-linear-models",
    "section": "Relationship between height and school",
    "text": "Relationship between height and school\n\nlinear_reg() |>\n  set_engine(\"lm\") |>\n  fit(Height_in ~ school_pntg, data = pp) |>\n  tidy()\n\n# A tibble: 7 × 5\n  term            estimate std.error statistic p.value\n  <chr>              <dbl>     <dbl>     <dbl>   <dbl>\n1 (Intercept)        14.0       10.0     1.40  0.162  \n2 school_pntgD/FL     2.33      10.0     0.232 0.816  \n3 school_pntgF       10.2       10.0     1.02  0.309  \n4 school_pntgG        1.65      11.9     0.139 0.889  \n5 school_pntgI       10.3       10.0     1.02  0.306  \n6 school_pntgS       30.4       11.4     2.68  0.00744\n7 school_pntgX        2.87      10.3     0.279 0.780"
  },
  {
    "objectID": "content/lectures/07-linear-models.html#dummy-variables",
    "href": "content/lectures/07-linear-models.html#dummy-variables",
    "title": "07-linear-models",
    "section": "Dummy variables",
    "text": "Dummy variables\n\n\n# A tibble: 7 × 5\n  term            estimate std.error statistic p.value\n  <chr>              <dbl>     <dbl>     <dbl>   <dbl>\n1 (Intercept)        14.0       10.0     1.40  0.162  \n2 school_pntgD/FL     2.33      10.0     0.232 0.816  \n3 school_pntgF       10.2       10.0     1.02  0.309  \n4 school_pntgG        1.65      11.9     0.139 0.889  \n5 school_pntgI       10.3       10.0     1.02  0.306  \n6 school_pntgS       30.4       11.4     2.68  0.00744\n7 school_pntgX        2.87      10.3     0.279 0.780  \n\n\n\nWhen the categorical explanatory variable has many levels, they’re encoded to dummy variables\nEach coefficient describes the expected difference between heights in that particular school compared to the baseline level"
  },
  {
    "objectID": "content/lectures/07-linear-models.html#categorical-predictor-with-3-levels",
    "href": "content/lectures/07-linear-models.html#categorical-predictor-with-3-levels",
    "title": "07-linear-models",
    "section": "Categorical predictor with 3+ levels",
    "text": "Categorical predictor with 3+ levels\n\n\n\n\n\n\n\nschool_pntg\nD_FL\nF\nG\nI\nS\nX\n\n\n\n\nA\n0\n0\n0\n0\n0\n0\n\n\nD/FL\n1\n0\n0\n0\n0\n0\n\n\nF\n0\n1\n0\n0\n0\n0\n\n\nG\n0\n0\n1\n0\n0\n0\n\n\nI\n0\n0\n0\n1\n0\n0\n\n\nS\n0\n0\n0\n0\n1\n0\n\n\nX\n0\n0\n0\n0\n0\n1\n\n\n\n\n\n\n\n\n\n\n# A tibble: 3,393 × 3\n   name      Height_in school_pntg\n   <chr>         <dbl> <chr>      \n 1 L1764-2          37 F          \n 2 L1764-3          18 I          \n 3 L1764-4          13 D/FL       \n 4 L1764-5a         14 F          \n 5 L1764-5b         14 F          \n 6 L1764-6           7 I          \n 7 L1764-7a          6 F          \n 8 L1764-7b          6 F          \n 9 L1764-8          15 I          \n10 L1764-9a          9 D/FL       \n11 L1764-9b          9 D/FL       \n12 L1764-10a        16 X          \n13 L1764-10b        16 X          \n14 L1764-10c        16 X          \n15 L1764-11         20 D/FL       \n16 L1764-12a        14 D/FL       \n17 L1764-12b        14 D/FL       \n18 L1764-13a        15 D/FL       \n19 L1764-13b        15 D/FL       \n20 L1764-14         37 F          \n# … with 3,373 more rows"
  },
  {
    "objectID": "content/lectures/07-linear-models.html#the-linear-model-with-multiple-predictors",
    "href": "content/lectures/07-linear-models.html#the-linear-model-with-multiple-predictors",
    "title": "07-linear-models",
    "section": "The linear model with multiple predictors",
    "text": "The linear model with multiple predictors\n\nPopulation model:\n\n\\[ \\hat{y} = \\beta_0 + \\beta_1~x_1 + \\beta_2~x_2 + \\cdots + \\beta_k~x_k \\]\n\n\nSample model that we use to estimate the population model:\n\n\\[ \\hat{y} = b_0 + b_1~x_1 + b_2~x_2 + \\cdots + b_k~x_k \\]"
  },
  {
    "objectID": "content/lectures/07-linear-models.html#relationship-bw-height-and-school",
    "href": "content/lectures/07-linear-models.html#relationship-bw-height-and-school",
    "title": "07-linear-models",
    "section": "Relationship b/w height and school",
    "text": "Relationship b/w height and school\n\n\n# A tibble: 7 × 5\n  term            estimate std.error statistic p.value\n  <chr>              <dbl>     <dbl>     <dbl>   <dbl>\n1 (Intercept)        14.0       10.0     1.40  0.162  \n2 school_pntgD/FL     2.33      10.0     0.232 0.816  \n3 school_pntgF       10.2       10.0     1.02  0.309  \n4 school_pntgG        1.65      11.9     0.139 0.889  \n5 school_pntgI       10.3       10.0     1.02  0.306  \n6 school_pntgS       30.4       11.4     2.68  0.00744\n7 school_pntgX        2.87      10.3     0.279 0.780  \n\n\n\nAustrian school (A) paintings are expected, on average, to be 14 inches tall.\nDutch/Flemish school (D/FL) paintings are expected, on average, to be 2.33 inches taller than Austrian school paintings.\nFrench school (F) paintings are expected, on average, to be 10.2 inches taller than Austrian school paintings.\nGerman school (G) paintings are expected, on average, to be 1.65 inches taller than Austrian school paintings.\nItalian school (I) paintings are expected, on average, to be 10.3 inches taller than Austrian school paintings.\nSpanish school (S) paintings are expected, on average, to be 30.4 inches taller than Austrian school paintings.\nPaintings whose school is unknown (X) are expected, on average, to be 2.87 inches taller than Austrian school paintings. ]"
  },
  {
    "objectID": "content/lectures/07-linear-models.html#predict-height-from-width",
    "href": "content/lectures/07-linear-models.html#predict-height-from-width",
    "title": "07-linear-models",
    "section": "Predict height from width",
    "text": "Predict height from width\n❓ On average, how tall are paintings that are 60 inches wide? \\[\\widehat{Height_{in}} = 3.62 + 0.78~Width_{in}\\]\n\n\n3.62 + 0.78 * 60\n\n[1] 50.42\n\n\n“On average, we expect paintings that are 60 inches wide to be 50.42 inches high.”\nWarning: We “expect” this to happen, but there will be some variability. (We’ll learn about measuring the variability around the prediction later.)"
  },
  {
    "objectID": "content/lectures/07-linear-models.html#prediction-vs.-extrapolation",
    "href": "content/lectures/07-linear-models.html#prediction-vs.-extrapolation",
    "title": "07-linear-models",
    "section": "Prediction vs. extrapolation",
    "text": "Prediction vs. extrapolation\n❓ On average, how tall are paintings that are 400 inches wide? \\[\\widehat{Height_{in}} = 3.62 + 0.78~Width_{in}\\]"
  },
  {
    "objectID": "content/lectures/07-linear-models.html#watch-out-for-extrapolation",
    "href": "content/lectures/07-linear-models.html#watch-out-for-extrapolation",
    "title": "07-linear-models",
    "section": "Watch out for extrapolation!",
    "text": "Watch out for extrapolation!\n\n“When those blizzards hit the East Coast this winter, it proved to my satisfaction that global warming was a fraud. That snow was freezing cold. But in an alarming trend, temperatures this spring have risen. Consider this: On February 6th it was 10 degrees. Today it hit almost 80. At this rate, by August it will be 220 degrees. So clearly folks the climate debate rages on.”1  Stephen Colbert, April 6th, 2010"
  },
  {
    "objectID": "content/lectures/07-linear-models.html#measuring-the-strength-of-the-fit",
    "href": "content/lectures/07-linear-models.html#measuring-the-strength-of-the-fit",
    "title": "07-linear-models",
    "section": "Measuring the strength of the fit",
    "text": "Measuring the strength of the fit\n\nThe strength of the fit of a linear model is most commonly evaluated using \\(R^2\\).\nIt tells us what percent of variability in the response variable is explained by the model.\nThe remainder of the variability is explained by variables not included in the model.\n\\(R^2\\) is sometimes called the coefficient of determination."
  },
  {
    "objectID": "content/lectures/07-linear-models.html#obtaining-r2-in-r",
    "href": "content/lectures/07-linear-models.html#obtaining-r2-in-r",
    "title": "07-linear-models",
    "section": "Obtaining \\(R^2\\) in R",
    "text": "Obtaining \\(R^2\\) in R\n\nHeight vs. width\n\n\nglance(m_ht_wt)\n\n# A tibble: 1 × 12\n  r.squared adj.r.sq…¹ sigma stati…² p.value    df  logLik    AIC    BIC devia…³\n      <dbl>      <dbl> <dbl>   <dbl>   <dbl> <dbl>   <dbl>  <dbl>  <dbl>   <dbl>\n1     0.683      0.683  8.30   6749.       0     1 -11083. 22173. 22191. 216055.\n# … with 2 more variables: df.residual <int>, nobs <int>, and abbreviated\n#   variable names ¹​adj.r.squared, ²​statistic, ³​deviance\n\nglance(m_ht_wt)$r.squared # extract R-squared\n\n[1] 0.6829468\n\n\nRoughly 68% of the variability in heights of paintings can be explained by their widths.\n\n\nHeight vs. landscape features\n\n\nglance(m_ht_lands)$r.squared\n\n[1] 0.03456724"
  },
  {
    "objectID": "content/lectures/07-linear-models.html#data-paris-paintings-1",
    "href": "content/lectures/07-linear-models.html#data-paris-paintings-1",
    "title": "07-linear-models",
    "section": "Data: Paris Paintings",
    "text": "Data: Paris Paintings"
  },
  {
    "objectID": "content/lectures/07-linear-models.html#price-vs.-width",
    "href": "content/lectures/07-linear-models.html#price-vs.-width",
    "title": "07-linear-models",
    "section": "Price vs. width",
    "text": "Price vs. width\n❓ Describe the relationship between price and width of paintings whose width is less than 100in."
  },
  {
    "objectID": "content/lectures/07-linear-models.html#price-vs.-width-1",
    "href": "content/lectures/07-linear-models.html#price-vs.-width-1",
    "title": "07-linear-models",
    "section": "Price vs. width",
    "text": "Price vs. width\n❓ Which plot shows a more linear relationship?"
  },
  {
    "objectID": "content/lectures/07-linear-models.html#price-vs.-width-residuals",
    "href": "content/lectures/07-linear-models.html#price-vs.-width-residuals",
    "title": "07-linear-models",
    "section": "Price vs. width, residuals",
    "text": "Price vs. width, residuals\n❓ Which plot shows a residuals that are uncorrelated with predicted values from the model?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n❓What’s the unit of residuals?"
  },
  {
    "objectID": "content/lectures/07-linear-models.html#transforming-the-data",
    "href": "content/lectures/07-linear-models.html#transforming-the-data",
    "title": "07-linear-models",
    "section": "Transforming the data",
    "text": "Transforming the data\n\nWe saw that price has a right-skewed distribution, and the relationship between price and width of painting is non-linear.\n\n\n\nIn these situations a transformation applied to the response variable may be useful.\n\n\n\n\nIn order to decide which transformation to use, we should examine the distribution of the response variable.\n\n\n\n\nThe extremely right skewed distribution suggests that a log transformation may be useful.\n\nlog = natural log, \\(ln\\)\nDefault base of the log function in R is the natural log:  log(x, base = exp(1))"
  },
  {
    "objectID": "content/lectures/07-linear-models.html#logged-price-vs.-width",
    "href": "content/lectures/07-linear-models.html#logged-price-vs.-width",
    "title": "07-linear-models",
    "section": "Logged price vs. width",
    "text": "Logged price vs. width\n❓ How do we interpret the slope of this model?"
  },
  {
    "objectID": "content/lectures/07-linear-models.html#interpreting-models-with-log-transformation",
    "href": "content/lectures/07-linear-models.html#interpreting-models-with-log-transformation",
    "title": "07-linear-models",
    "section": "Interpreting models with log transformation",
    "text": "Interpreting models with log transformation\n\nm_lprice_wt <- lm(log(price) ~ Width_in, data = pp_wt_lt_100)\nm_lprice_wt |>\n  tidy() |>\n  select(term, estimate) |>\n  mutate(estimate = round(estimate, 3))\n\n# A tibble: 2 × 2\n  term        estimate\n  <chr>          <dbl>\n1 (Intercept)    4.67 \n2 Width_in       0.019"
  },
  {
    "objectID": "content/lectures/07-linear-models.html#linear-model-with-log-transformation",
    "href": "content/lectures/07-linear-models.html#linear-model-with-log-transformation",
    "title": "07-linear-models",
    "section": "Linear model with log transformation",
    "text": "Linear model with log transformation\n\\[ \\widehat{log(price)} = 4.67 + 0.02 Width \\]\n\n\nFor each additional inch the painting is wider, the log price of the painting is expected to be higher, on average, by 0.02 livres.\n\n\n\n\nwhich is not a very useful statement…"
  },
  {
    "objectID": "content/lectures/07-linear-models.html#working-with-logs",
    "href": "content/lectures/07-linear-models.html#working-with-logs",
    "title": "07-linear-models",
    "section": "Working with logs",
    "text": "Working with logs\n\nSubtraction and logs: \\(log(a) − log(b) = log(a / b)\\)\n\n\n\nNatural logarithm: \\(e^{log(x)} = x\\)\n\n\n\n\nWe can use these identities to “undo” the log transformation"
  },
  {
    "objectID": "content/lectures/07-linear-models.html#interpreting-models-with-log-transformation-1",
    "href": "content/lectures/07-linear-models.html#interpreting-models-with-log-transformation-1",
    "title": "07-linear-models",
    "section": "Interpreting models with log transformation",
    "text": "Interpreting models with log transformation\nThe slope coefficient for the log transformed model is 0.02, meaning the log price difference between paintings whose widths are one inch apart is predicted to be 0.02 log livres.\n\n\\[ log(\\text{price for width x+1}) - log(\\text{price for width x}) = 0.02 \\]\n\n\n\\[ log\\left(\\frac{\\text{price for width x+1}}{\\text{price for width x}}\\right) = 0.02 \\]\n\n\n\\[ e^{log\\left(\\frac{\\text{price for width x+1}}{\\text{price for width x}}\\right)} = e^{0.02} \\]\n\n\n\\[ \\frac{\\text{price for width x+1}}{\\text{price for width x}} \\approx 1.02 \\]\n\n\nFor each additional inch the painting is wider, the price of the painting is expected to be higher, on average, by a factor of 1.02."
  },
  {
    "objectID": "content/lectures/07-linear-models.html#shortcuts-in-r",
    "href": "content/lectures/07-linear-models.html#shortcuts-in-r",
    "title": "07-linear-models",
    "section": "Shortcuts in R",
    "text": "Shortcuts in R\n\nm_lprice_wt |>\n  tidy() |>\n  select(term, estimate) |>\n  mutate(estimate = round(estimate, 3))\n\n# A tibble: 2 × 2\n  term        estimate\n  <chr>          <dbl>\n1 (Intercept)    4.67 \n2 Width_in       0.019\n\n\n\nm_lprice_wt |>\n  tidy() |>\n  select(term, estimate) |>\n  mutate(estimate = round(exp(estimate), 3))\n\n# A tibble: 2 × 2\n  term        estimate\n  <chr>          <dbl>\n1 (Intercept)   107.  \n2 Width_in        1.02"
  },
  {
    "objectID": "content/lectures/07-linear-models.html#recap-log-transformations",
    "href": "content/lectures/07-linear-models.html#recap-log-transformations",
    "title": "07-linear-models",
    "section": "Recap: Log Transformations",
    "text": "Recap: Log Transformations\n\nNon-constant variance is one of the most common model violations, however it is usually fixable by transforming the response (y) variable.\n\n\n\nThe most common transformation when the response variable is right skewed is the log transform: \\(log(y)\\), especially useful when the response variable is (extremely) right skewed.\n\n\n\n\nThis transformation is also useful for variance stabilization.\n\n\n\n\nWhen using a log transformation on the response variable the interpretation of the slope changes: “For each unit increase in x, y is expected on average to be higher/lower  by a factor of \\(e^{b_1}\\).”\n\n\n\n\nAnother useful transformation is the square root: \\(\\sqrt{y}\\), especially useful when the response variable is counts."
  },
  {
    "objectID": "content/lectures/07-linear-models.html#aside-when-y-0",
    "href": "content/lectures/07-linear-models.html#aside-when-y-0",
    "title": "07-linear-models",
    "section": "Aside: when \\(y = 0\\)",
    "text": "Aside: when \\(y = 0\\)\nIn some cases the value of the response variable might be 0, and\n\nlog(0)\n\n[1] -Inf\n\n\n\nThe trick is to add a very small number to the value of the response variable for these cases so that the log function can still be applied:\n\nlog(0 + 0.00001)\n\n[1] -11.51293"
  },
  {
    "objectID": "content/lectures/07-linear-models.html#recap",
    "href": "content/lectures/07-linear-models.html#recap",
    "title": "07-linear-models",
    "section": "Recap",
    "text": "Recap\n\nCan I carry out linear regression using the tidymodels approach?\nCan I interpret and explain the results from a linear model with a single predictor?\nDo I understand the limitations of modelling data w/ linear regression?\nCan I describe and implement the use of a dummy variable in linear regression?\nCan I determine when logistic transformation may be appropriate? Can I interpret these results?"
  },
  {
    "objectID": "content/lectures/07-linear-models.html#suggested-reading",
    "href": "content/lectures/07-linear-models.html#suggested-reading",
    "title": "07-linear-models",
    "section": "Suggested Reading",
    "text": "Suggested Reading\n\nR4DS Chapter 24: Model Building\nIntroduction to Modern Statistics Chapter 7: Linear Regression with a Single Predictor"
  },
  {
    "objectID": "content/lectures/11-cs01-data-slides.html#qa",
    "href": "content/lectures/11-cs01-data-slides.html#qa",
    "title": "11-cs01-data",
    "section": "Q&A",
    "text": "Q&A\n\nQ: Is there ever a time when we should use \\(R^2\\) instead of adjusted R^2 when analyzing a model?\nA: When talking about variance explained of a single model, \\(R^2\\) is great, but when comparing across models, you’ll always want to use adjusted \\(R^2\\)\n\n\nQ: How do we use the data from OCS for our case study? Should we merge the data files?\nA: Excellent question! That’s what today’s lecture is all about. There’s a whole lot of wrangling to do before we can use these data!\n\n\nQ: Do we need to look at the p-value when we do analysis? (Midterm01)\nA: When interpreting a model, no. When doing hypothesis testing (we’ll get there), it is one piece you can look at. A few people did interpret p-values on the midterm, and that’s ok! (But it was not required.)\n\n\nQ: Can we have a system where we can find other students to group with? Like a google form?\nA: Great question! I’ll start a pinned thread on Campuswire so you all can find one another.\n\n\nQ: I think the data seems pretty confusing.\nA: That’s b/c it is! We’ve got a lot of work to do to get it into a usable/understandable format.\n\n\nQ: In what context of data we should use interaction model or main effect model?\nA: Interaction terms should be included when the relationship between one predictor and the outcome varies by another predictor."
  },
  {
    "objectID": "content/lectures/11-cs01-data-slides.html#course-announcements",
    "href": "content/lectures/11-cs01-data-slides.html#course-announcements",
    "title": "11-cs01-data",
    "section": "Course Announcements",
    "text": "Course Announcements\nDue Dates:\n\nLab 05 due tomorrow (2/17; 11:59 PM)\nmid-course survey (optional for EC) due tomorrow (2/17; 11:59 PM)\nLecture Participation survey “due” after class\n\n\nNotes:\n\nCS01\n\ninstructions posted on website\ninvited to GH repo (accept invitation, please!)\nhave an email with other group mates\ngoal: meet more people in the class & work together\n\nHW03 posted\nReminder to think about final project group mates; thread on campuswire"
  },
  {
    "objectID": "content/lectures/11-cs01-data-slides.html#agenda",
    "href": "content/lectures/11-cs01-data-slides.html#agenda",
    "title": "11-cs01-data",
    "section": "Agenda",
    "text": "Agenda\n\nBackground\nData Intro\nWrangle\nCombine!"
  },
  {
    "objectID": "content/lectures/11-cs01-data-slides.html#right-to-carry-laws1",
    "href": "content/lectures/11-cs01-data-slides.html#right-to-carry-laws1",
    "title": "11-cs01-data",
    "section": "Right To Carry Laws1",
    "text": "Right To Carry Laws1\nRight to Carry (RTC) Laws - “a law that specifies if and how citizens are allowed to have a firearm on their person or nearby (for example, in a citizen’s car) in public.”2\nCase Study Reference: Wright, Carrie and Ontiveros, Michael and Jager, Leah and Taub, Margaret and Hicks, Stephanie. (2020). https://github.com//opencasestudies/ocs-bp-RTC-analysis. Influence of Multicollinearity on Measured Impact of Right-to-Carry Gun Laws (Version v1.0.0).In this discussion, we will use the National Rifle Association (NRA) terminology. Please keep in mind that there are other terms that people use."
  },
  {
    "objectID": "content/lectures/11-cs01-data-slides.html#rtc-laws-contd",
    "href": "content/lectures/11-cs01-data-slides.html#rtc-laws-contd",
    "title": "11-cs01-data",
    "section": "RTC Laws (cont’d)",
    "text": "RTC Laws (cont’d)\n\n\nThe Second Amendment to the United States Constitution guarantees the right to “keep and bear arms”. The amendment was ratified in 1791 as part of the Bill of Rights.\nThere are no federal laws about carrying firearms in public.\nThese laws are created and enforced at the US state level. States vary greatly in their laws about the right to carry firearms.\nSome require extensive effort to obtain a permit to legally carry a firearm, while other states require very minimal effort to do so. An increasing number of states do not require permits at all."
  },
  {
    "objectID": "content/lectures/11-cs01-data-slides.html#rtc-laws-across-the-us",
    "href": "content/lectures/11-cs01-data-slides.html#rtc-laws-across-the-us",
    "title": "11-cs01-data",
    "section": "RTC Laws Across the US",
    "text": "RTC Laws Across the US"
  },
  {
    "objectID": "content/lectures/11-cs01-data-slides.html#rtc-laws-across-the-us-1",
    "href": "content/lectures/11-cs01-data-slides.html#rtc-laws-across-the-us-1",
    "title": "11-cs01-data",
    "section": "RTC Laws Across the US",
    "text": "RTC Laws Across the US"
  },
  {
    "objectID": "content/lectures/11-cs01-data-slides.html#the-data-source",
    "href": "content/lectures/11-cs01-data-slides.html#the-data-source",
    "title": "11-cs01-data",
    "section": "The Data: Source",
    "text": "The Data: Source\nTwo contradictory analyses:\n\nJohn J. Donohue et al., Right‐to‐Carry Laws and Violent Crime: A Comprehensive Assessment Using Panel Data and a State‐Level Synthetic Control Analysis. Journal of Empirical Legal Studies, 16,2 (2019).\nDavid B. Mustard & John Lott. Crime, Deterrence, and Right-to-Carry Concealed Handguns. Coase-Sandor Institute for Law & Economics Working Paper No. 41, (1996)."
  },
  {
    "objectID": "content/lectures/11-cs01-data-slides.html#the-data-1",
    "href": "content/lectures/11-cs01-data-slides.html#the-data-1",
    "title": "11-cs01-data",
    "section": "The Data",
    "text": "The Data"
  },
  {
    "objectID": "content/lectures/11-cs01-data-slides.html#two-analyses",
    "href": "content/lectures/11-cs01-data-slides.html#two-analyses",
    "title": "11-cs01-data",
    "section": "Two Analyses",
    "text": "Two Analyses"
  },
  {
    "objectID": "content/lectures/11-cs01-data-slides.html#limitations",
    "href": "content/lectures/11-cs01-data-slides.html#limitations",
    "title": "11-cs01-data",
    "section": "Limitations",
    "text": "Limitations\n\n\nThe analyses differed in variables used; we will not be recreating either analysis in full\nWe’ll account for either the adoption or lack of adoption of a permissive right-to-carry law in each state; we will not account for differences in the level of permissiveness of the laws.\nRace is included here (as it was in initial analysis); however, any association between demographic variables (indicating the proportion of the population from specific race and age groups) and violent crime does not necessarily indicate that the two are linked causally."
  },
  {
    "objectID": "content/lectures/11-cs01-data-slides.html#packages",
    "href": "content/lectures/11-cs01-data-slides.html#packages",
    "title": "11-cs01-data",
    "section": "Packages",
    "text": "Packages\n\nlibrary(OCSdata) # will need to be installed\nlibrary(tidyverse)\nlibrary(pdftools)\nlibrary(readxl)"
  },
  {
    "objectID": "content/lectures/11-cs01-data-slides.html#raw-data",
    "href": "content/lectures/11-cs01-data-slides.html#raw-data",
    "title": "11-cs01-data",
    "section": "Raw Data",
    "text": "Raw Data\nThere are a whole bunch of different data files we’ll be using…\n\n# only get the data once\nOCSdata::load_raw_data(\"ocs-bp-RTC-wrangling\", outpath = '.')\n\n\ncreates a “data” sub-directory in your current working directory (if it does not already exist)\ncreates a “raw” sub-directory within “data”; contains the directories with the data\n\n👉 Your Turn: Load the data into RStudio. It will take a while…so just let it get started."
  },
  {
    "objectID": "content/lectures/11-cs01-data-slides.html#the-goal",
    "href": "content/lectures/11-cs01-data-slides.html#the-goal",
    "title": "11-cs01-data",
    "section": "The Goal",
    "text": "The Goal\nGet two datasets (Lott, Donohue) that contain demographic, population, police staffing, unemployment, violent crime, RTC, and poverty information at the state level across time.\n\n❓ What would be the tidy way to store these data?"
  },
  {
    "objectID": "content/lectures/11-cs01-data-slides.html#your-turn",
    "href": "content/lectures/11-cs01-data-slides.html#your-turn",
    "title": "11-cs01-data",
    "section": "Your Turn",
    "text": "Your Turn\n🧠 Take a look in one of the data folders, open at least one of the data files to view it, and try to get a sense of the type of information contained within it.\n\n\nPut a green sticky on the front of your computer when you’re done. Put a pink if you want help/have a question."
  },
  {
    "objectID": "content/lectures/11-cs01-data-slides.html#demographic-population-data",
    "href": "content/lectures/11-cs01-data-slides.html#demographic-population-data",
    "title": "11-cs01-data",
    "section": "Demographic & Population Data",
    "text": "Demographic & Population Data\n\nCodeData\n\n\n\ndem_77_79 <- read_csv(\"data/raw/Demographics/Decade_1970/pe-19.csv\", skip = 5)\n\ndem_80_89 <- list.files(recursive = TRUE,\n                  path = \"data/raw/Demographics/Decade_1980\",\n                  pattern = \"*.csv\",\n                  full.names = TRUE) |> \n  purrr::map(~read_csv(., skip=5))\n\ndem_90_99 <- list.files(recursive = TRUE,\n                  path = \"data/raw/Demographics/Decade_1990\",\n                  pattern = \"*.txt\",\n                  full.names = TRUE) |> \n  map(~read_table2(., skip = 14))\n\ndem_00_10 <- list.files(recursive = TRUE,\n                  path = \"data/raw/Demographics/Decade_2000\",\n                  pattern = \"*.csv\",\n                   full.names = TRUE) |> \n   map(~read_csv(.))\n\nSource: US Census Bureau Data\n\n\n\nglimpse(dem_00_10[[1]])\n\nRows: 62,244\nColumns: 21\n$ REGION            <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ DIVISION          <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ STATE             <chr> \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0…\n$ NAME              <chr> \"United States\", \"United States\", \"United States\", \"…\n$ SEX               <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ ORIGIN            <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ RACE              <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ AGEGRP            <dbl> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15…\n$ ESTIMATESBASE2000 <dbl> 281424600, 19176154, 20549855, 20528425, 20218782, 1…\n$ POPESTIMATE2000   <dbl> 282162411, 19178293, 20463852, 20637696, 20294955, 1…\n$ POPESTIMATE2001   <dbl> 284968955, 19298217, 20173362, 20978678, 20456284, 1…\n$ POPESTIMATE2002   <dbl> 287625193, 19429192, 19872417, 21261421, 20610370, 2…\n$ POPESTIMATE2003   <dbl> 290107933, 19592446, 19620851, 21415353, 20797166, 2…\n$ POPESTIMATE2004   <dbl> 292805298, 19785885, 19454237, 21411680, 21102552, 2…\n$ POPESTIMATE2005   <dbl> 295516599, 19917400, 19389067, 21212579, 21486214, 2…\n$ POPESTIMATE2006   <dbl> 298379912, 19938883, 19544688, 21033138, 21807709, 2…\n$ POPESTIMATE2007   <dbl> 301231207, 20125962, 19714611, 20841042, 22067816, 2…\n$ POPESTIMATE2008   <dbl> 304093966, 20271127, 19929602, 20706655, 22210880, 2…\n$ POPESTIMATE2009   <dbl> 306771529, 20244518, 20182499, 20660564, 22192810, 2…\n$ CENSUS2010POP     <dbl> 308745538, 20201362, 20348657, 20677194, 22040343, 2…\n$ POPESTIMATE2010   <dbl> 309349689, 20200529, 20382409, 20694011, 21959087, 2…"
  },
  {
    "objectID": "content/lectures/11-cs01-data-slides.html#state-fips-codes",
    "href": "content/lectures/11-cs01-data-slides.html#state-fips-codes",
    "title": "11-cs01-data",
    "section": "State FIPS Codes",
    "text": "State FIPS Codes\n\nImageCodeDataWrangling\n\n\n\n\n\n\nSTATE_FIPS <- readxl::read_xls(\"data/raw/State_FIPS_codes/state-geocodes-v2014.xls\", skip = 5)\n\n\n\n\nglimpse(STATE_FIPS)\n\nRows: 64\nColumns: 4\n$ Region          <chr> \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\",…\n$ Division        <chr> \"0\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"2\", \"2\", \"2\",…\n$ `State\\n(FIPS)` <chr> \"00\", \"00\", \"09\", \"23\", \"25\", \"33\", \"44\", \"50\", \"00\", …\n$ Name            <chr> \"Northeast Region\", \"New England Division\", \"Connectic…\n\n\n\n\n\nSTATE_FIPS <- STATE_FIPS |>\n  rename(STATEFP = `State\\n(FIPS)`,\n         STATE = Name) |>\n  select(STATEFP, STATE) |>\n  filter(STATEFP != \"00\")\n\nSTATE_FIPS\n\n# A tibble: 51 × 2\n   STATEFP STATE        \n   <chr>   <chr>        \n 1 09      Connecticut  \n 2 23      Maine        \n 3 25      Massachusetts\n 4 33      New Hampshire\n 5 44      Rhode Island \n 6 50      Vermont      \n 7 34      New Jersey   \n 8 36      New York     \n 9 42      Pennsylvania \n10 17      Illinois     \n# … with 41 more rows"
  },
  {
    "objectID": "content/lectures/11-cs01-data-slides.html#police-staffing-data",
    "href": "content/lectures/11-cs01-data-slides.html#police-staffing-data",
    "title": "11-cs01-data",
    "section": "Police Staffing Data",
    "text": "Police Staffing Data\n\nCodeData\n\n\nThere’s an issue currently with the ps_data file from OCS, so we’ll use this file instead:\n\nps_data <- read_csv(\"https://raw.githubusercontent.com/COGS137/datasets/main/pe_1960_2018.csv\")\n\n\n\n\nglimpse(ps_data)\n\nRows: 2,242\nColumns: 3\n$ data_year           <dbl> 1977, 1977, 1977, 1977, 1977, 1977, 1977, 1977, 19…\n$ state_abbr          <chr> \"AK\", \"AL\", \"AR\", \"AS\", \"AZ\", \"CA\", \"CO\", \"CT\", \"C…\n$ officer_state_total <dbl> 544, 7380, 3344, 0, 6414, 65596, 7337, 6051, 0, 47…"
  },
  {
    "objectID": "content/lectures/11-cs01-data-slides.html#unemployment-data",
    "href": "content/lectures/11-cs01-data-slides.html#unemployment-data",
    "title": "11-cs01-data",
    "section": "Unemployment Data",
    "text": "Unemployment Data\n\nImageCodeDataWrangle\n\n\n\n\n\nunemployment\n\n\n\n\n\nue_rate_data <- list.files(recursive = TRUE,\n                          path = \"data/raw/Unemployment\",\n                          pattern = \"*.xlsx\",\n                          full.names = TRUE) |> \nmap(~read_xlsx(., skip = 10))\n\nue_rate_names <- list.files(recursive = TRUE,\n                          path = \"data/raw/Unemployment\",\n                          pattern = \"*.xlsx\",\n                          full.names = TRUE) |>\nmap(~read_xlsx(., range = \"B4:B6\")) |>\n  map(c(1,2)) |>\nunlist()\n\nnames(ue_rate_data) <- ue_rate_names\n\n\n\n\nhead(ue_rate_data)[1]\n\n$Alabama\n# A tibble: 44 × 14\n    Year   Jan   Feb   Mar   Apr   May   Jun   Jul   Aug   Sep   Oct   Nov   Dec\n   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n 1  1977   7.5   9     7.7   7.2   6.8   8.6   8     7.8   6.7   6.3   6.3   6  \n 2  1978   7.1   6.9   6.2   5.4   5.1   6.9   6.7   6.7   6.5   6.3   6.3   6.5\n 3  1979   6.7   7.5   6.9   6.6   6.4   8.4   7.7   7.8   7.1   7.2   6.9   6.7\n 4  1980   7.7   7.8   7.4   7.4   8.4   9.7  10.4  10.3   9.3   9.6   9.4   9  \n 5  1981  10    10.3   9.5   9.1   9.4  11.1  10.4  10.9  10.8  11.7  11.5  11.8\n 6  1982  13.2  13.2  12.9  12.6  12.8  14.5  14.7  14.8  14.7  15.1  15.4  15.3\n 7  1983  16    16    14.5  13.7  13.3  14.6  13.9  13.8  13.2  12.8  12.1  11.8\n 8  1984  12.5  12.4  11.4  10.8  10.1  11.3  11.5  11.3  10.8  10.2   9.7  10.1\n 9  1985  10.7  10.5   9.8   8.7   8.4   9.6   9.2   8.8   8.6   8.6   8.4   8.7\n10  1986   9.3  10.4  10.1   9.4   9.4  10.5   9.7   9.6   9.7   9.7   9.6   9  \n# … with 34 more rows, and 1 more variable: Annual <dbl>\n\n\n\n\n\nue_rate_data <- ue_rate_data |>\n  map_df(bind_rows, .id = \"STATE\") |>\n  select(STATE, Year, Annual) |>\n  rename(\"YEAR\" = Year,\n         \"VALUE\" = Annual) |>\n  mutate(VARIABLE = \"Unemployment_rate\")\n\nue_rate_data\n\n# A tibble: 2,244 × 4\n   STATE    YEAR VALUE VARIABLE         \n   <chr>   <dbl> <dbl> <chr>            \n 1 Alabama  1977   7.3 Unemployment_rate\n 2 Alabama  1978   6.4 Unemployment_rate\n 3 Alabama  1979   7.2 Unemployment_rate\n 4 Alabama  1980   8.9 Unemployment_rate\n 5 Alabama  1981  10.6 Unemployment_rate\n 6 Alabama  1982  14.1 Unemployment_rate\n 7 Alabama  1983  13.8 Unemployment_rate\n 8 Alabama  1984  11   Unemployment_rate\n 9 Alabama  1985   9.2 Unemployment_rate\n10 Alabama  1986   9.7 Unemployment_rate\n# … with 2,234 more rows"
  },
  {
    "objectID": "content/lectures/11-cs01-data-slides.html#poverty-data",
    "href": "content/lectures/11-cs01-data-slides.html#poverty-data",
    "title": "11-cs01-data",
    "section": "Poverty Data",
    "text": "Poverty Data\n\nCodeData\n\n\n\npoverty_rate_data <- read_xls(\"data/raw/Poverty/hstpov21.xls\", skip=2)\n\n\n\n\nhead(poverty_rate_data)\n\n# A tibble: 6 × 6\n  `NOTE: Number in thousands.` ...2  ...3   ...4              ...5         ...6 \n  <chr>                        <chr> <chr>  <chr>             <chr>        <chr>\n1 2018                         <NA>  <NA>    <NA>             <NA>          <NA>\n2 STATE                        Total Number \"Standard\\nerror\" Percent      \"Sta…\n3 Alabama                      4877  779    \"65\"              16           \"1.3\"\n4 Alaska                       720   94     \"9\"               13.1         \"1.2\"\n5 Arizona                      7241  929    \"80\"              12.80000000… \"1.1…\n6 Arkansas                     2912  462    \"38\"              15.9         \"1.3\"\n\n\n\n\n\nSource: US Census Bureau Data"
  },
  {
    "objectID": "content/lectures/11-cs01-data-slides.html#violent-crime-data",
    "href": "content/lectures/11-cs01-data-slides.html#violent-crime-data",
    "title": "11-cs01-data",
    "section": "Violent Crime Data",
    "text": "Violent Crime Data\n\nCodeData\n\n\n\ncrime_data <- read_lines(\"data/raw/Crime/CrimeStatebyState.csv\",\n                         skip = 2, \n                         skip_empty_rows = TRUE)\n\nDue to spaces and / in the column names, read_lines() from the readr package works better than read_csv()\n\n\n\nhead(crime_data)\n\n[1] \"Estimated crime in Alabama\"                                                                                                         \n[2] \",,National or state crime,,,,,,,\"                                                                                                   \n[3] \",,Violent crime,,,,,,,\"                                                                                                             \n[4] \"Year,Population,Violent crime total,Murder and nonnegligent Manslaughter,Legacy rape /1,Revised rape /2,Robbery,Aggravated assault,\"\n[5] \"1977,   3690000,      15293,         524,         929,,       3572,      10268 \"                                                    \n[6] \"1978,   3742000,      15682,         499,         954,,       3708,      10521 \""
  },
  {
    "objectID": "content/lectures/11-cs01-data-slides.html#right-to-carry-data",
    "href": "content/lectures/11-cs01-data-slides.html#right-to-carry-data",
    "title": "11-cs01-data",
    "section": "Right-To-Carry Data",
    "text": "Right-To-Carry Data\n\nCodeData\n\n\n\nDAWpaper <- pdf_text(\"data/raw/w23510.pdf\")\n\n\n\n\nhead(DAWpaper[1])\n\n[1] \"                              NBER WORKING PAPER SERIES\\n\\n\\n\\n                  RIGHT-TO-CARRY LAWS AND VIOLENT CRIME:\\n             A COMPREHENSIVE ASSESSMENT USING PANEL DATA AND\\n                 A STATE-LEVEL SYNTHETIC CONTROL ANALYSIS\\n\\n                                        John J. Donohue\\n                                          Abhay Aneja\\n                                         Kyle D. Weber\\n\\n                                      Working Paper 23510\\n                              http://www.nber.org/papers/w23510\\n\\n\\n                     NATIONAL BUREAU OF ECONOMIC RESEARCH\\n                              1050 Massachusetts Avenue\\n                                 Cambridge, MA 02138\\n                           June 2017, Revised November 2018\\n\\n\\n\\nPreviously circulated as \\\"Right-to-Carry Laws and Violent Crime: A Comprehensive Assessment\\nUsing Panel Data and a State-Level Synthetic Controls Analysis.\\\" We thank Dan Ho, Stefano\\nDellaVigna, Rob Tibshirani, Trevor Hastie, StefanWager, Jeff Strnad, and participants at the\\n2011 Conference of Empirical Legal Studies (CELS), 2012 American Law and Economics\\nAssociation (ALEA) Annual Meeting, 2013 Canadian Law and Economics Association (CLEA)\\nAnnual Meeting, 2015 NBER Summer Institute (Crime), and the Stanford Law School faculty\\nworkshop for their comments and helpful suggestions. Financial support was provided by\\nStanford Law School. We are indebted to Alberto Abadie, Alexis Diamond, and Jens\\nHainmueller for their work developing the synthetic control algorithm and programming the Stata\\nmodule used in this paper and for their helpful comments. The authors would also like to thank\\nAlex Albright, Andrew Baker, Jacob Dorn, Bhargav Gopal, Crystal Huang, Mira Korb, Haksoo\\nLee, Isaac Rabbani, Akshay Rao, Vikram Rao, Henrik Sachs and Sidharth Sah who provided\\nexcellent research assistance, as well as Addis O’Connor and Alex Chekholko at the Research\\nComputing division of Stanford’s Information Technology Services for their technical support.\\nThe views expressed herein are those of the author and do not necessarily reflect the views of the\\nNational Bureau of Economic Research.\\n\\nNBER working papers are circulated for discussion and comment purposes. They have not been\\npeer-reviewed or been subject to the review by the NBER Board of Directors that accompanies\\nofficial NBER publications.\\n\\n© 2017 by John J. Donohue, Abhay Aneja, and Kyle D. Weber. All rights reserved. Short\\nsections of text, not to exceed two paragraphs, may be quoted without explicit permission\\nprovided that full credit, including © notice, is given to the source.\\n\""
  },
  {
    "objectID": "content/lectures/11-cs01-data-slides.html#save-imported-data",
    "href": "content/lectures/11-cs01-data-slides.html#save-imported-data",
    "title": "11-cs01-data",
    "section": "Save (Imported) Data",
    "text": "Save (Imported) Data\n\nsave(dem_77_79, dem_80_89, dem_90_99, dem_00_10, \n     STATE_FIPS, \n     ps_data, \n     ue_rate_data, \n     poverty_rate_data,\n     crime_data,\n     DAWpaper, file = \"data/imported_data_rtc.rda\")"
  },
  {
    "objectID": "content/lectures/11-cs01-data-slides.html#wrangle-demo-data",
    "href": "content/lectures/11-cs01-data-slides.html#wrangle-demo-data",
    "title": "11-cs01-data",
    "section": "Wrangle: Demo Data",
    "text": "Wrangle: Demo Data\n\n77-7980s90s00s\n\n\n\ndem_77_79 <- dem_77_79 |>\n  rename(\"race_sex\" =`Race/Sex Indicator`) |>\n  mutate(SEX = str_extract(race_sex, \"male|female\"),\n        RACE = str_extract(race_sex, \"Black|White|Other\"))|>\n  select(-`FIPS State Code`, -`race_sex`) |>\n  rename(\"YEAR\" = `Year of Estimate`,\n        \"STATE\" = `State Name`) |>\n  filter(YEAR %in% 1977:1979)\n\ndem_77_79 <- dem_77_79 |>\n  pivot_longer(cols=contains(\"years\"),\n               names_to = \"AGE_GROUP\",\n               values_to = \"SUB_POP\")\n\nglimpse(dem_77_79)\n\nRows: 16,524\nColumns: 6\n$ YEAR      <dbl> 1977, 1977, 1977, 1977, 1977, 1977, 1977, 1977, 1977, 1977, …\n$ STATE     <chr> \"Alabama\", \"Alabama\", \"Alabama\", \"Alabama\", \"Alabama\", \"Alab…\n$ SEX       <chr> \"male\", \"male\", \"male\", \"male\", \"male\", \"male\", \"male\", \"mal…\n$ RACE      <chr> \"White\", \"White\", \"White\", \"White\", \"White\", \"White\", \"White…\n$ AGE_GROUP <chr> \"Under 5 years\", \"5 to 9 years\", \"10 to 14 years\", \"15 to 19…\n$ SUB_POP   <dbl> 98814, 113365, 123107, 135343, 126053, 111547, 100674, 81038…\n\n\n\n\n\ndem_80_89 <- dem_80_89 |>\n  map_df(bind_rows)\n\ndem_80_89 <- dem_80_89 |>\n  rename(\"race_sex\" =`Race/Sex Indicator`) |>\n  mutate(SEX = str_extract(race_sex, \"male|female\"),\n        RACE = str_extract(race_sex, \"Black|White|Other\"))|>\n  select( -`race_sex`) |>\n  rename(\"YEAR\" = `Year of Estimate`) |> \n  rename(\"STATEFP_temp\" = \"FIPS State and County Codes\") |>\n  mutate(STATEFP = str_sub(STATEFP_temp, start = 1, end = 2)) |>\n    left_join(STATE_FIPS, by = \"STATEFP\") |>\n  select(-STATEFP)\n\ndem_80_89 <- dem_80_89 |>\n  pivot_longer(cols=contains(\"years\"),\n               names_to = \"AGE_GROUP\",\n               values_to = \"SUB_POP_temp\") |>\n  group_by(YEAR, STATE, AGE_GROUP, SEX, RACE) |>\n  summarize(SUB_POP = sum(SUB_POP_temp), .groups=\"drop\")\n\ndem_80_89\n\n# A tibble: 55,080 × 6\n    YEAR STATE   AGE_GROUP      SEX    RACE  SUB_POP\n   <dbl> <chr>   <chr>          <chr>  <chr>   <dbl>\n 1  1980 Alabama 10 to 14 years female Black   50108\n 2  1980 Alabama 10 to 14 years female Other     805\n 3  1980 Alabama 10 to 14 years female White  109066\n 4  1980 Alabama 10 to 14 years male   Black   50768\n 5  1980 Alabama 10 to 14 years male   Other     826\n 6  1980 Alabama 10 to 14 years male   White  115988\n 7  1980 Alabama 15 to 19 years female Black   58428\n 8  1980 Alabama 15 to 19 years female Other     743\n 9  1980 Alabama 15 to 19 years female White  126783\n10  1980 Alabama 15 to 19 years male   Black   56808\n# … with 55,070 more rows\n\n\n\n\n\ndem_90_99 <- dem_90_99 |>\n  map_df(bind_rows)\n\ncolnames(dem_90_99) <- c(\"YEAR\", \"STATEFP\", \"Age\", \"NH_W_M\", \"NH_W_F\", \"NH_B_M\",\n                         \"NH_B_F\", \"NH_AIAN_M\", \"NH_AIAN_F\", \"NH_API_M\", \"NH_API_F\",\n                         \"H_W_M\", \"H_W_F\", \"H_B_M\", \"H_B_F\", \"H_AIAN_M\", \"H_AIAN_F\",\n                         \"H_API_M\", \"H_API_F\")\n\ndem_90_99 <- dem_90_99 |>\n  drop_na() |>\n  mutate(W_M = NH_W_M + H_W_M, W_F = NH_W_F + H_W_F,\n         B_M = NH_B_M + H_B_M, B_F = NH_B_F + H_B_F,\n         AIAN_M = NH_AIAN_M + H_AIAN_M, AIAN_F = NH_AIAN_F + H_AIAN_F,\n         API_M = NH_API_M + H_API_M, API_F = NH_API_F + H_API_F) |>\n  select(-starts_with(\"NH_\"), -starts_with(\"H_\"))\n\ndem_90_99 <- dem_90_99 |>\n  mutate(AGE_GROUP = cut(Age,\n                         breaks = seq(0,90, by=5),\n                         right = FALSE, labels = pull(distinct(dem_77_79,AGE_GROUP), AGE_GROUP))) |>\n  select(-Age) |>\n  pivot_longer(cols = c(starts_with(\"W_\"),\n                        starts_with(\"B_\"),\n                        starts_with(\"AIAN_\"),\n                        starts_with(\"API_\")),\n               names_to = \"RACE\",\n               values_to = \"SUB_POP_temp\") |>\n  mutate(SEX = case_when(str_detect(RACE, \"_M\") ~ \"Male\",\n                         TRUE ~ \"Female\"),\n         RACE = case_when(str_detect(RACE, \"W_\") ~ \"White\",\n                          str_detect(RACE, \"B_\") ~ \"Black\",\n                          TRUE ~ \"Other\"))\n\ndem_90_99 <- dem_90_99 |>\n  left_join(STATE_FIPS, by = \"STATEFP\") |>\n  select(-STATEFP) |>\n  group_by(YEAR, STATE, AGE_GROUP, SEX, RACE) |>\n  summarize(SUB_POP = sum(SUB_POP_temp), .groups=\"drop\")\n\nglimpse(dem_90_99)\n\nRows: 55,080\nColumns: 6\n$ YEAR      <dbl> 1990, 1990, 1990, 1990, 1990, 1990, 1990, 1990, 1990, 1990, …\n$ STATE     <chr> \"Alabama\", \"Alabama\", \"Alabama\", \"Alabama\", \"Alabama\", \"Alab…\n$ AGE_GROUP <fct> Under 5 years, Under 5 years, Under 5 years, Under 5 years, …\n$ SEX       <chr> \"Female\", \"Female\", \"Female\", \"Male\", \"Male\", \"Male\", \"Femal…\n$ RACE      <chr> \"Black\", \"Other\", \"White\", \"Black\", \"Other\", \"White\", \"Black…\n$ SUB_POP   <dbl> 45377, 1406, 92380, 46635, 1360, 98524, 46067, 1698, 92530, …\n\n\n\n\n\ndem_00_10 <- dem_00_10 |>\n  map_df(bind_rows)\n\ndem_00_10 <- dem_00_10 |>\n  select(-ESTIMATESBASE2000,-CENSUS2010POP) |>\n  filter(NAME != \"United States\",\n         SEX != 0,\n         RACE != 0,\n         AGEGRP != 0, \n         ORIGIN == 0) |>\n  select(-REGION, -DIVISION, -ORIGIN, -STATE) |>\n  rename(\"STATE\" = NAME,\n         \"AGE_GROUP\" = AGEGRP)\n\ndem_00_10 <- dem_00_10 |>\n  mutate(SEX = factor(SEX, levels = 1:2, labels = c(\"Male\", \"Female\")),\n         RACE = factor(RACE, levels = 1:6, labels = c(\"White\", \"Black\", rep(\"Other\",4))),\n         AGE_GROUP = factor(AGE_GROUP, levels = 1:18,\n                            labels = pull(distinct(dem_77_79,AGE_GROUP), AGE_GROUP)))\n\ndem_00_10 <- dem_00_10 |>\n  pivot_longer(cols=contains(\"ESTIMATE\"), names_to = \"YEAR\", values_to = \"SUB_POP_temp\") |>\n   mutate(YEAR = str_sub(YEAR, start=-4),\n          YEAR = as.numeric(YEAR)) |> \n  group_by(YEAR, AGE_GROUP, STATE, SEX, RACE) |>\n  summarize(SUB_POP = sum(SUB_POP_temp), .groups = \"drop\")\n                            \nglimpse(dem_00_10)\n\nRows: 60,588\nColumns: 6\n$ YEAR      <dbl> 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, …\n$ AGE_GROUP <fct> Under 5 years, Under 5 years, Under 5 years, Under 5 years, …\n$ STATE     <chr> \"Alabama\", \"Alabama\", \"Alabama\", \"Alabama\", \"Alabama\", \"Alab…\n$ SEX       <fct> Male, Male, Male, Female, Female, Female, Male, Male, Male, …\n$ RACE      <fct> White, Black, Other, White, Black, Other, White, Black, Othe…\n$ SUB_POP   <dbl> 99527, 46595, 4487, 94473, 45672, 4431, 14765, 1039, 8572, 1…"
  },
  {
    "objectID": "content/lectures/11-cs01-data-slides.html#wrangle-population-data",
    "href": "content/lectures/11-cs01-data-slides.html#wrangle-population-data",
    "title": "11-cs01-data",
    "section": "Wrangle: Population Data",
    "text": "Wrangle: Population Data\n\n77-7980s90s00s\n\n\n\npop_77_79 <- dem_77_79 |>\n  group_by(YEAR, STATE) |>\n  summarize(TOT_POP = sum(SUB_POP), .groups = \"drop\") \n\npop_77_79 \n\n# A tibble: 153 × 3\n    YEAR STATE                 TOT_POP\n   <dbl> <chr>                   <dbl>\n 1  1977 Alabama               3782571\n 2  1977 Alaska                 397220\n 3  1977 Arizona               2427296\n 4  1977 Arkansas              2207195\n 5  1977 California           22350332\n 6  1977 Colorado              2696179\n 7  1977 Connecticut           3088745\n 8  1977 Delaware               594815\n 9  1977 District of Columbia   681766\n10  1977 Florida               8888806\n# … with 143 more rows\n\n\n\n\n\npop_80_89 <- dem_80_89 |>\n  group_by(YEAR, STATE) |>\n  summarize(TOT_POP = sum(SUB_POP), .groups = \"drop\") \n\n\n\n\npop_90_99 <- dem_90_99 |>\n  group_by(YEAR, STATE) |>\n  summarize(TOT_POP = sum(SUB_POP), .groups = \"drop\")\n\n\n\n\npop_00_10 <- dem_00_10 |>\n  group_by(YEAR, STATE) |>\n  summarize(TOT_POP = sum(SUB_POP), .groups = \"drop\")"
  },
  {
    "objectID": "content/lectures/11-cs01-data-slides.html#combine-demo-population",
    "href": "content/lectures/11-cs01-data-slides.html#combine-demo-population",
    "title": "11-cs01-data",
    "section": "Combine: Demo + Population",
    "text": "Combine: Demo + Population\n\n77-7980s90s00sIdea\n\n\n\ndem_77_79 <- dem_77_79 |>\n  left_join(pop_77_79, by = c(\"YEAR\", \"STATE\")) |> \n  mutate(PERC_SUB_POP = (SUB_POP/TOT_POP)*100) |>\n  select(-SUB_POP, -TOT_POP) |>\n  mutate(SEX = str_to_title(SEX))\n\n\ndem_77_79\n\n# A tibble: 16,524 × 6\n    YEAR STATE   SEX   RACE  AGE_GROUP      PERC_SUB_POP\n   <dbl> <chr>   <chr> <chr> <chr>                 <dbl>\n 1  1977 Alabama Male  White Under 5 years          2.61\n 2  1977 Alabama Male  White 5 to 9 years           3.00\n 3  1977 Alabama Male  White 10 to 14 years         3.25\n 4  1977 Alabama Male  White 15 to 19 years         3.58\n 5  1977 Alabama Male  White 20 to 24 years         3.33\n 6  1977 Alabama Male  White 25 to 29 years         2.95\n 7  1977 Alabama Male  White 30 to 34 years         2.66\n 8  1977 Alabama Male  White 35 to 39 years         2.14\n 9  1977 Alabama Male  White 40 to 44 years         1.98\n10  1977 Alabama Male  White 45 to 49 years         2.02\n# … with 16,514 more rows\n\n\n\n\n\ndem_80_89 <- dem_80_89 |>\n  left_join(pop_80_89, by = c(\"YEAR\", \"STATE\")) |>\n  mutate(PERC_SUB_POP = (SUB_POP/TOT_POP)*100) |>\n  select(-SUB_POP, -TOT_POP) |>\n  mutate(SEX = str_to_title(SEX))\n\n\n\n\ndem_90_99 <- dem_90_99 |>\n  left_join(pop_90_99, by = c(\"YEAR\", \"STATE\")) |>\n  mutate(PERC_SUB_POP = (SUB_POP/TOT_POP)*100) |>\n  select(-SUB_POP, -TOT_POP)\n\ndem_90_99\n\n# A tibble: 55,080 × 6\n    YEAR STATE   AGE_GROUP     SEX    RACE  PERC_SUB_POP\n   <dbl> <chr>   <fct>         <chr>  <chr>        <dbl>\n 1  1990 Alabama Under 5 years Female Black       1.12  \n 2  1990 Alabama Under 5 years Female Other       0.0347\n 3  1990 Alabama Under 5 years Female White       2.28  \n 4  1990 Alabama Under 5 years Male   Black       1.15  \n 5  1990 Alabama Under 5 years Male   Other       0.0336\n 6  1990 Alabama Under 5 years Male   White       2.43  \n 7  1990 Alabama 5 to 9 years  Female Black       1.14  \n 8  1990 Alabama 5 to 9 years  Female Other       0.0419\n 9  1990 Alabama 5 to 9 years  Female White       2.29  \n10  1990 Alabama 5 to 9 years  Male   Black       1.16  \n# … with 55,070 more rows\n\n\n\n\n\ndem_00_10 <- dem_00_10 |>\n  left_join(pop_00_10, by = c(\"YEAR\", \"STATE\")) |>\n  mutate(PERC_SUB_POP = (SUB_POP/TOT_POP)*100) |>\n  select(-SUB_POP, -TOT_POP)\n\ndem_00_10\n\n# A tibble: 60,588 × 6\n    YEAR AGE_GROUP     STATE   SEX    RACE  PERC_SUB_POP\n   <dbl> <fct>         <chr>   <fct>  <fct>        <dbl>\n 1  2000 Under 5 years Alabama Male   White       2.24  \n 2  2000 Under 5 years Alabama Male   Black       1.05  \n 3  2000 Under 5 years Alabama Male   Other       0.101 \n 4  2000 Under 5 years Alabama Female White       2.12  \n 5  2000 Under 5 years Alabama Female Black       1.03  \n 6  2000 Under 5 years Alabama Female Other       0.0995\n 7  2000 Under 5 years Alaska  Male   White       2.35  \n 8  2000 Under 5 years Alaska  Male   Black       0.165 \n 9  2000 Under 5 years Alaska  Male   Other       1.37  \n10  2000 Under 5 years Alaska  Female White       2.26  \n# … with 60,578 more rows\n\n\n\n\n❗ This would be a good part of the code to write a user-defined function…"
  },
  {
    "objectID": "content/lectures/11-cs01-data-slides.html#aside-udf",
    "href": "content/lectures/11-cs01-data-slides.html#aside-udf",
    "title": "11-cs01-data",
    "section": "Aside: UDF",
    "text": "Aside: UDF\n\nThe WhatThe HowExampleUsing the function\n\n\n\nUser-defined functions (UDFs) are functions you write to make your code cleaner\nAny time you copy+paste very similar code, think to yourself…I should make this a function!\n\n\n\nThe general syntax for a function in R is:\n\nfunction_name <- function(parameters){\n  # code to carry out\n  # using the parameters\n}\n\nNote: by default the last object created within the function is returned from the function\n\n\n\ncombine_demo_pop <- function(df_dem, df_pop){\n  df_dem <- df_dem |>\n  group_by(YEAR, STATE) |>\n  summarize(TOT_POP = sum(SUB_POP), .groups = \"drop\")\n  \n  df_dem |>\n  left_join(df_pop, by = c(\"YEAR\", \"STATE\")) |>\n  mutate(PERC_SUB_POP = (SUB_POP/TOT_POP)*100) |>\n  select(-SUB_POP, -TOT_POP) |>\n  mutate(SEX = str_to_title(SEX))\n}\n\n\n\n\ncombined_df <- combine_demo_pop(dem_00_10, pop_00_10)\n\n\nNote: if you’ve already combined the data into dem_00_10, this would not work.\nCleaning up/improving code in your case studies is encouraged!"
  },
  {
    "objectID": "content/lectures/11-cs01-data-slides.html#combine-demopop-across-decades",
    "href": "content/lectures/11-cs01-data-slides.html#combine-demopop-across-decades",
    "title": "11-cs01-data",
    "section": "Combine: Demo/Pop Across Decades",
    "text": "Combine: Demo/Pop Across Decades\n\ndem <- bind_rows(dem_77_79,\n                 dem_80_89,\n                 dem_90_99,\n                 dem_00_10)\n\nglimpse(dem)\n\nRows: 187,272\nColumns: 6\n$ YEAR         <dbl> 1977, 1977, 1977, 1977, 1977, 1977, 1977, 1977, 1977, 197…\n$ STATE        <chr> \"Alabama\", \"Alabama\", \"Alabama\", \"Alabama\", \"Alabama\", \"A…\n$ SEX          <chr> \"Male\", \"Male\", \"Male\", \"Male\", \"Male\", \"Male\", \"Male\", \"…\n$ RACE         <chr> \"White\", \"White\", \"White\", \"White\", \"White\", \"White\", \"Wh…\n$ AGE_GROUP    <chr> \"Under 5 years\", \"5 to 9 years\", \"10 to 14 years\", \"15 to…\n$ PERC_SUB_POP <dbl> 2.6123502, 2.9970356, 3.2545853, 3.5780690, 3.3324688, 2.…"
  },
  {
    "objectID": "content/lectures/11-cs01-data-slides.html#demographic-data-donohue",
    "href": "content/lectures/11-cs01-data-slides.html#demographic-data-donohue",
    "title": "11-cs01-data",
    "section": "Demographic Data (Donohue)",
    "text": "Demographic Data (Donohue)\n\nDONOHUE_AGE_GROUPS <- c(\"15 to 19 years\",\n                        \"20 to 24 years\",\n                        \"25 to 29 years\",\n                        \"30 to 34 years\",\n                        \"35 to 39 years\")\n\ndem_DONOHUE <- dem |>\n  filter(AGE_GROUP %in% DONOHUE_AGE_GROUPS,\n               SEX == \"Male\") |>\n  mutate(AGE_GROUP = fct_collapse(AGE_GROUP, \"20 to 39 years\"=c(\"20 to 24 years\",\n                                                                \"25 to 29 years\",\n                                                                \"30 to 34 years\",\n                                                                \"35 to 39 years\")),\n         AGE_GROUP = str_replace_all(string = AGE_GROUP, \n                                     pattern = \" \", \n                                     replacement = \"_\")) |>\n  group_by(YEAR, STATE, RACE, SEX, AGE_GROUP) |>\n  summarize(PERC_SUB_POP = sum(PERC_SUB_POP), .groups = \"drop\") |>\n  unite(col = \"VARIABLE\", RACE, SEX, AGE_GROUP, sep = \"_\") |>\n  rename(\"VALUE\" = PERC_SUB_POP)\n\ndem_DONOHUE\n\n# A tibble: 10,404 × 4\n    YEAR STATE   VARIABLE                    VALUE\n   <dbl> <chr>   <chr>                       <dbl>\n 1  1977 Alabama Black_Male_15_to_19_years  1.55  \n 2  1977 Alabama Black_Male_20_to_39_years  3.04  \n 3  1977 Alabama Other_Male_15_to_19_years  0.0178\n 4  1977 Alabama Other_Male_20_to_39_years  0.0642\n 5  1977 Alabama White_Male_15_to_19_years  3.58  \n 6  1977 Alabama White_Male_20_to_39_years 11.1   \n 7  1977 Alaska  Black_Male_15_to_19_years  0.163 \n 8  1977 Alaska  Black_Male_20_to_39_years  0.968 \n 9  1977 Alaska  Other_Male_15_to_19_years  1.12  \n10  1977 Alaska  Other_Male_20_to_39_years  2.73  \n# … with 10,394 more rows"
  },
  {
    "objectID": "content/lectures/11-cs01-data-slides.html#demographic-data-lott",
    "href": "content/lectures/11-cs01-data-slides.html#demographic-data-lott",
    "title": "11-cs01-data",
    "section": "Demographic Data (Lott)",
    "text": "Demographic Data (Lott)\n\nLOTT_AGE_GROUPS_NULL <- c(\"Under 5 years\",\n                          \"5 to 9 years\")\n\ndem_LOTT <- dem |>\n  filter(!(AGE_GROUP %in% LOTT_AGE_GROUPS_NULL) )|>\n  mutate(AGE_GROUP = fct_collapse(AGE_GROUP,\n                                  \"10 to 19 years\"=c(\"10 to 14 years\", \"15 to 19 years\"),\n                                  \"20 to 29 years\"=c(\"20 to 24 years\", \"25 to 29 years\"),\n                                  \"30 to 39 years\"=c(\"30 to 34 years\", \"35 to 39 years\"),\n                                  \"40 to 49 years\"=c(\"40 to 44 years\", \"45 to 49 years\"),\n                                  \"50 to 64 years\"=c(\"50 to 54 years\", \"55 to 59 years\",\n                                                     \"60 to 64 years\"),\n                                  \"65 years and over\"=c(\"65 to 69 years\", \"70 to 74 years\", \n                                                        \"75 to 79 years\", \"80 to 84 years\",\n                                                        \"85 years and over\")),\n         AGE_GROUP = str_replace_all(AGE_GROUP, \" \", \"_\")) |>\n  group_by(YEAR, STATE, RACE, SEX, AGE_GROUP) |>\n  summarize(PERC_SUB_POP = sum(PERC_SUB_POP), .groups = \"drop\") |>\n  unite(col = \"VARIABLE\", RACE, SEX, AGE_GROUP, sep = \"_\") |>\n  rename(\"VALUE\" = PERC_SUB_POP)\n\nglimpse(dem_LOTT)\n\nRows: 62,424\nColumns: 4\n$ YEAR     <dbl> 1977, 1977, 1977, 1977, 1977, 1977, 1977, 1977, 1977, 1977, 1…\n$ STATE    <chr> \"Alabama\", \"Alabama\", \"Alabama\", \"Alabama\", \"Alabama\", \"Alaba…\n$ VARIABLE <chr> \"Black_Female_10_to_19_years\", \"Black_Female_20_to_29_years\",…\n$ VALUE    <dbl> 3.01067713, 2.32860137, 1.29295656, 1.18231753, 1.73263106, 1…"
  },
  {
    "objectID": "content/lectures/11-cs01-data-slides.html#combine-population-data",
    "href": "content/lectures/11-cs01-data-slides.html#combine-population-data",
    "title": "11-cs01-data",
    "section": "Combine: Population Data",
    "text": "Combine: Population Data\n\npopulation_data <- bind_rows(pop_77_79,\n                             pop_80_89,\n                             pop_90_99,\n                             pop_00_10)\n\npopulation_data <- population_data |>\n  mutate(VARIABLE = \"Population\") |>\n  rename(\"VALUE\" = TOT_POP)"
  },
  {
    "objectID": "content/lectures/11-cs01-data-slides.html#wrangling-police-staffing",
    "href": "content/lectures/11-cs01-data-slides.html#wrangling-police-staffing",
    "title": "11-cs01-data",
    "section": "Wrangling: Police staffing",
    "text": "Wrangling: Police staffing\n\n# the provided dataset has already had a bit of wrangling done for you\nps_data\n\n# A tibble: 2,242 × 3\n   data_year state_abbr officer_state_total\n       <dbl> <chr>                    <dbl>\n 1      1977 AK                         544\n 2      1977 AL                        7380\n 3      1977 AR                        3344\n 4      1977 AS                           0\n 5      1977 AZ                        6414\n 6      1977 CA                       65596\n 7      1977 CO                        7337\n 8      1977 CT                        6051\n 9      1977 CZ                           0\n10      1977 DC                        4751\n# … with 2,232 more rows\n\n\n\nremove territories\n\nstate_of_interest_NULL <- c(\"AS\", \"GM\", \"CZ\", \"FS\", \"MP\", \"OT\", \"PR\", \"VI\")\n\nps_data <- ps_data |>\n  filter(!(state_abbr %in% state_of_interest_NULL)) \n\nUse state abbreviations\n\nstate_abb_data <- tibble(\"state_abbr\" = state.abb, \"STATE\" = state.name)\nstate_abb_data <- state_abb_data |>\n  mutate(state_abbr = str_replace(string = state_abbr, \n                                  pattern = \"NE\", \n                                  replacement = \"NB\")) |>\n  add_row(state_abbr = \"DC\", STATE = \"District of Columbia\")\n\nps_data <- ps_data |> \n  left_join(state_abb_data, by = \"state_abbr\") |>\n  select(-state_abbr) |> \n  rename(YEAR = \"data_year\",\n         VALUE = \"officer_state_total\") |>\n  mutate(VARIABLE = \"officer_state_total\")\n\nps_data\n\n# A tibble: 1,938 × 4\n    YEAR VALUE STATE                VARIABLE           \n   <dbl> <dbl> <chr>                <chr>              \n 1  1977   544 Alaska               officer_state_total\n 2  1977  7380 Alabama              officer_state_total\n 3  1977  3344 Arkansas             officer_state_total\n 4  1977  6414 Arizona              officer_state_total\n 5  1977 65596 California           officer_state_total\n 6  1977  7337 Colorado             officer_state_total\n 7  1977  6051 Connecticut          officer_state_total\n 8  1977  4751 District of Columbia officer_state_total\n 9  1977  1018 Delaware             officer_state_total\n10  1977 24588 Florida              officer_state_total\n# … with 1,928 more rows\n\n\nScaling\n\ndenominator_temp <- population_data |> \n  select(-VARIABLE) |>\n  rename(\"Population_temp\"=VALUE) \n\nps_data <- ps_data |> \n  left_join(denominator_temp, by=c(\"STATE\",\"YEAR\")) |>\n  mutate(VALUE = (VALUE * 100000) / Population_temp) |>\n  mutate(VARIABLE = \"police_per_100k_lag\") |>\n  select(-Population_temp)\n\nhead(ps_data)\n\n# A tibble: 6 × 4\n   YEAR VALUE STATE      VARIABLE           \n  <dbl> <dbl> <chr>      <chr>              \n1  1977  137. Alaska     police_per_100k_lag\n2  1977  195. Alabama    police_per_100k_lag\n3  1977  152. Arkansas   police_per_100k_lag\n4  1977  264. Arizona    police_per_100k_lag\n5  1977  293. California police_per_100k_lag\n6  1977  272. Colorado   police_per_100k_lag"
  },
  {
    "objectID": "content/lectures/11-cs01-data-slides.html#wrangling-poverty-rate",
    "href": "content/lectures/11-cs01-data-slides.html#wrangling-poverty-rate",
    "title": "11-cs01-data",
    "section": "Wrangling: Poverty Rate",
    "text": "Wrangling: Poverty Rate\n\n\n# A tibble: 5 × 6\n  `NOTE: Number in thousands.` ...2  ...3   ...4              ...5         ...6 \n  <chr>                        <chr> <chr>  <chr>             <chr>        <chr>\n1 2018                         <NA>  <NA>    <NA>             <NA>          <NA>\n2 STATE                        Total Number \"Standard\\nerror\" Percent      \"Sta…\n3 Alabama                      4877  779    \"65\"              16           \"1.3\"\n4 Alaska                       720   94     \"9\"               13.1         \"1.2\"\n5 Arizona                      7241  929    \"80\"              12.80000000… \"1.1…\n\n\n\n\ncolnames(poverty_rate_data) <- c(\"STATE\", \"Total\", \"Number\", \"Number_se\",\n                                 \"Percent\", \"Percent_se\")\n\npoverty_rate_data <- poverty_rate_data |>\n  filter(STATE != \"STATE\") |> \n  mutate(length_state = map_dbl(STATE, str_length)) |> # determine how long string in \"STATE\" column is\n  filter(length_state < 100) |> # filter to only include possible state lengths\n  mutate(STATE = str_replace(STATE, pattern = \"D.C.\", \n                              replacement = \"District of Columbia\" )) \n\nyear_values <- poverty_rate_data |>\n  filter(str_detect(STATE, \"[:digit:]\")) |>\n  distinct(STATE)\nyear_values <- rep(pull(year_values, STATE), each = 52) # repeat values from STATE column 52 times each\n\npoverty_rate_data <- poverty_rate_data |>\n  mutate(year_value = year_values) |>\n  select(-length_state) |>\n  filter(str_detect(STATE, \"[:alpha:]\"))\n\npoverty_rate_data <- poverty_rate_data |>\n  filter(year_value != \"2017\") |> \n  filter(year_value != \"2013 (18)\") |>\n  mutate(YEAR = str_sub(year_value, start = 1, end = 4)) |>\n  select(-c(Number, Number_se, Percent_se, Total, year_value)) |>\n  rename(\"VALUE\" = Percent) |>\n  mutate(VARIABLE = \"Poverty_rate\",\n         YEAR = as.numeric(YEAR),\n         VALUE = as.numeric(VALUE))\n\npoverty_rate_data\n\n# A tibble: 1,989 × 4\n   STATE                VALUE  YEAR VARIABLE    \n   <chr>                <dbl> <dbl> <chr>       \n 1 Alabama               16    2018 Poverty_rate\n 2 Alaska                13.1  2018 Poverty_rate\n 3 Arizona               12.8  2018 Poverty_rate\n 4 Arkansas              15.9  2018 Poverty_rate\n 5 California            11.9  2018 Poverty_rate\n 6 Colorado               9.1  2018 Poverty_rate\n 7 Connecticut           10.2  2018 Poverty_rate\n 8 Delaware               7.4  2018 Poverty_rate\n 9 District of Columbia  14.7  2018 Poverty_rate\n10 Florida               13.7  2018 Poverty_rate\n# … with 1,979 more rows"
  },
  {
    "objectID": "content/lectures/11-cs01-data-slides.html#wrangling-crime-data",
    "href": "content/lectures/11-cs01-data-slides.html#wrangling-crime-data",
    "title": "11-cs01-data",
    "section": "Wrangling: Crime Data",
    "text": "Wrangling: Crime Data\n\ncrime_data <- crime_data[-((str_which(crime_data, \"The figures shown in this column for the offense of rape were estimated using the legacy UCR definition of rape\")-1): length(crime_data)+1)]\n\nn_rows <- 2014-1977+1 # determine how many rows there are for each state\nrep_cycle <- 4 + n_rows\nrep_cycle_cut <- 2 + n_rows\ncolnames_crime <- (crime_data[4])\n\n# specify which rows are to be deleted based on the file format\ndelete_rows <- c(seq(from = 2, \n                       to = length(crime_data),  \n                       by = rep_cycle),\n                 seq(from = 3, \n                       to = length(crime_data),\n                       by = rep_cycle), \n                 seq(from = 4,\n                       to = length(crime_data),\n                       by = rep_cycle))\nsort(delete_rows) # which rows are to be deleted\n\n  [1]    2    3    4   44   45   46   86   87   88  128  129  130  170  171  172\n [16]  212  213  214  254  255  256  296  297  298  338  339  340  380  381  382\n [31]  422  423  424  464  465  466  506  507  508  548  549  550  590  591  592\n [46]  632  633  634  674  675  676  716  717  718  758  759  760  800  801  802\n [61]  842  843  844  884  885  886  926  927  928  968  969  970 1010 1011 1012\n [76] 1052 1053 1054 1094 1095 1096 1136 1137 1138 1178 1179 1180 1220 1221 1222\n [91] 1262 1263 1264 1304 1305 1306 1346 1347 1348 1388 1389 1390 1430 1431 1432\n[106] 1472 1473 1474 1514 1515 1516 1556 1557 1558 1598 1599 1600 1640 1641 1642\n[121] 1682 1683 1684 1724 1725 1726 1766 1767 1768 1808 1809 1810 1850 1851 1852\n[136] 1892 1893 1894 1934 1935 1936 1976 1977 1978 2018 2019 2020 2060 2061 2062\n[151] 2102 2103 2104\n\n# convince yourself you did it right\n# should these rows be deleted?\ncrime_data[44:46]\n\n[1] \",,National or state crime,,,,,,,\"                                                                                                   \n[2] \",,Violent crime,,,,,,,\"                                                                                                             \n[3] \"Year,Population,Violent crime total,Murder and nonnegligent Manslaughter,Legacy rape /1,Revised rape /2,Robbery,Aggravated assault,\"\n\ncrime_data <- crime_data[-delete_rows]\n\n# extract state labels from data\nstate_labels <- crime_data[str_which(crime_data, \"Estimated crime in \")]\nstate_labels <- str_remove(state_labels, pattern = \"Estimated crime in \")\nstate_label_order <- rep(state_labels, each = n_rows) # repeat n_rows times\n\ncrime_data <- crime_data[-str_which(crime_data, \"Estimated crime\")]\ncrime_data_sep <- read_csv(I(crime_data), col_names = FALSE) |> \n  select(-X6) # remove random extra-comma column\n\n# get column names for later\ncolnames(crime_data_sep) <- c(\"Year\", \n                              \"Population\", \n                              \"Violent_crime_total\",\n                              \"Murder_and_nonnegligent_Manslaughter\",\n                              \"Legacy_rape\",\n                              \"Revised_rape\", \n                              \"Robbery\",\n                              \"Aggravated_assault\")\n# add column names in\ncrime_data_sep <- bind_cols(STATE = state_label_order, crime_data_sep)\n\ncrime_data <- crime_data_sep |>\n  mutate(VARIABLE = \"Viol_crime_count\") |>\n  rename(\"VALUE\" = Violent_crime_total) |>\n  rename(\"YEAR\" = Year) |>\n  select(YEAR,STATE, VARIABLE, VALUE)\n\ncrime_data\n\n# A tibble: 1,938 × 4\n    YEAR STATE   VARIABLE         VALUE\n   <dbl> <chr>   <chr>            <dbl>\n 1  1977 Alabama Viol_crime_count 15293\n 2  1978 Alabama Viol_crime_count 15682\n 3  1979 Alabama Viol_crime_count 15578\n 4  1980 Alabama Viol_crime_count 17320\n 5  1981 Alabama Viol_crime_count 18423\n 6  1982 Alabama Viol_crime_count 17653\n 7  1983 Alabama Viol_crime_count 16471\n 8  1984 Alabama Viol_crime_count 17204\n 9  1985 Alabama Viol_crime_count 18398\n10  1986 Alabama Viol_crime_count 22616\n# … with 1,928 more rows"
  },
  {
    "objectID": "content/lectures/11-cs01-data-slides.html#wrangling-rtc-laws",
    "href": "content/lectures/11-cs01-data-slides.html#wrangling-rtc-laws",
    "title": "11-cs01-data",
    "section": "Wrangling: RTC Laws",
    "text": "Wrangling: RTC Laws\n\nDAWpaper_p_62 <- DAWpaper[[62]]\nstr(DAWpaper_p_62, nchar.max = 1000) # see data\n\n chr \"                                          Table A1: RTC Adoption Dates\\n\\n         State         Effective Date of RTC Law   Fraction of Year In Effect Year of Passage   RTC Date (Synthetic Controls Analysis)\\n      Alabama                      1975                                                                        1975\\n       Alaska                   10/1/1994                            0.252                                     1995\\n       Arizona                  7/17/1994                            0.460                                     1995\\n      Arkansas                  7/27/1995                            0.433                                     1996\\n     California                    N/A                                                                            0\\n      Colorado                  5/17/2003                            0.627                                     2003\\n    Connecticut                    1970                                \"| __truncated__\n\np_62 <- DAWpaper_p_62 |>\n  str_split(\"\\n\") |>\n  unlist() |>\n  as_tibble() |>\n  slice(-(1:2)) |> \n  rename(RTC = value) |>\n  slice(-c(53:54)) |>  # physical page 60 marking; empty line removal\n  mutate(RTC = str_replace_all(RTC, \"\\\\s{40,}\", \"|N/A|\"),\n         RTC = str_trim(RTC, side = \"left\"),\n         RTC = str_replace_all(RTC, \"\\\\s{2,15}\", \"|\"))\n\nhead(p_62)\n\n# A tibble: 6 × 1\n  RTC                                                                           \n  <chr>                                                                         \n1 State|Effective Date of RTC Law|Fraction of Year In Effect Year of Passage|RT…\n2 Alabama||1975|N/A|1975                                                        \n3 Alaska||10/1/1994||0.252|||1995                                               \n4 Arizona||7/17/1994||0.460|||1995                                              \n5 Arkansas||7/27/1995||0.433|||1996                                             \n6 California||N/A|N/A|0                                                         \n\np_62 <- pull(p_62, RTC) |>\n  str_split( \"\\\\|{1,}\")  # split data on \"|\" symbol\n\n# get the tibble!\np_62 <- as_tibble(do.call(rbind, p_62)) # rbind and not bind_cols here b/c we have no column names yet\n\ncolnames(p_62) <- c(\"STATE\",\n                    \"E_Date_RTC\",\n                    \"Frac_Yr_Eff_Yr_Pass\",\n                    \"RTC_Date_SA\")\n\np_62 <- p_62 |>\n  slice(-c(1, 53:nrow(p_62))) # remove unnecessary rows\n\nRTC <- p_62 |> \n  select(STATE, RTC_Date_SA) |>\n  rename(RTC_LAW_YEAR = RTC_Date_SA) |>\n  mutate(RTC_LAW_YEAR = as.numeric(RTC_LAW_YEAR)) |>\n  mutate(RTC_LAW_YEAR = case_when(RTC_LAW_YEAR == 0 ~ Inf,\n                                  TRUE ~ RTC_LAW_YEAR))"
  },
  {
    "objectID": "content/lectures/11-cs01-data-slides.html#wrangling-combining-donohue",
    "href": "content/lectures/11-cs01-data-slides.html#wrangling-combining-donohue",
    "title": "11-cs01-data",
    "section": "Wrangling: Combining! (Donohue)",
    "text": "Wrangling: Combining! (Donohue)\n\n# combine after all that wrangling!\nDONOHUE_DF <- bind_rows(dem_DONOHUE,\n                        ue_rate_data,\n                        poverty_rate_data,\n                        crime_data,\n                        population_data,\n                        ps_data)\nDONOHUE_DF\n\n# A tibble: 20,247 × 4\n    YEAR STATE   VARIABLE                    VALUE\n   <dbl> <chr>   <chr>                       <dbl>\n 1  1977 Alabama Black_Male_15_to_19_years  1.55  \n 2  1977 Alabama Black_Male_20_to_39_years  3.04  \n 3  1977 Alabama Other_Male_15_to_19_years  0.0178\n 4  1977 Alabama Other_Male_20_to_39_years  0.0642\n 5  1977 Alabama White_Male_15_to_19_years  3.58  \n 6  1977 Alabama White_Male_20_to_39_years 11.1   \n 7  1977 Alaska  Black_Male_15_to_19_years  0.163 \n 8  1977 Alaska  Black_Male_20_to_39_years  0.968 \n 9  1977 Alaska  Other_Male_15_to_19_years  1.12  \n10  1977 Alaska  Other_Male_20_to_39_years  2.73  \n# … with 20,237 more rows\n\n# to wide format!\nDONOHUE_DF <- DONOHUE_DF |>\n  pivot_wider(names_from = \"VARIABLE\",\n              values_from = \"VALUE\")\n\n# add in RTC data!\nDONOHUE_DF <- DONOHUE_DF |>\n  left_join(RTC , by = c(\"STATE\")) |>\n  mutate(RTC_LAW = case_when(YEAR >= RTC_LAW_YEAR ~ TRUE,\n                              TRUE ~ FALSE)) |>\n drop_na() # drop rows with missing information\n\n# filter to only data where RTC laws were adopted between 1980-2010\n# have crime data pre- and post-adoption this way\nbaseline_year <- min(DONOHUE_DF$YEAR)\ncensoring_year <- max(DONOHUE_DF$YEAR)\n\nDONOHUE_DF <- DONOHUE_DF |>\n  mutate(TIME_0 = baseline_year,\n         TIME_INF = censoring_year) |>\n  filter(RTC_LAW_YEAR > TIME_0)\n\n# calculate violent crime rate; put population/crime on log scale\nDONOHUE_DF <- DONOHUE_DF |>\n  mutate(Viol_crime_rate_1k = (Viol_crime_count*1000)/Population,\n         Viol_crime_rate_1k_log = log(Viol_crime_rate_1k),\n         Population_log = log(Population))\n\nDONOHUE_DF |>\n  slice_sample(n = 10) |>\n  glimpse()\n\nRows: 10\nColumns: 20\n$ YEAR                      <dbl> 2009, 1986, 1992, 1981, 1990, 1983, 2005, 19…\n$ STATE                     <chr> \"Minnesota\", \"California\", \"Kentucky\", \"Nebr…\n$ Black_Male_15_to_19_years <dbl> 0.2548472, 0.3455360, 0.3533476, 0.1863184, …\n$ Black_Male_20_to_39_years <dbl> 0.8633071, 1.5016507, 1.1550816, 0.4942727, …\n$ Other_Male_15_to_19_years <dbl> 0.37353232, 0.40635016, 0.02944341, 0.060691…\n$ Other_Male_20_to_39_years <dbl> 1.1702258, 1.7399484, 0.1288748, 0.2036768, …\n$ White_Male_15_to_19_years <dbl> 2.993011, 3.162248, 3.439502, 4.201508, 3.04…\n$ White_Male_20_to_39_years <dbl> 11.40734, 15.82407, 14.28975, 15.18530, 12.1…\n$ Unemployment_rate         <dbl> 7.8, 6.7, 6.9, 4.2, 6.9, 9.9, 4.1, 3.9, 5.5,…\n$ Poverty_rate              <dbl> 11.1, 12.7, 19.7, 14.0, 19.6, 12.6, 10.6, 11…\n$ Viol_crime_count          <dbl> 12874, 248370, 20107, 2861, 12511, 2940, 146…\n$ Population                <dbl> 5281203, 27102241, 3756358, 1578481, 2354343…\n$ police_per_100k_lag       <dbl> 262.1372, 279.8772, 236.6654, 179.8565, 228.…\n$ RTC_LAW_YEAR              <dbl> 2003, Inf, 1997, 2007, 1996, 1995, 1996, 200…\n$ RTC_LAW                   <lgl> TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, TRU…\n$ TIME_0                    <dbl> 1980, 1980, 1980, 1980, 1980, 1980, 1980, 19…\n$ TIME_INF                  <dbl> 2010, 2010, 2010, 2010, 2010, 2010, 2010, 20…\n$ Viol_crime_rate_1k        <dbl> 2.437702, 9.164187, 5.352791, 1.812502, 5.31…\n$ Viol_crime_rate_1k_log    <dbl> 0.8910559, 2.2153032, 1.6776181, 0.5947082, …\n$ Population_log            <dbl> 15.47966, 17.11513, 15.13896, 14.27197, 14.6…"
  },
  {
    "objectID": "content/lectures/11-cs01-data-slides.html#wrangling-combining-lott",
    "href": "content/lectures/11-cs01-data-slides.html#wrangling-combining-lott",
    "title": "11-cs01-data",
    "section": "Wrangling: Combining! (Lott)",
    "text": "Wrangling: Combining! (Lott)\n\nLOTT_DF <- bind_rows(dem_LOTT,\n                     ue_rate_data,\n                     poverty_rate_data,\n                     crime_data,\n                     population_data,\n                     ps_data) |>\n  pivot_wider(names_from = \"VARIABLE\",\n              values_from = \"VALUE\") |>\n  left_join(RTC , by = c(\"STATE\")) |>\n  mutate(RTC_LAW = case_when(YEAR >= RTC_LAW_YEAR ~ TRUE,\n                              TRUE ~ FALSE)) |>\n   drop_na()\n\nbaseline_year <- min(LOTT_DF$YEAR)\ncensoring_year <- max(LOTT_DF$YEAR)\n\nLOTT_DF <- LOTT_DF |>\n  mutate(TIME_0 = baseline_year,\n         TIME_INF = censoring_year) |>\n  filter(RTC_LAW_YEAR > TIME_0)\n\nLOTT_DF <- LOTT_DF |>\n  mutate(Viol_crime_rate_1k = (Viol_crime_count*1000)/Population,\n         Viol_crime_rate_1k_log = log(Viol_crime_rate_1k),\n         Population_log = log(Population))\n\nLOTT_DF\n\n# A tibble: 1,364 × 50\n    YEAR STATE   Black…¹ Black…² Black…³ Black…⁴ Black…⁵ Black…⁶ Black…⁷ Black…⁸\n   <dbl> <chr>     <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1  1980 Alaska   0.264    0.443  0.201   0.116   0.0924 0.0264    0.297   0.695\n 2  1980 Arizona  0.287    0.278  0.165   0.119   0.136  0.103     0.311   0.338\n 3  1980 Arkans…  1.82     1.50   0.842   0.634   1.02   1.16      1.81    1.26 \n 4  1980 Califo…  0.780    0.815  0.581   0.394   0.456  0.292     0.808   0.815\n 5  1980 Colora…  0.352    0.388  0.245   0.172   0.164  0.103     0.377   0.467\n 6  1980 Delawa…  1.87     1.68   1.14    0.783   0.952  0.670     1.81    1.36 \n 7  1980 Distri…  6.53     7.54   5.18    3.89    6.10   4.15      6.32    6.40 \n 8  1980 Florida  1.50     1.37   0.912   0.679   0.812  0.604     1.49    1.20 \n 9  1980 Georgia  2.90     2.78   1.85    1.22    1.56   1.35      2.92    2.45 \n10  1980 Hawaii   0.0930   0.215  0.0776  0.0253  0.0197 0.00738   0.180   0.656\n# … with 1,354 more rows, 40 more variables: Black_Male_30_to_39_years <dbl>,\n#   Black_Male_40_to_49_years <dbl>, Black_Male_50_to_64_years <dbl>,\n#   Black_Male_65_years_and_over <dbl>, Other_Female_10_to_19_years <dbl>,\n#   Other_Female_20_to_29_years <dbl>, Other_Female_30_to_39_years <dbl>,\n#   Other_Female_40_to_49_years <dbl>, Other_Female_50_to_64_years <dbl>,\n#   Other_Female_65_years_and_over <dbl>, Other_Male_10_to_19_years <dbl>,\n#   Other_Male_20_to_29_years <dbl>, Other_Male_30_to_39_years <dbl>, …"
  },
  {
    "objectID": "content/lectures/11-cs01-data-slides.html#why",
    "href": "content/lectures/11-cs01-data-slides.html#why",
    "title": "11-cs01-data",
    "section": "Why?",
    "text": "Why?\n❓ Why are there different dimensions for LOTT vs DONOHUE??\n\ndim(LOTT_DF)\n\n[1] 1364   50\n\n\n\ndim(DONOHUE_DF)\n\n[1] 1364   20"
  },
  {
    "objectID": "content/lectures/11-cs01-data-slides.html#things-to-consider",
    "href": "content/lectures/11-cs01-data-slides.html#things-to-consider",
    "title": "11-cs01-data",
    "section": "Things to Consider",
    "text": "Things to Consider\n\n\nHow RMarkdown documents work\nHow to control what is executed each time you render\nWhat to do with all this after this lecture?"
  },
  {
    "objectID": "content/lectures/11-cs01-data-slides.html#save",
    "href": "content/lectures/11-cs01-data-slides.html#save",
    "title": "11-cs01-data",
    "section": "Save",
    "text": "Save\n\nsave(LOTT_DF, DONOHUE_DF, file = \"data/wrangled/wrangled_data_rtc.rda\")\n\n\n\n\nhttps://cogs137.github.io/website/"
  },
  {
    "objectID": "content/lectures/11-cs01-data.html",
    "href": "content/lectures/11-cs01-data.html",
    "title": "11-cs01-data",
    "section": "",
    "text": "Q: Is there ever a time when we should use \\(R^2\\) instead of adjusted R^2 when analyzing a model?\nA: When talking about variance explained of a single model, \\(R^2\\) is great, but when comparing across models, you’ll always want to use adjusted \\(R^2\\)\n\n\nQ: How do we use the data from OCS for our case study? Should we merge the data files?\nA: Excellent question! That’s what today’s lecture is all about. There’s a whole lot of wrangling to do before we can use these data!\n\n\nQ: Do we need to look at the p-value when we do analysis? (Midterm01)\nA: When interpreting a model, no. When doing hypothesis testing (we’ll get there), it is one piece you can look at. A few people did interpret p-values on the midterm, and that’s ok! (But it was not required.)\n\n\nQ: Can we have a system where we can find other students to group with? Like a google form?\nA: Great question! I’ll start a pinned thread on Campuswire so you all can find one another.\n\n\nQ: I think the data seems pretty confusing.\nA: That’s b/c it is! We’ve got a lot of work to do to get it into a usable/understandable format.\n\n\nQ: In what context of data we should use interaction model or main effect model?\nA: Interaction terms should be included when the relationship between one predictor and the outcome varies by another predictor.\n\n\n\n\nDue Dates:\n\nLab 05 due tomorrow (2/17; 11:59 PM)\nmid-course survey (optional for EC) due tomorrow (2/17; 11:59 PM)\nLecture Participation survey “due” after class\n\n\nNotes:\n\nCS01\n\ninstructions posted on website\ninvited to GH repo (accept invitation, please!)\nhave an email with other group mates\ngoal: meet more people in the class & work together\n\nHW03 posted\nReminder to think about final project group mates; thread on campuswire\n\n\n\n\n\n\nBackground\nData Intro\nWrangle\nCombine!"
  },
  {
    "objectID": "content/lectures/11-cs01-data.html#right-to-carry-laws1",
    "href": "content/lectures/11-cs01-data.html#right-to-carry-laws1",
    "title": "11-cs01-data",
    "section": "Right To Carry Laws1",
    "text": "Right To Carry Laws1\nRight to Carry (RTC) Laws - “a law that specifies if and how citizens are allowed to have a firearm on their person or nearby (for example, in a citizen’s car) in public.”2"
  },
  {
    "objectID": "content/lectures/11-cs01-data.html#rtc-laws-contd",
    "href": "content/lectures/11-cs01-data.html#rtc-laws-contd",
    "title": "11-cs01-data",
    "section": "RTC Laws (cont’d)",
    "text": "RTC Laws (cont’d)\n\n\nThe Second Amendment to the United States Constitution guarantees the right to “keep and bear arms”. The amendment was ratified in 1791 as part of the Bill of Rights.\nThere are no federal laws about carrying firearms in public.\nThese laws are created and enforced at the US state level. States vary greatly in their laws about the right to carry firearms.\nSome require extensive effort to obtain a permit to legally carry a firearm, while other states require very minimal effort to do so. An increasing number of states do not require permits at all."
  },
  {
    "objectID": "content/lectures/11-cs01-data.html#rtc-laws-across-the-us",
    "href": "content/lectures/11-cs01-data.html#rtc-laws-across-the-us",
    "title": "11-cs01-data",
    "section": "RTC Laws Across the US",
    "text": "RTC Laws Across the US"
  },
  {
    "objectID": "content/lectures/11-cs01-data.html#rtc-laws-across-the-us-1",
    "href": "content/lectures/11-cs01-data.html#rtc-laws-across-the-us-1",
    "title": "11-cs01-data",
    "section": "RTC Laws Across the US",
    "text": "RTC Laws Across the US"
  },
  {
    "objectID": "content/lectures/11-cs01-data.html#the-data-source",
    "href": "content/lectures/11-cs01-data.html#the-data-source",
    "title": "11-cs01-data",
    "section": "The Data: Source",
    "text": "The Data: Source\nTwo contradictory analyses:\n\nJohn J. Donohue et al., Right‐to‐Carry Laws and Violent Crime: A Comprehensive Assessment Using Panel Data and a State‐Level Synthetic Control Analysis. Journal of Empirical Legal Studies, 16,2 (2019).\nDavid B. Mustard & John Lott. Crime, Deterrence, and Right-to-Carry Concealed Handguns. Coase-Sandor Institute for Law & Economics Working Paper No. 41, (1996)."
  },
  {
    "objectID": "content/lectures/11-cs01-data.html#the-data-1",
    "href": "content/lectures/11-cs01-data.html#the-data-1",
    "title": "11-cs01-data",
    "section": "The Data",
    "text": "The Data"
  },
  {
    "objectID": "content/lectures/11-cs01-data.html#two-analyses",
    "href": "content/lectures/11-cs01-data.html#two-analyses",
    "title": "11-cs01-data",
    "section": "Two Analyses",
    "text": "Two Analyses"
  },
  {
    "objectID": "content/lectures/11-cs01-data.html#limitations",
    "href": "content/lectures/11-cs01-data.html#limitations",
    "title": "11-cs01-data",
    "section": "Limitations",
    "text": "Limitations\n\n\nThe analyses differed in variables used; we will not be recreating either analysis in full\nWe’ll account for either the adoption or lack of adoption of a permissive right-to-carry law in each state; we will not account for differences in the level of permissiveness of the laws.\nRace is included here (as it was in initial analysis); however, any association between demographic variables (indicating the proportion of the population from specific race and age groups) and violent crime does not necessarily indicate that the two are linked causally."
  },
  {
    "objectID": "content/lectures/11-cs01-data.html#packages",
    "href": "content/lectures/11-cs01-data.html#packages",
    "title": "11-cs01-data",
    "section": "Packages",
    "text": "Packages\n\nlibrary(OCSdata) # will need to be installed\nlibrary(tidyverse)\nlibrary(pdftools)\nlibrary(readxl)"
  },
  {
    "objectID": "content/lectures/11-cs01-data.html#raw-data",
    "href": "content/lectures/11-cs01-data.html#raw-data",
    "title": "11-cs01-data",
    "section": "Raw Data",
    "text": "Raw Data\nThere are a whole bunch of different data files we’ll be using…\n\n# only get the data once\nOCSdata::load_raw_data(\"ocs-bp-RTC-wrangling\", outpath = '.')\n\n\ncreates a “data” sub-directory in your current working directory (if it does not already exist)\ncreates a “raw” sub-directory within “data”; contains the directories with the data\n\n👉 Your Turn: Load the data into RStudio. It will take a while…so just let it get started."
  },
  {
    "objectID": "content/lectures/11-cs01-data.html#the-goal",
    "href": "content/lectures/11-cs01-data.html#the-goal",
    "title": "11-cs01-data",
    "section": "The Goal",
    "text": "The Goal\nGet two datasets (Lott, Donohue) that contain demographic, population, police staffing, unemployment, violent crime, RTC, and poverty information at the state level across time.\n\n❓ What would be the tidy way to store these data?"
  },
  {
    "objectID": "content/lectures/11-cs01-data.html#your-turn",
    "href": "content/lectures/11-cs01-data.html#your-turn",
    "title": "11-cs01-data",
    "section": "Your Turn",
    "text": "Your Turn\n🧠 Take a look in one of the data folders, open at least one of the data files to view it, and try to get a sense of the type of information contained within it.\n\n\nPut a green sticky on the front of your computer when you’re done. Put a pink if you want help/have a question."
  },
  {
    "objectID": "content/lectures/11-cs01-data.html#demographic-population-data",
    "href": "content/lectures/11-cs01-data.html#demographic-population-data",
    "title": "11-cs01-data",
    "section": "Demographic & Population Data",
    "text": "Demographic & Population Data\n\nCodeData\n\n\n\ndem_77_79 <- read_csv(\"data/raw/Demographics/Decade_1970/pe-19.csv\", skip = 5)\n\ndem_80_89 <- list.files(recursive = TRUE,\n                  path = \"data/raw/Demographics/Decade_1980\",\n                  pattern = \"*.csv\",\n                  full.names = TRUE) |> \n  purrr::map(~read_csv(., skip=5))\n\ndem_90_99 <- list.files(recursive = TRUE,\n                  path = \"data/raw/Demographics/Decade_1990\",\n                  pattern = \"*.txt\",\n                  full.names = TRUE) |> \n  map(~read_table2(., skip = 14))\n\ndem_00_10 <- list.files(recursive = TRUE,\n                  path = \"data/raw/Demographics/Decade_2000\",\n                  pattern = \"*.csv\",\n                   full.names = TRUE) |> \n   map(~read_csv(.))\n\nSource: US Census Bureau Data\n\n\n\nglimpse(dem_00_10[[1]])\n\nRows: 62,244\nColumns: 21\n$ REGION            <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ DIVISION          <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ STATE             <chr> \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0…\n$ NAME              <chr> \"United States\", \"United States\", \"United States\", \"…\n$ SEX               <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ ORIGIN            <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ RACE              <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ AGEGRP            <dbl> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15…\n$ ESTIMATESBASE2000 <dbl> 281424600, 19176154, 20549855, 20528425, 20218782, 1…\n$ POPESTIMATE2000   <dbl> 282162411, 19178293, 20463852, 20637696, 20294955, 1…\n$ POPESTIMATE2001   <dbl> 284968955, 19298217, 20173362, 20978678, 20456284, 1…\n$ POPESTIMATE2002   <dbl> 287625193, 19429192, 19872417, 21261421, 20610370, 2…\n$ POPESTIMATE2003   <dbl> 290107933, 19592446, 19620851, 21415353, 20797166, 2…\n$ POPESTIMATE2004   <dbl> 292805298, 19785885, 19454237, 21411680, 21102552, 2…\n$ POPESTIMATE2005   <dbl> 295516599, 19917400, 19389067, 21212579, 21486214, 2…\n$ POPESTIMATE2006   <dbl> 298379912, 19938883, 19544688, 21033138, 21807709, 2…\n$ POPESTIMATE2007   <dbl> 301231207, 20125962, 19714611, 20841042, 22067816, 2…\n$ POPESTIMATE2008   <dbl> 304093966, 20271127, 19929602, 20706655, 22210880, 2…\n$ POPESTIMATE2009   <dbl> 306771529, 20244518, 20182499, 20660564, 22192810, 2…\n$ CENSUS2010POP     <dbl> 308745538, 20201362, 20348657, 20677194, 22040343, 2…\n$ POPESTIMATE2010   <dbl> 309349689, 20200529, 20382409, 20694011, 21959087, 2…"
  },
  {
    "objectID": "content/lectures/11-cs01-data.html#state-fips-codes",
    "href": "content/lectures/11-cs01-data.html#state-fips-codes",
    "title": "11-cs01-data",
    "section": "State FIPS Codes",
    "text": "State FIPS Codes\n\nImageCodeDataWrangling\n\n\n\n\n\n\nSTATE_FIPS <- readxl::read_xls(\"data/raw/State_FIPS_codes/state-geocodes-v2014.xls\", skip = 5)\n\n\n\n\nglimpse(STATE_FIPS)\n\nRows: 64\nColumns: 4\n$ Region          <chr> \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\",…\n$ Division        <chr> \"0\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"2\", \"2\", \"2\",…\n$ `State\\n(FIPS)` <chr> \"00\", \"00\", \"09\", \"23\", \"25\", \"33\", \"44\", \"50\", \"00\", …\n$ Name            <chr> \"Northeast Region\", \"New England Division\", \"Connectic…\n\n\n\n\n\nSTATE_FIPS <- STATE_FIPS |>\n  rename(STATEFP = `State\\n(FIPS)`,\n         STATE = Name) |>\n  select(STATEFP, STATE) |>\n  filter(STATEFP != \"00\")\n\nSTATE_FIPS\n\n# A tibble: 51 × 2\n   STATEFP STATE        \n   <chr>   <chr>        \n 1 09      Connecticut  \n 2 23      Maine        \n 3 25      Massachusetts\n 4 33      New Hampshire\n 5 44      Rhode Island \n 6 50      Vermont      \n 7 34      New Jersey   \n 8 36      New York     \n 9 42      Pennsylvania \n10 17      Illinois     \n# … with 41 more rows"
  },
  {
    "objectID": "content/lectures/11-cs01-data.html#police-staffing-data",
    "href": "content/lectures/11-cs01-data.html#police-staffing-data",
    "title": "11-cs01-data",
    "section": "Police Staffing Data",
    "text": "Police Staffing Data\n\nCodeData\n\n\nThere’s an issue currently with the ps_data file from OCS, so we’ll use this file instead:\n\nps_data <- read_csv(\"https://raw.githubusercontent.com/COGS137/datasets/main/pe_1960_2018.csv\")\n\n\n\n\nglimpse(ps_data)\n\nRows: 2,242\nColumns: 3\n$ data_year           <dbl> 1977, 1977, 1977, 1977, 1977, 1977, 1977, 1977, 19…\n$ state_abbr          <chr> \"AK\", \"AL\", \"AR\", \"AS\", \"AZ\", \"CA\", \"CO\", \"CT\", \"C…\n$ officer_state_total <dbl> 544, 7380, 3344, 0, 6414, 65596, 7337, 6051, 0, 47…"
  },
  {
    "objectID": "content/lectures/11-cs01-data.html#unemployment-data",
    "href": "content/lectures/11-cs01-data.html#unemployment-data",
    "title": "11-cs01-data",
    "section": "Unemployment Data",
    "text": "Unemployment Data\n\nImageCodeDataWrangle\n\n\n\n\n\nunemployment\n\n\n\n\n\nue_rate_data <- list.files(recursive = TRUE,\n                          path = \"data/raw/Unemployment\",\n                          pattern = \"*.xlsx\",\n                          full.names = TRUE) |> \nmap(~read_xlsx(., skip = 10))\n\nue_rate_names <- list.files(recursive = TRUE,\n                          path = \"data/raw/Unemployment\",\n                          pattern = \"*.xlsx\",\n                          full.names = TRUE) |>\nmap(~read_xlsx(., range = \"B4:B6\")) |>\n  map(c(1,2)) |>\nunlist()\n\nnames(ue_rate_data) <- ue_rate_names\n\n\n\n\nhead(ue_rate_data)[1]\n\n$Alabama\n# A tibble: 44 × 14\n    Year   Jan   Feb   Mar   Apr   May   Jun   Jul   Aug   Sep   Oct   Nov   Dec\n   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n 1  1977   7.5   9     7.7   7.2   6.8   8.6   8     7.8   6.7   6.3   6.3   6  \n 2  1978   7.1   6.9   6.2   5.4   5.1   6.9   6.7   6.7   6.5   6.3   6.3   6.5\n 3  1979   6.7   7.5   6.9   6.6   6.4   8.4   7.7   7.8   7.1   7.2   6.9   6.7\n 4  1980   7.7   7.8   7.4   7.4   8.4   9.7  10.4  10.3   9.3   9.6   9.4   9  \n 5  1981  10    10.3   9.5   9.1   9.4  11.1  10.4  10.9  10.8  11.7  11.5  11.8\n 6  1982  13.2  13.2  12.9  12.6  12.8  14.5  14.7  14.8  14.7  15.1  15.4  15.3\n 7  1983  16    16    14.5  13.7  13.3  14.6  13.9  13.8  13.2  12.8  12.1  11.8\n 8  1984  12.5  12.4  11.4  10.8  10.1  11.3  11.5  11.3  10.8  10.2   9.7  10.1\n 9  1985  10.7  10.5   9.8   8.7   8.4   9.6   9.2   8.8   8.6   8.6   8.4   8.7\n10  1986   9.3  10.4  10.1   9.4   9.4  10.5   9.7   9.6   9.7   9.7   9.6   9  \n# … with 34 more rows, and 1 more variable: Annual <dbl>\n\n\n\n\n\nue_rate_data <- ue_rate_data |>\n  map_df(bind_rows, .id = \"STATE\") |>\n  select(STATE, Year, Annual) |>\n  rename(\"YEAR\" = Year,\n         \"VALUE\" = Annual) |>\n  mutate(VARIABLE = \"Unemployment_rate\")\n\nue_rate_data\n\n# A tibble: 2,244 × 4\n   STATE    YEAR VALUE VARIABLE         \n   <chr>   <dbl> <dbl> <chr>            \n 1 Alabama  1977   7.3 Unemployment_rate\n 2 Alabama  1978   6.4 Unemployment_rate\n 3 Alabama  1979   7.2 Unemployment_rate\n 4 Alabama  1980   8.9 Unemployment_rate\n 5 Alabama  1981  10.6 Unemployment_rate\n 6 Alabama  1982  14.1 Unemployment_rate\n 7 Alabama  1983  13.8 Unemployment_rate\n 8 Alabama  1984  11   Unemployment_rate\n 9 Alabama  1985   9.2 Unemployment_rate\n10 Alabama  1986   9.7 Unemployment_rate\n# … with 2,234 more rows"
  },
  {
    "objectID": "content/lectures/11-cs01-data.html#poverty-data",
    "href": "content/lectures/11-cs01-data.html#poverty-data",
    "title": "11-cs01-data",
    "section": "Poverty Data",
    "text": "Poverty Data\n\nCodeData\n\n\n\npoverty_rate_data <- read_xls(\"data/raw/Poverty/hstpov21.xls\", skip=2)\n\n\n\n\nhead(poverty_rate_data)\n\n# A tibble: 6 × 6\n  `NOTE: Number in thousands.` ...2  ...3   ...4              ...5         ...6 \n  <chr>                        <chr> <chr>  <chr>             <chr>        <chr>\n1 2018                         <NA>  <NA>    <NA>             <NA>          <NA>\n2 STATE                        Total Number \"Standard\\nerror\" Percent      \"Sta…\n3 Alabama                      4877  779    \"65\"              16           \"1.3\"\n4 Alaska                       720   94     \"9\"               13.1         \"1.2\"\n5 Arizona                      7241  929    \"80\"              12.80000000… \"1.1…\n6 Arkansas                     2912  462    \"38\"              15.9         \"1.3\"\n\n\n\n\n\nSource: US Census Bureau Data"
  },
  {
    "objectID": "content/lectures/11-cs01-data.html#violent-crime-data",
    "href": "content/lectures/11-cs01-data.html#violent-crime-data",
    "title": "11-cs01-data",
    "section": "Violent Crime Data",
    "text": "Violent Crime Data\n\nCodeData\n\n\n\ncrime_data <- read_lines(\"data/raw/Crime/CrimeStatebyState.csv\",\n                         skip = 2, \n                         skip_empty_rows = TRUE)\n\nDue to spaces and / in the column names, read_lines() from the readr package works better than read_csv()\n\n\n\nhead(crime_data)\n\n[1] \"Estimated crime in Alabama\"                                                                                                         \n[2] \",,National or state crime,,,,,,,\"                                                                                                   \n[3] \",,Violent crime,,,,,,,\"                                                                                                             \n[4] \"Year,Population,Violent crime total,Murder and nonnegligent Manslaughter,Legacy rape /1,Revised rape /2,Robbery,Aggravated assault,\"\n[5] \"1977,   3690000,      15293,         524,         929,,       3572,      10268 \"                                                    \n[6] \"1978,   3742000,      15682,         499,         954,,       3708,      10521 \""
  },
  {
    "objectID": "content/lectures/11-cs01-data.html#right-to-carry-data",
    "href": "content/lectures/11-cs01-data.html#right-to-carry-data",
    "title": "11-cs01-data",
    "section": "Right-To-Carry Data",
    "text": "Right-To-Carry Data\n\nCodeData\n\n\n\nDAWpaper <- pdf_text(\"data/raw/w23510.pdf\")\n\n\n\n\nhead(DAWpaper[1])\n\n[1] \"                              NBER WORKING PAPER SERIES\\n\\n\\n\\n                  RIGHT-TO-CARRY LAWS AND VIOLENT CRIME:\\n             A COMPREHENSIVE ASSESSMENT USING PANEL DATA AND\\n                 A STATE-LEVEL SYNTHETIC CONTROL ANALYSIS\\n\\n                                        John J. Donohue\\n                                          Abhay Aneja\\n                                         Kyle D. Weber\\n\\n                                      Working Paper 23510\\n                              http://www.nber.org/papers/w23510\\n\\n\\n                     NATIONAL BUREAU OF ECONOMIC RESEARCH\\n                              1050 Massachusetts Avenue\\n                                 Cambridge, MA 02138\\n                           June 2017, Revised November 2018\\n\\n\\n\\nPreviously circulated as \\\"Right-to-Carry Laws and Violent Crime: A Comprehensive Assessment\\nUsing Panel Data and a State-Level Synthetic Controls Analysis.\\\" We thank Dan Ho, Stefano\\nDellaVigna, Rob Tibshirani, Trevor Hastie, StefanWager, Jeff Strnad, and participants at the\\n2011 Conference of Empirical Legal Studies (CELS), 2012 American Law and Economics\\nAssociation (ALEA) Annual Meeting, 2013 Canadian Law and Economics Association (CLEA)\\nAnnual Meeting, 2015 NBER Summer Institute (Crime), and the Stanford Law School faculty\\nworkshop for their comments and helpful suggestions. Financial support was provided by\\nStanford Law School. We are indebted to Alberto Abadie, Alexis Diamond, and Jens\\nHainmueller for their work developing the synthetic control algorithm and programming the Stata\\nmodule used in this paper and for their helpful comments. The authors would also like to thank\\nAlex Albright, Andrew Baker, Jacob Dorn, Bhargav Gopal, Crystal Huang, Mira Korb, Haksoo\\nLee, Isaac Rabbani, Akshay Rao, Vikram Rao, Henrik Sachs and Sidharth Sah who provided\\nexcellent research assistance, as well as Addis O’Connor and Alex Chekholko at the Research\\nComputing division of Stanford’s Information Technology Services for their technical support.\\nThe views expressed herein are those of the author and do not necessarily reflect the views of the\\nNational Bureau of Economic Research.\\n\\nNBER working papers are circulated for discussion and comment purposes. They have not been\\npeer-reviewed or been subject to the review by the NBER Board of Directors that accompanies\\nofficial NBER publications.\\n\\n© 2017 by John J. Donohue, Abhay Aneja, and Kyle D. Weber. All rights reserved. Short\\nsections of text, not to exceed two paragraphs, may be quoted without explicit permission\\nprovided that full credit, including © notice, is given to the source.\\n\""
  },
  {
    "objectID": "content/lectures/11-cs01-data.html#save-imported-data",
    "href": "content/lectures/11-cs01-data.html#save-imported-data",
    "title": "11-cs01-data",
    "section": "Save (Imported) Data",
    "text": "Save (Imported) Data\n\nsave(dem_77_79, dem_80_89, dem_90_99, dem_00_10, \n     STATE_FIPS, \n     ps_data, \n     ue_rate_data, \n     poverty_rate_data,\n     crime_data,\n     DAWpaper, file = \"data/imported_data_rtc.rda\")"
  },
  {
    "objectID": "content/lectures/11-cs01-data.html#wrangle-demo-data",
    "href": "content/lectures/11-cs01-data.html#wrangle-demo-data",
    "title": "11-cs01-data",
    "section": "Wrangle: Demo Data",
    "text": "Wrangle: Demo Data\n\n77-7980s90s00s\n\n\n\ndem_77_79 <- dem_77_79 |>\n  rename(\"race_sex\" =`Race/Sex Indicator`) |>\n  mutate(SEX = str_extract(race_sex, \"male|female\"),\n        RACE = str_extract(race_sex, \"Black|White|Other\"))|>\n  select(-`FIPS State Code`, -`race_sex`) |>\n  rename(\"YEAR\" = `Year of Estimate`,\n        \"STATE\" = `State Name`) |>\n  filter(YEAR %in% 1977:1979)\n\ndem_77_79 <- dem_77_79 |>\n  pivot_longer(cols=contains(\"years\"),\n               names_to = \"AGE_GROUP\",\n               values_to = \"SUB_POP\")\n\nglimpse(dem_77_79)\n\nRows: 16,524\nColumns: 6\n$ YEAR      <dbl> 1977, 1977, 1977, 1977, 1977, 1977, 1977, 1977, 1977, 1977, …\n$ STATE     <chr> \"Alabama\", \"Alabama\", \"Alabama\", \"Alabama\", \"Alabama\", \"Alab…\n$ SEX       <chr> \"male\", \"male\", \"male\", \"male\", \"male\", \"male\", \"male\", \"mal…\n$ RACE      <chr> \"White\", \"White\", \"White\", \"White\", \"White\", \"White\", \"White…\n$ AGE_GROUP <chr> \"Under 5 years\", \"5 to 9 years\", \"10 to 14 years\", \"15 to 19…\n$ SUB_POP   <dbl> 98814, 113365, 123107, 135343, 126053, 111547, 100674, 81038…\n\n\n\n\n\ndem_80_89 <- dem_80_89 |>\n  map_df(bind_rows)\n\ndem_80_89 <- dem_80_89 |>\n  rename(\"race_sex\" =`Race/Sex Indicator`) |>\n  mutate(SEX = str_extract(race_sex, \"male|female\"),\n        RACE = str_extract(race_sex, \"Black|White|Other\"))|>\n  select( -`race_sex`) |>\n  rename(\"YEAR\" = `Year of Estimate`) |> \n  rename(\"STATEFP_temp\" = \"FIPS State and County Codes\") |>\n  mutate(STATEFP = str_sub(STATEFP_temp, start = 1, end = 2)) |>\n    left_join(STATE_FIPS, by = \"STATEFP\") |>\n  select(-STATEFP)\n\ndem_80_89 <- dem_80_89 |>\n  pivot_longer(cols=contains(\"years\"),\n               names_to = \"AGE_GROUP\",\n               values_to = \"SUB_POP_temp\") |>\n  group_by(YEAR, STATE, AGE_GROUP, SEX, RACE) |>\n  summarize(SUB_POP = sum(SUB_POP_temp), .groups=\"drop\")\n\ndem_80_89\n\n# A tibble: 55,080 × 6\n    YEAR STATE   AGE_GROUP      SEX    RACE  SUB_POP\n   <dbl> <chr>   <chr>          <chr>  <chr>   <dbl>\n 1  1980 Alabama 10 to 14 years female Black   50108\n 2  1980 Alabama 10 to 14 years female Other     805\n 3  1980 Alabama 10 to 14 years female White  109066\n 4  1980 Alabama 10 to 14 years male   Black   50768\n 5  1980 Alabama 10 to 14 years male   Other     826\n 6  1980 Alabama 10 to 14 years male   White  115988\n 7  1980 Alabama 15 to 19 years female Black   58428\n 8  1980 Alabama 15 to 19 years female Other     743\n 9  1980 Alabama 15 to 19 years female White  126783\n10  1980 Alabama 15 to 19 years male   Black   56808\n# … with 55,070 more rows\n\n\n\n\n\ndem_90_99 <- dem_90_99 |>\n  map_df(bind_rows)\n\ncolnames(dem_90_99) <- c(\"YEAR\", \"STATEFP\", \"Age\", \"NH_W_M\", \"NH_W_F\", \"NH_B_M\",\n                         \"NH_B_F\", \"NH_AIAN_M\", \"NH_AIAN_F\", \"NH_API_M\", \"NH_API_F\",\n                         \"H_W_M\", \"H_W_F\", \"H_B_M\", \"H_B_F\", \"H_AIAN_M\", \"H_AIAN_F\",\n                         \"H_API_M\", \"H_API_F\")\n\ndem_90_99 <- dem_90_99 |>\n  drop_na() |>\n  mutate(W_M = NH_W_M + H_W_M, W_F = NH_W_F + H_W_F,\n         B_M = NH_B_M + H_B_M, B_F = NH_B_F + H_B_F,\n         AIAN_M = NH_AIAN_M + H_AIAN_M, AIAN_F = NH_AIAN_F + H_AIAN_F,\n         API_M = NH_API_M + H_API_M, API_F = NH_API_F + H_API_F) |>\n  select(-starts_with(\"NH_\"), -starts_with(\"H_\"))\n\ndem_90_99 <- dem_90_99 |>\n  mutate(AGE_GROUP = cut(Age,\n                         breaks = seq(0,90, by=5),\n                         right = FALSE, labels = pull(distinct(dem_77_79,AGE_GROUP), AGE_GROUP))) |>\n  select(-Age) |>\n  pivot_longer(cols = c(starts_with(\"W_\"),\n                        starts_with(\"B_\"),\n                        starts_with(\"AIAN_\"),\n                        starts_with(\"API_\")),\n               names_to = \"RACE\",\n               values_to = \"SUB_POP_temp\") |>\n  mutate(SEX = case_when(str_detect(RACE, \"_M\") ~ \"Male\",\n                         TRUE ~ \"Female\"),\n         RACE = case_when(str_detect(RACE, \"W_\") ~ \"White\",\n                          str_detect(RACE, \"B_\") ~ \"Black\",\n                          TRUE ~ \"Other\"))\n\ndem_90_99 <- dem_90_99 |>\n  left_join(STATE_FIPS, by = \"STATEFP\") |>\n  select(-STATEFP) |>\n  group_by(YEAR, STATE, AGE_GROUP, SEX, RACE) |>\n  summarize(SUB_POP = sum(SUB_POP_temp), .groups=\"drop\")\n\nglimpse(dem_90_99)\n\nRows: 55,080\nColumns: 6\n$ YEAR      <dbl> 1990, 1990, 1990, 1990, 1990, 1990, 1990, 1990, 1990, 1990, …\n$ STATE     <chr> \"Alabama\", \"Alabama\", \"Alabama\", \"Alabama\", \"Alabama\", \"Alab…\n$ AGE_GROUP <fct> Under 5 years, Under 5 years, Under 5 years, Under 5 years, …\n$ SEX       <chr> \"Female\", \"Female\", \"Female\", \"Male\", \"Male\", \"Male\", \"Femal…\n$ RACE      <chr> \"Black\", \"Other\", \"White\", \"Black\", \"Other\", \"White\", \"Black…\n$ SUB_POP   <dbl> 45377, 1406, 92380, 46635, 1360, 98524, 46067, 1698, 92530, …\n\n\n\n\n\ndem_00_10 <- dem_00_10 |>\n  map_df(bind_rows)\n\ndem_00_10 <- dem_00_10 |>\n  select(-ESTIMATESBASE2000,-CENSUS2010POP) |>\n  filter(NAME != \"United States\",\n         SEX != 0,\n         RACE != 0,\n         AGEGRP != 0, \n         ORIGIN == 0) |>\n  select(-REGION, -DIVISION, -ORIGIN, -STATE) |>\n  rename(\"STATE\" = NAME,\n         \"AGE_GROUP\" = AGEGRP)\n\ndem_00_10 <- dem_00_10 |>\n  mutate(SEX = factor(SEX, levels = 1:2, labels = c(\"Male\", \"Female\")),\n         RACE = factor(RACE, levels = 1:6, labels = c(\"White\", \"Black\", rep(\"Other\",4))),\n         AGE_GROUP = factor(AGE_GROUP, levels = 1:18,\n                            labels = pull(distinct(dem_77_79,AGE_GROUP), AGE_GROUP)))\n\ndem_00_10 <- dem_00_10 |>\n  pivot_longer(cols=contains(\"ESTIMATE\"), names_to = \"YEAR\", values_to = \"SUB_POP_temp\") |>\n   mutate(YEAR = str_sub(YEAR, start=-4),\n          YEAR = as.numeric(YEAR)) |> \n  group_by(YEAR, AGE_GROUP, STATE, SEX, RACE) |>\n  summarize(SUB_POP = sum(SUB_POP_temp), .groups = \"drop\")\n                            \nglimpse(dem_00_10)\n\nRows: 60,588\nColumns: 6\n$ YEAR      <dbl> 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, …\n$ AGE_GROUP <fct> Under 5 years, Under 5 years, Under 5 years, Under 5 years, …\n$ STATE     <chr> \"Alabama\", \"Alabama\", \"Alabama\", \"Alabama\", \"Alabama\", \"Alab…\n$ SEX       <fct> Male, Male, Male, Female, Female, Female, Male, Male, Male, …\n$ RACE      <fct> White, Black, Other, White, Black, Other, White, Black, Othe…\n$ SUB_POP   <dbl> 99527, 46595, 4487, 94473, 45672, 4431, 14765, 1039, 8572, 1…"
  },
  {
    "objectID": "content/lectures/11-cs01-data.html#wrangle-population-data",
    "href": "content/lectures/11-cs01-data.html#wrangle-population-data",
    "title": "11-cs01-data",
    "section": "Wrangle: Population Data",
    "text": "Wrangle: Population Data\n\n77-7980s90s00s\n\n\n\npop_77_79 <- dem_77_79 |>\n  group_by(YEAR, STATE) |>\n  summarize(TOT_POP = sum(SUB_POP), .groups = \"drop\") \n\npop_77_79 \n\n# A tibble: 153 × 3\n    YEAR STATE                 TOT_POP\n   <dbl> <chr>                   <dbl>\n 1  1977 Alabama               3782571\n 2  1977 Alaska                 397220\n 3  1977 Arizona               2427296\n 4  1977 Arkansas              2207195\n 5  1977 California           22350332\n 6  1977 Colorado              2696179\n 7  1977 Connecticut           3088745\n 8  1977 Delaware               594815\n 9  1977 District of Columbia   681766\n10  1977 Florida               8888806\n# … with 143 more rows\n\n\n\n\n\npop_80_89 <- dem_80_89 |>\n  group_by(YEAR, STATE) |>\n  summarize(TOT_POP = sum(SUB_POP), .groups = \"drop\") \n\n\n\n\npop_90_99 <- dem_90_99 |>\n  group_by(YEAR, STATE) |>\n  summarize(TOT_POP = sum(SUB_POP), .groups = \"drop\")\n\n\n\n\npop_00_10 <- dem_00_10 |>\n  group_by(YEAR, STATE) |>\n  summarize(TOT_POP = sum(SUB_POP), .groups = \"drop\")"
  },
  {
    "objectID": "content/lectures/11-cs01-data.html#combine-demo-population",
    "href": "content/lectures/11-cs01-data.html#combine-demo-population",
    "title": "11-cs01-data",
    "section": "Combine: Demo + Population",
    "text": "Combine: Demo + Population\n\n77-7980s90s00sIdea\n\n\n\ndem_77_79 <- dem_77_79 |>\n  left_join(pop_77_79, by = c(\"YEAR\", \"STATE\")) |> \n  mutate(PERC_SUB_POP = (SUB_POP/TOT_POP)*100) |>\n  select(-SUB_POP, -TOT_POP) |>\n  mutate(SEX = str_to_title(SEX))\n\n\ndem_77_79\n\n# A tibble: 16,524 × 6\n    YEAR STATE   SEX   RACE  AGE_GROUP      PERC_SUB_POP\n   <dbl> <chr>   <chr> <chr> <chr>                 <dbl>\n 1  1977 Alabama Male  White Under 5 years          2.61\n 2  1977 Alabama Male  White 5 to 9 years           3.00\n 3  1977 Alabama Male  White 10 to 14 years         3.25\n 4  1977 Alabama Male  White 15 to 19 years         3.58\n 5  1977 Alabama Male  White 20 to 24 years         3.33\n 6  1977 Alabama Male  White 25 to 29 years         2.95\n 7  1977 Alabama Male  White 30 to 34 years         2.66\n 8  1977 Alabama Male  White 35 to 39 years         2.14\n 9  1977 Alabama Male  White 40 to 44 years         1.98\n10  1977 Alabama Male  White 45 to 49 years         2.02\n# … with 16,514 more rows\n\n\n\n\n\ndem_80_89 <- dem_80_89 |>\n  left_join(pop_80_89, by = c(\"YEAR\", \"STATE\")) |>\n  mutate(PERC_SUB_POP = (SUB_POP/TOT_POP)*100) |>\n  select(-SUB_POP, -TOT_POP) |>\n  mutate(SEX = str_to_title(SEX))\n\n\n\n\ndem_90_99 <- dem_90_99 |>\n  left_join(pop_90_99, by = c(\"YEAR\", \"STATE\")) |>\n  mutate(PERC_SUB_POP = (SUB_POP/TOT_POP)*100) |>\n  select(-SUB_POP, -TOT_POP)\n\ndem_90_99\n\n# A tibble: 55,080 × 6\n    YEAR STATE   AGE_GROUP     SEX    RACE  PERC_SUB_POP\n   <dbl> <chr>   <fct>         <chr>  <chr>        <dbl>\n 1  1990 Alabama Under 5 years Female Black       1.12  \n 2  1990 Alabama Under 5 years Female Other       0.0347\n 3  1990 Alabama Under 5 years Female White       2.28  \n 4  1990 Alabama Under 5 years Male   Black       1.15  \n 5  1990 Alabama Under 5 years Male   Other       0.0336\n 6  1990 Alabama Under 5 years Male   White       2.43  \n 7  1990 Alabama 5 to 9 years  Female Black       1.14  \n 8  1990 Alabama 5 to 9 years  Female Other       0.0419\n 9  1990 Alabama 5 to 9 years  Female White       2.29  \n10  1990 Alabama 5 to 9 years  Male   Black       1.16  \n# … with 55,070 more rows\n\n\n\n\n\ndem_00_10 <- dem_00_10 |>\n  left_join(pop_00_10, by = c(\"YEAR\", \"STATE\")) |>\n  mutate(PERC_SUB_POP = (SUB_POP/TOT_POP)*100) |>\n  select(-SUB_POP, -TOT_POP)\n\ndem_00_10\n\n# A tibble: 60,588 × 6\n    YEAR AGE_GROUP     STATE   SEX    RACE  PERC_SUB_POP\n   <dbl> <fct>         <chr>   <fct>  <fct>        <dbl>\n 1  2000 Under 5 years Alabama Male   White       2.24  \n 2  2000 Under 5 years Alabama Male   Black       1.05  \n 3  2000 Under 5 years Alabama Male   Other       0.101 \n 4  2000 Under 5 years Alabama Female White       2.12  \n 5  2000 Under 5 years Alabama Female Black       1.03  \n 6  2000 Under 5 years Alabama Female Other       0.0995\n 7  2000 Under 5 years Alaska  Male   White       2.35  \n 8  2000 Under 5 years Alaska  Male   Black       0.165 \n 9  2000 Under 5 years Alaska  Male   Other       1.37  \n10  2000 Under 5 years Alaska  Female White       2.26  \n# … with 60,578 more rows\n\n\n\n\n❗ This would be a good part of the code to write a user-defined function…"
  },
  {
    "objectID": "content/lectures/11-cs01-data.html#aside-udf",
    "href": "content/lectures/11-cs01-data.html#aside-udf",
    "title": "11-cs01-data",
    "section": "Aside: UDF",
    "text": "Aside: UDF\n\nThe WhatThe HowExampleUsing the function\n\n\n\nUser-defined functions (UDFs) are functions you write to make your code cleaner\nAny time you copy+paste very similar code, think to yourself…I should make this a function!\n\n\n\nThe general syntax for a function in R is:\n\nfunction_name <- function(parameters){\n  # code to carry out\n  # using the parameters\n}\n\nNote: by default the last object created within the function is returned from the function\n\n\n\ncombine_demo_pop <- function(df_dem, df_pop){\n  df_dem <- df_dem |>\n  group_by(YEAR, STATE) |>\n  summarize(TOT_POP = sum(SUB_POP), .groups = \"drop\")\n  \n  df_dem |>\n  left_join(df_pop, by = c(\"YEAR\", \"STATE\")) |>\n  mutate(PERC_SUB_POP = (SUB_POP/TOT_POP)*100) |>\n  select(-SUB_POP, -TOT_POP) |>\n  mutate(SEX = str_to_title(SEX))\n}\n\n\n\n\ncombined_df <- combine_demo_pop(dem_00_10, pop_00_10)\n\n\nNote: if you’ve already combined the data into dem_00_10, this would not work.\nCleaning up/improving code in your case studies is encouraged!"
  },
  {
    "objectID": "content/lectures/11-cs01-data.html#combine-demopop-across-decades",
    "href": "content/lectures/11-cs01-data.html#combine-demopop-across-decades",
    "title": "11-cs01-data",
    "section": "Combine: Demo/Pop Across Decades",
    "text": "Combine: Demo/Pop Across Decades\n\ndem <- bind_rows(dem_77_79,\n                 dem_80_89,\n                 dem_90_99,\n                 dem_00_10)\n\nglimpse(dem)\n\nRows: 187,272\nColumns: 6\n$ YEAR         <dbl> 1977, 1977, 1977, 1977, 1977, 1977, 1977, 1977, 1977, 197…\n$ STATE        <chr> \"Alabama\", \"Alabama\", \"Alabama\", \"Alabama\", \"Alabama\", \"A…\n$ SEX          <chr> \"Male\", \"Male\", \"Male\", \"Male\", \"Male\", \"Male\", \"Male\", \"…\n$ RACE         <chr> \"White\", \"White\", \"White\", \"White\", \"White\", \"White\", \"Wh…\n$ AGE_GROUP    <chr> \"Under 5 years\", \"5 to 9 years\", \"10 to 14 years\", \"15 to…\n$ PERC_SUB_POP <dbl> 2.6123502, 2.9970356, 3.2545853, 3.5780690, 3.3324688, 2.…"
  },
  {
    "objectID": "content/lectures/11-cs01-data.html#demographic-data-donohue",
    "href": "content/lectures/11-cs01-data.html#demographic-data-donohue",
    "title": "11-cs01-data",
    "section": "Demographic Data (Donohue)",
    "text": "Demographic Data (Donohue)\n\nDONOHUE_AGE_GROUPS <- c(\"15 to 19 years\",\n                        \"20 to 24 years\",\n                        \"25 to 29 years\",\n                        \"30 to 34 years\",\n                        \"35 to 39 years\")\n\ndem_DONOHUE <- dem |>\n  filter(AGE_GROUP %in% DONOHUE_AGE_GROUPS,\n               SEX == \"Male\") |>\n  mutate(AGE_GROUP = fct_collapse(AGE_GROUP, \"20 to 39 years\"=c(\"20 to 24 years\",\n                                                                \"25 to 29 years\",\n                                                                \"30 to 34 years\",\n                                                                \"35 to 39 years\")),\n         AGE_GROUP = str_replace_all(string = AGE_GROUP, \n                                     pattern = \" \", \n                                     replacement = \"_\")) |>\n  group_by(YEAR, STATE, RACE, SEX, AGE_GROUP) |>\n  summarize(PERC_SUB_POP = sum(PERC_SUB_POP), .groups = \"drop\") |>\n  unite(col = \"VARIABLE\", RACE, SEX, AGE_GROUP, sep = \"_\") |>\n  rename(\"VALUE\" = PERC_SUB_POP)\n\ndem_DONOHUE\n\n# A tibble: 10,404 × 4\n    YEAR STATE   VARIABLE                    VALUE\n   <dbl> <chr>   <chr>                       <dbl>\n 1  1977 Alabama Black_Male_15_to_19_years  1.55  \n 2  1977 Alabama Black_Male_20_to_39_years  3.04  \n 3  1977 Alabama Other_Male_15_to_19_years  0.0178\n 4  1977 Alabama Other_Male_20_to_39_years  0.0642\n 5  1977 Alabama White_Male_15_to_19_years  3.58  \n 6  1977 Alabama White_Male_20_to_39_years 11.1   \n 7  1977 Alaska  Black_Male_15_to_19_years  0.163 \n 8  1977 Alaska  Black_Male_20_to_39_years  0.968 \n 9  1977 Alaska  Other_Male_15_to_19_years  1.12  \n10  1977 Alaska  Other_Male_20_to_39_years  2.73  \n# … with 10,394 more rows"
  },
  {
    "objectID": "content/lectures/11-cs01-data.html#demographic-data-lott",
    "href": "content/lectures/11-cs01-data.html#demographic-data-lott",
    "title": "11-cs01-data",
    "section": "Demographic Data (Lott)",
    "text": "Demographic Data (Lott)\n\nLOTT_AGE_GROUPS_NULL <- c(\"Under 5 years\",\n                          \"5 to 9 years\")\n\ndem_LOTT <- dem |>\n  filter(!(AGE_GROUP %in% LOTT_AGE_GROUPS_NULL) )|>\n  mutate(AGE_GROUP = fct_collapse(AGE_GROUP,\n                                  \"10 to 19 years\"=c(\"10 to 14 years\", \"15 to 19 years\"),\n                                  \"20 to 29 years\"=c(\"20 to 24 years\", \"25 to 29 years\"),\n                                  \"30 to 39 years\"=c(\"30 to 34 years\", \"35 to 39 years\"),\n                                  \"40 to 49 years\"=c(\"40 to 44 years\", \"45 to 49 years\"),\n                                  \"50 to 64 years\"=c(\"50 to 54 years\", \"55 to 59 years\",\n                                                     \"60 to 64 years\"),\n                                  \"65 years and over\"=c(\"65 to 69 years\", \"70 to 74 years\", \n                                                        \"75 to 79 years\", \"80 to 84 years\",\n                                                        \"85 years and over\")),\n         AGE_GROUP = str_replace_all(AGE_GROUP, \" \", \"_\")) |>\n  group_by(YEAR, STATE, RACE, SEX, AGE_GROUP) |>\n  summarize(PERC_SUB_POP = sum(PERC_SUB_POP), .groups = \"drop\") |>\n  unite(col = \"VARIABLE\", RACE, SEX, AGE_GROUP, sep = \"_\") |>\n  rename(\"VALUE\" = PERC_SUB_POP)\n\nglimpse(dem_LOTT)\n\nRows: 62,424\nColumns: 4\n$ YEAR     <dbl> 1977, 1977, 1977, 1977, 1977, 1977, 1977, 1977, 1977, 1977, 1…\n$ STATE    <chr> \"Alabama\", \"Alabama\", \"Alabama\", \"Alabama\", \"Alabama\", \"Alaba…\n$ VARIABLE <chr> \"Black_Female_10_to_19_years\", \"Black_Female_20_to_29_years\",…\n$ VALUE    <dbl> 3.01067713, 2.32860137, 1.29295656, 1.18231753, 1.73263106, 1…"
  },
  {
    "objectID": "content/lectures/11-cs01-data.html#combine-population-data",
    "href": "content/lectures/11-cs01-data.html#combine-population-data",
    "title": "11-cs01-data",
    "section": "Combine: Population Data",
    "text": "Combine: Population Data\n\npopulation_data <- bind_rows(pop_77_79,\n                             pop_80_89,\n                             pop_90_99,\n                             pop_00_10)\n\npopulation_data <- population_data |>\n  mutate(VARIABLE = \"Population\") |>\n  rename(\"VALUE\" = TOT_POP)"
  },
  {
    "objectID": "content/lectures/11-cs01-data.html#wrangling-police-staffing",
    "href": "content/lectures/11-cs01-data.html#wrangling-police-staffing",
    "title": "11-cs01-data",
    "section": "Wrangling: Police staffing",
    "text": "Wrangling: Police staffing\n\n# the provided dataset has already had a bit of wrangling done for you\nps_data\n\n# A tibble: 2,242 × 3\n   data_year state_abbr officer_state_total\n       <dbl> <chr>                    <dbl>\n 1      1977 AK                         544\n 2      1977 AL                        7380\n 3      1977 AR                        3344\n 4      1977 AS                           0\n 5      1977 AZ                        6414\n 6      1977 CA                       65596\n 7      1977 CO                        7337\n 8      1977 CT                        6051\n 9      1977 CZ                           0\n10      1977 DC                        4751\n# … with 2,232 more rows\n\n\n\n\nremove territories\n\nstate_of_interest_NULL <- c(\"AS\", \"GM\", \"CZ\", \"FS\", \"MP\", \"OT\", \"PR\", \"VI\")\n\nps_data <- ps_data |>\n  filter(!(state_abbr %in% state_of_interest_NULL)) \n\n\n\nUse state abbreviations\n\nstate_abb_data <- tibble(\"state_abbr\" = state.abb, \"STATE\" = state.name)\nstate_abb_data <- state_abb_data |>\n  mutate(state_abbr = str_replace(string = state_abbr, \n                                  pattern = \"NE\", \n                                  replacement = \"NB\")) |>\n  add_row(state_abbr = \"DC\", STATE = \"District of Columbia\")\n\nps_data <- ps_data |> \n  left_join(state_abb_data, by = \"state_abbr\") |>\n  select(-state_abbr) |> \n  rename(YEAR = \"data_year\",\n         VALUE = \"officer_state_total\") |>\n  mutate(VARIABLE = \"officer_state_total\")\n\nps_data\n\n# A tibble: 1,938 × 4\n    YEAR VALUE STATE                VARIABLE           \n   <dbl> <dbl> <chr>                <chr>              \n 1  1977   544 Alaska               officer_state_total\n 2  1977  7380 Alabama              officer_state_total\n 3  1977  3344 Arkansas             officer_state_total\n 4  1977  6414 Arizona              officer_state_total\n 5  1977 65596 California           officer_state_total\n 6  1977  7337 Colorado             officer_state_total\n 7  1977  6051 Connecticut          officer_state_total\n 8  1977  4751 District of Columbia officer_state_total\n 9  1977  1018 Delaware             officer_state_total\n10  1977 24588 Florida              officer_state_total\n# … with 1,928 more rows\n\n\n\n\nScaling\n\ndenominator_temp <- population_data |> \n  select(-VARIABLE) |>\n  rename(\"Population_temp\"=VALUE) \n\nps_data <- ps_data |> \n  left_join(denominator_temp, by=c(\"STATE\",\"YEAR\")) |>\n  mutate(VALUE = (VALUE * 100000) / Population_temp) |>\n  mutate(VARIABLE = \"police_per_100k_lag\") |>\n  select(-Population_temp)\n\nhead(ps_data)\n\n# A tibble: 6 × 4\n   YEAR VALUE STATE      VARIABLE           \n  <dbl> <dbl> <chr>      <chr>              \n1  1977  137. Alaska     police_per_100k_lag\n2  1977  195. Alabama    police_per_100k_lag\n3  1977  152. Arkansas   police_per_100k_lag\n4  1977  264. Arizona    police_per_100k_lag\n5  1977  293. California police_per_100k_lag\n6  1977  272. Colorado   police_per_100k_lag"
  },
  {
    "objectID": "content/lectures/11-cs01-data.html#wrangling-poverty-rate",
    "href": "content/lectures/11-cs01-data.html#wrangling-poverty-rate",
    "title": "11-cs01-data",
    "section": "Wrangling: Poverty Rate",
    "text": "Wrangling: Poverty Rate\n\n\n# A tibble: 5 × 6\n  `NOTE: Number in thousands.` ...2  ...3   ...4              ...5         ...6 \n  <chr>                        <chr> <chr>  <chr>             <chr>        <chr>\n1 2018                         <NA>  <NA>    <NA>             <NA>          <NA>\n2 STATE                        Total Number \"Standard\\nerror\" Percent      \"Sta…\n3 Alabama                      4877  779    \"65\"              16           \"1.3\"\n4 Alaska                       720   94     \"9\"               13.1         \"1.2\"\n5 Arizona                      7241  929    \"80\"              12.80000000… \"1.1…\n\n\n\n\ncolnames(poverty_rate_data) <- c(\"STATE\", \"Total\", \"Number\", \"Number_se\",\n                                 \"Percent\", \"Percent_se\")\n\npoverty_rate_data <- poverty_rate_data |>\n  filter(STATE != \"STATE\") |> \n  mutate(length_state = map_dbl(STATE, str_length)) |> # determine how long string in \"STATE\" column is\n  filter(length_state < 100) |> # filter to only include possible state lengths\n  mutate(STATE = str_replace(STATE, pattern = \"D.C.\", \n                              replacement = \"District of Columbia\" )) \n\nyear_values <- poverty_rate_data |>\n  filter(str_detect(STATE, \"[:digit:]\")) |>\n  distinct(STATE)\nyear_values <- rep(pull(year_values, STATE), each = 52) # repeat values from STATE column 52 times each\n\npoverty_rate_data <- poverty_rate_data |>\n  mutate(year_value = year_values) |>\n  select(-length_state) |>\n  filter(str_detect(STATE, \"[:alpha:]\"))\n\npoverty_rate_data <- poverty_rate_data |>\n  filter(year_value != \"2017\") |> \n  filter(year_value != \"2013 (18)\") |>\n  mutate(YEAR = str_sub(year_value, start = 1, end = 4)) |>\n  select(-c(Number, Number_se, Percent_se, Total, year_value)) |>\n  rename(\"VALUE\" = Percent) |>\n  mutate(VARIABLE = \"Poverty_rate\",\n         YEAR = as.numeric(YEAR),\n         VALUE = as.numeric(VALUE))\n\npoverty_rate_data\n\n# A tibble: 1,989 × 4\n   STATE                VALUE  YEAR VARIABLE    \n   <chr>                <dbl> <dbl> <chr>       \n 1 Alabama               16    2018 Poverty_rate\n 2 Alaska                13.1  2018 Poverty_rate\n 3 Arizona               12.8  2018 Poverty_rate\n 4 Arkansas              15.9  2018 Poverty_rate\n 5 California            11.9  2018 Poverty_rate\n 6 Colorado               9.1  2018 Poverty_rate\n 7 Connecticut           10.2  2018 Poverty_rate\n 8 Delaware               7.4  2018 Poverty_rate\n 9 District of Columbia  14.7  2018 Poverty_rate\n10 Florida               13.7  2018 Poverty_rate\n# … with 1,979 more rows"
  },
  {
    "objectID": "content/lectures/11-cs01-data.html#wrangling-crime-data",
    "href": "content/lectures/11-cs01-data.html#wrangling-crime-data",
    "title": "11-cs01-data",
    "section": "Wrangling: Crime Data",
    "text": "Wrangling: Crime Data\n\ncrime_data <- crime_data[-((str_which(crime_data, \"The figures shown in this column for the offense of rape were estimated using the legacy UCR definition of rape\")-1): length(crime_data)+1)]\n\nn_rows <- 2014-1977+1 # determine how many rows there are for each state\nrep_cycle <- 4 + n_rows\nrep_cycle_cut <- 2 + n_rows\ncolnames_crime <- (crime_data[4])\n\n# specify which rows are to be deleted based on the file format\ndelete_rows <- c(seq(from = 2, \n                       to = length(crime_data),  \n                       by = rep_cycle),\n                 seq(from = 3, \n                       to = length(crime_data),\n                       by = rep_cycle), \n                 seq(from = 4,\n                       to = length(crime_data),\n                       by = rep_cycle))\nsort(delete_rows) # which rows are to be deleted\n\n  [1]    2    3    4   44   45   46   86   87   88  128  129  130  170  171  172\n [16]  212  213  214  254  255  256  296  297  298  338  339  340  380  381  382\n [31]  422  423  424  464  465  466  506  507  508  548  549  550  590  591  592\n [46]  632  633  634  674  675  676  716  717  718  758  759  760  800  801  802\n [61]  842  843  844  884  885  886  926  927  928  968  969  970 1010 1011 1012\n [76] 1052 1053 1054 1094 1095 1096 1136 1137 1138 1178 1179 1180 1220 1221 1222\n [91] 1262 1263 1264 1304 1305 1306 1346 1347 1348 1388 1389 1390 1430 1431 1432\n[106] 1472 1473 1474 1514 1515 1516 1556 1557 1558 1598 1599 1600 1640 1641 1642\n[121] 1682 1683 1684 1724 1725 1726 1766 1767 1768 1808 1809 1810 1850 1851 1852\n[136] 1892 1893 1894 1934 1935 1936 1976 1977 1978 2018 2019 2020 2060 2061 2062\n[151] 2102 2103 2104\n\n# convince yourself you did it right\n# should these rows be deleted?\ncrime_data[44:46]\n\n[1] \",,National or state crime,,,,,,,\"                                                                                                   \n[2] \",,Violent crime,,,,,,,\"                                                                                                             \n[3] \"Year,Population,Violent crime total,Murder and nonnegligent Manslaughter,Legacy rape /1,Revised rape /2,Robbery,Aggravated assault,\"\n\ncrime_data <- crime_data[-delete_rows]\n\n# extract state labels from data\nstate_labels <- crime_data[str_which(crime_data, \"Estimated crime in \")]\nstate_labels <- str_remove(state_labels, pattern = \"Estimated crime in \")\nstate_label_order <- rep(state_labels, each = n_rows) # repeat n_rows times\n\ncrime_data <- crime_data[-str_which(crime_data, \"Estimated crime\")]\ncrime_data_sep <- read_csv(I(crime_data), col_names = FALSE) |> \n  select(-X6) # remove random extra-comma column\n\n# get column names for later\ncolnames(crime_data_sep) <- c(\"Year\", \n                              \"Population\", \n                              \"Violent_crime_total\",\n                              \"Murder_and_nonnegligent_Manslaughter\",\n                              \"Legacy_rape\",\n                              \"Revised_rape\", \n                              \"Robbery\",\n                              \"Aggravated_assault\")\n# add column names in\ncrime_data_sep <- bind_cols(STATE = state_label_order, crime_data_sep)\n\ncrime_data <- crime_data_sep |>\n  mutate(VARIABLE = \"Viol_crime_count\") |>\n  rename(\"VALUE\" = Violent_crime_total) |>\n  rename(\"YEAR\" = Year) |>\n  select(YEAR,STATE, VARIABLE, VALUE)\n\ncrime_data\n\n# A tibble: 1,938 × 4\n    YEAR STATE   VARIABLE         VALUE\n   <dbl> <chr>   <chr>            <dbl>\n 1  1977 Alabama Viol_crime_count 15293\n 2  1978 Alabama Viol_crime_count 15682\n 3  1979 Alabama Viol_crime_count 15578\n 4  1980 Alabama Viol_crime_count 17320\n 5  1981 Alabama Viol_crime_count 18423\n 6  1982 Alabama Viol_crime_count 17653\n 7  1983 Alabama Viol_crime_count 16471\n 8  1984 Alabama Viol_crime_count 17204\n 9  1985 Alabama Viol_crime_count 18398\n10  1986 Alabama Viol_crime_count 22616\n# … with 1,928 more rows"
  },
  {
    "objectID": "content/lectures/11-cs01-data.html#wrangling-rtc-laws",
    "href": "content/lectures/11-cs01-data.html#wrangling-rtc-laws",
    "title": "11-cs01-data",
    "section": "Wrangling: RTC Laws",
    "text": "Wrangling: RTC Laws\n\nDAWpaper_p_62 <- DAWpaper[[62]]\nstr(DAWpaper_p_62, nchar.max = 1000) # see data\n\n chr \"                                          Table A1: RTC Adoption Dates\\n\\n         State         Effective Date of RTC Law   Fraction of Year In Effect Year of Passage   RTC Date (Synthetic Controls Analysis)\\n      Alabama                      1975                                                                        1975\\n       Alaska                   10/1/1994                            0.252                                     1995\\n       Arizona                  7/17/1994                            0.460                                     1995\\n      Arkansas                  7/27/1995                            0.433                                     1996\\n     California                    N/A                                                                            0\\n      Colorado                  5/17/2003                            0.627                                     2003\\n    Connecticut                    1970                                \"| __truncated__\n\np_62 <- DAWpaper_p_62 |>\n  str_split(\"\\n\") |>\n  unlist() |>\n  as_tibble() |>\n  slice(-(1:2)) |> \n  rename(RTC = value) |>\n  slice(-c(53:54)) |>  # physical page 60 marking; empty line removal\n  mutate(RTC = str_replace_all(RTC, \"\\\\s{40,}\", \"|N/A|\"),\n         RTC = str_trim(RTC, side = \"left\"),\n         RTC = str_replace_all(RTC, \"\\\\s{2,15}\", \"|\"))\n\nhead(p_62)\n\n# A tibble: 6 × 1\n  RTC                                                                           \n  <chr>                                                                         \n1 State|Effective Date of RTC Law|Fraction of Year In Effect Year of Passage|RT…\n2 Alabama||1975|N/A|1975                                                        \n3 Alaska||10/1/1994||0.252|||1995                                               \n4 Arizona||7/17/1994||0.460|||1995                                              \n5 Arkansas||7/27/1995||0.433|||1996                                             \n6 California||N/A|N/A|0                                                         \n\np_62 <- pull(p_62, RTC) |>\n  str_split( \"\\\\|{1,}\")  # split data on \"|\" symbol\n\n# get the tibble!\np_62 <- as_tibble(do.call(rbind, p_62)) # rbind and not bind_cols here b/c we have no column names yet\n\ncolnames(p_62) <- c(\"STATE\",\n                    \"E_Date_RTC\",\n                    \"Frac_Yr_Eff_Yr_Pass\",\n                    \"RTC_Date_SA\")\n\np_62 <- p_62 |>\n  slice(-c(1, 53:nrow(p_62))) # remove unnecessary rows\n\nRTC <- p_62 |> \n  select(STATE, RTC_Date_SA) |>\n  rename(RTC_LAW_YEAR = RTC_Date_SA) |>\n  mutate(RTC_LAW_YEAR = as.numeric(RTC_LAW_YEAR)) |>\n  mutate(RTC_LAW_YEAR = case_when(RTC_LAW_YEAR == 0 ~ Inf,\n                                  TRUE ~ RTC_LAW_YEAR))"
  },
  {
    "objectID": "content/lectures/11-cs01-data.html#wrangling-combining-donohue",
    "href": "content/lectures/11-cs01-data.html#wrangling-combining-donohue",
    "title": "11-cs01-data",
    "section": "Wrangling: Combining! (Donohue)",
    "text": "Wrangling: Combining! (Donohue)\n\n# combine after all that wrangling!\nDONOHUE_DF <- bind_rows(dem_DONOHUE,\n                        ue_rate_data,\n                        poverty_rate_data,\n                        crime_data,\n                        population_data,\n                        ps_data)\nDONOHUE_DF\n\n# A tibble: 20,247 × 4\n    YEAR STATE   VARIABLE                    VALUE\n   <dbl> <chr>   <chr>                       <dbl>\n 1  1977 Alabama Black_Male_15_to_19_years  1.55  \n 2  1977 Alabama Black_Male_20_to_39_years  3.04  \n 3  1977 Alabama Other_Male_15_to_19_years  0.0178\n 4  1977 Alabama Other_Male_20_to_39_years  0.0642\n 5  1977 Alabama White_Male_15_to_19_years  3.58  \n 6  1977 Alabama White_Male_20_to_39_years 11.1   \n 7  1977 Alaska  Black_Male_15_to_19_years  0.163 \n 8  1977 Alaska  Black_Male_20_to_39_years  0.968 \n 9  1977 Alaska  Other_Male_15_to_19_years  1.12  \n10  1977 Alaska  Other_Male_20_to_39_years  2.73  \n# … with 20,237 more rows\n\n# to wide format!\nDONOHUE_DF <- DONOHUE_DF |>\n  pivot_wider(names_from = \"VARIABLE\",\n              values_from = \"VALUE\")\n\n# add in RTC data!\nDONOHUE_DF <- DONOHUE_DF |>\n  left_join(RTC , by = c(\"STATE\")) |>\n  mutate(RTC_LAW = case_when(YEAR >= RTC_LAW_YEAR ~ TRUE,\n                              TRUE ~ FALSE)) |>\n drop_na() # drop rows with missing information\n\n# filter to only data where RTC laws were adopted between 1980-2010\n# have crime data pre- and post-adoption this way\nbaseline_year <- min(DONOHUE_DF$YEAR)\ncensoring_year <- max(DONOHUE_DF$YEAR)\n\nDONOHUE_DF <- DONOHUE_DF |>\n  mutate(TIME_0 = baseline_year,\n         TIME_INF = censoring_year) |>\n  filter(RTC_LAW_YEAR > TIME_0)\n\n# calculate violent crime rate; put population/crime on log scale\nDONOHUE_DF <- DONOHUE_DF |>\n  mutate(Viol_crime_rate_1k = (Viol_crime_count*1000)/Population,\n         Viol_crime_rate_1k_log = log(Viol_crime_rate_1k),\n         Population_log = log(Population))\n\nDONOHUE_DF |>\n  slice_sample(n = 10) |>\n  glimpse()\n\nRows: 10\nColumns: 20\n$ YEAR                      <dbl> 1983, 1995, 1993, 1984, 1989, 1980, 1985, 20…\n$ STATE                     <chr> \"South Dakota\", \"Illinois\", \"Missouri\", \"Mon…\n$ Black_Male_15_to_19_years <dbl> 0.02337605, 0.66743318, 0.45968150, 0.016324…\n$ Black_Male_20_to_39_years <dbl> 0.12582664, 2.25592315, 1.64776640, 0.076017…\n$ Other_Male_15_to_19_years <dbl> 0.38007726, 0.12976933, 0.05750553, 0.307235…\n$ Other_Male_20_to_39_years <dbl> 0.9747236, 0.5522369, 0.2520735, 0.8877189, …\n$ White_Male_15_to_19_years <dbl> 3.740601, 2.799039, 2.977038, 3.710706, 2.97…\n$ White_Male_20_to_39_years <dbl> 14.73961, 12.65294, 13.16111, 15.34327, 13.6…\n$ Unemployment_rate         <dbl> 5.2, 5.2, 6.2, 7.6, 6.0, 6.6, 9.1, 4.3, 9.9,…\n$ Poverty_rate              <dbl> 18.4, 12.4, 16.1, 13.8, 12.7, 12.8, 15.6, 10…\n$ Viol_crime_count          <dbl> 840, 117836, 38963, 1958, 98611, 17673, 8244…\n$ Population                <dbl> 693017, 11884935, 5237757, 820868, 11409801,…\n$ police_per_100k_lag       <dbl> 177.7734, 356.9224, 275.3469, 245.8373, 318.…\n$ RTC_LAW_YEAR              <dbl> 1985, 2014, 2004, 1992, 2014, 1995, 2014, 20…\n$ RTC_LAW                   <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FA…\n$ TIME_0                    <dbl> 1980, 1980, 1980, 1980, 1980, 1980, 1980, 19…\n$ TIME_INF                  <dbl> 2010, 2010, 2010, 2010, 2010, 2010, 2010, 20…\n$ Viol_crime_rate_1k        <dbl> 1.212091, 9.914737, 7.438871, 2.385280, 8.64…\n$ Viol_crime_rate_1k_log    <dbl> 0.1923474, 2.2940222, 2.0067191, 0.8693165, …\n$ Population_log            <dbl> 13.44881, 16.29078, 15.47140, 13.61812, 16.2…"
  },
  {
    "objectID": "content/lectures/11-cs01-data.html#wrangling-combining-lott",
    "href": "content/lectures/11-cs01-data.html#wrangling-combining-lott",
    "title": "11-cs01-data",
    "section": "Wrangling: Combining! (Lott)",
    "text": "Wrangling: Combining! (Lott)\n\nLOTT_DF <- bind_rows(dem_LOTT,\n                     ue_rate_data,\n                     poverty_rate_data,\n                     crime_data,\n                     population_data,\n                     ps_data) |>\n  pivot_wider(names_from = \"VARIABLE\",\n              values_from = \"VALUE\") |>\n  left_join(RTC , by = c(\"STATE\")) |>\n  mutate(RTC_LAW = case_when(YEAR >= RTC_LAW_YEAR ~ TRUE,\n                              TRUE ~ FALSE)) |>\n   drop_na()\n\nbaseline_year <- min(LOTT_DF$YEAR)\ncensoring_year <- max(LOTT_DF$YEAR)\n\nLOTT_DF <- LOTT_DF |>\n  mutate(TIME_0 = baseline_year,\n         TIME_INF = censoring_year) |>\n  filter(RTC_LAW_YEAR > TIME_0)\n\nLOTT_DF <- LOTT_DF |>\n  mutate(Viol_crime_rate_1k = (Viol_crime_count*1000)/Population,\n         Viol_crime_rate_1k_log = log(Viol_crime_rate_1k),\n         Population_log = log(Population))\n\nLOTT_DF\n\n# A tibble: 1,364 × 50\n    YEAR STATE   Black…¹ Black…² Black…³ Black…⁴ Black…⁵ Black…⁶ Black…⁷ Black…⁸\n   <dbl> <chr>     <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1  1980 Alaska   0.264    0.443  0.201   0.116   0.0924 0.0264    0.297   0.695\n 2  1980 Arizona  0.287    0.278  0.165   0.119   0.136  0.103     0.311   0.338\n 3  1980 Arkans…  1.82     1.50   0.842   0.634   1.02   1.16      1.81    1.26 \n 4  1980 Califo…  0.780    0.815  0.581   0.394   0.456  0.292     0.808   0.815\n 5  1980 Colora…  0.352    0.388  0.245   0.172   0.164  0.103     0.377   0.467\n 6  1980 Delawa…  1.87     1.68   1.14    0.783   0.952  0.670     1.81    1.36 \n 7  1980 Distri…  6.53     7.54   5.18    3.89    6.10   4.15      6.32    6.40 \n 8  1980 Florida  1.50     1.37   0.912   0.679   0.812  0.604     1.49    1.20 \n 9  1980 Georgia  2.90     2.78   1.85    1.22    1.56   1.35      2.92    2.45 \n10  1980 Hawaii   0.0930   0.215  0.0776  0.0253  0.0197 0.00738   0.180   0.656\n# … with 1,354 more rows, 40 more variables: Black_Male_30_to_39_years <dbl>,\n#   Black_Male_40_to_49_years <dbl>, Black_Male_50_to_64_years <dbl>,\n#   Black_Male_65_years_and_over <dbl>, Other_Female_10_to_19_years <dbl>,\n#   Other_Female_20_to_29_years <dbl>, Other_Female_30_to_39_years <dbl>,\n#   Other_Female_40_to_49_years <dbl>, Other_Female_50_to_64_years <dbl>,\n#   Other_Female_65_years_and_over <dbl>, Other_Male_10_to_19_years <dbl>,\n#   Other_Male_20_to_29_years <dbl>, Other_Male_30_to_39_years <dbl>, …"
  },
  {
    "objectID": "content/lectures/11-cs01-data.html#why",
    "href": "content/lectures/11-cs01-data.html#why",
    "title": "11-cs01-data",
    "section": "Why?",
    "text": "Why?\n❓ Why are there different dimensions for LOTT vs DONOHUE??\n\ndim(LOTT_DF)\n\n[1] 1364   50\n\n\n\ndim(DONOHUE_DF)\n\n[1] 1364   20"
  },
  {
    "objectID": "content/lectures/11-cs01-data.html#things-to-consider",
    "href": "content/lectures/11-cs01-data.html#things-to-consider",
    "title": "11-cs01-data",
    "section": "Things to Consider",
    "text": "Things to Consider\n\n\nHow RMarkdown documents work\nHow to control what is executed each time you render\nWhat to do with all this after this lecture?"
  },
  {
    "objectID": "content/lectures/11-cs01-data.html#save",
    "href": "content/lectures/11-cs01-data.html#save",
    "title": "11-cs01-data",
    "section": "Save",
    "text": "Save\n\nsave(LOTT_DF, DONOHUE_DF, file = \"data/wrangled/wrangled_data_rtc.rda\")"
  },
  {
    "objectID": "content/lectures/08-effective-communication-slides.html#course-announcements",
    "href": "content/lectures/08-effective-communication-slides.html#course-announcements",
    "title": "08-effective-communication",
    "section": "Course Announcements",
    "text": "Course Announcements\n\nLecture Participation survey “due” after class\nMidterm due Monday (2/13; 11:59 PM):\n\nreleased Friday after lab\ncompleted individually\n\n\n\n\nPractice Midterm Posted (Answer key posted Wed/tomorrow)\nLab03 & Lab04 Scores & Feedback Posted\nLab04 Notes:\n\nModel Interpretations\nText, code, & viz all matter\n\nLink for Later"
  },
  {
    "objectID": "content/lectures/08-effective-communication-slides.html#agenda",
    "href": "content/lectures/08-effective-communication-slides.html#agenda",
    "title": "08-effective-communication",
    "section": "Agenda",
    "text": "Agenda\n\nCommunicating for your audience\nOral Communication\nWritten Communication\nVisual Communication"
  },
  {
    "objectID": "content/lectures/08-effective-communication-slides.html#what-does-this-mean",
    "href": "content/lectures/08-effective-communication-slides.html#what-does-this-mean",
    "title": "08-effective-communication",
    "section": "What does this mean?",
    "text": "What does this mean?\n❓ What does it mean to “consider your audience?”\n\nSimply: You do the work so they don’t have to.\n\n\n…also the aesthetic-usability effect exists."
  },
  {
    "objectID": "content/lectures/08-effective-communication-slides.html#whats-the-right-level",
    "href": "content/lectures/08-effective-communication-slides.html#whats-the-right-level",
    "title": "08-effective-communication",
    "section": "What’s the right level?",
    "text": "What’s the right level?\n\n\nGeneral Audience\n✔ background\n🚫 limit technical details\n🎉 emphasize take-home\n\n\n\nTechnical Audience\n⬇ limit background\n💻 all-the-details\n🎉 emphasize take-home"
  },
  {
    "objectID": "content/lectures/08-effective-communication-slides.html#considerations",
    "href": "content/lectures/08-effective-communication-slides.html#considerations",
    "title": "08-effective-communication",
    "section": "Considerations",
    "text": "Considerations\n\nPlatform: written? oral?\n\n\n\nSetting: informal? formal?\n\n\n\n\nTiming: never go over your time limit!"
  },
  {
    "objectID": "content/lectures/08-effective-communication-slides.html#storytelling",
    "href": "content/lectures/08-effective-communication-slides.html#storytelling",
    "title": "08-effective-communication",
    "section": "Storytelling",
    "text": "Storytelling\n\nStories have a beginning, a middle, and an end.\n\n\n\nStories do not need every detail of what you’ve tried\n\n\n\n\nReports and presentations should tell a story\nPlanning out your report/presentation can help\n\n\n\n\nHold the audience’s attention with what needs to be said; do so effectively\nTell your audience why they should care; why it matters\nYou should explain your choices and the “why”"
  },
  {
    "objectID": "content/lectures/08-effective-communication-slides.html#choose-informative-titles",
    "href": "content/lectures/08-effective-communication-slides.html#choose-informative-titles",
    "title": "08-effective-communication",
    "section": "Choose informative titles",
    "text": "Choose informative titles\nOn presentations: Balance b/w short and informative (goal: concise)\n\n\nAvoid: “Analyzing NHANES”\n\nBetter: “Data from the NHANES study shows that diet is related to overall health”\n\n\nOn visualizations: emphasize the take-home! (what’s learned or what action to take)\n\n\n\nAvoid: “Boxplot of gender”\n\nBetter: “Twice as many females as males included for analysis”\n\n\n\nAvoid: “Tickets vs. Time”\n\nBetter: “Staff unable to respond to incoming tickets; need to hire 2 FTEs”"
  },
  {
    "objectID": "content/lectures/08-effective-communication-slides.html#student-responses",
    "href": "content/lectures/08-effective-communication-slides.html#student-responses",
    "title": "08-effective-communication",
    "section": "Student responses",
    "text": "Student responses\n\n\n\n\n\nAdvice you've received\n\n\n\n\nSpeak loudly and clearly enough for everyone to hear (project your voice!); be engaging so that people are inclined to pay attention\n\n\nMake eye contact with your audience as you speak\n\n\nDon't just read off slides, and (most of the time) don't read from a script\n\n\nloud and clear voice\n\n\nPosture, eye contact, and mannerisms can all influence oral presentation performance. While presenting don't stand in one spot, get up, move around and engage with the audience.\n\n\ntry harder to better word choice\n\n\nLook at the audience when I am talking to them. Speak loud and clear.\n\n\nEye contact!!!\n\n\neye contact, try not to use filler words, talk slower than you would normally, don't just read off of the slides\n\n\ndont overcomplicate the wording, what might make sense to you might be revolutionary to someone else. Using simple words for simple explainations for begginer simple thought processes\n\n\ndrink water constantly\n\n\nmaking enough eye contact"
  },
  {
    "objectID": "content/lectures/08-effective-communication-slides.html#presentations-are-for-listening",
    "href": "content/lectures/08-effective-communication-slides.html#presentations-are-for-listening",
    "title": "08-effective-communication",
    "section": "Presentations are for listening",
    "text": "Presentations are for listening\n\nAdvantage: words to explain out loud what you’re showing\n\n\n\nYou are presenting for the person in the back of the room.\n\n\n\nTo accomplish:\n\ndon’t read directly off slides\nrepetition is ok: tell what you’re going to tell them, tell them, tell them what you told them\nuse animation to build your story (not to distract)\nintroduce your axes\ntext/labels larger\nwatch your speech speed\npractice!"
  },
  {
    "objectID": "content/lectures/08-effective-communication-slides.html#for-example-a-happy-ending-for-almost-everyone-in-little-red-riding-hood",
    "href": "content/lectures/08-effective-communication-slides.html#for-example-a-happy-ending-for-almost-everyone-in-little-red-riding-hood",
    "title": "08-effective-communication",
    "section": "For Example: A Happy Ending for (almost) everyone in Little Red Riding Hood",
    "text": "For Example: A Happy Ending for (almost) everyone in Little Red Riding Hood\n\nRed Riding Hood (RRH) has to walk 0.54 mi from Point A (home) to Point B (Grandma’s)\nRRH meets Wolf who (1) runs ahead to Grandma’s, (2) eats her, and (3) dresses in her clothes\nRRH arrives at Grandmas at 2PM, asks her three questions\nIdentified problem: after third question, Wolf eats RRH\nSolution: vendor (Woodsman) employs tool (ax)\nExpected outcome: Grandma and RRH alive, wolf is not"
  },
  {
    "objectID": "content/lectures/08-effective-communication-slides.html#student-responses-1",
    "href": "content/lectures/08-effective-communication-slides.html#student-responses-1",
    "title": "08-effective-communication",
    "section": "Student responses",
    "text": "Student responses\n\n\n\n\n\nAdvice you've received\n\n\n\n\nYour rough draft should be rough. Don't polish it because it will flush all your great ideas away.\n\n\nInclude data/metrics that highlight quantifiable impact of work.\n\n\nbe concise when writing\n\n\nshorter sentences = good\n\n\nState your main point clearly; use good grammar\n\n\ndon't use crazy fonts and coloring. If things need to be emphasized stick to italics bold and font size generally speaking.\n\n\nDisplay contents of slides in a left to right fashion.\n\n\nUse clear fonts.\n\n\nas concise as possible\n\n\nIf it's a presentation, less wording is often better. Use oral communication to fill in gaps between the main points\n\n\nRead what you write in between every iteration. Try to avoid repeating words - show some variety. Use punctuation well. Split up paragraphs; monolithic walls of text are intimidating and readers will skip them. It's cliche, but for a reason - the topic, argument, evidence structure is effective.\n\n\nExplicitly write out the opposing arguments/concerns in your paper and answer them as best you can. That way the paper feels more like a conversation with the author than just something to read.\n\n\nMake sentences flow well. Include a conclusion to summarize\n\n\nstay on topic, summarize main points at end,\n\n\nRepeat the point you want the readers to remember"
  },
  {
    "objectID": "content/lectures/08-effective-communication-slides.html#benefits-of-written-communciation",
    "href": "content/lectures/08-effective-communication-slides.html#benefits-of-written-communciation",
    "title": "08-effective-communication",
    "section": "Benefits of written communciation",
    "text": "Benefits of written communciation\nYour audience has time to process…but the explanation has to be there!\n\nVisually: more on a single visualization\n\n\nYes, often there are different visualizations for reports/papers than for presentations/lectures."
  },
  {
    "objectID": "content/lectures/08-effective-communication-slides.html#when-you-have-time-to-digest-read",
    "href": "content/lectures/08-effective-communication-slides.html#when-you-have-time-to-digest-read",
    "title": "08-effective-communication",
    "section": "When you have time to digest (read)",
    "text": "When you have time to digest (read)\n\n\n❓ What makes this an effective visualization for a written communication?”\nSource: Storytelling wtih data by cole nussbaumer knaflic"
  },
  {
    "objectID": "content/lectures/08-effective-communication-slides.html#data-science-reports-in-.rmd",
    "href": "content/lectures/08-effective-communication-slides.html#data-science-reports-in-.rmd",
    "title": "08-effective-communication",
    "section": "Data Science Reports in .Rmd",
    "text": "Data Science Reports in .Rmd\n\nAs concise as possible\nNecessary details (for your audience); nothing more\nTypical Sections: Introduction/Background, Setup, Data, Analysis, Conclusion, References"
  },
  {
    "objectID": "content/lectures/08-effective-communication-slides.html#controlling-html-document-settings",
    "href": "content/lectures/08-effective-communication-slides.html#controlling-html-document-settings",
    "title": "08-effective-communication",
    "section": "Controlling HTML document settings",
    "text": "Controlling HTML document settings\n\nTable of Contents\n\n---\ntitle: \"Document Title\"\noutput:\n  html_document:\n    toc: true\n    toc_float: true\n---\n\n\nTheme\n\n---\ntitle: \"Document Title\"\noutput:\n  html_document:\n    theme: united\n    highlight: tango\n---\n\n\n\nFigure Options\n\n---\ntitle: \"Document Title\"\noutput:\n  html_document:\n    fig_width: 7\n    fig_height: 6\n    fig_caption: true\n---\n\n\n\nCode Folding\n\n---\ntitle: \"Document Title\"\noutput:\n  html_document:\n    code_folding: hide\n---"
  },
  {
    "objectID": "content/lectures/08-effective-communication-slides.html#controlling-code-chunk-output",
    "href": "content/lectures/08-effective-communication-slides.html#controlling-code-chunk-output",
    "title": "08-effective-communication",
    "section": "Controlling code chunk output",
    "text": "Controlling code chunk output\n\nSpecified in the curly braces, separated by commas\n\n\n{r, chunk-label, results='hide', fig.height=4}\n\n\n\neval: whether to execute the code chunk\necho: whether to include the code in the output\nwarning, message, and error: whether to show warnings, messages, or errors in the knit document\nfig.width and fig.height: control the width/height of plots\n\n\n\n\nControlling for the whole document:\n\nknitr::opts_chunk$set(fig.width = 8, collapse = TRUE)"
  },
  {
    "objectID": "content/lectures/08-effective-communication-slides.html#editing-proofreading",
    "href": "content/lectures/08-effective-communication-slides.html#editing-proofreading",
    "title": "08-effective-communication",
    "section": "Editing & Proofreading",
    "text": "Editing & Proofreading\n\nDid you end up telling a story?\n\nThings missing?\nThings to delete?\n\n\n\n\nDo not fall in love with your words/code/plots\n\n\n\n\nDo spell check\nDo read it over before sending/presenting/submitting"
  },
  {
    "objectID": "content/lectures/08-effective-communication-slides.html#aside-citing-sources",
    "href": "content/lectures/08-effective-communication-slides.html#aside-citing-sources",
    "title": "08-effective-communication",
    "section": "Aside: Citing Sources",
    "text": "Aside: Citing Sources\nWhen are citations needed?\n\n\n\n“We will be doing our analysis using two different data sets created by two different groups: Donohue and Mustard + Lott, or simply Lott”\n\n\n\n\n\n\n“What turned from the idea of carrying firearms to protect oneself from enemies such as the British monarchy and the unknown frontier of North America has now become a nationwide issue.”\n\n\n\n\n\n\n“Right to Carry Laws refer to laws that specify how citizens are allowed to carry concealed handguns when they’re away from home without a permit”\n\n\n\n\n\n\n“In this case study, we are examining the relationship between unemployment rate, poverty rate, police staffing, and violent crime rate.”\n\n\n\n\n\n\n“In the United States, the second amendment permits the right to bear arms, and this law has not been changed since its creation in 1791.”\n\n\n\n\n\n\n“The Right to Carry Laws (RTC) is defined as “a law that specifies if and how citizens are allowed to have a firearm on their person or nearby in public.””\n\n\n\n\nReminder: You do NOT get docked points for citing others’ work. You can be at risk of AI Violation if you don’t. When in doubt, give credit."
  },
  {
    "objectID": "content/lectures/08-effective-communication-slides.html#footnotes-in-.rmd",
    "href": "content/lectures/08-effective-communication-slides.html#footnotes-in-.rmd",
    "title": "08-effective-communication",
    "section": "Footnotes in .Rmd",
    "text": "Footnotes in .Rmd\nHow to specify a footnote in text:\nHere is some body text.[^1]\nHow to include the footnote’s reference:\n[^1]: This footnote will appear at the bottom of the page.\n\n\nNote: .bib files can be included with BibTeX references using the bibliography parameter in your YAML"
  },
  {
    "objectID": "content/lectures/08-effective-communication-slides.html#student-responses-2",
    "href": "content/lectures/08-effective-communication-slides.html#student-responses-2",
    "title": "08-effective-communication",
    "section": "Student Responses",
    "text": "Student Responses\n\n\n\n\n\nAdvice you've received\n\n\n\n\nTry to make the title of the plot something descriptive rather than simply, eg, \"Time vs Length\" or \"linear regression of pet sizes\".\"\n\n\nshow the kind of plot that can be understood by audience\n\n\nI heard that when making a visual graphic, you should try remove as much as you can while still showing the necessary information. The less on the screen, the better.\n\n\nWhen giving a presentation, try to keep bullet points shorter than 7 words so it's easier digest/remember\n\n\nWhen displaying data and visualizations. Take note of people with eye color visualization disabilities. Also present things based on intuitive knowledge. Like reading left to right\n\n\nhighlighting only the important bits with color usage\n\n\n(picture / plot / visualization) > words\n\n\nUse appropriate colors and use them to highlight findings.\n\n\nMake plots big and clear\n\n\nSometimes simple is better, try to stay away from distracting visualizations\n\n\nUse appropriate (non-misleading) scales\n\n\nColors choices are important, and also remember about color blind people\n\n\nlabel axis, always include a title, use ticks if they help understand the data, think about color choices, big text\n\n\nInclude visuals only if they are meaningful and/or strengthen your argument"
  },
  {
    "objectID": "content/lectures/08-effective-communication-slides.html#the-glamour-of-graphics",
    "href": "content/lectures/08-effective-communication-slides.html#the-glamour-of-graphics",
    "title": "08-effective-communication",
    "section": "The Glamour of Graphics",
    "text": "The Glamour of Graphics\n\nbuilds on top of the grammar (components) of a graphic\nconsiderations for the design of a graphic\ncolor, typography, layout\ngoing from accurate to 😍effective\n\n\n\nThese ideas and slides are all modified from Will Chase’s rstudio::conf2020 slides/talk"
  },
  {
    "objectID": "content/lectures/08-effective-communication-slides.html#left-align-titles-at-top-left",
    "href": "content/lectures/08-effective-communication-slides.html#left-align-titles-at-top-left",
    "title": "08-effective-communication",
    "section": "Left-align titles at top-left",
    "text": "Left-align titles at top-left\n\n\n😬 Accurate\n\nggplot(penguins, aes(x = species, fill = species)) +\n  geom_bar() +\n  labs(title = \"Adelie Penguins are the most common in Antarctica\", \n       subtitle = \"Frequency of each penguin species studied near Palmer Station, Antarctica\") +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))\n\n\n\n\n\n😍 Effective\n\nggplot(penguins, aes(x = species, fill = species)) +\n  geom_bar() +\n  labs(title = \"Adelie Penguins are the most common in Antarctica\", \n       subtitle = \"Frequency of each penguin species studied near Palmer Station, Antarctica\") +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),\n        plot.title.position = \"plot\")"
  },
  {
    "objectID": "content/lectures/08-effective-communication-slides.html#avoid-head-tilting",
    "href": "content/lectures/08-effective-communication-slides.html#avoid-head-tilting",
    "title": "08-effective-communication",
    "section": "Avoid head-tilting",
    "text": "Avoid head-tilting\n\n\n😬 Accurate\n\nggplot(penguins, aes(x = species, fill = species)) +\n  geom_bar() +\n  labs(title = \"Adelie Penguins are the most common in Antarctica\", \n       subtitle = \"Frequency of each penguin species studied near Palmer Station, Antarctica\") +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),\n        plot.title.position = \"plot\")\n\n\n\n\n\n😍 Effective\n\nggplot(penguins, aes(y = species, fill = species)) +\n  geom_bar() +\n  labs(title = \"Adelie Penguins are the most common in Antarctica\", \n       subtitle = \"Frequency of each penguin species studied near Palmer Station, Antarctica\") +\n  theme(plot.title.position = \"plot\")"
  },
  {
    "objectID": "content/lectures/08-effective-communication-slides.html#borders-backgrounds",
    "href": "content/lectures/08-effective-communication-slides.html#borders-backgrounds",
    "title": "08-effective-communication",
    "section": "Borders & Backgrounds: 👎",
    "text": "Borders & Backgrounds: 👎\n\n\n😬 Accurate\n\nggplot(penguins, aes(y = species, fill = species)) +\n  geom_bar() +\n  labs(title = \"Adelie Penguins are the most common in Antarctica\", \n       subtitle = \"Frequency of each penguin species studied near Palmer Station, Antarctica\") +\n  theme_bw() +\n  theme(plot.title.position = \"plot\") \n\n\n\n\n\n😍 Effective\n\nggplot(penguins, aes(y = species, fill = species)) +\n  geom_bar() +\n  labs(title = \"Adelie Penguins are the most common in Antarctica\", \n       subtitle = \"Frequency of each penguin species studied near Palmer Station, Antarctica\") +\n  theme_minimal() +\n  theme(plot.title.position = \"plot\")"
  },
  {
    "objectID": "content/lectures/08-effective-communication-slides.html#organize-removelighten-as-much-as-possible",
    "href": "content/lectures/08-effective-communication-slides.html#organize-removelighten-as-much-as-possible",
    "title": "08-effective-communication",
    "section": "Organize & Remove/Lighten as much as possible",
    "text": "Organize & Remove/Lighten as much as possible\n\n\n😬 Accurate\n\nggplot(penguins, aes(y = species, fill = species)) +\n  geom_bar() +\n  labs(title = \"Adelie Penguins are the most common in Antarctica\", \n       subtitle = \"Frequency of each penguin species studied near Palmer Station, Antarctica\") +\n  theme_minimal() +\n  theme(plot.title.position = \"plot\") \n\n\n\n\n\n😍 Effective\n\nggplot(penguins, aes(y = fct_rev(fct_infreq(species)), fill = species)) +\n  geom_bar() +\n  geom_text(stat='count', aes(label=..count..), hjust = 1.5, color = \"white\", size = 6) +\n  scale_x_continuous(expand = c(0, 0)) +\n  scale_fill_manual(values = c(\"#454545\", rep(\"#adadad\", 2))) +\n  labs(title = \"Adelie Penguins are the most common in Antarctica\", \n       subtitle = \"Frequency of each penguin species studied near Palmer Station, Antarctica\") +\n  theme_minimal(base_size = 18) +\n  theme(axis.text.x = element_blank(),\n        plot.title.position = \"plot\", \n        panel.grid.major = element_blank(), panel.grid.minor = element_blank(),\n        axis.title = element_blank())"
  },
  {
    "objectID": "content/lectures/08-effective-communication-slides.html#legends-suck",
    "href": "content/lectures/08-effective-communication-slides.html#legends-suck",
    "title": "08-effective-communication",
    "section": "Legends suck",
    "text": "Legends suck\n\n\n😬 Accurate\n\nggplot(penguins, aes(y = fct_rev(fct_infreq(species)), fill = species)) +\n  geom_bar() +\n  geom_text(stat='count', aes(label=..count..), hjust = 1.5, color = \"white\", size = 6) +\n  scale_x_continuous(expand = c(0, 0)) +\n  scale_fill_manual(values = c(\"#454545\", rep(\"#adadad\", 2))) +\n  labs(title = \"Adelie Penguins are the most common in Antarctica\", \n       subtitle = \"Frequency of each penguin species studied near Palmer Station, Antarctica\") +\n  theme_minimal(base_size = 18) +\n  theme(axis.text.x = element_blank(),\n        plot.title.position = \"plot\", \n        panel.grid.major = element_blank(), panel.grid.minor = element_blank(),\n        axis.title = element_blank())\n\n\n\n\n\n😍 Effective\n\nggplot(penguins, aes(y = fct_rev(fct_infreq(species)), fill = species)) +\n  geom_bar() +\n  geom_text(stat='count', aes(label=..count..), hjust = 1.5, color = \"white\", size = 7) +\n  scale_x_continuous(expand = c(0, 0)) +\n  scale_fill_manual(values = c(\"#454545\", rep(\"#adadad\", 2))) +\n  labs(title = \"Adelie Penguins are the most common in Antarctica\", \n       subtitle = \"Frequency of each penguin species studied near Palmer Station, Antarctica\") +\n  theme_minimal(base_size = 20) +\n  theme(axis.text.x = element_blank(),\n        plot.title.position = \"plot\", \n        panel.grid.major = element_blank(), panel.grid.minor = element_blank(),\n        axis.title = element_blank(),\n        legend.position = \"none\")"
  },
  {
    "objectID": "content/lectures/08-effective-communication-slides.html#additional-guidance",
    "href": "content/lectures/08-effective-communication-slides.html#additional-guidance",
    "title": "08-effective-communication",
    "section": "Additional Guidance",
    "text": "Additional Guidance\n\nWhite space is like garlic - take the amount you need and triple it\nFonts Matter\nUse Color Effectively"
  },
  {
    "objectID": "content/lectures/08-effective-communication-slides.html#suggested-reading",
    "href": "content/lectures/08-effective-communication-slides.html#suggested-reading",
    "title": "08-effective-communication",
    "section": "Suggested Reading",
    "text": "Suggested Reading\n\nBookdown Section 2.6 R Code Chunks & inline R code\nBookdown Chapter 3: Documents\nWill Chase’s rstudio::conf2020 talk: “The Glamour of Graphics” [slides] [video]\n\n\n\n\nhttps://cogs137.github.io/website/"
  },
  {
    "objectID": "content/lectures/08-effective-communication.html",
    "href": "content/lectures/08-effective-communication.html",
    "title": "08-effective-communication",
    "section": "",
    "text": "Lecture Participation survey “due” after class\nMidterm due Monday (2/13; 11:59 PM):\n\nreleased Friday after lab\ncompleted individually\n\n\n\n\nPractice Midterm Posted (Answer key posted Wed/tomorrow)\nLab03 & Lab04 Scores & Feedback Posted\nLab04 Notes:\n\nModel Interpretations\nText, code, & viz all matter\n\nLink for Later\n\n\n\n\n\n\nCommunicating for your audience\nOral Communication\nWritten Communication\nVisual Communication"
  },
  {
    "objectID": "content/lectures/08-effective-communication.html#what-does-this-mean",
    "href": "content/lectures/08-effective-communication.html#what-does-this-mean",
    "title": "08-effective-communication",
    "section": "What does this mean?",
    "text": "What does this mean?\n❓ What does it mean to “consider your audience?”\n\nSimply: You do the work so they don’t have to.\n\n\n…also the aesthetic-usability effect exists."
  },
  {
    "objectID": "content/lectures/08-effective-communication.html#whats-the-right-level",
    "href": "content/lectures/08-effective-communication.html#whats-the-right-level",
    "title": "08-effective-communication",
    "section": "What’s the right level?",
    "text": "What’s the right level?\n\n\nGeneral Audience\n✔ background\n🚫 limit technical details\n🎉 emphasize take-home\n\n\n\nTechnical Audience\n⬇ limit background\n💻 all-the-details\n🎉 emphasize take-home"
  },
  {
    "objectID": "content/lectures/08-effective-communication.html#considerations",
    "href": "content/lectures/08-effective-communication.html#considerations",
    "title": "08-effective-communication",
    "section": "Considerations",
    "text": "Considerations\n\nPlatform: written? oral?\n\n\n\nSetting: informal? formal?\n\n\n\n\nTiming: never go over your time limit!"
  },
  {
    "objectID": "content/lectures/08-effective-communication.html#storytelling",
    "href": "content/lectures/08-effective-communication.html#storytelling",
    "title": "08-effective-communication",
    "section": "Storytelling",
    "text": "Storytelling\n\nStories have a beginning, a middle, and an end.\n\n\n\nStories do not need every detail of what you’ve tried\n\n\n\n\nReports and presentations should tell a story\nPlanning out your report/presentation can help\n\n\n\n\nHold the audience’s attention with what needs to be said; do so effectively\nTell your audience why they should care; why it matters\nYou should explain your choices and the “why”"
  },
  {
    "objectID": "content/lectures/08-effective-communication.html#choose-informative-titles",
    "href": "content/lectures/08-effective-communication.html#choose-informative-titles",
    "title": "08-effective-communication",
    "section": "Choose informative titles",
    "text": "Choose informative titles\nOn presentations: Balance b/w short and informative (goal: concise)\n\n\nAvoid: “Analyzing NHANES”\n\nBetter: “Data from the NHANES study shows that diet is related to overall health”\n\n\nOn visualizations: emphasize the take-home! (what’s learned or what action to take)\n\n\n\nAvoid: “Boxplot of gender”\n\nBetter: “Twice as many females as males included for analysis”\n\n\n\nAvoid: “Tickets vs. Time”\n\nBetter: “Staff unable to respond to incoming tickets; need to hire 2 FTEs”"
  },
  {
    "objectID": "content/lectures/08-effective-communication.html#student-responses",
    "href": "content/lectures/08-effective-communication.html#student-responses",
    "title": "08-effective-communication",
    "section": "Student responses",
    "text": "Student responses\n\n\n\n\n\nAdvice you've received\n\n\n\n\nSpeak loudly and clearly enough for everyone to hear (project your voice!); be engaging so that people are inclined to pay attention\n\n\nMake eye contact with your audience as you speak\n\n\nDon't just read off slides, and (most of the time) don't read from a script\n\n\nloud and clear voice\n\n\nPosture, eye contact, and mannerisms can all influence oral presentation performance. While presenting don't stand in one spot, get up, move around and engage with the audience.\n\n\ntry harder to better word choice\n\n\nLook at the audience when I am talking to them. Speak loud and clear.\n\n\nEye contact!!!\n\n\neye contact, try not to use filler words, talk slower than you would normally, don't just read off of the slides\n\n\ndont overcomplicate the wording, what might make sense to you might be revolutionary to someone else. Using simple words for simple explainations for begginer simple thought processes\n\n\ndrink water constantly\n\n\nmaking enough eye contact"
  },
  {
    "objectID": "content/lectures/08-effective-communication.html#presentations-are-for-listening",
    "href": "content/lectures/08-effective-communication.html#presentations-are-for-listening",
    "title": "08-effective-communication",
    "section": "Presentations are for listening",
    "text": "Presentations are for listening\n\nAdvantage: words to explain out loud what you’re showing\n\n\n\nYou are presenting for the person in the back of the room.\n\n\n\nTo accomplish:\n\ndon’t read directly off slides\nrepetition is ok: tell what you’re going to tell them, tell them, tell them what you told them\nuse animation to build your story (not to distract)\nintroduce your axes\ntext/labels larger\nwatch your speech speed\npractice!"
  },
  {
    "objectID": "content/lectures/08-effective-communication.html#for-example-a-happy-ending-for-almost-everyone-in-little-red-riding-hood",
    "href": "content/lectures/08-effective-communication.html#for-example-a-happy-ending-for-almost-everyone-in-little-red-riding-hood",
    "title": "08-effective-communication",
    "section": "For Example: A Happy Ending for (almost) everyone in Little Red Riding Hood",
    "text": "For Example: A Happy Ending for (almost) everyone in Little Red Riding Hood\n\nRed Riding Hood (RRH) has to walk 0.54 mi from Point A (home) to Point B (Grandma’s)\nRRH meets Wolf who (1) runs ahead to Grandma’s, (2) eats her, and (3) dresses in her clothes\nRRH arrives at Grandmas at 2PM, asks her three questions\nIdentified problem: after third question, Wolf eats RRH\nSolution: vendor (Woodsman) employs tool (ax)\nExpected outcome: Grandma and RRH alive, wolf is not"
  },
  {
    "objectID": "content/lectures/08-effective-communication.html#student-responses-1",
    "href": "content/lectures/08-effective-communication.html#student-responses-1",
    "title": "08-effective-communication",
    "section": "Student responses",
    "text": "Student responses\n\n\n\n\n\nAdvice you've received\n\n\n\n\nYour rough draft should be rough. Don't polish it because it will flush all your great ideas away.\n\n\nInclude data/metrics that highlight quantifiable impact of work.\n\n\nbe concise when writing\n\n\nshorter sentences = good\n\n\nState your main point clearly; use good grammar\n\n\ndon't use crazy fonts and coloring. If things need to be emphasized stick to italics bold and font size generally speaking.\n\n\nDisplay contents of slides in a left to right fashion.\n\n\nUse clear fonts.\n\n\nas concise as possible\n\n\nIf it's a presentation, less wording is often better. Use oral communication to fill in gaps between the main points\n\n\nRead what you write in between every iteration. Try to avoid repeating words - show some variety. Use punctuation well. Split up paragraphs; monolithic walls of text are intimidating and readers will skip them. It's cliche, but for a reason - the topic, argument, evidence structure is effective.\n\n\nExplicitly write out the opposing arguments/concerns in your paper and answer them as best you can. That way the paper feels more like a conversation with the author than just something to read.\n\n\nMake sentences flow well. Include a conclusion to summarize\n\n\nstay on topic, summarize main points at end,\n\n\nRepeat the point you want the readers to remember"
  },
  {
    "objectID": "content/lectures/08-effective-communication.html#benefits-of-written-communciation",
    "href": "content/lectures/08-effective-communication.html#benefits-of-written-communciation",
    "title": "08-effective-communication",
    "section": "Benefits of written communciation",
    "text": "Benefits of written communciation\nYour audience has time to process…but the explanation has to be there!\n\nVisually: more on a single visualization\n\n\nYes, often there are different visualizations for reports/papers than for presentations/lectures."
  },
  {
    "objectID": "content/lectures/08-effective-communication.html#when-you-have-time-to-digest-read",
    "href": "content/lectures/08-effective-communication.html#when-you-have-time-to-digest-read",
    "title": "08-effective-communication",
    "section": "When you have time to digest (read)",
    "text": "When you have time to digest (read)\n\n\n❓ What makes this an effective visualization for a written communication?”\nSource: Storytelling wtih data by cole nussbaumer knaflic"
  },
  {
    "objectID": "content/lectures/08-effective-communication.html#data-science-reports-in-.rmd",
    "href": "content/lectures/08-effective-communication.html#data-science-reports-in-.rmd",
    "title": "08-effective-communication",
    "section": "Data Science Reports in .Rmd",
    "text": "Data Science Reports in .Rmd\n\nAs concise as possible\nNecessary details (for your audience); nothing more\nTypical Sections: Introduction/Background, Setup, Data, Analysis, Conclusion, References"
  },
  {
    "objectID": "content/lectures/08-effective-communication.html#controlling-html-document-settings",
    "href": "content/lectures/08-effective-communication.html#controlling-html-document-settings",
    "title": "08-effective-communication",
    "section": "Controlling HTML document settings",
    "text": "Controlling HTML document settings\n\nTable of Contents\n\n---\ntitle: \"Document Title\"\noutput:\n  html_document:\n    toc: true\n    toc_float: true\n---\n\n\nTheme\n\n---\ntitle: \"Document Title\"\noutput:\n  html_document:\n    theme: united\n    highlight: tango\n---\n\n\n\nFigure Options\n\n---\ntitle: \"Document Title\"\noutput:\n  html_document:\n    fig_width: 7\n    fig_height: 6\n    fig_caption: true\n---\n\n\n\nCode Folding\n\n---\ntitle: \"Document Title\"\noutput:\n  html_document:\n    code_folding: hide\n---"
  },
  {
    "objectID": "content/lectures/08-effective-communication.html#controlling-code-chunk-output",
    "href": "content/lectures/08-effective-communication.html#controlling-code-chunk-output",
    "title": "08-effective-communication",
    "section": "Controlling code chunk output",
    "text": "Controlling code chunk output\n\nSpecified in the curly braces, separated by commas\n\n\n{r, chunk-label, results='hide', fig.height=4}\n\n\n\neval: whether to execute the code chunk\necho: whether to include the code in the output\nwarning, message, and error: whether to show warnings, messages, or errors in the knit document\nfig.width and fig.height: control the width/height of plots\n\n\n\n\nControlling for the whole document:\n\nknitr::opts_chunk$set(fig.width = 8, collapse = TRUE)"
  },
  {
    "objectID": "content/lectures/08-effective-communication.html#editing-proofreading",
    "href": "content/lectures/08-effective-communication.html#editing-proofreading",
    "title": "08-effective-communication",
    "section": "Editing & Proofreading",
    "text": "Editing & Proofreading\n\nDid you end up telling a story?\n\nThings missing?\nThings to delete?\n\n\n\n\nDo not fall in love with your words/code/plots\n\n\n\n\nDo spell check\nDo read it over before sending/presenting/submitting"
  },
  {
    "objectID": "content/lectures/08-effective-communication.html#aside-citing-sources",
    "href": "content/lectures/08-effective-communication.html#aside-citing-sources",
    "title": "08-effective-communication",
    "section": "Aside: Citing Sources",
    "text": "Aside: Citing Sources\nWhen are citations needed?\n\n\n\n“We will be doing our analysis using two different data sets created by two different groups: Donohue and Mustard + Lott, or simply Lott”\n\n\n\n\n\n\n“What turned from the idea of carrying firearms to protect oneself from enemies such as the British monarchy and the unknown frontier of North America has now become a nationwide issue.”\n\n\n\n\n\n\n“Right to Carry Laws refer to laws that specify how citizens are allowed to carry concealed handguns when they’re away from home without a permit”\n\n\n\n\n\n\n“In this case study, we are examining the relationship between unemployment rate, poverty rate, police staffing, and violent crime rate.”\n\n\n\n\n\n\n“In the United States, the second amendment permits the right to bear arms, and this law has not been changed since its creation in 1791.”\n\n\n\n\n\n\n“The Right to Carry Laws (RTC) is defined as “a law that specifies if and how citizens are allowed to have a firearm on their person or nearby in public.””\n\n\n\n\nReminder: You do NOT get docked points for citing others’ work. You can be at risk of AI Violation if you don’t. When in doubt, give credit."
  },
  {
    "objectID": "content/lectures/08-effective-communication.html#footnotes-in-.rmd",
    "href": "content/lectures/08-effective-communication.html#footnotes-in-.rmd",
    "title": "08-effective-communication",
    "section": "Footnotes in .Rmd",
    "text": "Footnotes in .Rmd\nHow to specify a footnote in text:\nHere is some body text.[^1]\nHow to include the footnote’s reference:\n[^1]: This footnote will appear at the bottom of the page.\n\n\nNote: .bib files can be included with BibTeX references using the bibliography parameter in your YAML"
  },
  {
    "objectID": "content/lectures/08-effective-communication.html#student-responses-2",
    "href": "content/lectures/08-effective-communication.html#student-responses-2",
    "title": "08-effective-communication",
    "section": "Student Responses",
    "text": "Student Responses\n\n\n\n\n\nAdvice you've received\n\n\n\n\nTry to make the title of the plot something descriptive rather than simply, eg, \"Time vs Length\" or \"linear regression of pet sizes\".\"\n\n\nshow the kind of plot that can be understood by audience\n\n\nI heard that when making a visual graphic, you should try remove as much as you can while still showing the necessary information. The less on the screen, the better.\n\n\nWhen giving a presentation, try to keep bullet points shorter than 7 words so it's easier digest/remember\n\n\nWhen displaying data and visualizations. Take note of people with eye color visualization disabilities. Also present things based on intuitive knowledge. Like reading left to right\n\n\nhighlighting only the important bits with color usage\n\n\n(picture / plot / visualization) > words\n\n\nUse appropriate colors and use them to highlight findings.\n\n\nMake plots big and clear\n\n\nSometimes simple is better, try to stay away from distracting visualizations\n\n\nUse appropriate (non-misleading) scales\n\n\nColors choices are important, and also remember about color blind people\n\n\nlabel axis, always include a title, use ticks if they help understand the data, think about color choices, big text\n\n\nInclude visuals only if they are meaningful and/or strengthen your argument"
  },
  {
    "objectID": "content/lectures/08-effective-communication.html#the-glamour-of-graphics",
    "href": "content/lectures/08-effective-communication.html#the-glamour-of-graphics",
    "title": "08-effective-communication",
    "section": "The Glamour of Graphics",
    "text": "The Glamour of Graphics\n\nbuilds on top of the grammar (components) of a graphic\nconsiderations for the design of a graphic\ncolor, typography, layout\ngoing from accurate to 😍effective\n\n\n\nThese ideas and slides are all modified from Will Chase’s rstudio::conf2020 slides/talk"
  },
  {
    "objectID": "content/lectures/08-effective-communication.html#left-align-titles-at-top-left",
    "href": "content/lectures/08-effective-communication.html#left-align-titles-at-top-left",
    "title": "08-effective-communication",
    "section": "Left-align titles at top-left",
    "text": "Left-align titles at top-left\n\n\n😬 Accurate\n\nggplot(penguins, aes(x = species, fill = species)) +\n  geom_bar() +\n  labs(title = \"Adelie Penguins are the most common in Antarctica\", \n       subtitle = \"Frequency of each penguin species studied near Palmer Station, Antarctica\") +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))\n\n\n\n\n\n😍 Effective\n\nggplot(penguins, aes(x = species, fill = species)) +\n  geom_bar() +\n  labs(title = \"Adelie Penguins are the most common in Antarctica\", \n       subtitle = \"Frequency of each penguin species studied near Palmer Station, Antarctica\") +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),\n        plot.title.position = \"plot\")"
  },
  {
    "objectID": "content/lectures/08-effective-communication.html#avoid-head-tilting",
    "href": "content/lectures/08-effective-communication.html#avoid-head-tilting",
    "title": "08-effective-communication",
    "section": "Avoid head-tilting",
    "text": "Avoid head-tilting\n\n\n😬 Accurate\n\nggplot(penguins, aes(x = species, fill = species)) +\n  geom_bar() +\n  labs(title = \"Adelie Penguins are the most common in Antarctica\", \n       subtitle = \"Frequency of each penguin species studied near Palmer Station, Antarctica\") +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),\n        plot.title.position = \"plot\")\n\n\n\n\n\n😍 Effective\n\nggplot(penguins, aes(y = species, fill = species)) +\n  geom_bar() +\n  labs(title = \"Adelie Penguins are the most common in Antarctica\", \n       subtitle = \"Frequency of each penguin species studied near Palmer Station, Antarctica\") +\n  theme(plot.title.position = \"plot\")"
  },
  {
    "objectID": "content/lectures/08-effective-communication.html#borders-backgrounds",
    "href": "content/lectures/08-effective-communication.html#borders-backgrounds",
    "title": "08-effective-communication",
    "section": "Borders & Backgrounds: 👎",
    "text": "Borders & Backgrounds: 👎\n\n\n😬 Accurate\n\nggplot(penguins, aes(y = species, fill = species)) +\n  geom_bar() +\n  labs(title = \"Adelie Penguins are the most common in Antarctica\", \n       subtitle = \"Frequency of each penguin species studied near Palmer Station, Antarctica\") +\n  theme_bw() +\n  theme(plot.title.position = \"plot\") \n\n\n\n\n\n😍 Effective\n\nggplot(penguins, aes(y = species, fill = species)) +\n  geom_bar() +\n  labs(title = \"Adelie Penguins are the most common in Antarctica\", \n       subtitle = \"Frequency of each penguin species studied near Palmer Station, Antarctica\") +\n  theme_minimal() +\n  theme(plot.title.position = \"plot\")"
  },
  {
    "objectID": "content/lectures/08-effective-communication.html#organize-removelighten-as-much-as-possible",
    "href": "content/lectures/08-effective-communication.html#organize-removelighten-as-much-as-possible",
    "title": "08-effective-communication",
    "section": "Organize & Remove/Lighten as much as possible",
    "text": "Organize & Remove/Lighten as much as possible\n\n\n😬 Accurate\n\nggplot(penguins, aes(y = species, fill = species)) +\n  geom_bar() +\n  labs(title = \"Adelie Penguins are the most common in Antarctica\", \n       subtitle = \"Frequency of each penguin species studied near Palmer Station, Antarctica\") +\n  theme_minimal() +\n  theme(plot.title.position = \"plot\") \n\n\n\n\n\n😍 Effective\n\nggplot(penguins, aes(y = fct_rev(fct_infreq(species)), fill = species)) +\n  geom_bar() +\n  geom_text(stat='count', aes(label=..count..), hjust = 1.5, color = \"white\", size = 6) +\n  scale_x_continuous(expand = c(0, 0)) +\n  scale_fill_manual(values = c(\"#454545\", rep(\"#adadad\", 2))) +\n  labs(title = \"Adelie Penguins are the most common in Antarctica\", \n       subtitle = \"Frequency of each penguin species studied near Palmer Station, Antarctica\") +\n  theme_minimal(base_size = 18) +\n  theme(axis.text.x = element_blank(),\n        plot.title.position = \"plot\", \n        panel.grid.major = element_blank(), panel.grid.minor = element_blank(),\n        axis.title = element_blank())"
  },
  {
    "objectID": "content/lectures/08-effective-communication.html#legends-suck",
    "href": "content/lectures/08-effective-communication.html#legends-suck",
    "title": "08-effective-communication",
    "section": "Legends suck",
    "text": "Legends suck\n\n\n😬 Accurate\n\nggplot(penguins, aes(y = fct_rev(fct_infreq(species)), fill = species)) +\n  geom_bar() +\n  geom_text(stat='count', aes(label=..count..), hjust = 1.5, color = \"white\", size = 6) +\n  scale_x_continuous(expand = c(0, 0)) +\n  scale_fill_manual(values = c(\"#454545\", rep(\"#adadad\", 2))) +\n  labs(title = \"Adelie Penguins are the most common in Antarctica\", \n       subtitle = \"Frequency of each penguin species studied near Palmer Station, Antarctica\") +\n  theme_minimal(base_size = 18) +\n  theme(axis.text.x = element_blank(),\n        plot.title.position = \"plot\", \n        panel.grid.major = element_blank(), panel.grid.minor = element_blank(),\n        axis.title = element_blank())\n\n\n\n\n\n😍 Effective\n\nggplot(penguins, aes(y = fct_rev(fct_infreq(species)), fill = species)) +\n  geom_bar() +\n  geom_text(stat='count', aes(label=..count..), hjust = 1.5, color = \"white\", size = 7) +\n  scale_x_continuous(expand = c(0, 0)) +\n  scale_fill_manual(values = c(\"#454545\", rep(\"#adadad\", 2))) +\n  labs(title = \"Adelie Penguins are the most common in Antarctica\", \n       subtitle = \"Frequency of each penguin species studied near Palmer Station, Antarctica\") +\n  theme_minimal(base_size = 20) +\n  theme(axis.text.x = element_blank(),\n        plot.title.position = \"plot\", \n        panel.grid.major = element_blank(), panel.grid.minor = element_blank(),\n        axis.title = element_blank(),\n        legend.position = \"none\")"
  },
  {
    "objectID": "content/lectures/08-effective-communication.html#additional-guidance",
    "href": "content/lectures/08-effective-communication.html#additional-guidance",
    "title": "08-effective-communication",
    "section": "Additional Guidance",
    "text": "Additional Guidance\n\nWhite space is like garlic - take the amount you need and triple it\nFonts Matter\nUse Color Effectively"
  },
  {
    "objectID": "content/lectures/08-effective-communication.html#suggested-reading",
    "href": "content/lectures/08-effective-communication.html#suggested-reading",
    "title": "08-effective-communication",
    "section": "Suggested Reading",
    "text": "Suggested Reading\n\nBookdown Section 2.6 R Code Chunks & inline R code\nBookdown Chapter 3: Documents\nWill Chase’s rstudio::conf2020 talk: “The Glamour of Graphics” [slides] [video]"
  },
  {
    "objectID": "content/lectures/06-analysis-slides.html#qa",
    "href": "content/lectures/06-analysis-slides.html#qa",
    "title": "06-analysis",
    "section": "Q&A",
    "text": "Q&A\n\nQ: What if we’re not good at coming up with ideas of what plots to generate from a given dataset?\nA: We’re going to discuss this and practice this! If you’re not sure where to start, the DatatoViz resource is a great place to help with ideas! If you’re still struggling, be sure when we get to case studies to really think to yourself for each plot, why did prof choose this plot? Could another have been better? And, discuss with your teammates (once you have those)!\n\n\nQ: maybe i missed it… but i am confused about the difference between “count” and “proportions”. Would they end up being the same thing? is the code different for doing count vs. proportion?\nA: Another student had this question, and it’s a good one! Count is for the value across the dataset. Proportions are calculated within the group, such that each group’s values are displayed out of 100%. Happy to discuss more if there are questions. We’ll see an example of this in today’s lecture!\n\n\nQ: Not the lecture, but the way to think in the way to get the “right” plot for the data.\nA: So, the good news is that there isn’t typically one right way. There’s room for personalization, personal preferences, and sometimes, there’s just more than one way! The bad news is that it takes time to learn best practices…but that’s part of what this class is all about!\n\n\nQ: Why is ChatGPT mentioned in the lab answers?\nA: Because I assume that some students are using this as a resource. And, that’s great! It’s there so that you get a sense of ChatGPT’s strengths (sometimes it really does give helpful dplyr code or get you started on the right path) and its weaknesses (it’s still important to think critically if you’re choosing to use it as a tool!) ChatGPT is by no means required in this course. In fact, I think labs/assignments may take longer if you are using it. I don’t have a sense yet who would learn the material better!"
  },
  {
    "objectID": "content/lectures/06-analysis-slides.html#agenda",
    "href": "content/lectures/06-analysis-slides.html#agenda",
    "title": "06-analysis",
    "section": "Agenda",
    "text": "Agenda\n\nDiscuss Exploratory Data Analysis (EDA)\nIntroduce modelling as a concept\nPaintings example\n\nEDA\nModelling (Linear)"
  },
  {
    "objectID": "content/lectures/06-analysis-slides.html#course-announcements",
    "href": "content/lectures/06-analysis-slides.html#course-announcements",
    "title": "06-analysis",
    "section": "Course Announcements",
    "text": "Course Announcements\nDue Dates:\n\nLab 04 due Friday (1/27; 11:59 PM)\nLecture Participation survey “due” after class\nHW02 due Monday (2/6; 11:59 PM)\n\nNotes:\n\nHW01 Grades (Canvas) & Feedback (GitHub Issue) Posted\nLab03 Answer Key Posted"
  },
  {
    "objectID": "content/lectures/06-analysis-slides.html#what-is-eda",
    "href": "content/lectures/06-analysis-slides.html#what-is-eda",
    "title": "06-analysis",
    "section": "What is EDA?",
    "text": "What is EDA?\n\nExploratory data analysis (EDA) is an aproach to analyzing data sets to summarize and understand its main characteristics.\nOften, this is visual….but the visuals do not have to be perfect. (Save that for communication)\nCalculating summary statistics is also part of EDA.\n\n\n\nData tidying/wrangling/manipulation/transformation typically happens before this stage of the analysis.\n\n\n\nThe Goal: KNOW YOUR DATA!"
  },
  {
    "objectID": "content/lectures/06-analysis-slides.html#consider-no.-of-variables-involved",
    "href": "content/lectures/06-analysis-slides.html#consider-no.-of-variables-involved",
    "title": "06-analysis",
    "section": "Consider: No. of variables involved",
    "text": "Consider: No. of variables involved\n\nUnivariate data analysis - distribution of single variable\nBivariate data analysis - relationship between two variables\nMultivariate data analysis - relationship between many variables at once, usually focusing on the relationship between two while conditioning for others"
  },
  {
    "objectID": "content/lectures/06-analysis-slides.html#consider-types-of-variables",
    "href": "content/lectures/06-analysis-slides.html#consider-types-of-variables",
    "title": "06-analysis",
    "section": "Consider: Types of variables",
    "text": "Consider: Types of variables\n\nNumerical variables can be classified as continuous or discrete based on whether or not the variable can take on an infinite number of values or only non-negative whole numbers, respectively.\nIf the variable is categorical, we can determine if it is ordinal based on whether or not the levels have a natural ordering."
  },
  {
    "objectID": "content/lectures/06-analysis-slides.html#data-visualization",
    "href": "content/lectures/06-analysis-slides.html#data-visualization",
    "title": "06-analysis",
    "section": "Data visualization",
    "text": "Data visualization\n\n“The simple graph has brought more information to the data analyst’s mind than any other device.” — John Tukey\n\n\nData visualization is the creation and study of the visual representation of data.\nThere are many tools for visualizing data (R is one of them), and many approaches/systems within R for making data visualizations (ggplot2 is what we’ll continue to use).\nEDA will involve making plots/visualizing your data"
  },
  {
    "objectID": "content/lectures/06-analysis-slides.html#paris-paintings",
    "href": "content/lectures/06-analysis-slides.html#paris-paintings",
    "title": "06-analysis",
    "section": "Paris Paintings",
    "text": "Paris Paintings\n\npp <- read_csv(\"https://raw.githubusercontent.com/COGS137/datasets/main/paris_paintings.csv\", \n               na = c(\"n/a\", \"\", \"NA\"))\n\n\nSource: Printed catalogs of 28 auction sales in Paris, 1764 - 1780\nData curators Sandra van Ginhoven and Hilary Coe Cronheim (who were PhD students in the Duke Art, Law, and Markets Initiative at the time of putting together this dataset) translated and tabulated the catalogues\n3393 paintings, their prices, and descriptive details from sales catalogues over 60 variables"
  },
  {
    "objectID": "content/lectures/06-analysis-slides.html#auctions-today",
    "href": "content/lectures/06-analysis-slides.html#auctions-today",
    "title": "06-analysis",
    "section": "Auctions today",
    "text": "Auctions today\n\n\n\n\n\n\n\nSource: Sothebys"
  },
  {
    "objectID": "content/lectures/06-analysis-slides.html#auctions-back-in-the-day",
    "href": "content/lectures/06-analysis-slides.html#auctions-back-in-the-day",
    "title": "06-analysis",
    "section": "Auctions back in the day",
    "text": "Auctions back in the day\n\nSource: Pierre-Antoine de Machy, Public Sale at the Hôtel Bullion, Musée Carnavalet, Paris (18th century)"
  },
  {
    "objectID": "content/lectures/06-analysis-slides.html#paris-auction-market",
    "href": "content/lectures/06-analysis-slides.html#paris-auction-market",
    "title": "06-analysis",
    "section": "Paris auction market",
    "text": "Paris auction market"
  },
  {
    "objectID": "content/lectures/06-analysis-slides.html#depart-pour-la-chasse",
    "href": "content/lectures/06-analysis-slides.html#depart-pour-la-chasse",
    "title": "06-analysis",
    "section": "Depart pour la chasse",
    "text": "Depart pour la chasse"
  },
  {
    "objectID": "content/lectures/06-analysis-slides.html#auction-catalogue-text",
    "href": "content/lectures/06-analysis-slides.html#auction-catalogue-text",
    "title": "06-analysis",
    "section": "Auction catalogue text",
    "text": "Auction catalogue text\n\n\n\n\nTwo paintings very rich in composition, of a beautiful execution, and whose merit is very remarkable, each 17 inches 3 lines high, 23 inches wide; the first, painted on wood, comes from the Cabinet of Madame la Comtesse de Verrue; it represents a departure for the hunt: it shows in the front a child on a white horse, a man who gives the horn to gather the dogs, a falconer and other figures nicely distributed across the width of the painting; two horses drinking from a fountain; on the right in the corner a lovely country house topped by a terrace, on which people are at the table, others who play instruments; trees and fabriques pleasantly enrich the background."
  },
  {
    "objectID": "content/lectures/06-analysis-slides.html#depart-pour-la-chasse-as-data",
    "href": "content/lectures/06-analysis-slides.html#depart-pour-la-chasse-as-data",
    "title": "06-analysis",
    "section": "Depart pour la chasse as Data",
    "text": "Depart pour la chasse as Data"
  },
  {
    "objectID": "content/lectures/06-analysis-slides.html#section",
    "href": "content/lectures/06-analysis-slides.html#section",
    "title": "06-analysis",
    "section": "",
    "text": "pp |>\n  filter(name == \"R1777-89a\") |>\n  glimpse()\n\nRows: 1\nColumns: 61\n$ name              <chr> \"R1777-89a\"\n$ sale              <chr> \"R1777\"\n$ lot               <chr> \"89\"\n$ position          <dbl> 0.3755274\n$ dealer            <chr> \"R\"\n$ year              <dbl> 1777\n$ origin_author     <chr> \"D/FL\"\n$ origin_cat        <chr> \"D/FL\"\n$ school_pntg       <chr> \"D/FL\"\n$ diff_origin       <dbl> 0\n$ logprice          <dbl> 8.575462\n$ price             <dbl> 5300\n$ count             <dbl> 1\n$ subject           <chr> \"D\\x8epart pour la chasse\"\n$ authorstandard    <chr> \"Wouwerman, Philips\"\n$ artistliving      <dbl> 0\n$ authorstyle       <chr> NA\n$ author            <chr> \"Philippe Wouwermans\"\n$ winningbidder     <chr> \"Langlier, Jacques for Poullain, Antoine\"\n$ winningbiddertype <chr> \"DC\"\n$ endbuyer          <chr> \"C\"\n$ Interm            <dbl> 1\n$ type_intermed     <chr> \"D\"\n$ Height_in         <dbl> 17.25\n$ Width_in          <dbl> 23\n$ Surface_Rect      <dbl> 396.75\n$ Diam_in           <dbl> NA\n$ Surface_Rnd       <dbl> NA\n$ Shape             <chr> \"squ_rect\"\n$ Surface           <dbl> 396.75\n$ material          <chr> \"bois\"\n$ mat               <chr> \"b\"\n$ materialCat       <chr> \"wood\"\n$ quantity          <dbl> 1\n$ nfigures          <dbl> 0\n$ engraved          <dbl> 0\n$ original          <dbl> 0\n$ prevcoll          <dbl> 1\n$ othartist         <dbl> 0\n$ paired            <dbl> 1\n$ figures           <dbl> 0\n$ finished          <dbl> 0\n$ lrgfont           <dbl> 0\n$ relig             <dbl> 0\n$ landsALL          <dbl> 1\n$ lands_sc          <dbl> 0\n$ lands_elem        <dbl> 1\n$ lands_figs        <dbl> 1\n$ lands_ment        <dbl> 0\n$ arch              <dbl> 1\n$ mytho             <dbl> 0\n$ peasant           <dbl> 0\n$ othgenre          <dbl> 0\n$ singlefig         <dbl> 0\n$ portrait          <dbl> 0\n$ still_life        <dbl> 0\n$ discauth          <dbl> 0\n$ history           <dbl> 0\n$ allegory          <dbl> 0\n$ pastorale         <dbl> 0\n$ other             <dbl> 0"
  },
  {
    "objectID": "content/lectures/06-analysis-slides.html#visualizing-numerical-data",
    "href": "content/lectures/06-analysis-slides.html#visualizing-numerical-data",
    "title": "06-analysis",
    "section": "Visualizing numerical data",
    "text": "Visualizing numerical data\nDescribing shapes of numerical distributions\n\nshape:\n\nskewness: right-skewed, left-skewed, symmetric (skew is to the side of the longer tail)\nmodality: unimodal, bimodal, multimodal, uniform\n\ncenter: mean (mean), median (median), mode (not always useful)\nspread: range (range), standard deviation (sd), inter-quartile range (IQR)\nunusual observations"
  },
  {
    "objectID": "content/lectures/06-analysis-slides.html#histograms",
    "href": "content/lectures/06-analysis-slides.html#histograms",
    "title": "06-analysis",
    "section": "Histograms",
    "text": "Histograms\n\nHeightsWidthsPrices\n\n\n\nggplot(data = pp, aes(x = Height_in)) +\n  geom_histogram(binwidth = 5) +\n  labs(x = \"Height, in inches\", y = NULL)\n\n\n\n\n\n\n\nggplot(data = pp, aes(x = Width_in)) +\n  geom_histogram(binwidth = 5) +\n  labs(x = \"Width, in inches\", y = NULL)\n\n\n\n\n\n\n\nggplot(data = pp, aes(x = price)) +\n  geom_histogram(binwidth = 100) +\n  labs(x = \"Price\", y = NULL)"
  },
  {
    "objectID": "content/lectures/06-analysis-slides.html#density-plots",
    "href": "content/lectures/06-analysis-slides.html#density-plots",
    "title": "06-analysis",
    "section": "Density plots",
    "text": "Density plots\n\nggplot(data = pp, mapping = aes(x = Height_in)) +\n  geom_density()"
  },
  {
    "objectID": "content/lectures/06-analysis-slides.html#side-by-side-box-plots",
    "href": "content/lectures/06-analysis-slides.html#side-by-side-box-plots",
    "title": "06-analysis",
    "section": "Side-by-side box plots",
    "text": "Side-by-side box plots\n\nggplot(data = pp, mapping = aes(y = Height_in, x = as.factor(landsALL))) +\n  geom_boxplot()"
  },
  {
    "objectID": "content/lectures/06-analysis-slides.html#visualizing-categorical-data",
    "href": "content/lectures/06-analysis-slides.html#visualizing-categorical-data",
    "title": "06-analysis",
    "section": "Visualizing categorical data",
    "text": "Visualizing categorical data\n\ncount/proportion of values\nunusual observations"
  },
  {
    "objectID": "content/lectures/06-analysis-slides.html#bar-plots",
    "href": "content/lectures/06-analysis-slides.html#bar-plots",
    "title": "06-analysis",
    "section": "Bar plots",
    "text": "Bar plots\n\nggplot(data = pp, mapping = aes(x = as.factor(landsALL))) +\n  geom_bar()"
  },
  {
    "objectID": "content/lectures/06-analysis-slides.html#segmented-bar-plots-counts",
    "href": "content/lectures/06-analysis-slides.html#segmented-bar-plots-counts",
    "title": "06-analysis",
    "section": "Segmented bar plots, counts",
    "text": "Segmented bar plots, counts\n\nggplot(data = pp, mapping = aes(x = as.factor(landsALL), fill = materialCat)) +\n  geom_bar()"
  },
  {
    "objectID": "content/lectures/06-analysis-slides.html#segmented-bar-plots-proportions",
    "href": "content/lectures/06-analysis-slides.html#segmented-bar-plots-proportions",
    "title": "06-analysis",
    "section": "Segmented bar plots, proportions",
    "text": "Segmented bar plots, proportions\n\nggplot(data = pp, mapping = aes(x = as.factor(landsALL), fill = materialCat)) +\n  geom_bar(position = \"fill\") +\n  labs(y = \"proportion\")"
  },
  {
    "objectID": "content/lectures/06-analysis-slides.html#your-turn",
    "href": "content/lectures/06-analysis-slides.html#your-turn",
    "title": "06-analysis",
    "section": "Your Turn",
    "text": "Your Turn\n❓ Which of the previous two bar plots is a more useful representation for visualizing the relationship between landscape and painting material?\n\n❓ What else would you want to do/know to complete EDA?\n\n\n🧠 Try to answer at least one thing you’d want to know from the dataset.\n\n\n\nPut a green sticky on the front of your computer when you’re done. Put a pink if you want help/have a question."
  },
  {
    "objectID": "content/lectures/06-analysis-slides.html#modelling-1",
    "href": "content/lectures/06-analysis-slides.html#modelling-1",
    "title": "06-analysis",
    "section": "Modelling",
    "text": "Modelling\n\nUse models to explain the relationship between variables and to make predictions\nFor now we focus on linear models (but remember there are other types of models too!)"
  },
  {
    "objectID": "content/lectures/06-analysis-slides.html#packages",
    "href": "content/lectures/06-analysis-slides.html#packages",
    "title": "06-analysis",
    "section": "Packages",
    "text": "Packages\n\n\n\n\n\n\nYou’re familiar with the tidyverse:\n\n\nlibrary(tidyverse)\n\n\nThe broom package takes the messy output of built-in functions in R, such as lm, and turns them into tidy data frames.\n\n\nlibrary(broom)"
  },
  {
    "objectID": "content/lectures/06-analysis-slides.html#modelling-the-relationship-between-variables",
    "href": "content/lectures/06-analysis-slides.html#modelling-the-relationship-between-variables",
    "title": "06-analysis",
    "section": "Modelling the relationship between variables",
    "text": "Modelling the relationship between variables\nEDA: Prices\n❗ Describe the distribution of prices of paintings.\n\nggplot(data = pp, aes(x = price)) +\n  geom_histogram(binwidth = 1000)"
  },
  {
    "objectID": "content/lectures/06-analysis-slides.html#models-as-functions",
    "href": "content/lectures/06-analysis-slides.html#models-as-functions",
    "title": "06-analysis",
    "section": "Models as functions",
    "text": "Models as functions\n\nWe can represent relationships between variables using functions\nA function is a mathematical concept: the relationship between an output and one or more inputs.\n\nPlug in the inputs and receive back the output\nExample: the formula \\(y = 3x + 7\\) is a function with input \\(x\\) and output \\(y\\), when \\(x\\) is \\(5\\), the output \\(y\\) is \\(22\\)\n\n\ny = 3 * 5 + 7 = 22"
  },
  {
    "objectID": "content/lectures/06-analysis-slides.html#height-as-a-function-of-width",
    "href": "content/lectures/06-analysis-slides.html#height-as-a-function-of-width",
    "title": "06-analysis",
    "section": "Height as a function of width",
    "text": "Height as a function of width\n❗ Describe the relationship between height and width of paintings."
  },
  {
    "objectID": "content/lectures/06-analysis-slides.html#visualizing-the-linear-model",
    "href": "content/lectures/06-analysis-slides.html#visualizing-the-linear-model",
    "title": "06-analysis",
    "section": "Visualizing the linear model",
    "text": "Visualizing the linear model\n\nggplot(data = pp, aes(x = Width_in, y = Height_in)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") # lm for linear model"
  },
  {
    "objectID": "content/lectures/06-analysis-slides.html#visualizing-the-linear-model-1",
    "href": "content/lectures/06-analysis-slides.html#visualizing-the-linear-model-1",
    "title": "06-analysis",
    "section": "Visualizing the linear model",
    "text": "Visualizing the linear model\n… without the measure of uncertainty around the line\n\nggplot(data = pp, aes(x = Width_in, y = Height_in)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) # lm for linear model"
  },
  {
    "objectID": "content/lectures/06-analysis-slides.html#visualizing-the-linear-model-2",
    "href": "content/lectures/06-analysis-slides.html#visualizing-the-linear-model-2",
    "title": "06-analysis",
    "section": "Visualizing the linear model",
    "text": "Visualizing the linear model\n… with different cosmetic choices for the line\n\nggplot(data = pp, aes(x = Width_in, y = Height_in)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE, \n              col = \"pink\",      # color\n              lty = 2,           # line type\n              linewidth = 3)     # line weight"
  },
  {
    "objectID": "content/lectures/06-analysis-slides.html#vocabulary",
    "href": "content/lectures/06-analysis-slides.html#vocabulary",
    "title": "06-analysis",
    "section": "Vocabulary",
    "text": "Vocabulary\n\nResponse variable: Variable whose behavior or variation you are trying to understand, on the y-axis (dependent variable)\n\n\n\nExplanatory variables: Other variables that you want to use to explain the variation in the response, on the x-axis (independent variables)\n\n\n\n\nPredicted value: Output of the function model function\n\nThe model function gives the typical value of the response variable conditioning on the explanatory variables\n\n\n\n\n\nResiduals: Show how far each case is from its model value\n\nResidual = Observed value - Predicted value\nTells how far above/below the model function each case is"
  },
  {
    "objectID": "content/lectures/06-analysis-slides.html#residuals",
    "href": "content/lectures/06-analysis-slides.html#residuals",
    "title": "06-analysis",
    "section": "Residuals",
    "text": "Residuals\n❓ What does a negative residual mean? Which paintings on the plot have have negative residuals?"
  },
  {
    "objectID": "content/lectures/06-analysis-slides.html#section-1",
    "href": "content/lectures/06-analysis-slides.html#section-1",
    "title": "06-analysis",
    "section": "",
    "text": "The plot below displays the relationship between height and width of paintings. It uses a lower alpha level for the points than the previous plots we looked at.\n\n❓ What feature is apparent in this plot that was not (as) apparent in the previous plots? What might be the reason for this feature?"
  },
  {
    "objectID": "content/lectures/06-analysis-slides.html#landscape-paintings",
    "href": "content/lectures/06-analysis-slides.html#landscape-paintings",
    "title": "06-analysis",
    "section": "Landscape paintings",
    "text": "Landscape paintings\n\nLandscape painting is the depiction in art of landscapes – natural scenery such as mountains, valleys, trees, rivers, and forests, especially where the main subject is a wide view – with its elements arranged into a coherent composition.1\n\nLandscape paintings tend to be wider than longer.\n\nPortrait painting is a genre in painting, where the intent is to depict a human subject.2\n\nPortrait paintings tend to be longer than wider.\n\n\nSource: Wikipedia, Landscape paintingSource: Wikipedia, Portait painting"
  },
  {
    "objectID": "content/lectures/06-analysis-slides.html#multiple-explanatory-variables",
    "href": "content/lectures/06-analysis-slides.html#multiple-explanatory-variables",
    "title": "06-analysis",
    "section": "Multiple explanatory variables",
    "text": "Multiple explanatory variables\n❓ How, if at all, does the relationship between width and height of paintings vary by whether or not they have any landscape elements?\n\nggplot(data = pp, aes(x = Width_in, y = Height_in, \n                      color = factor(landsALL))) +\n  geom_point(alpha = 0.4) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(color = \"landscape\")"
  },
  {
    "objectID": "content/lectures/06-analysis-slides.html#models---upsides-and-downsides",
    "href": "content/lectures/06-analysis-slides.html#models---upsides-and-downsides",
    "title": "06-analysis",
    "section": "Models - upsides and downsides",
    "text": "Models - upsides and downsides\n\nModels can sometimes reveal patterns that are not evident in a graph of the data. This is a great advantage of modelling over simple visual inspection of data.\n\n\n\nThere is a real risk, however, that a model is imposing structure that is not really there on the scatter of data, just as people imagine animal shapes in the stars. A skeptical approach is always warranted."
  },
  {
    "objectID": "content/lectures/06-analysis-slides.html#variation-around-the-model",
    "href": "content/lectures/06-analysis-slides.html#variation-around-the-model",
    "title": "06-analysis",
    "section": "Variation around the model…",
    "text": "Variation around the model…\nis just as important as the model, if not more!\n\nStatistics is the explanation of variation in the context of what remains unexplained.\n\n\n\nThe scatter suggests that there might be other factors that account for large parts of painting-to-painting variability, or perhaps just that randomness plays a big role.\nAdding more explanatory variables to a model can sometimes usefully reduce the size of the scatter around the model. (We’ll talk more about this later.)"
  },
  {
    "objectID": "content/lectures/06-analysis-slides.html#how-do-we-use-models",
    "href": "content/lectures/06-analysis-slides.html#how-do-we-use-models",
    "title": "06-analysis",
    "section": "How do we use models?",
    "text": "How do we use models?\n\nExplanation: Characterize the relationship between \\(y\\) and \\(x\\) via slopes for numerical explanatory variables or differences for categorical explanatory variables (Inference)\nPrediction: Plug in \\(x\\), get the predicted \\(y\\) (Machine Learning)"
  },
  {
    "objectID": "content/lectures/06-analysis-slides.html#suggested-reading",
    "href": "content/lectures/06-analysis-slides.html#suggested-reading",
    "title": "06-analysis",
    "section": "Suggested Reading",
    "text": "Suggested Reading\n\nIntroduction to Modern Statistics Chapter 4: Exploring Categorical Data\nIntroduction to Modern Statistics Chapter 5: Exploring Numerical Data\nR4DS Chapter 22: Introduction to Modelling\nR4DS Chapter 23: Model Basics\nR4DS Chapter 24: Model Building\n\n\n\n\nhttps://cogs137.github.io/website/"
  },
  {
    "objectID": "content/lectures/06-analysis.html",
    "href": "content/lectures/06-analysis.html",
    "title": "06-analysis",
    "section": "",
    "text": "Q: What if we’re not good at coming up with ideas of what plots to generate from a given dataset?\nA: We’re going to discuss this and practice this! If you’re not sure where to start, the DatatoViz resource is a great place to help with ideas! If you’re still struggling, be sure when we get to case studies to really think to yourself for each plot, why did prof choose this plot? Could another have been better? And, discuss with your teammates (once you have those)!\n\n\nQ: maybe i missed it… but i am confused about the difference between “count” and “proportions”. Would they end up being the same thing? is the code different for doing count vs. proportion?\nA: Another student had this question, and it’s a good one! Count is for the value across the dataset. Proportions are calculated within the group, such that each group’s values are displayed out of 100%. Happy to discuss more if there are questions. We’ll see an example of this in today’s lecture!\n\n\nQ: Not the lecture, but the way to think in the way to get the “right” plot for the data.\nA: So, the good news is that there isn’t typically one right way. There’s room for personalization, personal preferences, and sometimes, there’s just more than one way! The bad news is that it takes time to learn best practices…but that’s part of what this class is all about!\n\n\nQ: Why is ChatGPT mentioned in the lab answers?\nA: Because I assume that some students are using this as a resource. And, that’s great! It’s there so that you get a sense of ChatGPT’s strengths (sometimes it really does give helpful dplyr code or get you started on the right path) and its weaknesses (it’s still important to think critically if you’re choosing to use it as a tool!) ChatGPT is by no means required in this course. In fact, I think labs/assignments may take longer if you are using it. I don’t have a sense yet who would learn the material better!\n\n\n\n\n\nDiscuss Exploratory Data Analysis (EDA)\nIntroduce modelling as a concept\nPaintings example\n\nEDA\nModelling (Linear)\n\n\n\n\n\nDue Dates:\n\nLab 04 due Friday (1/27; 11:59 PM)\nLecture Participation survey “due” after class\nHW02 due Monday (2/6; 11:59 PM)\n\nNotes:\n\nHW01 Grades (Canvas) & Feedback (GitHub Issue) Posted\nLab03 Answer Key Posted"
  },
  {
    "objectID": "content/lectures/06-analysis.html#what-is-eda",
    "href": "content/lectures/06-analysis.html#what-is-eda",
    "title": "06-analysis",
    "section": "What is EDA?",
    "text": "What is EDA?\n\nExploratory data analysis (EDA) is an aproach to analyzing data sets to summarize and understand its main characteristics.\nOften, this is visual….but the visuals do not have to be perfect. (Save that for communication)\nCalculating summary statistics is also part of EDA.\n\n\n\nData tidying/wrangling/manipulation/transformation typically happens before this stage of the analysis.\n\n\n\nThe Goal: KNOW YOUR DATA!"
  },
  {
    "objectID": "content/lectures/06-analysis.html#consider-no.-of-variables-involved",
    "href": "content/lectures/06-analysis.html#consider-no.-of-variables-involved",
    "title": "06-analysis",
    "section": "Consider: No. of variables involved",
    "text": "Consider: No. of variables involved\n\nUnivariate data analysis - distribution of single variable\nBivariate data analysis - relationship between two variables\nMultivariate data analysis - relationship between many variables at once, usually focusing on the relationship between two while conditioning for others"
  },
  {
    "objectID": "content/lectures/06-analysis.html#consider-types-of-variables",
    "href": "content/lectures/06-analysis.html#consider-types-of-variables",
    "title": "06-analysis",
    "section": "Consider: Types of variables",
    "text": "Consider: Types of variables\n\nNumerical variables can be classified as continuous or discrete based on whether or not the variable can take on an infinite number of values or only non-negative whole numbers, respectively.\nIf the variable is categorical, we can determine if it is ordinal based on whether or not the levels have a natural ordering."
  },
  {
    "objectID": "content/lectures/06-analysis.html#data-visualization",
    "href": "content/lectures/06-analysis.html#data-visualization",
    "title": "06-analysis",
    "section": "Data visualization",
    "text": "Data visualization\n\n“The simple graph has brought more information to the data analyst’s mind than any other device.” — John Tukey\n\n\nData visualization is the creation and study of the visual representation of data.\nThere are many tools for visualizing data (R is one of them), and many approaches/systems within R for making data visualizations (ggplot2 is what we’ll continue to use).\nEDA will involve making plots/visualizing your data"
  },
  {
    "objectID": "content/lectures/06-analysis.html#paris-paintings",
    "href": "content/lectures/06-analysis.html#paris-paintings",
    "title": "06-analysis",
    "section": "Paris Paintings",
    "text": "Paris Paintings\n\npp <- read_csv(\"https://raw.githubusercontent.com/COGS137/datasets/main/paris_paintings.csv\", \n               na = c(\"n/a\", \"\", \"NA\"))\n\n\nSource: Printed catalogs of 28 auction sales in Paris, 1764 - 1780\nData curators Sandra van Ginhoven and Hilary Coe Cronheim (who were PhD students in the Duke Art, Law, and Markets Initiative at the time of putting together this dataset) translated and tabulated the catalogues\n3393 paintings, their prices, and descriptive details from sales catalogues over 60 variables"
  },
  {
    "objectID": "content/lectures/06-analysis.html#auctions-today",
    "href": "content/lectures/06-analysis.html#auctions-today",
    "title": "06-analysis",
    "section": "Auctions today",
    "text": "Auctions today\n\n\n\n\n\n\n\nSource: Sothebys"
  },
  {
    "objectID": "content/lectures/06-analysis.html#auctions-back-in-the-day",
    "href": "content/lectures/06-analysis.html#auctions-back-in-the-day",
    "title": "06-analysis",
    "section": "Auctions back in the day",
    "text": "Auctions back in the day\n\n\n\n\n\nSource: Pierre-Antoine de Machy, Public Sale at the Hôtel Bullion, Musée Carnavalet, Paris (18th century)"
  },
  {
    "objectID": "content/lectures/06-analysis.html#paris-auction-market",
    "href": "content/lectures/06-analysis.html#paris-auction-market",
    "title": "06-analysis",
    "section": "Paris auction market",
    "text": "Paris auction market"
  },
  {
    "objectID": "content/lectures/06-analysis.html#depart-pour-la-chasse",
    "href": "content/lectures/06-analysis.html#depart-pour-la-chasse",
    "title": "06-analysis",
    "section": "Depart pour la chasse",
    "text": "Depart pour la chasse"
  },
  {
    "objectID": "content/lectures/06-analysis.html#auction-catalogue-text",
    "href": "content/lectures/06-analysis.html#auction-catalogue-text",
    "title": "06-analysis",
    "section": "Auction catalogue text",
    "text": "Auction catalogue text\n\n\n\n\nTwo paintings very rich in composition, of a beautiful execution, and whose merit is very remarkable, each 17 inches 3 lines high, 23 inches wide; the first, painted on wood, comes from the Cabinet of Madame la Comtesse de Verrue; it represents a departure for the hunt: it shows in the front a child on a white horse, a man who gives the horn to gather the dogs, a falconer and other figures nicely distributed across the width of the painting; two horses drinking from a fountain; on the right in the corner a lovely country house topped by a terrace, on which people are at the table, others who play instruments; trees and fabriques pleasantly enrich the background."
  },
  {
    "objectID": "content/lectures/06-analysis.html#depart-pour-la-chasse-as-data",
    "href": "content/lectures/06-analysis.html#depart-pour-la-chasse-as-data",
    "title": "06-analysis",
    "section": "Depart pour la chasse as Data",
    "text": "Depart pour la chasse as Data"
  },
  {
    "objectID": "content/lectures/06-analysis.html#section",
    "href": "content/lectures/06-analysis.html#section",
    "title": "06-analysis",
    "section": "",
    "text": "pp |>\n  filter(name == \"R1777-89a\") |>\n  glimpse()\n\nRows: 1\nColumns: 61\n$ name              <chr> \"R1777-89a\"\n$ sale              <chr> \"R1777\"\n$ lot               <chr> \"89\"\n$ position          <dbl> 0.3755274\n$ dealer            <chr> \"R\"\n$ year              <dbl> 1777\n$ origin_author     <chr> \"D/FL\"\n$ origin_cat        <chr> \"D/FL\"\n$ school_pntg       <chr> \"D/FL\"\n$ diff_origin       <dbl> 0\n$ logprice          <dbl> 8.575462\n$ price             <dbl> 5300\n$ count             <dbl> 1\n$ subject           <chr> \"D\\x8epart pour la chasse\"\n$ authorstandard    <chr> \"Wouwerman, Philips\"\n$ artistliving      <dbl> 0\n$ authorstyle       <chr> NA\n$ author            <chr> \"Philippe Wouwermans\"\n$ winningbidder     <chr> \"Langlier, Jacques for Poullain, Antoine\"\n$ winningbiddertype <chr> \"DC\"\n$ endbuyer          <chr> \"C\"\n$ Interm            <dbl> 1\n$ type_intermed     <chr> \"D\"\n$ Height_in         <dbl> 17.25\n$ Width_in          <dbl> 23\n$ Surface_Rect      <dbl> 396.75\n$ Diam_in           <dbl> NA\n$ Surface_Rnd       <dbl> NA\n$ Shape             <chr> \"squ_rect\"\n$ Surface           <dbl> 396.75\n$ material          <chr> \"bois\"\n$ mat               <chr> \"b\"\n$ materialCat       <chr> \"wood\"\n$ quantity          <dbl> 1\n$ nfigures          <dbl> 0\n$ engraved          <dbl> 0\n$ original          <dbl> 0\n$ prevcoll          <dbl> 1\n$ othartist         <dbl> 0\n$ paired            <dbl> 1\n$ figures           <dbl> 0\n$ finished          <dbl> 0\n$ lrgfont           <dbl> 0\n$ relig             <dbl> 0\n$ landsALL          <dbl> 1\n$ lands_sc          <dbl> 0\n$ lands_elem        <dbl> 1\n$ lands_figs        <dbl> 1\n$ lands_ment        <dbl> 0\n$ arch              <dbl> 1\n$ mytho             <dbl> 0\n$ peasant           <dbl> 0\n$ othgenre          <dbl> 0\n$ singlefig         <dbl> 0\n$ portrait          <dbl> 0\n$ still_life        <dbl> 0\n$ discauth          <dbl> 0\n$ history           <dbl> 0\n$ allegory          <dbl> 0\n$ pastorale         <dbl> 0\n$ other             <dbl> 0"
  },
  {
    "objectID": "content/lectures/06-analysis.html#visualizing-numerical-data",
    "href": "content/lectures/06-analysis.html#visualizing-numerical-data",
    "title": "06-analysis",
    "section": "Visualizing numerical data",
    "text": "Visualizing numerical data\nDescribing shapes of numerical distributions\n\nshape:\n\nskewness: right-skewed, left-skewed, symmetric (skew is to the side of the longer tail)\nmodality: unimodal, bimodal, multimodal, uniform\n\ncenter: mean (mean), median (median), mode (not always useful)\nspread: range (range), standard deviation (sd), inter-quartile range (IQR)\nunusual observations"
  },
  {
    "objectID": "content/lectures/06-analysis.html#histograms",
    "href": "content/lectures/06-analysis.html#histograms",
    "title": "06-analysis",
    "section": "Histograms",
    "text": "Histograms\n\nHeightsWidthsPrices\n\n\n\nggplot(data = pp, aes(x = Height_in)) +\n  geom_histogram(binwidth = 5) +\n  labs(x = \"Height, in inches\", y = NULL)\n\n\n\n\n\n\n\nggplot(data = pp, aes(x = Width_in)) +\n  geom_histogram(binwidth = 5) +\n  labs(x = \"Width, in inches\", y = NULL)\n\n\n\n\n\n\n\nggplot(data = pp, aes(x = price)) +\n  geom_histogram(binwidth = 100) +\n  labs(x = \"Price\", y = NULL)"
  },
  {
    "objectID": "content/lectures/06-analysis.html#density-plots",
    "href": "content/lectures/06-analysis.html#density-plots",
    "title": "06-analysis",
    "section": "Density plots",
    "text": "Density plots\n\nggplot(data = pp, mapping = aes(x = Height_in)) +\n  geom_density()"
  },
  {
    "objectID": "content/lectures/06-analysis.html#side-by-side-box-plots",
    "href": "content/lectures/06-analysis.html#side-by-side-box-plots",
    "title": "06-analysis",
    "section": "Side-by-side box plots",
    "text": "Side-by-side box plots\n\nggplot(data = pp, mapping = aes(y = Height_in, x = as.factor(landsALL))) +\n  geom_boxplot()"
  },
  {
    "objectID": "content/lectures/06-analysis.html#visualizing-categorical-data",
    "href": "content/lectures/06-analysis.html#visualizing-categorical-data",
    "title": "06-analysis",
    "section": "Visualizing categorical data",
    "text": "Visualizing categorical data\n\ncount/proportion of values\nunusual observations"
  },
  {
    "objectID": "content/lectures/06-analysis.html#bar-plots",
    "href": "content/lectures/06-analysis.html#bar-plots",
    "title": "06-analysis",
    "section": "Bar plots",
    "text": "Bar plots\n\nggplot(data = pp, mapping = aes(x = as.factor(landsALL))) +\n  geom_bar()"
  },
  {
    "objectID": "content/lectures/06-analysis.html#segmented-bar-plots-counts",
    "href": "content/lectures/06-analysis.html#segmented-bar-plots-counts",
    "title": "06-analysis",
    "section": "Segmented bar plots, counts",
    "text": "Segmented bar plots, counts\n\nggplot(data = pp, mapping = aes(x = as.factor(landsALL), fill = materialCat)) +\n  geom_bar()"
  },
  {
    "objectID": "content/lectures/06-analysis.html#segmented-bar-plots-proportions",
    "href": "content/lectures/06-analysis.html#segmented-bar-plots-proportions",
    "title": "06-analysis",
    "section": "Segmented bar plots, proportions",
    "text": "Segmented bar plots, proportions\n\nggplot(data = pp, mapping = aes(x = as.factor(landsALL), fill = materialCat)) +\n  geom_bar(position = \"fill\") +\n  labs(y = \"proportion\")"
  },
  {
    "objectID": "content/lectures/06-analysis.html#your-turn",
    "href": "content/lectures/06-analysis.html#your-turn",
    "title": "06-analysis",
    "section": "Your Turn",
    "text": "Your Turn\n❓ Which of the previous two bar plots is a more useful representation for visualizing the relationship between landscape and painting material?\n\n❓ What else would you want to do/know to complete EDA?\n\n\n🧠 Try to answer at least one thing you’d want to know from the dataset.\n\n\nPut a green sticky on the front of your computer when you’re done. Put a pink if you want help/have a question."
  },
  {
    "objectID": "content/lectures/06-analysis.html#modelling-1",
    "href": "content/lectures/06-analysis.html#modelling-1",
    "title": "06-analysis",
    "section": "Modelling",
    "text": "Modelling\n\nUse models to explain the relationship between variables and to make predictions\nFor now we focus on linear models (but remember there are other types of models too!)"
  },
  {
    "objectID": "content/lectures/06-analysis.html#packages",
    "href": "content/lectures/06-analysis.html#packages",
    "title": "06-analysis",
    "section": "Packages",
    "text": "Packages\n\n\n\n\n\n\nYou’re familiar with the tidyverse:\n\n\nlibrary(tidyverse)\n\n\nThe broom package takes the messy output of built-in functions in R, such as lm, and turns them into tidy data frames.\n\n\nlibrary(broom)"
  },
  {
    "objectID": "content/lectures/06-analysis.html#modelling-the-relationship-between-variables",
    "href": "content/lectures/06-analysis.html#modelling-the-relationship-between-variables",
    "title": "06-analysis",
    "section": "Modelling the relationship between variables",
    "text": "Modelling the relationship between variables\nEDA: Prices\n❗ Describe the distribution of prices of paintings.\n\nggplot(data = pp, aes(x = price)) +\n  geom_histogram(binwidth = 1000)"
  },
  {
    "objectID": "content/lectures/06-analysis.html#models-as-functions",
    "href": "content/lectures/06-analysis.html#models-as-functions",
    "title": "06-analysis",
    "section": "Models as functions",
    "text": "Models as functions\n\nWe can represent relationships between variables using functions\nA function is a mathematical concept: the relationship between an output and one or more inputs.\n\nPlug in the inputs and receive back the output\nExample: the formula \\(y = 3x + 7\\) is a function with input \\(x\\) and output \\(y\\), when \\(x\\) is \\(5\\), the output \\(y\\) is \\(22\\)\n\n\ny = 3 * 5 + 7 = 22"
  },
  {
    "objectID": "content/lectures/06-analysis.html#height-as-a-function-of-width",
    "href": "content/lectures/06-analysis.html#height-as-a-function-of-width",
    "title": "06-analysis",
    "section": "Height as a function of width",
    "text": "Height as a function of width\n❗ Describe the relationship between height and width of paintings."
  },
  {
    "objectID": "content/lectures/06-analysis.html#visualizing-the-linear-model",
    "href": "content/lectures/06-analysis.html#visualizing-the-linear-model",
    "title": "06-analysis",
    "section": "Visualizing the linear model",
    "text": "Visualizing the linear model\n\nggplot(data = pp, aes(x = Width_in, y = Height_in)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") # lm for linear model"
  },
  {
    "objectID": "content/lectures/06-analysis.html#visualizing-the-linear-model-1",
    "href": "content/lectures/06-analysis.html#visualizing-the-linear-model-1",
    "title": "06-analysis",
    "section": "Visualizing the linear model",
    "text": "Visualizing the linear model\n… without the measure of uncertainty around the line\n\nggplot(data = pp, aes(x = Width_in, y = Height_in)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) # lm for linear model"
  },
  {
    "objectID": "content/lectures/06-analysis.html#visualizing-the-linear-model-2",
    "href": "content/lectures/06-analysis.html#visualizing-the-linear-model-2",
    "title": "06-analysis",
    "section": "Visualizing the linear model",
    "text": "Visualizing the linear model\n… with different cosmetic choices for the line\n\nggplot(data = pp, aes(x = Width_in, y = Height_in)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE, \n              col = \"pink\",      # color\n              lty = 2,           # line type\n              linewidth = 3)     # line weight"
  },
  {
    "objectID": "content/lectures/06-analysis.html#vocabulary",
    "href": "content/lectures/06-analysis.html#vocabulary",
    "title": "06-analysis",
    "section": "Vocabulary",
    "text": "Vocabulary\n\nResponse variable: Variable whose behavior or variation you are trying to understand, on the y-axis (dependent variable)\n\n\n\nExplanatory variables: Other variables that you want to use to explain the variation in the response, on the x-axis (independent variables)\n\n\n\n\nPredicted value: Output of the function model function\n\nThe model function gives the typical value of the response variable conditioning on the explanatory variables\n\n\n\n\n\nResiduals: Show how far each case is from its model value\n\nResidual = Observed value - Predicted value\nTells how far above/below the model function each case is"
  },
  {
    "objectID": "content/lectures/06-analysis.html#residuals",
    "href": "content/lectures/06-analysis.html#residuals",
    "title": "06-analysis",
    "section": "Residuals",
    "text": "Residuals\n❓ What does a negative residual mean? Which paintings on the plot have have negative residuals?"
  },
  {
    "objectID": "content/lectures/06-analysis.html#section-1",
    "href": "content/lectures/06-analysis.html#section-1",
    "title": "06-analysis",
    "section": "",
    "text": "The plot below displays the relationship between height and width of paintings. It uses a lower alpha level for the points than the previous plots we looked at.\n\n\n\n\n\n❓ What feature is apparent in this plot that was not (as) apparent in the previous plots? What might be the reason for this feature?"
  },
  {
    "objectID": "content/lectures/06-analysis.html#landscape-paintings",
    "href": "content/lectures/06-analysis.html#landscape-paintings",
    "title": "06-analysis",
    "section": "Landscape paintings",
    "text": "Landscape paintings\n\nLandscape painting is the depiction in art of landscapes – natural scenery such as mountains, valleys, trees, rivers, and forests, especially where the main subject is a wide view – with its elements arranged into a coherent composition.1\n\nLandscape paintings tend to be wider than longer.\n\nPortrait painting is a genre in painting, where the intent is to depict a human subject.2\n\nPortrait paintings tend to be longer than wider."
  },
  {
    "objectID": "content/lectures/06-analysis.html#multiple-explanatory-variables",
    "href": "content/lectures/06-analysis.html#multiple-explanatory-variables",
    "title": "06-analysis",
    "section": "Multiple explanatory variables",
    "text": "Multiple explanatory variables\n❓ How, if at all, does the relationship between width and height of paintings vary by whether or not they have any landscape elements?\n\nggplot(data = pp, aes(x = Width_in, y = Height_in, \n                      color = factor(landsALL))) +\n  geom_point(alpha = 0.4) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(color = \"landscape\")"
  },
  {
    "objectID": "content/lectures/06-analysis.html#models---upsides-and-downsides",
    "href": "content/lectures/06-analysis.html#models---upsides-and-downsides",
    "title": "06-analysis",
    "section": "Models - upsides and downsides",
    "text": "Models - upsides and downsides\n\nModels can sometimes reveal patterns that are not evident in a graph of the data. This is a great advantage of modelling over simple visual inspection of data.\n\n\n\nThere is a real risk, however, that a model is imposing structure that is not really there on the scatter of data, just as people imagine animal shapes in the stars. A skeptical approach is always warranted."
  },
  {
    "objectID": "content/lectures/06-analysis.html#variation-around-the-model",
    "href": "content/lectures/06-analysis.html#variation-around-the-model",
    "title": "06-analysis",
    "section": "Variation around the model…",
    "text": "Variation around the model…\nis just as important as the model, if not more!\n\nStatistics is the explanation of variation in the context of what remains unexplained.\n\n\n\nThe scatter suggests that there might be other factors that account for large parts of painting-to-painting variability, or perhaps just that randomness plays a big role.\nAdding more explanatory variables to a model can sometimes usefully reduce the size of the scatter around the model. (We’ll talk more about this later.)"
  },
  {
    "objectID": "content/lectures/06-analysis.html#how-do-we-use-models",
    "href": "content/lectures/06-analysis.html#how-do-we-use-models",
    "title": "06-analysis",
    "section": "How do we use models?",
    "text": "How do we use models?\n\nExplanation: Characterize the relationship between \\(y\\) and \\(x\\) via slopes for numerical explanatory variables or differences for categorical explanatory variables (Inference)\nPrediction: Plug in \\(x\\), get the predicted \\(y\\) (Machine Learning)"
  },
  {
    "objectID": "content/lectures/06-analysis.html#suggested-reading",
    "href": "content/lectures/06-analysis.html#suggested-reading",
    "title": "06-analysis",
    "section": "Suggested Reading",
    "text": "Suggested Reading\n\nIntroduction to Modern Statistics Chapter 4: Exploring Categorical Data\nIntroduction to Modern Statistics Chapter 5: Exploring Numerical Data\nR4DS Chapter 22: Introduction to Modelling\nR4DS Chapter 23: Model Basics\nR4DS Chapter 24: Model Building"
  },
  {
    "objectID": "content/lectures/05-viz-slides.html#qa",
    "href": "content/lectures/05-viz-slides.html#qa",
    "title": "05-viz",
    "section": "Q&A",
    "text": "Q&A\n\nQ: What were those columns in the NC Bike Accident Data we used?\nA: Variables are described here\n\n\nQ: I was confused by wrap vs grid and how should I choose between them.\nA: When you want to generate a plot that uses two other variables in the dataset to determine which subset of the data to plot, grid! When you want to use a single variable to facet your data and want to specify how many columns/rows to display, wrap!\n\n\nQ: When programming in R so far, I often find myself stuck at getting going on a problem and have a different time identifying on where to start. Any tips/advice on how to get past this initial bump in order to start getting through the problem?\nA: This is a common struggle! This may sound like an old-person response, but jotting down what you have and what you want (like on actual paper/iPad) can be really helpful. For example, if you have 3 columns and you know you want to have 3 columns at the end, but you want fewer rows, you can draw a picture of this and help yourself realize you need a filter. Of course when there are multiple steps, the drawings become a bit more complex…but also more helpful! The same can be said for data visualization. Drawing out quickly what you want can help you get started.\n\n\nQ:In what time frame will the lecture survey be available, how many hours after class will the survey be closed\nA: It will be open for at least 2h.\n\n\nQ:For HW1 Q7, I used read_csv and got an error message. I tried read.csv and it worked. Is there any difference between read_csv and read.csv?\nA: Hmm…I’d love to take a look to see what error you got. They are similar and often behave the same way. The difference is read.csv() was made before the tidyverse, so it reads your data in as a dataframe. read_csv() is a function that “plays nicely” with the tidyverse and reads the data in as a tibble/data frame. What does that mean practically? It means that typically each one will read the data in and you’ll get the same number of rows and columns. What could differ would be the column names and/or the column types (depending upon the data). All that said, read_csv() is what I’ll recommend in this course…so that’s why I’m curious about the error you got!"
  },
  {
    "objectID": "content/lectures/05-viz-slides.html#course-announcements",
    "href": "content/lectures/05-viz-slides.html#course-announcements",
    "title": "05-viz",
    "section": "Course Announcements",
    "text": "Course Announcements\nDue Dates:\n\nLab 03 due Friday (1/27; 11:59 PM)\nLecture Participation survey “due” after class\n\nCourse Announcements:\n\nLab02 Grades (Canvas) & Feedback (GitHub Issue) Posted\nHW02 Now Available\nDiscord? - Campuswire post\n“Vote” on posts when grades released (pink: send message; green: announce in class)"
  },
  {
    "objectID": "content/lectures/05-viz-slides.html#keep-it-simple",
    "href": "content/lectures/05-viz-slides.html#keep-it-simple",
    "title": "05-viz",
    "section": "Keep it simple",
    "text": "Keep it simple"
  },
  {
    "objectID": "content/lectures/05-viz-slides.html#use-color-to-draw-attention",
    "href": "content/lectures/05-viz-slides.html#use-color-to-draw-attention",
    "title": "05-viz",
    "section": "Use color to draw attention",
    "text": "Use color to draw attention"
  },
  {
    "objectID": "content/lectures/05-viz-slides.html#tell-a-story",
    "href": "content/lectures/05-viz-slides.html#tell-a-story",
    "title": "05-viz",
    "section": "Tell a story",
    "text": "Tell a story\n\n\n\n\n\n\n\nCredit: Angela Zoss and Eric Monson, Duke DVS"
  },
  {
    "objectID": "content/lectures/05-viz-slides.html#principles-for-effective-visualizations-1",
    "href": "content/lectures/05-viz-slides.html#principles-for-effective-visualizations-1",
    "title": "05-viz",
    "section": "Principles for effective visualizations",
    "text": "Principles for effective visualizations\n\nOrder matters\nPut long categories on the y-axis\nKeep scales consistent\nSelect meaningful colors\nUse meaningful and nonredundant labels"
  },
  {
    "objectID": "content/lectures/05-viz-slides.html#data",
    "href": "content/lectures/05-viz-slides.html#data",
    "title": "05-viz",
    "section": "Data",
    "text": "Data\nIn September 2019, YouGov survey asked 1,639 GB adults the following question:\n\n\n\nIn hindsight, do you think Britain was right/wrong to vote to leave EU?\n\nRight to leave\n\nWrong to leave\n\nDon’t know\n\n\n\n\n\n\n\n\n\n\n\n\nSource: YouGov Survey Results, retrieved Oct 7, 2019"
  },
  {
    "objectID": "content/lectures/05-viz-slides.html#the-data-code",
    "href": "content/lectures/05-viz-slides.html#the-data-code",
    "title": "05-viz",
    "section": "The Data: Code",
    "text": "The Data: Code\n\nbrexit <- tibble(\n  opinion = c(\n    rep(\"Right\", 664), rep(\"Wrong\", 787), rep(\"Don't know\", 188)\n  ),\n  region = c(\n    rep(\"london\", 63), rep(\"rest_of_south\", 241), rep(\"midlands_wales\", 145), rep(\"north\", 176), rep(\"scot\", 39),\n    rep(\"london\", 110), rep(\"rest_of_south\", 257), rep(\"midlands_wales\", 152), rep(\"north\", 176), rep(\"scot\", 92),\n    rep(\"london\", 24), rep(\"rest_of_south\", 49), rep(\"midlands_wales\", 57), rep(\"north\", 48), rep(\"scot\", 10)\n  )\n)"
  },
  {
    "objectID": "content/lectures/05-viz-slides.html#order-matters",
    "href": "content/lectures/05-viz-slides.html#order-matters",
    "title": "05-viz",
    "section": "Order matters",
    "text": "Order matters\nAlphabetical is rarely ideal\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(brexit, aes(x = opinion)) +\n  geom_bar()"
  },
  {
    "objectID": "content/lectures/05-viz-slides.html#order-by-frequency",
    "href": "content/lectures/05-viz-slides.html#order-by-frequency",
    "title": "05-viz",
    "section": "Order by frequency",
    "text": "Order by frequency\n\nPlotCode\n\n\n\n\n\n\n\n\n\nfct_infreq: Reorder factors’ levels by frequency\n\nggplot(brexit, aes(x = fct_infreq(opinion))) + \n  geom_bar()"
  },
  {
    "objectID": "content/lectures/05-viz-slides.html#clean-up-labels",
    "href": "content/lectures/05-viz-slides.html#clean-up-labels",
    "title": "05-viz",
    "section": "Clean up labels",
    "text": "Clean up labels\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(brexit, aes(x = opinion)) +\n  geom_bar() +\n  labs( \n    x = \"Opinion\", \n    y = \"Count\" \n  )"
  },
  {
    "objectID": "content/lectures/05-viz-slides.html#avoiding-alphabetical-order",
    "href": "content/lectures/05-viz-slides.html#avoiding-alphabetical-order",
    "title": "05-viz",
    "section": "Avoiding Alphabetical Order",
    "text": "Avoiding Alphabetical Order\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(brexit, aes(x = region)) +\n  geom_bar()"
  },
  {
    "objectID": "content/lectures/05-viz-slides.html#use-inherent-level-order",
    "href": "content/lectures/05-viz-slides.html#use-inherent-level-order",
    "title": "05-viz",
    "section": "Use inherent level order",
    "text": "Use inherent level order\n\nRelevelPlot\n\n\nfct_relevel: Reorder factor levels using a custom order\n\nbrexit <- brexit |>\n  mutate(\n    region = fct_relevel( \n      region,\n      \"london\", \"rest_of_south\", \"midlands_wales\", \"north\", \"scot\"\n    )\n  )"
  },
  {
    "objectID": "content/lectures/05-viz-slides.html#clean-up-labels-1",
    "href": "content/lectures/05-viz-slides.html#clean-up-labels-1",
    "title": "05-viz",
    "section": "Clean up labels",
    "text": "Clean up labels\n\nRecodePlot\n\n\nfct_recode: Change factor levels by hand\n\nbrexit <- brexit |>\n  mutate(\n    region = fct_recode( \n      region,\n      London = \"london\",\n      `Rest of South` = \"rest_of_south\",\n      `Midlands / Wales` = \"midlands_wales\",\n      North = \"north\",\n      Scotland = \"scot\"\n    )\n  )"
  },
  {
    "objectID": "content/lectures/05-viz-slides.html#put-long-categories-on-the-y-axis",
    "href": "content/lectures/05-viz-slides.html#put-long-categories-on-the-y-axis",
    "title": "05-viz",
    "section": "Put long categories on the y-axis",
    "text": "Put long categories on the y-axis\nLong categories can be hard to read"
  },
  {
    "objectID": "content/lectures/05-viz-slides.html#move-them-to-the-y-axis",
    "href": "content/lectures/05-viz-slides.html#move-them-to-the-y-axis",
    "title": "05-viz",
    "section": "Move them to the y-axis",
    "text": "Move them to the y-axis\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(brexit, aes(y = region)) + \n  geom_bar()"
  },
  {
    "objectID": "content/lectures/05-viz-slides.html#and-reverse-the-order-of-levels",
    "href": "content/lectures/05-viz-slides.html#and-reverse-the-order-of-levels",
    "title": "05-viz",
    "section": "And reverse the order of levels",
    "text": "And reverse the order of levels\n\nPlotCode\n\n\n\n\n\n\n\n\n\nfct_rev: Reverse order of factor levels\n\nggplot(brexit, aes(y = fct_rev(region))) + \n  geom_bar()"
  },
  {
    "objectID": "content/lectures/05-viz-slides.html#clean-up-labels-2",
    "href": "content/lectures/05-viz-slides.html#clean-up-labels-2",
    "title": "05-viz",
    "section": "Clean up labels",
    "text": "Clean up labels\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(brexit, aes(y = fct_rev(region))) +\n  geom_bar() +\n  labs( \n    x = \"Count\", \n    y = \"Region\" \n  )"
  },
  {
    "objectID": "content/lectures/05-viz-slides.html#segmented-bar-plots-can-be-hard-to-read",
    "href": "content/lectures/05-viz-slides.html#segmented-bar-plots-can-be-hard-to-read",
    "title": "05-viz",
    "section": "Segmented bar plots can be hard to read",
    "text": "Segmented bar plots can be hard to read\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(brexit, aes(y = region, fill = opinion)) + \n  geom_bar()"
  },
  {
    "objectID": "content/lectures/05-viz-slides.html#use-facets",
    "href": "content/lectures/05-viz-slides.html#use-facets",
    "title": "05-viz",
    "section": "Use facets",
    "text": "Use facets\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(brexit, aes(y = opinion, fill = region)) +\n  geom_bar() +\n  facet_wrap(~region, nrow = 1)"
  },
  {
    "objectID": "content/lectures/05-viz-slides.html#avoid-redundancy",
    "href": "content/lectures/05-viz-slides.html#avoid-redundancy",
    "title": "05-viz",
    "section": "Avoid redundancy?",
    "text": "Avoid redundancy?"
  },
  {
    "objectID": "content/lectures/05-viz-slides.html#redundancy-can-help-tell-a-story",
    "href": "content/lectures/05-viz-slides.html#redundancy-can-help-tell-a-story",
    "title": "05-viz",
    "section": "Redundancy can help tell a story",
    "text": "Redundancy can help tell a story\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(brexit, aes(y = opinion, fill = opinion)) +\n  geom_bar() +\n  facet_wrap(~region, nrow = 1)"
  },
  {
    "objectID": "content/lectures/05-viz-slides.html#be-selective-with-redundancy",
    "href": "content/lectures/05-viz-slides.html#be-selective-with-redundancy",
    "title": "05-viz",
    "section": "Be selective with redundancy",
    "text": "Be selective with redundancy\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(brexit, aes(y = opinion, fill = opinion)) +\n  geom_bar() +\n  facet_wrap(~region, nrow = 1) +\n  guides(fill = \"none\")"
  },
  {
    "objectID": "content/lectures/05-viz-slides.html#use-informative-labels",
    "href": "content/lectures/05-viz-slides.html#use-informative-labels",
    "title": "05-viz",
    "section": "Use informative labels",
    "text": "Use informative labels\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(brexit, aes(y = opinion, fill = opinion)) +\n  geom_bar() +\n  facet_wrap(~region, nrow = 1) +\n  guides(fill = \"none\") +\n  labs(\n    title = \"Was Britain right/wrong to vote to leave EU?\", \n    x = NULL, y = NULL\n  )"
  },
  {
    "objectID": "content/lectures/05-viz-slides.html#a-bit-more-info",
    "href": "content/lectures/05-viz-slides.html#a-bit-more-info",
    "title": "05-viz",
    "section": "A bit more info",
    "text": "A bit more info\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(brexit, aes(y = opinion, fill = opinion)) +\n  geom_bar() +\n  facet_wrap(~region, nrow = 1) +\n  guides(fill = \"none\") +\n  labs(\n    title = \"Was Britain right/wrong to vote to leave EU?\",\n    subtitle = \"YouGov Survey Results, 2-3 September 2019\", \n    caption = \"Source: https://d25d2506sfb94s.cloudfront.net/cumulus_uploads/document/x0msmggx08/YouGov%20-%20Brexit%20and%202019%20election.pdf\", \n    x = NULL, y = NULL\n  )"
  },
  {
    "objectID": "content/lectures/05-viz-slides.html#lets-do-better",
    "href": "content/lectures/05-viz-slides.html#lets-do-better",
    "title": "05-viz",
    "section": "Let’s do better",
    "text": "Let’s do better\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(brexit, aes(y = opinion, fill = opinion)) +\n  geom_bar() +\n  facet_wrap(~region, nrow = 1) +\n  guides(fill = \"none\") +\n  labs(\n    title = \"Was Britain right/wrong to vote to leave EU?\",\n    subtitle = \"YouGov Survey Results, 2-3 September 2019\",\n    caption = \"Source: bit.ly/2lCJZVg\", \n    x = NULL, y = NULL\n  )"
  },
  {
    "objectID": "content/lectures/05-viz-slides.html#fix-up-facet-labels",
    "href": "content/lectures/05-viz-slides.html#fix-up-facet-labels",
    "title": "05-viz",
    "section": "Fix up facet labels",
    "text": "Fix up facet labels\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(brexit, aes(y = opinion, fill = opinion)) +\n  geom_bar() +\n  facet_wrap(~region,\n    nrow = 1,\n    labeller = label_wrap_gen(width = 12) \n  ) + \n  guides(fill = \"none\") +\n  labs(\n    title = \"Was Britain right/wrong to vote to leave EU?\",\n    subtitle = \"YouGov Survey Results, 2-3 September 2019\",\n    caption = \"Source: bit.ly/2lCJZVg\",\n    x = NULL, y = NULL\n  )"
  },
  {
    "objectID": "content/lectures/05-viz-slides.html#rainbow-colors-not-always-best",
    "href": "content/lectures/05-viz-slides.html#rainbow-colors-not-always-best",
    "title": "05-viz",
    "section": "Rainbow colors not always best",
    "text": "Rainbow colors not always best"
  },
  {
    "objectID": "content/lectures/05-viz-slides.html#manually-choose-colors-when-needed",
    "href": "content/lectures/05-viz-slides.html#manually-choose-colors-when-needed",
    "title": "05-viz",
    "section": "Manually choose colors when needed",
    "text": "Manually choose colors when needed\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(brexit, aes(y = opinion, fill = opinion)) +\n  geom_bar() +\n  facet_wrap(~region, nrow = 1, labeller = label_wrap_gen(width = 12)) +\n  guides(fill = \"none\") +\n  labs(title = \"Was Britain right/wrong to vote to leave EU?\",\n       subtitle = \"YouGov Survey Results, 2-3 September 2019\",\n       caption = \"Source: bit.ly/2lCJZVg\",\n       x = NULL, y = NULL) +\n  scale_fill_manual(values = c( \n    \"Wrong\" = \"red\", \n    \"Right\" = \"green\", \n    \"Don't know\" = \"gray\" \n  ))"
  },
  {
    "objectID": "content/lectures/05-viz-slides.html#choosing-better-colors",
    "href": "content/lectures/05-viz-slides.html#choosing-better-colors",
    "title": "05-viz",
    "section": "Choosing better colors",
    "text": "Choosing better colors\ncolorbrewer2.org"
  },
  {
    "objectID": "content/lectures/05-viz-slides.html#use-better-colors",
    "href": "content/lectures/05-viz-slides.html#use-better-colors",
    "title": "05-viz",
    "section": "Use better colors",
    "text": "Use better colors\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(brexit, aes(y = opinion, fill = opinion)) +\n  geom_bar() +\n  facet_wrap(~region, nrow = 1, labeller = label_wrap_gen(width = 12)) +\n  guides(fill = \"none\") +\n  labs(title = \"Was Britain right/wrong to vote to leave EU?\",\n       subtitle = \"YouGov Survey Results, 2-3 September 2019\",\n       caption = \"Source: bit.ly/2lCJZVg\",\n       x = NULL, y = NULL) +\n  scale_fill_manual(values = c(\n    \"Wrong\" = \"#ef8a62\", \n    \"Right\" = \"#67a9cf\", \n    \"Don't know\" = \"gray\" \n  ))"
  },
  {
    "objectID": "content/lectures/05-viz-slides.html#select-theme",
    "href": "content/lectures/05-viz-slides.html#select-theme",
    "title": "05-viz",
    "section": "Select theme",
    "text": "Select theme\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(brexit, aes(y = opinion, fill = opinion)) +\n  geom_bar() +\n  facet_wrap(~region, nrow = 1, labeller = label_wrap_gen(width = 12)) +\n  guides(fill = \"none\") +\n  labs(title = \"Was Britain right/wrong to vote to leave EU?\",\n       subtitle = \"YouGov Survey Results, 2-3 September 2019\",\n       caption = \"Source: bit.ly/2lCJZVg\",\n       x = NULL, y = NULL) +\n  scale_fill_manual(values = c(\"Wrong\" = \"#ef8a62\",\n                               \"Right\" = \"#67a9cf\",\n                               \"Don't know\" = \"gray\")) +\n  theme_minimal() \n\n\n\n\n\n\nggthemes described here"
  },
  {
    "objectID": "content/lectures/05-viz-slides.html#customize-theme",
    "href": "content/lectures/05-viz-slides.html#customize-theme",
    "title": "05-viz",
    "section": "Customize theme",
    "text": "Customize theme\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(brexit, aes(y = opinion, fill = opinion)) +\n  geom_bar() +\n  facet_wrap(~region, nrow = 1, labeller = label_wrap_gen(width = 12)) +\n  guides(fill = \"none\") +\n  labs(title = \"Was Britain right/wrong to vote to leave EU?\",\n       subtitle = \"YouGov Survey Results, 2-3 September 2019\",\n       caption = \"Source: bit.ly/2lCJZVg\",\n       x = NULL, y = NULL) +\n  scale_fill_manual(values = c(\"Wrong\" = \"#ef8a62\",\n                               \"Right\" = \"#67a9cf\",\n                               \"Don't know\" = \"gray\")) +\n  theme_minimal(base_size = 16) + \n  theme(plot.title.position = \"plot\", \n        panel.grid.major.y = element_blank())"
  },
  {
    "objectID": "content/lectures/05-viz-slides.html#your-turn",
    "href": "content/lectures/05-viz-slides.html#your-turn",
    "title": "05-viz",
    "section": "Your Turn",
    "text": "Your Turn\n\nRead in the data (Data slide)\nThink of at least three different ways to tell slightly different stories with these data\nTry to implement at least one of these ideas!"
  },
  {
    "objectID": "content/lectures/05-viz-slides.html#suggested-reading",
    "href": "content/lectures/05-viz-slides.html#suggested-reading",
    "title": "05-viz",
    "section": "Suggested Reading",
    "text": "Suggested Reading\n\nR4DS Chapter 28: Graphics for Communication\nThe Glamour of Graphics: [video] [slides] [Prof’s slides inspired by Will’s talk]\n\n\n\n\nhttps://cogs137.github.io/website/"
  },
  {
    "objectID": "content/lectures/05-viz.html",
    "href": "content/lectures/05-viz.html",
    "title": "05-viz",
    "section": "",
    "text": "Slides modified from datascienceinabox.org\n\n\n\nQ: What were those columns in the NC Bike Accident Data we used?\nA: Variables are described here\n\n\nQ: I was confused by wrap vs grid and how should I choose between them.\nA: When you want to generate a plot that uses two other variables in the dataset to determine which subset of the data to plot, grid! When you want to use a single variable to facet your data and want to specify how many columns/rows to display, wrap!\n\n\nQ: When programming in R so far, I often find myself stuck at getting going on a problem and have a different time identifying on where to start. Any tips/advice on how to get past this initial bump in order to start getting through the problem?\nA: This is a common struggle! This may sound like an old-person response, but jotting down what you have and what you want (like on actual paper/iPad) can be really helpful. For example, if you have 3 columns and you know you want to have 3 columns at the end, but you want fewer rows, you can draw a picture of this and help yourself realize you need a filter. Of course when there are multiple steps, the drawings become a bit more complex…but also more helpful! The same can be said for data visualization. Drawing out quickly what you want can help you get started.\n\n\nQ:In what time frame will the lecture survey be available, how many hours after class will the survey be closed\nA: It will be open for at least 2h.\n\n\nQ:For HW1 Q7, I used read_csv and got an error message. I tried read.csv and it worked. Is there any difference between read_csv and read.csv?\nA: Hmm…I’d love to take a look to see what error you got. They are similar and often behave the same way. The difference is read.csv() was made before the tidyverse, so it reads your data in as a dataframe. read_csv() is a function that “plays nicely” with the tidyverse and reads the data in as a tibble/data frame. What does that mean practically? It means that typically each one will read the data in and you’ll get the same number of rows and columns. What could differ would be the column names and/or the column types (depending upon the data). All that said, read_csv() is what I’ll recommend in this course…so that’s why I’m curious about the error you got!\n\n\n\n\nDue Dates:\n\nLab 03 due Friday (1/27; 11:59 PM)\nLecture Participation survey “due” after class\n\nCourse Announcements:\n\nLab02 Grades (Canvas) & Feedback (GitHub Issue) Posted\nHW02 Now Available\nDiscord? - Campuswire post\n“Vote” on posts when grades released (pink: send message; green: announce in class)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCredit: Angela Zoss and Eric Monson, Duke DVS"
  },
  {
    "objectID": "content/lectures/05-viz.html#principles-for-effective-visualizations-1",
    "href": "content/lectures/05-viz.html#principles-for-effective-visualizations-1",
    "title": "05-viz",
    "section": "Principles for effective visualizations",
    "text": "Principles for effective visualizations\n\nOrder matters\nPut long categories on the y-axis\nKeep scales consistent\nSelect meaningful colors\nUse meaningful and nonredundant labels"
  },
  {
    "objectID": "content/lectures/05-viz.html#data",
    "href": "content/lectures/05-viz.html#data",
    "title": "05-viz",
    "section": "Data",
    "text": "Data\nIn September 2019, YouGov survey asked 1,639 GB adults the following question:\n\n\n\nIn hindsight, do you think Britain was right/wrong to vote to leave EU?\n\nRight to leave\n\nWrong to leave\n\nDon’t know\n\n\n\n\n\n\n\n\n\n\n\n\nSource: YouGov Survey Results, retrieved Oct 7, 2019"
  },
  {
    "objectID": "content/lectures/05-viz.html#the-data-code",
    "href": "content/lectures/05-viz.html#the-data-code",
    "title": "05-viz",
    "section": "The Data: Code",
    "text": "The Data: Code\n\nbrexit <- tibble(\n  opinion = c(\n    rep(\"Right\", 664), rep(\"Wrong\", 787), rep(\"Don't know\", 188)\n  ),\n  region = c(\n    rep(\"london\", 63), rep(\"rest_of_south\", 241), rep(\"midlands_wales\", 145), rep(\"north\", 176), rep(\"scot\", 39),\n    rep(\"london\", 110), rep(\"rest_of_south\", 257), rep(\"midlands_wales\", 152), rep(\"north\", 176), rep(\"scot\", 92),\n    rep(\"london\", 24), rep(\"rest_of_south\", 49), rep(\"midlands_wales\", 57), rep(\"north\", 48), rep(\"scot\", 10)\n  )\n)"
  },
  {
    "objectID": "content/lectures/05-viz.html#order-matters",
    "href": "content/lectures/05-viz.html#order-matters",
    "title": "05-viz",
    "section": "Order matters",
    "text": "Order matters\nAlphabetical is rarely ideal\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(brexit, aes(x = opinion)) +\n  geom_bar()"
  },
  {
    "objectID": "content/lectures/05-viz.html#order-by-frequency",
    "href": "content/lectures/05-viz.html#order-by-frequency",
    "title": "05-viz",
    "section": "Order by frequency",
    "text": "Order by frequency\n\nPlotCode\n\n\n\n\n\n\n\n\n\nfct_infreq: Reorder factors’ levels by frequency\n\nggplot(brexit, aes(x = fct_infreq(opinion))) + \n  geom_bar()"
  },
  {
    "objectID": "content/lectures/05-viz.html#clean-up-labels",
    "href": "content/lectures/05-viz.html#clean-up-labels",
    "title": "05-viz",
    "section": "Clean up labels",
    "text": "Clean up labels\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(brexit, aes(x = opinion)) +\n  geom_bar() +\n  labs( \n    x = \"Opinion\", \n    y = \"Count\" \n  )"
  },
  {
    "objectID": "content/lectures/05-viz.html#avoiding-alphabetical-order",
    "href": "content/lectures/05-viz.html#avoiding-alphabetical-order",
    "title": "05-viz",
    "section": "Avoiding Alphabetical Order",
    "text": "Avoiding Alphabetical Order\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(brexit, aes(x = region)) +\n  geom_bar()"
  },
  {
    "objectID": "content/lectures/05-viz.html#use-inherent-level-order",
    "href": "content/lectures/05-viz.html#use-inherent-level-order",
    "title": "05-viz",
    "section": "Use inherent level order",
    "text": "Use inherent level order\n\nRelevelPlot\n\n\nfct_relevel: Reorder factor levels using a custom order\n\nbrexit <- brexit |>\n  mutate(\n    region = fct_relevel( \n      region,\n      \"london\", \"rest_of_south\", \"midlands_wales\", \"north\", \"scot\"\n    )\n  )"
  },
  {
    "objectID": "content/lectures/05-viz.html#clean-up-labels-1",
    "href": "content/lectures/05-viz.html#clean-up-labels-1",
    "title": "05-viz",
    "section": "Clean up labels",
    "text": "Clean up labels\n\nRecodePlot\n\n\nfct_recode: Change factor levels by hand\n\nbrexit <- brexit |>\n  mutate(\n    region = fct_recode( \n      region,\n      London = \"london\",\n      `Rest of South` = \"rest_of_south\",\n      `Midlands / Wales` = \"midlands_wales\",\n      North = \"north\",\n      Scotland = \"scot\"\n    )\n  )"
  },
  {
    "objectID": "content/lectures/05-viz.html#put-long-categories-on-the-y-axis",
    "href": "content/lectures/05-viz.html#put-long-categories-on-the-y-axis",
    "title": "05-viz",
    "section": "Put long categories on the y-axis",
    "text": "Put long categories on the y-axis\nLong categories can be hard to read"
  },
  {
    "objectID": "content/lectures/05-viz.html#move-them-to-the-y-axis",
    "href": "content/lectures/05-viz.html#move-them-to-the-y-axis",
    "title": "05-viz",
    "section": "Move them to the y-axis",
    "text": "Move them to the y-axis\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(brexit, aes(y = region)) + \n  geom_bar()"
  },
  {
    "objectID": "content/lectures/05-viz.html#and-reverse-the-order-of-levels",
    "href": "content/lectures/05-viz.html#and-reverse-the-order-of-levels",
    "title": "05-viz",
    "section": "And reverse the order of levels",
    "text": "And reverse the order of levels\n\nPlotCode\n\n\n\n\n\n\n\n\n\nfct_rev: Reverse order of factor levels\n\nggplot(brexit, aes(y = fct_rev(region))) + \n  geom_bar()"
  },
  {
    "objectID": "content/lectures/05-viz.html#clean-up-labels-2",
    "href": "content/lectures/05-viz.html#clean-up-labels-2",
    "title": "05-viz",
    "section": "Clean up labels",
    "text": "Clean up labels\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(brexit, aes(y = fct_rev(region))) +\n  geom_bar() +\n  labs( \n    x = \"Count\", \n    y = \"Region\" \n  )"
  },
  {
    "objectID": "content/lectures/05-viz.html#segmented-bar-plots-can-be-hard-to-read",
    "href": "content/lectures/05-viz.html#segmented-bar-plots-can-be-hard-to-read",
    "title": "05-viz",
    "section": "Segmented bar plots can be hard to read",
    "text": "Segmented bar plots can be hard to read\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(brexit, aes(y = region, fill = opinion)) + \n  geom_bar()"
  },
  {
    "objectID": "content/lectures/05-viz.html#use-facets",
    "href": "content/lectures/05-viz.html#use-facets",
    "title": "05-viz",
    "section": "Use facets",
    "text": "Use facets\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(brexit, aes(y = opinion, fill = region)) +\n  geom_bar() +\n  facet_wrap(~region, nrow = 1)"
  },
  {
    "objectID": "content/lectures/05-viz.html#avoid-redundancy",
    "href": "content/lectures/05-viz.html#avoid-redundancy",
    "title": "05-viz",
    "section": "Avoid redundancy?",
    "text": "Avoid redundancy?"
  },
  {
    "objectID": "content/lectures/05-viz.html#redundancy-can-help-tell-a-story",
    "href": "content/lectures/05-viz.html#redundancy-can-help-tell-a-story",
    "title": "05-viz",
    "section": "Redundancy can help tell a story",
    "text": "Redundancy can help tell a story\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(brexit, aes(y = opinion, fill = opinion)) +\n  geom_bar() +\n  facet_wrap(~region, nrow = 1)"
  },
  {
    "objectID": "content/lectures/05-viz.html#be-selective-with-redundancy",
    "href": "content/lectures/05-viz.html#be-selective-with-redundancy",
    "title": "05-viz",
    "section": "Be selective with redundancy",
    "text": "Be selective with redundancy\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(brexit, aes(y = opinion, fill = opinion)) +\n  geom_bar() +\n  facet_wrap(~region, nrow = 1) +\n  guides(fill = \"none\")"
  },
  {
    "objectID": "content/lectures/05-viz.html#use-informative-labels",
    "href": "content/lectures/05-viz.html#use-informative-labels",
    "title": "05-viz",
    "section": "Use informative labels",
    "text": "Use informative labels\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(brexit, aes(y = opinion, fill = opinion)) +\n  geom_bar() +\n  facet_wrap(~region, nrow = 1) +\n  guides(fill = \"none\") +\n  labs(\n    title = \"Was Britain right/wrong to vote to leave EU?\", \n    x = NULL, y = NULL\n  )"
  },
  {
    "objectID": "content/lectures/05-viz.html#a-bit-more-info",
    "href": "content/lectures/05-viz.html#a-bit-more-info",
    "title": "05-viz",
    "section": "A bit more info",
    "text": "A bit more info\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(brexit, aes(y = opinion, fill = opinion)) +\n  geom_bar() +\n  facet_wrap(~region, nrow = 1) +\n  guides(fill = \"none\") +\n  labs(\n    title = \"Was Britain right/wrong to vote to leave EU?\",\n    subtitle = \"YouGov Survey Results, 2-3 September 2019\", \n    caption = \"Source: https://d25d2506sfb94s.cloudfront.net/cumulus_uploads/document/x0msmggx08/YouGov%20-%20Brexit%20and%202019%20election.pdf\", \n    x = NULL, y = NULL\n  )"
  },
  {
    "objectID": "content/lectures/05-viz.html#lets-do-better",
    "href": "content/lectures/05-viz.html#lets-do-better",
    "title": "05-viz",
    "section": "Let’s do better",
    "text": "Let’s do better\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(brexit, aes(y = opinion, fill = opinion)) +\n  geom_bar() +\n  facet_wrap(~region, nrow = 1) +\n  guides(fill = \"none\") +\n  labs(\n    title = \"Was Britain right/wrong to vote to leave EU?\",\n    subtitle = \"YouGov Survey Results, 2-3 September 2019\",\n    caption = \"Source: bit.ly/2lCJZVg\", \n    x = NULL, y = NULL\n  )"
  },
  {
    "objectID": "content/lectures/05-viz.html#fix-up-facet-labels",
    "href": "content/lectures/05-viz.html#fix-up-facet-labels",
    "title": "05-viz",
    "section": "Fix up facet labels",
    "text": "Fix up facet labels\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(brexit, aes(y = opinion, fill = opinion)) +\n  geom_bar() +\n  facet_wrap(~region,\n    nrow = 1,\n    labeller = label_wrap_gen(width = 12) \n  ) + \n  guides(fill = \"none\") +\n  labs(\n    title = \"Was Britain right/wrong to vote to leave EU?\",\n    subtitle = \"YouGov Survey Results, 2-3 September 2019\",\n    caption = \"Source: bit.ly/2lCJZVg\",\n    x = NULL, y = NULL\n  )"
  },
  {
    "objectID": "content/lectures/05-viz.html#rainbow-colors-not-always-best",
    "href": "content/lectures/05-viz.html#rainbow-colors-not-always-best",
    "title": "05-viz",
    "section": "Rainbow colors not always best",
    "text": "Rainbow colors not always best"
  },
  {
    "objectID": "content/lectures/05-viz.html#manually-choose-colors-when-needed",
    "href": "content/lectures/05-viz.html#manually-choose-colors-when-needed",
    "title": "05-viz",
    "section": "Manually choose colors when needed",
    "text": "Manually choose colors when needed\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(brexit, aes(y = opinion, fill = opinion)) +\n  geom_bar() +\n  facet_wrap(~region, nrow = 1, labeller = label_wrap_gen(width = 12)) +\n  guides(fill = \"none\") +\n  labs(title = \"Was Britain right/wrong to vote to leave EU?\",\n       subtitle = \"YouGov Survey Results, 2-3 September 2019\",\n       caption = \"Source: bit.ly/2lCJZVg\",\n       x = NULL, y = NULL) +\n  scale_fill_manual(values = c( \n    \"Wrong\" = \"red\", \n    \"Right\" = \"green\", \n    \"Don't know\" = \"gray\" \n  ))"
  },
  {
    "objectID": "content/lectures/05-viz.html#choosing-better-colors",
    "href": "content/lectures/05-viz.html#choosing-better-colors",
    "title": "05-viz",
    "section": "Choosing better colors",
    "text": "Choosing better colors\ncolorbrewer2.org"
  },
  {
    "objectID": "content/lectures/05-viz.html#use-better-colors",
    "href": "content/lectures/05-viz.html#use-better-colors",
    "title": "05-viz",
    "section": "Use better colors",
    "text": "Use better colors\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(brexit, aes(y = opinion, fill = opinion)) +\n  geom_bar() +\n  facet_wrap(~region, nrow = 1, labeller = label_wrap_gen(width = 12)) +\n  guides(fill = \"none\") +\n  labs(title = \"Was Britain right/wrong to vote to leave EU?\",\n       subtitle = \"YouGov Survey Results, 2-3 September 2019\",\n       caption = \"Source: bit.ly/2lCJZVg\",\n       x = NULL, y = NULL) +\n  scale_fill_manual(values = c(\n    \"Wrong\" = \"#ef8a62\", \n    \"Right\" = \"#67a9cf\", \n    \"Don't know\" = \"gray\" \n  ))"
  },
  {
    "objectID": "content/lectures/05-viz.html#select-theme",
    "href": "content/lectures/05-viz.html#select-theme",
    "title": "05-viz",
    "section": "Select theme",
    "text": "Select theme\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(brexit, aes(y = opinion, fill = opinion)) +\n  geom_bar() +\n  facet_wrap(~region, nrow = 1, labeller = label_wrap_gen(width = 12)) +\n  guides(fill = \"none\") +\n  labs(title = \"Was Britain right/wrong to vote to leave EU?\",\n       subtitle = \"YouGov Survey Results, 2-3 September 2019\",\n       caption = \"Source: bit.ly/2lCJZVg\",\n       x = NULL, y = NULL) +\n  scale_fill_manual(values = c(\"Wrong\" = \"#ef8a62\",\n                               \"Right\" = \"#67a9cf\",\n                               \"Don't know\" = \"gray\")) +\n  theme_minimal() \n\n\n\n\n\n\nggthemes described here"
  },
  {
    "objectID": "content/lectures/05-viz.html#customize-theme",
    "href": "content/lectures/05-viz.html#customize-theme",
    "title": "05-viz",
    "section": "Customize theme",
    "text": "Customize theme\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(brexit, aes(y = opinion, fill = opinion)) +\n  geom_bar() +\n  facet_wrap(~region, nrow = 1, labeller = label_wrap_gen(width = 12)) +\n  guides(fill = \"none\") +\n  labs(title = \"Was Britain right/wrong to vote to leave EU?\",\n       subtitle = \"YouGov Survey Results, 2-3 September 2019\",\n       caption = \"Source: bit.ly/2lCJZVg\",\n       x = NULL, y = NULL) +\n  scale_fill_manual(values = c(\"Wrong\" = \"#ef8a62\",\n                               \"Right\" = \"#67a9cf\",\n                               \"Don't know\" = \"gray\")) +\n  theme_minimal(base_size = 16) + \n  theme(plot.title.position = \"plot\", \n        panel.grid.major.y = element_blank())"
  },
  {
    "objectID": "content/lectures/05-viz.html#your-turn",
    "href": "content/lectures/05-viz.html#your-turn",
    "title": "05-viz",
    "section": "Your Turn",
    "text": "Your Turn\n\nRead in the data (Data slide)\nThink of at least three different ways to tell slightly different stories with these data\nTry to implement at least one of these ideas!"
  },
  {
    "objectID": "content/lectures/05-viz.html#suggested-reading",
    "href": "content/lectures/05-viz.html#suggested-reading",
    "title": "05-viz",
    "section": "Suggested Reading",
    "text": "Suggested Reading\n\nR4DS Chapter 28: Graphics for Communication\nThe Glamour of Graphics: [video] [slides] [Prof’s slides inspired by Will’s talk]"
  },
  {
    "objectID": "content/lectures/09-projects-slides.html#qa",
    "href": "content/lectures/09-projects-slides.html#qa",
    "title": "09-projects",
    "section": "Q&A",
    "text": "Q&A\n\nQ: When is the presentation?\nA: Discussing this today! It’s at the end of the quarter. While written reports will be completed throughout the rest of the quarter as we do case studies, an oral presentation will be part of your final project. These will be able to be recorded or given live in person during finals week.\n\n\nQ: Will we have another lab with as many questions as Lab 4? The turnaround was pretty stressful, so just want to be prepared.\nA: The next lab (multiple linear regression) is also a tady lengthy, but after that I don’t plan on the rest being quite as long. Just as a reminder that you do not need to complete the entire lab to receive credit!\n\n\nQ: I’m not really comfortable with log transformations yet. Will we get more practice on that?\nA: Yup! Last lecture was a first introduction. We’ll return to this in upcoming case studies. The midterm does not require any transformations."
  },
  {
    "objectID": "content/lectures/09-projects-slides.html#course-announcements",
    "href": "content/lectures/09-projects-slides.html#course-announcements",
    "title": "09-projects",
    "section": "Course Announcements",
    "text": "Course Announcements\n\nLecture Participation survey “due” after class\nMidterm due Monday (2/13; 11:59 PM):\n\nreleased Friday (tomorrow) after lab\ncompleted individually\n\nPractice Midterm Answer Key Posted"
  },
  {
    "objectID": "content/lectures/09-projects-slides.html#agenda",
    "href": "content/lectures/09-projects-slides.html#agenda",
    "title": "09-projects",
    "section": "Agenda",
    "text": "Agenda\n\nExam chat\nHW02 recap\nCase Studies\nFinal Project"
  },
  {
    "objectID": "content/lectures/09-projects-slides.html#midterm-details",
    "href": "content/lectures/09-projects-slides.html#midterm-details",
    "title": "09-projects",
    "section": "Midterm Details",
    "text": "Midterm Details\n\n\nInstructions will be posted on the website at 2PM Fri (tomorrow)\nYou’ll be provided a template (link on Canvas) and “submit” on GitHub\nYou’ll be provided with data and a data dictionary\nCovers data wrangling/tidying, dplyr, viz/ggplot2, and linear regression/tidymodels"
  },
  {
    "objectID": "content/lectures/09-projects-slides.html#hw02-q1",
    "href": "content/lectures/09-projects-slides.html#hw02-q1",
    "title": "09-projects",
    "section": "HW02 : Q1",
    "text": "HW02 : Q1\nGenerate a visualization that will allow readers to determine whether male or female penguins are larger (by mass)."
  },
  {
    "objectID": "content/lectures/09-projects-slides.html#boxplot",
    "href": "content/lectures/09-projects-slides.html#boxplot",
    "title": "09-projects",
    "section": "Boxplot",
    "text": "Boxplot\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\npenguins |>\n  drop_na() |> \n  ggplot(aes(x = sex, y = body_mass_g)) +\n  geom_boxplot() +\n  labs(title = \"Penguin body mass by sex\", \n       y = \"body mass (g)\") +\n  theme(plot.title.position = \"plot\")"
  },
  {
    "objectID": "content/lectures/09-projects-slides.html#histogram",
    "href": "content/lectures/09-projects-slides.html#histogram",
    "title": "09-projects",
    "section": "Histogram",
    "text": "Histogram\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\npenguins |>\n  filter(!is.na(sex)) |>\n  ggplot(mapping = aes(x = body_mass_g, fill = sex)) +\n  geom_histogram() +\n  labs(\n    title = 'Body Mass Distribution by Sex',\n    x = 'Body Mass (g)',\n    y = 'Count',\n    color = 'Sex'\n  )"
  },
  {
    "objectID": "content/lectures/09-projects-slides.html#faceted-histograms",
    "href": "content/lectures/09-projects-slides.html#faceted-histograms",
    "title": "09-projects",
    "section": "Faceted Histograms",
    "text": "Faceted Histograms\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\npenguins |>\n  filter(!is.na(body_mass_g)) |>\n  ggplot(., mapping=aes(y=body_mass_g)) + \n  geom_histogram(binwidth=100) +\n  facet_grid(. ~ sex) + \n  labs(\n    title='Frequency of Penguins based on their Body mass and Female/Male Penguins',\n    x='Frequency / Count',\n    y='Body Mass (of penguins, in g (grams))')"
  },
  {
    "objectID": "content/lectures/09-projects-slides.html#hw02-q2",
    "href": "content/lectures/09-projects-slides.html#hw02-q2",
    "title": "09-projects",
    "section": "HW02 : Q2",
    "text": "HW02 : Q2\nGenerate a barplot that visualizes how many penguins there are from each species on each island. Each island should be a different panel (in a 1 row x 3 columns visualization), and each chart should visualize the species count."
  },
  {
    "objectID": "content/lectures/09-projects-slides.html#barplot",
    "href": "content/lectures/09-projects-slides.html#barplot",
    "title": "09-projects",
    "section": "Barplot",
    "text": "Barplot\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(penguins, aes(x = species)) +\n  geom_bar() +\n  facet_wrap(~ island) +\n  labs(title = \"Count of species per island\") +\n  theme(plot.title.position = \"plot\")"
  },
  {
    "objectID": "content/lectures/09-projects-slides.html#barplot-with-color",
    "href": "content/lectures/09-projects-slides.html#barplot-with-color",
    "title": "09-projects",
    "section": "Barplot with color",
    "text": "Barplot with color\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n  ggplot(penguins, aes(x = fct_infreq(species), fill = species)) +\n  geom_bar() +\n  facet_wrap(~island, nrow = 1) +\n  guides(fill = \"none\") + \n  labs(\n    title = \"Count of Penguin Species Across the Palmer Archipelago Islands\",\n    x = \"Species\",\n    y = \"Number of Penguins\"\n  )"
  },
  {
    "objectID": "content/lectures/09-projects-slides.html#hw02-q3",
    "href": "content/lectures/09-projects-slides.html#hw02-q3",
    "title": "09-projects",
    "section": "HW02 : Q3",
    "text": "HW02 : Q3\nGenerate a scatterplot that will allow the viewer to determine whether flipper length has differed over time. Be sure to color the points on this plot by species."
  },
  {
    "objectID": "content/lectures/09-projects-slides.html#scatterplot-no-jitter",
    "href": "content/lectures/09-projects-slides.html#scatterplot-no-jitter",
    "title": "09-projects",
    "section": "Scatterplot (no jitter)",
    "text": "Scatterplot (no jitter)\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(penguins, aes(x = year, \n           y = flipper_length_mm,\n           color = species)) +\ngeom_point() + \nscale_color_viridis_d() +\nscale_x_continuous(n.breaks = 3) +\nlabs(\n  title = \"Flipper Lengths of Penguin Species Over Time\",\n  color = \"Species\",\n  x = \"Year\",\n  y = \"Flipper Length (mm)\"\n)"
  },
  {
    "objectID": "content/lectures/09-projects-slides.html#scatterplot-w-jitter",
    "href": "content/lectures/09-projects-slides.html#scatterplot-w-jitter",
    "title": "09-projects",
    "section": "Scatterplot (w/ jitter)",
    "text": "Scatterplot (w/ jitter)\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(penguins,\n       mapping = aes(x = factor(year),\n                     y = flipper_length_mm,\n                     color = species)) +\n  scale_color_viridis_d() +\n  geom_jitter(na.rm = TRUE) +\n  labs(title = \"Flipper length of different penguin species by year\",\n       y = \"Flipper length (mm)\",\n       x = \"Year\") +\n  theme(plot.title.position = \"plot\")"
  },
  {
    "objectID": "content/lectures/09-projects-slides.html#hw02-part-ii",
    "href": "content/lectures/09-projects-slides.html#hw02-part-ii",
    "title": "09-projects",
    "section": "HW02 : Part II",
    "text": "HW02 : Part II\nImitation is the highest form of flattery\nExample from: Eric Ko\n\nOriginalPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Eric890916\nchessData <- data.frame(country = c(\"United States\", \"Germany\", \"Canada\", \"Spain\", \"Russia\", \"France\", \"Bosnia and Herzegovina\", \"Croatia\", \"Turkey\", \"Austria\"),\n                        num = c(89, 55, 44, 41, 36, 34, 32, 32, 31, 29))\n\nggplot(chessData, aes(y = reorder(country, num), x = num)) + \n  geom_col(fill = \"#008080\") + \n  geom_text(aes(label = num), hjust = 1, nudge_x = -.5) +\n  labs(title = \"More players transfer to the U.S. than to any other country\",\n       subtitle = \"Nations that received the highest number of player transfers, 2000-17\",\n       caption = \"2017 data as of April 11. SOURCE: FIDE\",\n       x = \"NUMBER OF TRANSFERS\", y = \"COUNTRY\")"
  },
  {
    "objectID": "content/lectures/09-projects-slides.html#section",
    "href": "content/lectures/09-projects-slides.html#section",
    "title": "09-projects",
    "section": "",
    "text": "Example from: Christine Kwon\n\nOriginalPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\ncommon_first_names <- read.csv(\"https://raw.githubusercontent.com/fivethirtyeight/data/master/most-common-name/new-top-firstNames.csv\")\n\n# editing data\ncommon_first_names <- common_first_names[1:20, ]\ncommon_first_names <- common_first_names %>%\n  mutate(sex = case_when (name == \"Mary\" | \n                          name == \"Jennifer\" |\n                          name == \"Patricia\" |\n                          name == \"Linda\" |\n                          name == \"Elizabeth\" ~ \"female\",\n                          name != \"Mary\" | \n                          name != \"Jennifer\" |\n                          name != \"Patricia\" |\n                          name != \"Linda\" |\n                          name != \"Elizabeth\" ~ \"male\",),\n         percentage = round(newPerct2013 * 1000, digits = 1))\n\n# creating visualization\ncommon_first_names %>%\n  ggplot(aes(y = reorder(name, percentage),  x = percentage, fill = sex)) +\n  geom_histogram(stat = \"identity\") +\n  guides(fill = \"none\") +\n  annotate(\"text\", x = 9.65, y = 21.7, label = expression(bold(\"MALE\")), cex = 3.85, hjust = 1, vjust = 1, color = \"dodgerblue\") +\n  annotate(\"text\", x = 11.5, y = 21.7, label = expression(bold(\"FEMALE\")), cex = 3.85, hjust = 1, vjust = 1, color = \"gold1\") +\n  geom_text(aes(label = signif(percentage)), nudge_x = 0.5) +\n  labs(title = \"Most Common First Names\",\n       subtitle = \"Per 1,000 Americans as of 2013\") +\n  scale_fill_manual(values = c(\"male\" = \"dodgerblue\",\n                               \"female\" = \"gold1\")) +\n  theme_classic() +\n  theme(plot.title.position = \"plot\", \n        panel.grid.major.y = element_blank(),\n        plot.title = element_text(size = 16,\n                                  face = \"bold\"),\n        plot.subtitle = element_text(size = 11),\n        axis.ticks.x = element_blank(),\n        axis.ticks.y = element_blank(),\n        axis.line.x = element_blank(),\n        axis.line.y = element_blank(),\n        axis.text.x = element_blank(),\n        axis.text.y = element_text(color = \"black\"),\n        axis.title.x = element_blank(),\n        axis.title.y = element_blank())"
  },
  {
    "objectID": "content/lectures/09-projects-slides.html#section-1",
    "href": "content/lectures/09-projects-slides.html#section-1",
    "title": "09-projects",
    "section": "",
    "text": "Example by: Cheng Chang (FA21)\n\nOriginalPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n# get data\npoll <- read_csv(\"https://raw.githubusercontent.com/fivethirtyeight/covid-19-polls/master/covid_approval_polls_adjusted.csv\")\npoll_mean <- read_csv(\"https://raw.githubusercontent.com/fivethirtyeight/covid-19-polls/master/covid_approval_toplines.csv\")\n\npoll <- poll |>\n  filter(subject == \"Biden\", party != \"all\") |>\n  mutate(Party=case_when(party == \"D\" ~ \"Democrats\",\n                         party == \"I\" ~ \"Independents\",\n                         party == \"R\" ~ \"Republicans\")) |>\n  mutate(enddate=as.Date(enddate, format=\"%m/%d/%Y\"))\n\npoll_mean <- poll_mean |>\n  filter(subject == \"Biden\", party != \"all\") |>\n  mutate(Party=case_when(party == \"D\" ~ \"Democrats\",\n                         party == \"I\" ~ \"Independents\",\n                         party == \"R\" ~ \"Republicans\")) |>\n  mutate(modeldate=as.Date(modeldate, format=\"%m/%d/%Y\"))\n\nggplot() +\n  geom_point(data=poll,\n             aes(x=enddate, y=approve_adjusted, color=Party),\n             size=1,\n             alpha = 0.5) +\n  geom_path(data=poll_mean, aes(x=modeldate, y=approve_estimate, color=Party)) +\n  labs(title=\"Approval of Biden’s response varies widely by party\",\n       subtitle=\n         \"A calculation of the share of Democrats, Republicans and independents who approve of the president’s\\nhandling of the coronavirus outbreak\",\n       x=NULL,\n       y=NULL) +\n  scale_color_manual(values = c(\"Democrats\" = \"#2acaea\",\n                                \"Independents\" = \"#ce7e00\",\n                                \"Republicans\" = \"#f44336\")) +\n  theme(plot.title.position = \"plot\",\n        panel.grid.major = element_line(color=\"grey\"),\n        panel.border = element_rect(fill=NA, color=\"grey\"),\n        panel.background = element_rect(fill=\"white\"))"
  },
  {
    "objectID": "content/lectures/09-projects-slides.html#hw03-part-iii",
    "href": "content/lectures/09-projects-slides.html#hw03-part-iii",
    "title": "09-projects",
    "section": "HW03 : Part III",
    "text": "HW03 : Part III\nTake a Sad Plot & Make It Better\nExample from: Christine Kwon\n\nOriginalPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\nmedals <- tibble(\n  country = c(\n    rep(\"USA\", 79), rep(\"CHN\", 70), rep(\"ROC\", 53), rep(\"GBR\", 48), rep(\"JPN\", 40)),\n  medal_type = c(\n    rep(\"gold\", 25), rep(\"silver\", 31), rep(\"bronze\", 23),\n    rep(\"gold\", 32), rep(\"silver\", 22), rep(\"bronze\", 16),\n    rep(\"gold\", 14), rep(\"silver\", 21), rep(\"bronze\", 18),\n    rep(\"gold\", 15), rep(\"silver\", 18), rep(\"bronze\", 15),\n    rep(\"gold\", 21), rep(\"silver\", 7), rep(\"bronze\", 12)))\n\n# creating visualization\nmedal_viz <- medals %>%\n   mutate(country = factor(country, levels = c(\"JPN\", \"GBR\",\"ROC\", \"CHN\", \"USA\"))) %>%\n  ggplot(aes(y = country, fill = factor(medal_type, levels = c(\"bronze\", \"silver\", \"gold\")))) + \n  geom_bar() +\n  annotate(\"text\", x = 4.5, y = 5.05, label = \"25\", cex = 4, hjust = 1, vjust = 1) +\n  annotate(\"text\", x = 30.5, y = 5.05, label = \"31\", cex = 4, hjust = 1, vjust = 1) +\n  annotate(\"text\", x = 61.5, y = 5.05, label = \"23\", cex = 4, hjust = 1, vjust = 1) +\n  annotate(\"text\", x = 86.5, y = 5.05, label = expression(bold(\"79\")), cex = 5, hjust = 1, vjust = 1) +\n  annotate(\"text\", x = 4.5, y = 4.05, label = \"32\", cex = 4, hjust = 1, vjust = 1) +\n  annotate(\"text\", x = 37.5, y = 4.05, label = \"22\", cex = 4, hjust = 1, vjust = 1) +\n  annotate(\"text\", x = 58.5, y = 4.05, label = \"16\", cex = 4, hjust = 1, vjust = 1) +\n  annotate(\"text\", x = 76.5, y = 4.05, label = expression(bold(\"70\")), cex = 5, hjust = 1, vjust = 1) +\n  annotate(\"text\", x = 4.5, y = 3.05, label = \"14\", cex = 4, hjust = 1, vjust = 1) +\n  annotate(\"text\", x = 18.5, y = 3.05, label = \"21\", cex = 4, hjust = 1, vjust = 1) +\n  annotate(\"text\", x = 39.5, y = 3.05, label = \"18\", cex = 4, hjust = 1, vjust = 1) +\n  annotate(\"text\", x = 59.5, y = 3.05, label = expression(bold(\"53\")), cex = 5, hjust = 1, vjust = 1) +\n  annotate(\"text\", x = 4.5, y = 2.05, label = \"15\", cex = 4, hjust = 1, vjust = 1) +\n  annotate(\"text\", x = 19.5, y = 2.05, label = \"18\", cex = 4, hjust = 1, vjust = 1) +\n  annotate(\"text\", x = 38, y = 2.05, label = \"15\", cex = 4, hjust = 1, vjust = 1) +\n  annotate(\"text\", x = 54.5, y = 2.05, label = expression(bold(\"48\")), cex = 5, hjust = 1, vjust = 1) +\n  annotate(\"text\", x = 4.5, y = 1.05, label = \"21\", cex = 4, hjust = 1, vjust = 1) +\n  annotate(\"text\", x = 23.5, y = 1.05, label = \"7\", cex = 4, hjust = 1, vjust = 1) +\n  annotate(\"text\", x = 32.5, y = 1.05, label = \"12\", cex = 4, hjust = 1, vjust = 1) +\n  annotate(\"text\", x = 46.5, y = 1.05, label = expression(bold(\"40\")) , cex = 5, hjust = 1, vjust = 1) +\n  labs(title = \"Medals Won at the Tokyo Olympics (ongoing)\", \n       subtitle = \"Distribution of medals won by the top 5 countries (ordered by total)\", \n       fill = \"Medal Type\") +\n  scale_fill_manual(values = c(\"gold\" = \"gold\",\n                               \"silver\" = \"gray75\",\n                               \"bronze\" = \"tan3\")) +\n  theme(#legend.title = element_text(face = \"bold\"),\n        legend.position = \"top\") + \n  guides(fill = guide_legend(title.position = \"top\")) +\n  theme_classic() +\n  theme(plot.title.position = \"plot\", \n        panel.grid.major.y = element_blank(),\n        plot.title = element_text(size = 16,\n                                  face = \"bold\"),\n        plot.subtitle = element_text(size = 11),\n        axis.ticks.x = element_blank(),\n        axis.ticks.y = element_blank(),\n        axis.line.x = element_blank(),\n        axis.line.y = element_blank(),\n        axis.text.x = element_blank(),\n        axis.text.y = element_text(color = \"black\", \n                                   #face = \"bold\", \n                                   size = 11),\n        axis.title.x = element_blank(),\n        axis.title.y = element_blank())\n\n\nmedal_viz +\n  theme(legend.position = c(0.8, 0.25))"
  },
  {
    "objectID": "content/lectures/09-projects-slides.html#opencasestudies",
    "href": "content/lectures/09-projects-slides.html#opencasestudies",
    "title": "09-projects",
    "section": "OpenCaseStudies",
    "text": "OpenCaseStudies\n\nOpenCaseStudies\nUses R/the tidyverse\nasks public health-centric questions\ngoal: to teach statistical analysis/data science through case studies"
  },
  {
    "objectID": "content/lectures/09-projects-slides.html#what-well-do",
    "href": "content/lectures/09-projects-slides.html#what-well-do",
    "title": "09-projects",
    "section": "What We’ll Do",
    "text": "What We’ll Do\nFor each case study (2), during lecture:\n\nStats: (1-2d)\nBackground, Data & Wrangling (1-2d)\nEDA & Analysis (1d)\n\n\nFor each case study:\n\nyou’ll also work with case study data in lab.\nyou’ll work in assigned groups of ~3 students to complete a data science report"
  },
  {
    "objectID": "content/lectures/09-projects-slides.html#data-science-reports",
    "href": "content/lectures/09-projects-slides.html#data-science-reports",
    "title": "09-projects",
    "section": "Data Science Reports",
    "text": "Data Science Reports\nWith your group, you will:\n\ncarry out all steps of the analysis\n\nsome code will be taken directly from lecture\n\nadd text/organize into a report\n\n\n\nhave to extend the case study"
  },
  {
    "objectID": "content/lectures/09-projects-slides.html#what-does-extend-the-case-study-mean",
    "href": "content/lectures/09-projects-slides.html#what-does-extend-the-case-study-mean",
    "title": "09-projects",
    "section": "What does extend the case study mean?",
    "text": "What does extend the case study mean?\nYou’ll need to do something more on the topic beyond what is presented in class.\n\nExamples:\n\nAsking an additional question and answering it from the data provided\nFinding an additional dataset and using it to add to the case study\nGenerating a handful of additional and very informative visualizations (beyond what’s presented in class)"
  },
  {
    "objectID": "content/lectures/09-projects-slides.html#grading",
    "href": "content/lectures/09-projects-slides.html#grading",
    "title": "09-projects",
    "section": "Grading",
    "text": "Grading\nGraded on:\n\ncontent (code, text, viz)\neffective written communication\nextension carried out"
  },
  {
    "objectID": "content/lectures/09-projects-slides.html#final-project-logistics",
    "href": "content/lectures/09-projects-slides.html#final-project-logistics",
    "title": "09-projects",
    "section": "Final Project Logistics",
    "text": "Final Project Logistics\n\nwill be completed in groups of 3-4 students\nyou get to choose the group\nI will ask at the end of week 7 for your final project groups"
  },
  {
    "objectID": "content/lectures/09-projects-slides.html#final-project-details",
    "href": "content/lectures/09-projects-slides.html#final-project-details",
    "title": "09-projects",
    "section": "Final Project Details",
    "text": "Final Project Details\nTwo possible Paths:\n\nCreate a technical presentation on a statistics topic and/or an R package.\nCarry out a data analysis"
  },
  {
    "objectID": "content/lectures/09-projects-slides.html#option-1-technical-presentation",
    "href": "content/lectures/09-projects-slides.html#option-1-technical-presentation",
    "title": "09-projects",
    "section": "Option 1: Technical Presentation",
    "text": "Option 1: Technical Presentation\n\n.Rmd document used to make slides\n“Teaches” the details of the R package/statistics topic\nDemonstrates how to use the package and/or carry out the statistical analysis in R\nTopic/Package must go beyond what was taught in this course or what you should have learned in an intro stats course\nPresentation Length: 10-15min"
  },
  {
    "objectID": "content/lectures/09-projects-slides.html#option-2-data-analysis",
    "href": "content/lectures/09-projects-slides.html#option-2-data-analysis",
    "title": "09-projects",
    "section": "Option 2: Data Analysis",
    "text": "Option 2: Data Analysis\n\n.Rmd document used for data science report\nAsks a question, finds data, analyzes data (basically: a mini case report, but you find the data and formulate the question)\nPresentation Length: 3-5min (brief summary of the full report)"
  },
  {
    "objectID": "content/lectures/09-projects-slides.html#wherewhen-for-this-presentation",
    "href": "content/lectures/09-projects-slides.html#wherewhen-for-this-presentation",
    "title": "09-projects",
    "section": "Where/when for this presentation?",
    "text": "Where/when for this presentation?\nYou get to choose:\n\nRecord ahead of time: submit by Th 3/23 of finals week at 11:59 PM\nPresent in-person Th of finals week (slots to sign up for a time will be released later; want this option for those interested in getting more practice)"
  },
  {
    "objectID": "content/lectures/09-projects-slides.html#should-i-be-working-on-my-final-project-now",
    "href": "content/lectures/09-projects-slides.html#should-i-be-working-on-my-final-project-now",
    "title": "09-projects",
    "section": "Should I be working on my final project now?",
    "text": "Should I be working on my final project now?\n…probably not\n\nBut, you should start thinking about/getting a group of 3-4 people together.\n\n\nI’d recommend you start planning/working on your final project around wk 8\n\n\n\nhttps://cogs137.github.io/website/"
  },
  {
    "objectID": "content/lectures/09-projects.html",
    "href": "content/lectures/09-projects.html",
    "title": "09-projects",
    "section": "",
    "text": "Q: When is the presentation?\nA: Discussing this today! It’s at the end of the quarter. While written reports will be completed throughout the rest of the quarter as we do case studies, an oral presentation will be part of your final project. These will be able to be recorded or given live in person during finals week.\n\n\nQ: Will we have another lab with as many questions as Lab 4? The turnaround was pretty stressful, so just want to be prepared.\nA: The next lab (multiple linear regression) is also a tady lengthy, but after that I don’t plan on the rest being quite as long. Just as a reminder that you do not need to complete the entire lab to receive credit!\n\n\nQ: I’m not really comfortable with log transformations yet. Will we get more practice on that?\nA: Yup! Last lecture was a first introduction. We’ll return to this in upcoming case studies. The midterm does not require any transformations.\n\n\n\n\n\nLecture Participation survey “due” after class\nMidterm due Monday (2/13; 11:59 PM):\n\nreleased Friday (tomorrow) after lab\ncompleted individually\n\nPractice Midterm Answer Key Posted\n\n\n\n\n\nExam chat\nHW02 recap\nCase Studies\nFinal Project"
  },
  {
    "objectID": "content/lectures/09-projects.html#midterm-details",
    "href": "content/lectures/09-projects.html#midterm-details",
    "title": "09-projects",
    "section": "Midterm Details",
    "text": "Midterm Details\n\n\nInstructions will be posted on the website at 2PM Fri (tomorrow)\nYou’ll be provided a template (link on Canvas) and “submit” on GitHub\nYou’ll be provided with data and a data dictionary\nCovers data wrangling/tidying, dplyr, viz/ggplot2, and linear regression/tidymodels"
  },
  {
    "objectID": "content/lectures/09-projects.html#hw02-q1",
    "href": "content/lectures/09-projects.html#hw02-q1",
    "title": "09-projects",
    "section": "HW02 : Q1",
    "text": "HW02 : Q1\nGenerate a visualization that will allow readers to determine whether male or female penguins are larger (by mass)."
  },
  {
    "objectID": "content/lectures/09-projects.html#boxplot",
    "href": "content/lectures/09-projects.html#boxplot",
    "title": "09-projects",
    "section": "Boxplot",
    "text": "Boxplot\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\npenguins |>\n  drop_na() |> \n  ggplot(aes(x = sex, y = body_mass_g)) +\n  geom_boxplot() +\n  labs(title = \"Penguin body mass by sex\", \n       y = \"body mass (g)\") +\n  theme(plot.title.position = \"plot\")"
  },
  {
    "objectID": "content/lectures/09-projects.html#histogram",
    "href": "content/lectures/09-projects.html#histogram",
    "title": "09-projects",
    "section": "Histogram",
    "text": "Histogram\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\npenguins |>\n  filter(!is.na(sex)) |>\n  ggplot(mapping = aes(x = body_mass_g, fill = sex)) +\n  geom_histogram() +\n  labs(\n    title = 'Body Mass Distribution by Sex',\n    x = 'Body Mass (g)',\n    y = 'Count',\n    color = 'Sex'\n  )"
  },
  {
    "objectID": "content/lectures/09-projects.html#faceted-histograms",
    "href": "content/lectures/09-projects.html#faceted-histograms",
    "title": "09-projects",
    "section": "Faceted Histograms",
    "text": "Faceted Histograms\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\npenguins |>\n  filter(!is.na(body_mass_g)) |>\n  ggplot(., mapping=aes(y=body_mass_g)) + \n  geom_histogram(binwidth=100) +\n  facet_grid(. ~ sex) + \n  labs(\n    title='Frequency of Penguins based on their Body mass and Female/Male Penguins',\n    x='Frequency / Count',\n    y='Body Mass (of penguins, in g (grams))')"
  },
  {
    "objectID": "content/lectures/09-projects.html#hw02-q2",
    "href": "content/lectures/09-projects.html#hw02-q2",
    "title": "09-projects",
    "section": "HW02 : Q2",
    "text": "HW02 : Q2\nGenerate a barplot that visualizes how many penguins there are from each species on each island. Each island should be a different panel (in a 1 row x 3 columns visualization), and each chart should visualize the species count."
  },
  {
    "objectID": "content/lectures/09-projects.html#barplot",
    "href": "content/lectures/09-projects.html#barplot",
    "title": "09-projects",
    "section": "Barplot",
    "text": "Barplot\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(penguins, aes(x = species)) +\n  geom_bar() +\n  facet_wrap(~ island) +\n  labs(title = \"Count of species per island\") +\n  theme(plot.title.position = \"plot\")"
  },
  {
    "objectID": "content/lectures/09-projects.html#barplot-with-color",
    "href": "content/lectures/09-projects.html#barplot-with-color",
    "title": "09-projects",
    "section": "Barplot with color",
    "text": "Barplot with color\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n  ggplot(penguins, aes(x = fct_infreq(species), fill = species)) +\n  geom_bar() +\n  facet_wrap(~island, nrow = 1) +\n  guides(fill = \"none\") + \n  labs(\n    title = \"Count of Penguin Species Across the Palmer Archipelago Islands\",\n    x = \"Species\",\n    y = \"Number of Penguins\"\n  )"
  },
  {
    "objectID": "content/lectures/09-projects.html#hw02-q3",
    "href": "content/lectures/09-projects.html#hw02-q3",
    "title": "09-projects",
    "section": "HW02 : Q3",
    "text": "HW02 : Q3\nGenerate a scatterplot that will allow the viewer to determine whether flipper length has differed over time. Be sure to color the points on this plot by species."
  },
  {
    "objectID": "content/lectures/09-projects.html#scatterplot-no-jitter",
    "href": "content/lectures/09-projects.html#scatterplot-no-jitter",
    "title": "09-projects",
    "section": "Scatterplot (no jitter)",
    "text": "Scatterplot (no jitter)\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(penguins, aes(x = year, \n           y = flipper_length_mm,\n           color = species)) +\ngeom_point() + \nscale_color_viridis_d() +\nscale_x_continuous(n.breaks = 3) +\nlabs(\n  title = \"Flipper Lengths of Penguin Species Over Time\",\n  color = \"Species\",\n  x = \"Year\",\n  y = \"Flipper Length (mm)\"\n)"
  },
  {
    "objectID": "content/lectures/09-projects.html#scatterplot-w-jitter",
    "href": "content/lectures/09-projects.html#scatterplot-w-jitter",
    "title": "09-projects",
    "section": "Scatterplot (w/ jitter)",
    "text": "Scatterplot (w/ jitter)\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(penguins,\n       mapping = aes(x = factor(year),\n                     y = flipper_length_mm,\n                     color = species)) +\n  scale_color_viridis_d() +\n  geom_jitter(na.rm = TRUE) +\n  labs(title = \"Flipper length of different penguin species by year\",\n       y = \"Flipper length (mm)\",\n       x = \"Year\") +\n  theme(plot.title.position = \"plot\")"
  },
  {
    "objectID": "content/lectures/09-projects.html#hw02-part-ii",
    "href": "content/lectures/09-projects.html#hw02-part-ii",
    "title": "09-projects",
    "section": "HW02 : Part II",
    "text": "HW02 : Part II\nImitation is the highest form of flattery\nExample from: Eric Ko\n\nOriginalPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Eric890916\nchessData <- data.frame(country = c(\"United States\", \"Germany\", \"Canada\", \"Spain\", \"Russia\", \"France\", \"Bosnia and Herzegovina\", \"Croatia\", \"Turkey\", \"Austria\"),\n                        num = c(89, 55, 44, 41, 36, 34, 32, 32, 31, 29))\n\nggplot(chessData, aes(y = reorder(country, num), x = num)) + \n  geom_col(fill = \"#008080\") + \n  geom_text(aes(label = num), hjust = 1, nudge_x = -.5) +\n  labs(title = \"More players transfer to the U.S. than to any other country\",\n       subtitle = \"Nations that received the highest number of player transfers, 2000-17\",\n       caption = \"2017 data as of April 11. SOURCE: FIDE\",\n       x = \"NUMBER OF TRANSFERS\", y = \"COUNTRY\")"
  },
  {
    "objectID": "content/lectures/09-projects.html#section",
    "href": "content/lectures/09-projects.html#section",
    "title": "09-projects",
    "section": "",
    "text": "Example from: Christine Kwon\n\nOriginalPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\ncommon_first_names <- read.csv(\"https://raw.githubusercontent.com/fivethirtyeight/data/master/most-common-name/new-top-firstNames.csv\")\n\n# editing data\ncommon_first_names <- common_first_names[1:20, ]\ncommon_first_names <- common_first_names %>%\n  mutate(sex = case_when (name == \"Mary\" | \n                          name == \"Jennifer\" |\n                          name == \"Patricia\" |\n                          name == \"Linda\" |\n                          name == \"Elizabeth\" ~ \"female\",\n                          name != \"Mary\" | \n                          name != \"Jennifer\" |\n                          name != \"Patricia\" |\n                          name != \"Linda\" |\n                          name != \"Elizabeth\" ~ \"male\",),\n         percentage = round(newPerct2013 * 1000, digits = 1))\n\n# creating visualization\ncommon_first_names %>%\n  ggplot(aes(y = reorder(name, percentage),  x = percentage, fill = sex)) +\n  geom_histogram(stat = \"identity\") +\n  guides(fill = \"none\") +\n  annotate(\"text\", x = 9.65, y = 21.7, label = expression(bold(\"MALE\")), cex = 3.85, hjust = 1, vjust = 1, color = \"dodgerblue\") +\n  annotate(\"text\", x = 11.5, y = 21.7, label = expression(bold(\"FEMALE\")), cex = 3.85, hjust = 1, vjust = 1, color = \"gold1\") +\n  geom_text(aes(label = signif(percentage)), nudge_x = 0.5) +\n  labs(title = \"Most Common First Names\",\n       subtitle = \"Per 1,000 Americans as of 2013\") +\n  scale_fill_manual(values = c(\"male\" = \"dodgerblue\",\n                               \"female\" = \"gold1\")) +\n  theme_classic() +\n  theme(plot.title.position = \"plot\", \n        panel.grid.major.y = element_blank(),\n        plot.title = element_text(size = 16,\n                                  face = \"bold\"),\n        plot.subtitle = element_text(size = 11),\n        axis.ticks.x = element_blank(),\n        axis.ticks.y = element_blank(),\n        axis.line.x = element_blank(),\n        axis.line.y = element_blank(),\n        axis.text.x = element_blank(),\n        axis.text.y = element_text(color = \"black\"),\n        axis.title.x = element_blank(),\n        axis.title.y = element_blank())"
  },
  {
    "objectID": "content/lectures/09-projects.html#section-1",
    "href": "content/lectures/09-projects.html#section-1",
    "title": "09-projects",
    "section": "",
    "text": "Example by: Cheng Chang (FA21)\n\nOriginalPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n# get data\npoll <- read_csv(\"https://raw.githubusercontent.com/fivethirtyeight/covid-19-polls/master/covid_approval_polls_adjusted.csv\")\npoll_mean <- read_csv(\"https://raw.githubusercontent.com/fivethirtyeight/covid-19-polls/master/covid_approval_toplines.csv\")\n\npoll <- poll |>\n  filter(subject == \"Biden\", party != \"all\") |>\n  mutate(Party=case_when(party == \"D\" ~ \"Democrats\",\n                         party == \"I\" ~ \"Independents\",\n                         party == \"R\" ~ \"Republicans\")) |>\n  mutate(enddate=as.Date(enddate, format=\"%m/%d/%Y\"))\n\npoll_mean <- poll_mean |>\n  filter(subject == \"Biden\", party != \"all\") |>\n  mutate(Party=case_when(party == \"D\" ~ \"Democrats\",\n                         party == \"I\" ~ \"Independents\",\n                         party == \"R\" ~ \"Republicans\")) |>\n  mutate(modeldate=as.Date(modeldate, format=\"%m/%d/%Y\"))\n\nggplot() +\n  geom_point(data=poll,\n             aes(x=enddate, y=approve_adjusted, color=Party),\n             size=1,\n             alpha = 0.5) +\n  geom_path(data=poll_mean, aes(x=modeldate, y=approve_estimate, color=Party)) +\n  labs(title=\"Approval of Biden’s response varies widely by party\",\n       subtitle=\n         \"A calculation of the share of Democrats, Republicans and independents who approve of the president’s\\nhandling of the coronavirus outbreak\",\n       x=NULL,\n       y=NULL) +\n  scale_color_manual(values = c(\"Democrats\" = \"#2acaea\",\n                                \"Independents\" = \"#ce7e00\",\n                                \"Republicans\" = \"#f44336\")) +\n  theme(plot.title.position = \"plot\",\n        panel.grid.major = element_line(color=\"grey\"),\n        panel.border = element_rect(fill=NA, color=\"grey\"),\n        panel.background = element_rect(fill=\"white\"))"
  },
  {
    "objectID": "content/lectures/09-projects.html#hw03-part-iii",
    "href": "content/lectures/09-projects.html#hw03-part-iii",
    "title": "09-projects",
    "section": "HW03 : Part III",
    "text": "HW03 : Part III\nTake a Sad Plot & Make It Better\nExample from: Christine Kwon\n\nOriginalPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\nmedals <- tibble(\n  country = c(\n    rep(\"USA\", 79), rep(\"CHN\", 70), rep(\"ROC\", 53), rep(\"GBR\", 48), rep(\"JPN\", 40)),\n  medal_type = c(\n    rep(\"gold\", 25), rep(\"silver\", 31), rep(\"bronze\", 23),\n    rep(\"gold\", 32), rep(\"silver\", 22), rep(\"bronze\", 16),\n    rep(\"gold\", 14), rep(\"silver\", 21), rep(\"bronze\", 18),\n    rep(\"gold\", 15), rep(\"silver\", 18), rep(\"bronze\", 15),\n    rep(\"gold\", 21), rep(\"silver\", 7), rep(\"bronze\", 12)))\n\n# creating visualization\nmedal_viz <- medals %>%\n   mutate(country = factor(country, levels = c(\"JPN\", \"GBR\",\"ROC\", \"CHN\", \"USA\"))) %>%\n  ggplot(aes(y = country, fill = factor(medal_type, levels = c(\"bronze\", \"silver\", \"gold\")))) + \n  geom_bar() +\n  annotate(\"text\", x = 4.5, y = 5.05, label = \"25\", cex = 4, hjust = 1, vjust = 1) +\n  annotate(\"text\", x = 30.5, y = 5.05, label = \"31\", cex = 4, hjust = 1, vjust = 1) +\n  annotate(\"text\", x = 61.5, y = 5.05, label = \"23\", cex = 4, hjust = 1, vjust = 1) +\n  annotate(\"text\", x = 86.5, y = 5.05, label = expression(bold(\"79\")), cex = 5, hjust = 1, vjust = 1) +\n  annotate(\"text\", x = 4.5, y = 4.05, label = \"32\", cex = 4, hjust = 1, vjust = 1) +\n  annotate(\"text\", x = 37.5, y = 4.05, label = \"22\", cex = 4, hjust = 1, vjust = 1) +\n  annotate(\"text\", x = 58.5, y = 4.05, label = \"16\", cex = 4, hjust = 1, vjust = 1) +\n  annotate(\"text\", x = 76.5, y = 4.05, label = expression(bold(\"70\")), cex = 5, hjust = 1, vjust = 1) +\n  annotate(\"text\", x = 4.5, y = 3.05, label = \"14\", cex = 4, hjust = 1, vjust = 1) +\n  annotate(\"text\", x = 18.5, y = 3.05, label = \"21\", cex = 4, hjust = 1, vjust = 1) +\n  annotate(\"text\", x = 39.5, y = 3.05, label = \"18\", cex = 4, hjust = 1, vjust = 1) +\n  annotate(\"text\", x = 59.5, y = 3.05, label = expression(bold(\"53\")), cex = 5, hjust = 1, vjust = 1) +\n  annotate(\"text\", x = 4.5, y = 2.05, label = \"15\", cex = 4, hjust = 1, vjust = 1) +\n  annotate(\"text\", x = 19.5, y = 2.05, label = \"18\", cex = 4, hjust = 1, vjust = 1) +\n  annotate(\"text\", x = 38, y = 2.05, label = \"15\", cex = 4, hjust = 1, vjust = 1) +\n  annotate(\"text\", x = 54.5, y = 2.05, label = expression(bold(\"48\")), cex = 5, hjust = 1, vjust = 1) +\n  annotate(\"text\", x = 4.5, y = 1.05, label = \"21\", cex = 4, hjust = 1, vjust = 1) +\n  annotate(\"text\", x = 23.5, y = 1.05, label = \"7\", cex = 4, hjust = 1, vjust = 1) +\n  annotate(\"text\", x = 32.5, y = 1.05, label = \"12\", cex = 4, hjust = 1, vjust = 1) +\n  annotate(\"text\", x = 46.5, y = 1.05, label = expression(bold(\"40\")) , cex = 5, hjust = 1, vjust = 1) +\n  labs(title = \"Medals Won at the Tokyo Olympics (ongoing)\", \n       subtitle = \"Distribution of medals won by the top 5 countries (ordered by total)\", \n       fill = \"Medal Type\") +\n  scale_fill_manual(values = c(\"gold\" = \"gold\",\n                               \"silver\" = \"gray75\",\n                               \"bronze\" = \"tan3\")) +\n  theme(#legend.title = element_text(face = \"bold\"),\n        legend.position = \"top\") + \n  guides(fill = guide_legend(title.position = \"top\")) +\n  theme_classic() +\n  theme(plot.title.position = \"plot\", \n        panel.grid.major.y = element_blank(),\n        plot.title = element_text(size = 16,\n                                  face = \"bold\"),\n        plot.subtitle = element_text(size = 11),\n        axis.ticks.x = element_blank(),\n        axis.ticks.y = element_blank(),\n        axis.line.x = element_blank(),\n        axis.line.y = element_blank(),\n        axis.text.x = element_blank(),\n        axis.text.y = element_text(color = \"black\", \n                                   #face = \"bold\", \n                                   size = 11),\n        axis.title.x = element_blank(),\n        axis.title.y = element_blank())\n\n\nmedal_viz +\n  theme(legend.position = c(0.8, 0.25))"
  },
  {
    "objectID": "content/lectures/09-projects.html#opencasestudies",
    "href": "content/lectures/09-projects.html#opencasestudies",
    "title": "09-projects",
    "section": "OpenCaseStudies",
    "text": "OpenCaseStudies\n\nOpenCaseStudies\nUses R/the tidyverse\nasks public health-centric questions\ngoal: to teach statistical analysis/data science through case studies"
  },
  {
    "objectID": "content/lectures/09-projects.html#what-well-do",
    "href": "content/lectures/09-projects.html#what-well-do",
    "title": "09-projects",
    "section": "What We’ll Do",
    "text": "What We’ll Do\nFor each case study (2), during lecture:\n\nStats: (1-2d)\nBackground, Data & Wrangling (1-2d)\nEDA & Analysis (1d)\n\n\nFor each case study:\n\nyou’ll also work with case study data in lab.\nyou’ll work in assigned groups of ~3 students to complete a data science report"
  },
  {
    "objectID": "content/lectures/09-projects.html#data-science-reports",
    "href": "content/lectures/09-projects.html#data-science-reports",
    "title": "09-projects",
    "section": "Data Science Reports",
    "text": "Data Science Reports\nWith your group, you will:\n\ncarry out all steps of the analysis\n\nsome code will be taken directly from lecture\n\nadd text/organize into a report\n\n\n\nhave to extend the case study"
  },
  {
    "objectID": "content/lectures/09-projects.html#what-does-extend-the-case-study-mean",
    "href": "content/lectures/09-projects.html#what-does-extend-the-case-study-mean",
    "title": "09-projects",
    "section": "What does extend the case study mean?",
    "text": "What does extend the case study mean?\nYou’ll need to do something more on the topic beyond what is presented in class.\n\nExamples:\n\nAsking an additional question and answering it from the data provided\nFinding an additional dataset and using it to add to the case study\nGenerating a handful of additional and very informative visualizations (beyond what’s presented in class)"
  },
  {
    "objectID": "content/lectures/09-projects.html#grading",
    "href": "content/lectures/09-projects.html#grading",
    "title": "09-projects",
    "section": "Grading",
    "text": "Grading\nGraded on:\n\ncontent (code, text, viz)\neffective written communication\nextension carried out"
  },
  {
    "objectID": "content/lectures/09-projects.html#final-project-logistics",
    "href": "content/lectures/09-projects.html#final-project-logistics",
    "title": "09-projects",
    "section": "Final Project Logistics",
    "text": "Final Project Logistics\n\nwill be completed in groups of 3-4 students\nyou get to choose the group\nI will ask at the end of week 7 for your final project groups"
  },
  {
    "objectID": "content/lectures/09-projects.html#final-project-details",
    "href": "content/lectures/09-projects.html#final-project-details",
    "title": "09-projects",
    "section": "Final Project Details",
    "text": "Final Project Details\nTwo possible Paths:\n\nCreate a technical presentation on a statistics topic and/or an R package.\nCarry out a data analysis"
  },
  {
    "objectID": "content/lectures/09-projects.html#option-1-technical-presentation",
    "href": "content/lectures/09-projects.html#option-1-technical-presentation",
    "title": "09-projects",
    "section": "Option 1: Technical Presentation",
    "text": "Option 1: Technical Presentation\n\n.Rmd document used to make slides\n“Teaches” the details of the R package/statistics topic\nDemonstrates how to use the package and/or carry out the statistical analysis in R\nTopic/Package must go beyond what was taught in this course or what you should have learned in an intro stats course\nPresentation Length: 10-15min"
  },
  {
    "objectID": "content/lectures/09-projects.html#option-2-data-analysis",
    "href": "content/lectures/09-projects.html#option-2-data-analysis",
    "title": "09-projects",
    "section": "Option 2: Data Analysis",
    "text": "Option 2: Data Analysis\n\n.Rmd document used for data science report\nAsks a question, finds data, analyzes data (basically: a mini case report, but you find the data and formulate the question)\nPresentation Length: 3-5min (brief summary of the full report)"
  },
  {
    "objectID": "content/lectures/09-projects.html#wherewhen-for-this-presentation",
    "href": "content/lectures/09-projects.html#wherewhen-for-this-presentation",
    "title": "09-projects",
    "section": "Where/when for this presentation?",
    "text": "Where/when for this presentation?\nYou get to choose:\n\nRecord ahead of time: submit by Th 3/23 of finals week at 11:59 PM\nPresent in-person Th of finals week (slots to sign up for a time will be released later; want this option for those interested in getting more practice)"
  },
  {
    "objectID": "content/lectures/09-projects.html#should-i-be-working-on-my-final-project-now",
    "href": "content/lectures/09-projects.html#should-i-be-working-on-my-final-project-now",
    "title": "09-projects",
    "section": "Should I be working on my final project now?",
    "text": "Should I be working on my final project now?\n…probably not\n\nBut, you should start thinking about/getting a group of 3-4 people together.\n\n\nI’d recommend you start planning/working on your final project around wk 8"
  },
  {
    "objectID": "content/lectures/02-dplyr-slides.html#qa",
    "href": "content/lectures/02-dplyr-slides.html#qa",
    "title": "02-dplyr",
    "section": "Q&A",
    "text": "Q&A\n\nQ: what does |> mean?\nA: It means “and then” and is called a “pipe.” Discussing this in more detail in today’s lecture!\n\n\nQ: I think the lab is much more harder than the lecture.\nA: This first week there is a lot to learn regarding tooling, but once you’ve got that down the “process” of completing a lab will become second nature. Then, it’s just content…and applying something is always more difficult than listening to it being explained. So, labs will be a bit harder than lecture…but that’s by design b/c 1) we grade on effort (it’s ok to be wrong in labs!) and 2) answer keys will be posted (learning from mistakes/places we struggle is a great way to learn!)\n\n\nQ: Just curious about the oral presentation portion of the final project. Will this be a requirement in the form of a recorded video (like in COGS 108), or will we be presenting our project findings live in front of the class on the due date?\nA: There are going to be two options (most likely). A recording will definitely be an option. We’re also hoping to have an option where you can come present live, to the instructional staff and any students who want to learn from one another.\n\n\nQ: I am curious about the similarities and differences between both of Python and R!\nA: Very briefly, some similarities: both are object-oriented programming languages (although R is not only object-oriented); both are great for data analysis; differences: python arguably has a simpler syntax; R is, at its core, designed for statistical analysis so I’d argue it’s better for that; Python is a general-programming language so it’s arguablly better for software development; R has an implementation of the grammar of graphics, so I’d argue it’s better for data visualization (but some would disagree).\n\n\nQ: How can I understand dataframes in R easier?\nA: With practice! Today’s lecture, this week 2 lab, and your first hw will help you get additional practice. Then, we’ll use them throughout the course and build your understanding.\n\n\nQ: For very large data sets, how would you be able to find every type coercion?\nA: Each column would have a single type. glimpse() would help you identify the type of each column. From there, you can edit any that are not what you wanted.\n\n\nQ: Where would be a good location to get some practice on most of the packages we will be using in this class?\nA: The labs and homeworks are one place. But, there are also exercises in the “textbook” for this class: https://r4ds.had.co.nz/\n\n\nQ: How do we grasp Markdown easier?\nA: Trying things out and learning the basic rules. I would recommend starting with an RMarkdown document and just typing a sentence. Then knit to see what that looks like. Then, try to bold and italicize some text. Then try to add some headers. Then, add a bulleted list. Each time knitting to see the output. With that, you’ll have most of the markdown you’ll need! reference for basics\n\n\nQ: I am still not sure whether this class focuses more on the programming aspect or the mathematical concepts\nA: Both! First 5 weeks, more programming; Last 5: combination of both are used, but new programming concepts aren’t introduced a ton, so we focus on the stats while continuing to use what we learned the first five weeks!\n\n\nQ: Is there any rules for coercion?\nA: There are rules! Summarized here\n\n\nQ: When do we use R markdown?\nA: When completing labs, homework assignments, case studies, and likely on the final project. You can also take notes in RMarkdown, but that’s up to you!\n\n\nQ: Never heard about ggplot2. I think everyone had already heard of it previously…\nA: While some students have, you’re not alone! We’ll have two lectures on this and get plenty of practice soon!"
  },
  {
    "objectID": "content/lectures/02-dplyr-slides.html#course-announcements",
    "href": "content/lectures/02-dplyr-slides.html#course-announcements",
    "title": "02-dplyr",
    "section": "Course Announcements",
    "text": "Course Announcements\nDue Dates:\n\nLab 02 due Friday (1/20; 11:59 PM)\nHW01 due Monday (1/23; 11:59 PM)\nLecture Participation survey “due” after class\n\nNotes (1/19):\n\nLab01 Graded - see GitHub issue for comments; 2pts == full credit\n\nCommon issues:\n\nDid not knit file to HTML\nDid not include name in file\nYou do not need to version control the .RProj file\nYou should replace the “instruction” text with your explanations/interpretations\n\nIf you received a zero, you should have an email from me\n\nLab02 released\nHW01 released - let’s take a look"
  },
  {
    "objectID": "content/lectures/02-dplyr-slides.html#agenda",
    "href": "content/lectures/02-dplyr-slides.html#agenda",
    "title": "02-dplyr",
    "section": "Agenda",
    "text": "Agenda\n\ndplyr\n\nphilosophy\npipes\ncommon operations"
  },
  {
    "objectID": "content/lectures/02-dplyr-slides.html#philosophy",
    "href": "content/lectures/02-dplyr-slides.html#philosophy",
    "title": "02-dplyr",
    "section": "Philosophy",
    "text": "Philosophy\n\ndplyr is a grammar of data manipulation, providing a consistent set of verbs that help you solve the most common data manipulation challenges\n\n\n\nSource: dplyr.tidyverse.org"
  },
  {
    "objectID": "content/lectures/02-dplyr-slides.html#the-pipe-in-baser",
    "href": "content/lectures/02-dplyr-slides.html#the-pipe-in-baser",
    "title": "02-dplyr",
    "section": "The pipe in baseR",
    "text": "The pipe in baseR\n\n\n\n\n|> should be read as “and then”\nfor example “Wake up |> brush teeth” would be read as “wake up and then brush teeth”"
  },
  {
    "objectID": "content/lectures/02-dplyr-slides.html#where-does-the-name-come-from",
    "href": "content/lectures/02-dplyr-slides.html#where-does-the-name-come-from",
    "title": "02-dplyr",
    "section": "Where does the name come from?",
    "text": "Where does the name come from?\nThe pipe operator was first implemented in the package magrittr.\n\n\n\n\n\n\n\nYou will see this frequently in code online. It’s equivalent to |>."
  },
  {
    "objectID": "content/lectures/02-dplyr-slides.html#review-how-does-a-pipe-work",
    "href": "content/lectures/02-dplyr-slides.html#review-how-does-a-pipe-work",
    "title": "02-dplyr",
    "section": "Review: How does a pipe work?",
    "text": "Review: How does a pipe work?\n\nYou can think about the following sequence of actions - find key, unlock car, start car, drive to school, park.\n\n\n\nExpressed as a set of nested functions in R pseudocode this would look like:\n\n\npark(drive(start_car(find(\"keys\")), to = \"campus\"))\n\n\n\n\nWriting it out using pipes give it a more natural (and easier to read) structure:\n\n\nfind(\"keys\") |>\n  start_car() |>\n  drive(to = \"campus\") |>\n  park()"
  },
  {
    "objectID": "content/lectures/02-dplyr-slides.html#nc-dot-fatal-crashes-in-north-carolina",
    "href": "content/lectures/02-dplyr-slides.html#nc-dot-fatal-crashes-in-north-carolina",
    "title": "02-dplyr",
    "section": "NC DOT Fatal Crashes in North Carolina",
    "text": "NC DOT Fatal Crashes in North Carolina\nFrom OpenDurham’s Data Portal\n\nbike <- read_csv2(\"https://raw.githubusercontent.com/COGS137/datasets/main/nc_bike_crash.csv\", \n                  na = c(\"NA\", \"\", \".\"))"
  },
  {
    "objectID": "content/lectures/02-dplyr-slides.html#variables",
    "href": "content/lectures/02-dplyr-slides.html#variables",
    "title": "02-dplyr",
    "section": "Variables",
    "text": "Variables\nView the names of variables via\n\nnames(bike)\n\n [1] \"FID\"        \"OBJECTID\"   \"AmbulanceR\" \"BikeAge_Gr\" \"Bike_Age\"  \n [6] \"Bike_Alc_D\" \"Bike_Dir\"   \"Bike_Injur\" \"Bike_Pos\"   \"Bike_Race\" \n[11] \"Bike_Sex\"   \"City\"       \"County\"     \"CrashAlcoh\" \"CrashDay\"  \n[16] \"Crash_Date\" \"Crash_Grp\"  \"Crash_Hour\" \"Crash_Loc\"  \"Crash_Mont\"\n[21] \"Crash_Time\" \"Crash_Type\" \"Crash_Ty_1\" \"Crash_Year\" \"Crsh_Sevri\"\n[26] \"Developmen\" \"DrvrAge_Gr\" \"Drvr_Age\"   \"Drvr_Alc_D\" \"Drvr_EstSp\"\n[31] \"Drvr_Injur\" \"Drvr_Race\"  \"Drvr_Sex\"   \"Drvr_VehTy\" \"ExcsSpdInd\"\n[36] \"Hit_Run\"    \"Light_Cond\" \"Locality\"   \"Num_Lanes\"  \"Num_Units\" \n[41] \"Rd_Charact\" \"Rd_Class\"   \"Rd_Conditi\" \"Rd_Config\"  \"Rd_Defects\"\n[46] \"Rd_Feature\" \"Rd_Surface\" \"Region\"     \"Rural_Urba\" \"Speed_Limi\"\n[51] \"Traff_Cntr\" \"Weather\"    \"Workzone_I\" \"Location\""
  },
  {
    "objectID": "content/lectures/02-dplyr-slides.html#viewing-your-data",
    "href": "content/lectures/02-dplyr-slides.html#viewing-your-data",
    "title": "02-dplyr",
    "section": "Viewing your data",
    "text": "Viewing your data\n\nIn the Environment, click on the name of the data frame to view it in the data viewer (or use the View function)\nUse the glimpse function to take a peek\n\n\nglimpse(bike)\n\nRows: 5,716\nColumns: 54\n$ FID        <dbl> 18, 29, 33, 35, 49, 53, 56, 60, 63, 66, 72, 75, 82, 84, 85,…\n$ OBJECTID   <dbl> 19, 30, 34, 36, 50, 54, 57, 61, 64, 67, 73, 76, 83, 85, 86,…\n$ AmbulanceR <chr> \"No\", \"Yes\", \"No\", \"Yes\", \"No\", \"Yes\", \"Yes\", \"No\", \"Yes\", …\n$ BikeAge_Gr <chr> NA, \"50-59\", NA, \"16-19\", NA, \"50-59\", \"16-19\", \"40-49\", \"1…\n$ Bike_Age   <dbl> 6, 51, 10, 17, 6, 52, 18, 40, 6, 7, 45, 30, 17, 20, 14, 15,…\n$ Bike_Alc_D <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\",…\n$ Bike_Dir   <chr> \"Not Applicable\", \"With Traffic\", \"With Traffic\", NA, \"Faci…\n$ Bike_Injur <chr> \"C: Possible Injury\", \"C: Possible Injury\", \"Injury\", \"B: E…\n$ Bike_Pos   <chr> \"Driveway / Alley\", \"Travel Lane\", \"Travel Lane\", \"Travel L…\n$ Bike_Race  <chr> \"Black\", \"Black\", \"Black\", \"White\", \"Black\", \"White\", \"Blac…\n$ Bike_Sex   <chr> \"Female\", \"Male\", \"Male\", \"Male\", \"Male\", \"Male\", \"Female\",…\n$ City       <chr> \"Durham\", \"Greenville\", \"Farmville\", \"Charlotte\", \"Charlott…\n$ County     <chr> \"Durham\", \"Pitt\", \"Pitt\", \"Mecklenburg\", \"Mecklenburg\", \"Du…\n$ CrashAlcoh <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\",…\n$ CrashDay   <chr> \"01-01-06\", \"01-01-02\", \"01-01-07\", \"01-01-05\", NA, NA, NA,…\n$ Crash_Date <date> 2007-01-06, 2007-01-09, 2007-01-14, 2007-01-12, 2007-01-15…\n$ Crash_Grp  <chr> \"Bicyclist Failed to Yield - Midblock\", \"Crossing Paths - O…\n$ Crash_Hour <dbl> 13, 23, 16, 19, 12, 20, 19, 14, 16, 0, 17, 18, 14, 17, 19, …\n$ Crash_Loc  <chr> \"Non-Intersection\", \"Intersection-Related\", \"Intersection\",…\n$ Crash_Mont <chr> NA, NA, NA, NA, NA, \"01-04-01\", \"01-04-01\", NA, \"01-02-01\",…\n$ Crash_Time <dttm> 0001-01-01 13:17:58, 0001-01-01 23:08:58, 0001-01-01 16:44…\n$ Crash_Type <chr> \"Bicyclist Ride Out - Residential Driveway\", \"Crossing Path…\n$ Crash_Ty_1 <dbl> 353311, 211180, 111144, 119139, 112114, 311231, 119144, 132…\n$ Crash_Year <dbl> 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007,…\n$ Crsh_Sevri <chr> \"C: Possible Injury\", \"C: Possible Injury\", \"O: No Injury\",…\n$ Developmen <chr> \"Residential\", \"Commercial\", \"Residential\", \"Residential\", …\n$ DrvrAge_Gr <chr> \"60-69\", \"30-39\", \"50-59\", \"30-39\", NA, \"20-24\", \"40-49\", N…\n$ Drvr_Age   <dbl> 66, 34, 52, 33, NA, 20, 40, NA, 17, 51, NA, 64, 50, 66, 30,…\n$ Drvr_Alc_D <chr> \"No\", \"No\", \"No\", \"No\", \"Missing\", \"No\", \"No\", \"Missing\", \"…\n$ Drvr_EstSp <chr> \"11-15 mph\", \"0-5 mph\", \"21-25 mph\", \"46-50 mph\", \"16-20 mp…\n$ Drvr_Injur <chr> \"O: No Injury\", \"O: No Injury\", \"O: No Injury\", \"O: No Inju…\n$ Drvr_Race  <chr> \"Black\", \"Black\", \"White\", \"White\", \"/Missing\", \"White\", \"B…\n$ Drvr_Sex   <chr> \"Male\", \"Male\", \"Female\", \"Female\", NA, \"Female\", \"Male\", N…\n$ Drvr_VehTy <chr> \"Pickup\", \"Passenger Car\", \"Passenger Car\", \"Sport Utility\"…\n$ ExcsSpdInd <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\",…\n$ Hit_Run    <chr> \"No\", \"No\", \"No\", \"No\", \"Yes\", \"No\", \"No\", \"Yes\", \"No\", \"No…\n$ Light_Cond <chr> \"Daylight\", \"Dark - Lighted Roadway\", \"Daylight\", \"Dark - R…\n$ Locality   <chr> \"Mixed (30% To 70% Developed)\", \"Urban (>70% Developed)\", \"…\n$ Num_Lanes  <chr> \"2 lanes\", \"5 lanes\", \"2 lanes\", \"4 lanes\", \"2 lanes\", \"4 l…\n$ Num_Units  <dbl> 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,…\n$ Rd_Charact <chr> \"Straight - Level\", \"Straight - Level\", \"Straight - Level\",…\n$ Rd_Class   <chr> \"Local Street\", \"Local Street\", \"Local Street\", \"NC Route\",…\n$ Rd_Conditi <chr> \"Dry\", \"Dry\", \"Dry\", \"Dry\", \"Dry\", \"Dry\", \"Dry\", \"Dry\", \"Dr…\n$ Rd_Config  <chr> \"Two-Way, Not Divided\", \"Two-Way, Divided, Unprotected Medi…\n$ Rd_Defects <chr> \"None\", \"None\", \"None\", \"None\", \"None\", \"None\", \"None\", \"No…\n$ Rd_Feature <chr> \"No Special Feature\", \"Four-Way Intersection\", \"Four-Way In…\n$ Rd_Surface <chr> \"Smooth Asphalt\", \"Smooth Asphalt\", \"Smooth Asphalt\", \"Smoo…\n$ Region     <chr> \"Piedmont\", \"Coastal\", \"Coastal\", \"Piedmont\", \"Piedmont\", \"…\n$ Rural_Urba <chr> \"Urban\", \"Urban\", \"Rural\", \"Urban\", \"Urban\", \"Urban\", \"Urba…\n$ Speed_Limi <chr> \"20 - 25  MPH\", \"40 - 45  MPH\", \"30 - 35  MPH\", \"40 - 45  M…\n$ Traff_Cntr <chr> \"No Control Present\", \"Stop And Go Signal\", \"Stop Sign\", \"S…\n$ Weather    <chr> \"Clear\", \"Clear\", \"Clear\", \"Cloudy\", \"Clear\", \"Clear\", \"Cle…\n$ Workzone_I <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\",…\n$ Location   <chr> \"36.002743, -78.8785\", \"35.612984, -77.39265\", \"35.595676, …"
  },
  {
    "objectID": "content/lectures/02-dplyr-slides.html#a-grammar-of-data-manipulation",
    "href": "content/lectures/02-dplyr-slides.html#a-grammar-of-data-manipulation",
    "title": "02-dplyr",
    "section": "A Grammar of Data Manipulation",
    "text": "A Grammar of Data Manipulation\ndplyr is based on the concepts of functions as verbs that manipulate data frames.\nSingle data frame functions / verbs:\n\nfilter: pick rows matching criteria\nslice: pick rows using index(es)\nselect: pick columns by name\npull: grab a column as a vector\nrename: rename specific columns\narrange: reorder rows\nmutate: add new variables\ntransmute: create new data frame with variables\ndistinct: filter for unique rows\nsample_n / sample_frac: randomly sample rows\nsummarize: reduce variables to values\n… (many more)"
  },
  {
    "objectID": "content/lectures/02-dplyr-slides.html#dplyr-rules-for-functions",
    "href": "content/lectures/02-dplyr-slides.html#dplyr-rules-for-functions",
    "title": "02-dplyr",
    "section": "dplyr rules for functions",
    "text": "dplyr rules for functions\n\nFirst argument is always a data frame\nSubsequent arguments say what to do with that data frame\nAlways return a data frame\nDo not modify in place\nPerformance via lazy evaluation"
  },
  {
    "objectID": "content/lectures/02-dplyr-slides.html#filter-rows-with-filter",
    "href": "content/lectures/02-dplyr-slides.html#filter-rows-with-filter",
    "title": "02-dplyr",
    "section": "Filter rows with filter",
    "text": "Filter rows with filter\n\nSelect a subset of rows in a data frame.\nEasily filter for many conditions at once."
  },
  {
    "objectID": "content/lectures/02-dplyr-slides.html#filter",
    "href": "content/lectures/02-dplyr-slides.html#filter",
    "title": "02-dplyr",
    "section": "filter",
    "text": "filter\nfor crashes in Durham County\n\nbike |>\n  filter(County == \"Durham\")\n\n# A tibble: 253 × 54\n     FID OBJEC…¹ Ambul…² BikeA…³ Bike_…⁴ Bike_…⁵ Bike_…⁶ Bike_…⁷ Bike_…⁸ Bike_…⁹\n   <dbl>   <dbl> <chr>   <chr>     <dbl> <chr>   <chr>   <chr>   <chr>   <chr>  \n 1    18      19 No      <NA>          6 No      Not Ap… C: Pos… Drivew… Black  \n 2    53      54 Yes     50-59        52 No      With T… A: Dis… Travel… White  \n 3    56      57 Yes     16-19        18 No      <NA>    C: Pos… Travel… Black  \n 4   209     210 No      16-19        16 No      Facing… C: Pos… <NA>    Black  \n 5   228     229 Yes     40-49        40 No      With T… B: Evi… Bike L… Black  \n 6   620     621 Yes     50-59        55 No      With T… B: Evi… Travel… White  \n 7   667     668 Yes     60-69        61 No      Not Ap… B: Evi… Sidewa… Black  \n 8   458     459 Yes     60-69        62 No      With T… B: Evi… Travel… White  \n 9   576     577 No      40-49        49 No      With T… C: Pos… Travel… Black  \n10   618     619 No      20-24        23 No      With T… C: Pos… Travel… Asian  \n# … with 243 more rows, 44 more variables: Bike_Sex <chr>, City <chr>,\n#   County <chr>, CrashAlcoh <chr>, CrashDay <chr>, Crash_Date <date>,\n#   Crash_Grp <chr>, Crash_Hour <dbl>, Crash_Loc <chr>, Crash_Mont <chr>,\n#   Crash_Time <dttm>, Crash_Type <chr>, Crash_Ty_1 <dbl>, Crash_Year <dbl>,\n#   Crsh_Sevri <chr>, Developmen <chr>, DrvrAge_Gr <chr>, Drvr_Age <dbl>,\n#   Drvr_Alc_D <chr>, Drvr_EstSp <chr>, Drvr_Injur <chr>, Drvr_Race <chr>,\n#   Drvr_Sex <chr>, Drvr_VehTy <chr>, ExcsSpdInd <chr>, Hit_Run <chr>, …"
  },
  {
    "objectID": "content/lectures/02-dplyr-slides.html#filter-1",
    "href": "content/lectures/02-dplyr-slides.html#filter-1",
    "title": "02-dplyr",
    "section": "filter",
    "text": "filter\nfor crashes in Durham County where biker was < 10 yrs old\n\nbike |>\n  filter(County == \"Durham\", Bike_Age < 10)\n\n# A tibble: 20 × 54\n     FID OBJEC…¹ Ambul…² BikeA…³ Bike_…⁴ Bike_…⁵ Bike_…⁶ Bike_…⁷ Bike_…⁸ Bike_…⁹\n   <dbl>   <dbl> <chr>   <chr>     <dbl> <chr>   <chr>   <chr>   <chr>   <chr>  \n 1    18      19 No      <NA>          6 No      Not Ap… C: Pos… Drivew… Black  \n 2    47      48 No      10-Jun        9 No      Not Ap… O: No … Non-Ro… Black  \n 3   124     125 Yes     10-Jun        8 No      With T… C: Pos… Travel… Black  \n 4   531     532 Yes     10-Jun        7 No      With T… C: Pos… Travel… Black  \n 5   704     705 Yes     10-Jun        9 No      Not Ap… C: Pos… Non-Ro… Black  \n 6    42      43 No      10-Jun        8 No      With T… O: No … Travel… Black  \n 7   392     393 Yes     0-5           2 No      Not Ap… B: Evi… Drivew… Black  \n 8   941     942 No      10-Jun        9 No      With T… C: Pos… Travel… Black  \n 9   436     437 Yes     10-Jun        6 No      Not Ap… O: No … Drivew… Black  \n10   160     161 Yes     10-Jun        7 No      With T… C: Pos… Travel… Black  \n11   273     274 Yes     10-Jun        7 No      Facing… C: Pos… Travel… Black  \n12    78      79 Yes     10-Jun        7 No      With T… C: Pos… Travel… Black  \n13   422     423 No      10-Jun        9 No      Not Ap… O: No … Drivew… Black  \n14   570     571 No      <NA>          0 Missing Not Ap… Injury  Non-Ro… /Missi…\n15   683     684 Yes     10-Jun        8 No      Not Ap… C: Pos… Non-Ro… Black  \n16    62      63 Yes     10-Jun        7 No      With T… C: Pos… Travel… Black  \n17   248     249 No      0-5           4 No      Not Ap… O: No … Drivew… Hispan…\n18   306     307 Yes     10-Jun        8 No      With T… C: Pos… <NA>    Black  \n19   231     232 Yes     10-Jun        8 No      With T… C: Pos… Travel… Black  \n20   361     362 Yes     10-Jun        9 No      With T… B: Evi… Travel… Hispan…\n# … with 44 more variables: Bike_Sex <chr>, City <chr>, County <chr>,\n#   CrashAlcoh <chr>, CrashDay <chr>, Crash_Date <date>, Crash_Grp <chr>,\n#   Crash_Hour <dbl>, Crash_Loc <chr>, Crash_Mont <chr>, Crash_Time <dttm>,\n#   Crash_Type <chr>, Crash_Ty_1 <dbl>, Crash_Year <dbl>, Crsh_Sevri <chr>,\n#   Developmen <chr>, DrvrAge_Gr <chr>, Drvr_Age <dbl>, Drvr_Alc_D <chr>,\n#   Drvr_EstSp <chr>, Drvr_Injur <chr>, Drvr_Race <chr>, Drvr_Sex <chr>,\n#   Drvr_VehTy <chr>, ExcsSpdInd <chr>, Hit_Run <chr>, Light_Cond <chr>, …"
  },
  {
    "objectID": "content/lectures/02-dplyr-slides.html#aside-real-data-is-messy",
    "href": "content/lectures/02-dplyr-slides.html#aside-real-data-is-messy",
    "title": "02-dplyr",
    "section": "Aside: real data is messy!",
    "text": "Aside: real data is messy!\n   What in the world does a BikeAge_gr of 10-Jun or 15-Nov mean?\n\nbike |>\n  group_by(BikeAge_Gr) |>\n  summarize(crash_count = n())\n\n# A tibble: 13 × 2\n   BikeAge_Gr crash_count\n   <chr>            <int>\n 1 0-5                 60\n 2 10-Jun             421\n 3 15-Nov             747\n 4 16-19              605\n 5 20-24              680\n 6 25-29              430\n 7 30-39              658\n 8 40-49              920\n 9 50-59              739\n10 60-69              274\n11 70                  12\n12 70+                 58\n13 <NA>               112"
  },
  {
    "objectID": "content/lectures/02-dplyr-slides.html#careful-data-scientists-clean-up-their-data-first",
    "href": "content/lectures/02-dplyr-slides.html#careful-data-scientists-clean-up-their-data-first",
    "title": "02-dplyr",
    "section": "Careful data scientists clean up their data first!",
    "text": "Careful data scientists clean up their data first!\n\nWe’re going to need to do some text parsing to clean up these data\n\n10-Jun should be 6-10\n15-Nov should be 11-15"
  },
  {
    "objectID": "content/lectures/02-dplyr-slides.html#correct-and-overwrite-mutate",
    "href": "content/lectures/02-dplyr-slides.html#correct-and-overwrite-mutate",
    "title": "02-dplyr",
    "section": "Correct and overwrite mutate",
    "text": "Correct and overwrite mutate\n\nRemember we want to do the following in the BikeAge_Gr variable\n\n10-Jun should be 6-10\n15-Nov should be 11-15\n\n\n\nbike <- bike |>\n  mutate(\n    BikeAge_Gr = case_when(\n      BikeAge_Gr == \"10-Jun\" ~ \"6-10\",\n      BikeAge_Gr == \"15-Nov\" ~ \"11-15\",\n      TRUE                   ~ BikeAge_Gr     # everything else\n    )\n  )\n\n\nNote that we’re overwriting existing data and columns, so be careful!\n\nBut remember, it’s easy to revert if you make a mistake since we didn’t touch the raw data, we can always reload it and start over"
  },
  {
    "objectID": "content/lectures/02-dplyr-slides.html#check-before-you-move-on",
    "href": "content/lectures/02-dplyr-slides.html#check-before-you-move-on",
    "title": "02-dplyr",
    "section": "Check before you move on",
    "text": "Check before you move on\nAlways check your changes and confirm code did what you wanted it to do\n\nbike |>\n  group_by(BikeAge_Gr) |>\n  summarize(count = n())\n\n# A tibble: 13 × 2\n   BikeAge_Gr count\n   <chr>      <int>\n 1 0-5           60\n 2 11-15        747\n 3 16-19        605\n 4 20-24        680\n 5 25-29        430\n 6 30-39        658\n 7 40-49        920\n 8 50-59        739\n 9 6-10         421\n10 60-69        274\n11 70            12\n12 70+           58\n13 <NA>         112"
  },
  {
    "objectID": "content/lectures/02-dplyr-slides.html#mutate-to-add-new-variables",
    "href": "content/lectures/02-dplyr-slides.html#mutate-to-add-new-variables",
    "title": "02-dplyr",
    "section": "mutate to add new variables",
    "text": "mutate to add new variables\n   How is the new alcohol variable determined?\n\nbike |>\n  mutate(alcohol = case_when(\n    Bike_Alc_D == \"No\" & Drvr_Alc_D == \"No\"      ~ \"No\",\n    Bike_Alc_D == \"Yes\" | Drvr_Alc_D == \"Yes\"    ~ \"Yes\",\n    Bike_Alc_D == \"Missing\" & Drvr_Alc_D == \"No\" ~ \"Missing\",\n    Bike_Alc_D == \"No\" & Drvr_Alc_D == \"Missing\" ~ \"Missing\"\n  ))"
  },
  {
    "objectID": "content/lectures/02-dplyr-slides.html#save-when-you-mutate",
    "href": "content/lectures/02-dplyr-slides.html#save-when-you-mutate",
    "title": "02-dplyr",
    "section": "“Save” when you mutate",
    "text": "“Save” when you mutate\nMost often when you define a new variable with mutate you’ll also want to save the resulting data frame, often by writing over the original data frame.\n\nbike <- bike |>\n  mutate(alcohol = case_when(\n    Bike_Alc_D == \"No\" & Drvr_Alc_D == \"No\"      ~ \"No\",\n    Bike_Alc_D == \"Yes\" | Drvr_Alc_D == \"Yes\"    ~ \"Yes\",\n    Bike_Alc_D == \"Missing\" & Drvr_Alc_D == \"No\" ~ \"Missing\",\n    Bike_Alc_D == \"No\" & Drvr_Alc_D == \"Missing\" ~ \"Missing\"\n  ))"
  },
  {
    "objectID": "content/lectures/02-dplyr-slides.html#transmute-to-create-a-new-dataset",
    "href": "content/lectures/02-dplyr-slides.html#transmute-to-create-a-new-dataset",
    "title": "02-dplyr",
    "section": "transmute to create a new dataset",
    "text": "transmute to create a new dataset\nYou’ll use this much less often than mutate but when you need it, you need it.\n\nbike |> \n  transmute(ID = paste(FID, OBJECTID, sep = \"-\"))\n\n# A tibble: 5,716 × 1\n   ID   \n   <chr>\n 1 18-19\n 2 29-30\n 3 33-34\n 4 35-36\n 5 49-50\n 6 53-54\n 7 56-57\n 8 60-61\n 9 63-64\n10 66-67\n# … with 5,706 more rows"
  },
  {
    "objectID": "content/lectures/02-dplyr-slides.html#mutate-vs.-transmute",
    "href": "content/lectures/02-dplyr-slides.html#mutate-vs.-transmute",
    "title": "02-dplyr",
    "section": "mutate vs. transmute",
    "text": "mutate vs. transmute\n\nmutate adds new and keeps original\ntransmute adds new; drops existing"
  },
  {
    "objectID": "content/lectures/02-dplyr-slides.html#your-turn",
    "href": "content/lectures/02-dplyr-slides.html#your-turn",
    "title": "02-dplyr",
    "section": "Your Turn",
    "text": "Your Turn\nHow many accidents in our dataset required an ambulance ride (AmbulanceR) and had the Crash_Type “Bicyclist Lost Control - Mechanical Problems”?\n\n\nPut a green sticky on the front of your computer when you’re done. Put a pink if you want help/have a question."
  },
  {
    "objectID": "content/lectures/02-dplyr-slides.html#slice-for-certain-row-numbers",
    "href": "content/lectures/02-dplyr-slides.html#slice-for-certain-row-numbers",
    "title": "02-dplyr",
    "section": "slice for certain row numbers",
    "text": "slice for certain row numbers\nFirst five\n\nbike |>\n  slice(1:5)\n\n# A tibble: 5 × 54\n    FID OBJECTID Ambul…¹ BikeA…² Bike_…³ Bike_…⁴ Bike_…⁵ Bike_…⁶ Bike_…⁷ Bike_…⁸\n  <dbl>    <dbl> <chr>   <chr>     <dbl> <chr>   <chr>   <chr>   <chr>   <chr>  \n1    18       19 No      <NA>          6 No      Not Ap… C: Pos… Drivew… Black  \n2    29       30 Yes     50-59        51 No      With T… C: Pos… Travel… Black  \n3    33       34 No      <NA>         10 No      With T… Injury  Travel… Black  \n4    35       36 Yes     16-19        17 No      <NA>    B: Evi… Travel… White  \n5    49       50 No      <NA>          6 No      Facing… O: No … Travel… Black  \n# … with 44 more variables: Bike_Sex <chr>, City <chr>, County <chr>,\n#   CrashAlcoh <chr>, CrashDay <chr>, Crash_Date <date>, Crash_Grp <chr>,\n#   Crash_Hour <dbl>, Crash_Loc <chr>, Crash_Mont <chr>, Crash_Time <dttm>,\n#   Crash_Type <chr>, Crash_Ty_1 <dbl>, Crash_Year <dbl>, Crsh_Sevri <chr>,\n#   Developmen <chr>, DrvrAge_Gr <chr>, Drvr_Age <dbl>, Drvr_Alc_D <chr>,\n#   Drvr_EstSp <chr>, Drvr_Injur <chr>, Drvr_Race <chr>, Drvr_Sex <chr>,\n#   Drvr_VehTy <chr>, ExcsSpdInd <chr>, Hit_Run <chr>, Light_Cond <chr>, …"
  },
  {
    "objectID": "content/lectures/02-dplyr-slides.html#slice-for-certain-row-numbers-1",
    "href": "content/lectures/02-dplyr-slides.html#slice-for-certain-row-numbers-1",
    "title": "02-dplyr",
    "section": "slice for certain row numbers",
    "text": "slice for certain row numbers\nLast five\n\nlast_row <- nrow(bike)\nbike |>\n  slice((last_row - 4):last_row)\n\n# A tibble: 5 × 54\n    FID OBJECTID Ambul…¹ BikeA…² Bike_…³ Bike_…⁴ Bike_…⁵ Bike_…⁶ Bike_…⁷ Bike_…⁸\n  <dbl>    <dbl> <chr>   <chr>     <dbl> <chr>   <chr>   <chr>   <chr>   <chr>  \n1   460      461 Yes     6-10          7 No      Not Ap… C: Pos… Drivew… Black  \n2   474      475 Yes     50-59        50 No      With T… B: Evi… Travel… White  \n3   479      480 Yes     16-19        16 No      Not Ap… C: Pos… Sidewa… White  \n4   487      488 No      40-49        47 Yes     With T… C: Pos… Travel… White  \n5   488      489 Yes     30-39        35 No      Facing… C: Pos… Travel… Black  \n# … with 44 more variables: Bike_Sex <chr>, City <chr>, County <chr>,\n#   CrashAlcoh <chr>, CrashDay <chr>, Crash_Date <date>, Crash_Grp <chr>,\n#   Crash_Hour <dbl>, Crash_Loc <chr>, Crash_Mont <chr>, Crash_Time <dttm>,\n#   Crash_Type <chr>, Crash_Ty_1 <dbl>, Crash_Year <dbl>, Crsh_Sevri <chr>,\n#   Developmen <chr>, DrvrAge_Gr <chr>, Drvr_Age <dbl>, Drvr_Alc_D <chr>,\n#   Drvr_EstSp <chr>, Drvr_Injur <chr>, Drvr_Race <chr>, Drvr_Sex <chr>,\n#   Drvr_VehTy <chr>, ExcsSpdInd <chr>, Hit_Run <chr>, Light_Cond <chr>, …"
  },
  {
    "objectID": "content/lectures/02-dplyr-slides.html#select-to-keep-only-the-variables-you-mention",
    "href": "content/lectures/02-dplyr-slides.html#select-to-keep-only-the-variables-you-mention",
    "title": "02-dplyr",
    "section": "select to keep only the variables you mention",
    "text": "select to keep only the variables you mention\n\nbike |>\n  select(Crash_Loc, Hit_Run) |>\n  table()\n\n                      Hit_Run\nCrash_Loc                No  Yes\n  Intersection         2223  275\n  Intersection-Related  252   42\n  Location                3    7\n  Non-Intersection     2213  462\n  Non-Roadway           205   30"
  },
  {
    "objectID": "content/lectures/02-dplyr-slides.html#or-select-to-exclude-variables",
    "href": "content/lectures/02-dplyr-slides.html#or-select-to-exclude-variables",
    "title": "02-dplyr",
    "section": "or select to exclude variables",
    "text": "or select to exclude variables\n\nbike |>\n  select(-OBJECTID)\n\n# A tibble: 5,716 × 53\n     FID Ambul…¹ BikeA…² Bike_…³ Bike_…⁴ Bike_…⁵ Bike_…⁶ Bike_…⁷ Bike_…⁸ Bike_…⁹\n   <dbl> <chr>   <chr>     <dbl> <chr>   <chr>   <chr>   <chr>   <chr>   <chr>  \n 1    18 No      <NA>          6 No      Not Ap… C: Pos… Drivew… Black   Female \n 2    29 Yes     50-59        51 No      With T… C: Pos… Travel… Black   Male   \n 3    33 No      <NA>         10 No      With T… Injury  Travel… Black   Male   \n 4    35 Yes     16-19        17 No      <NA>    B: Evi… Travel… White   Male   \n 5    49 No      <NA>          6 No      Facing… O: No … Travel… Black   Male   \n 6    53 Yes     50-59        52 No      With T… A: Dis… Travel… White   Male   \n 7    56 Yes     16-19        18 No      <NA>    C: Pos… Travel… Black   Female \n 8    60 No      40-49        40 No      Facing… B: Evi… Sidewa… Hispan… Male   \n 9    63 Yes     6-10          6 No      Facing… B: Evi… Travel… White   Male   \n10    66 Yes     6-10          7 No      <NA>    B: Evi… Non-Ro… Black   Female \n# … with 5,706 more rows, 43 more variables: City <chr>, County <chr>,\n#   CrashAlcoh <chr>, CrashDay <chr>, Crash_Date <date>, Crash_Grp <chr>,\n#   Crash_Hour <dbl>, Crash_Loc <chr>, Crash_Mont <chr>, Crash_Time <dttm>,\n#   Crash_Type <chr>, Crash_Ty_1 <dbl>, Crash_Year <dbl>, Crsh_Sevri <chr>,\n#   Developmen <chr>, DrvrAge_Gr <chr>, Drvr_Age <dbl>, Drvr_Alc_D <chr>,\n#   Drvr_EstSp <chr>, Drvr_Injur <chr>, Drvr_Race <chr>, Drvr_Sex <chr>,\n#   Drvr_VehTy <chr>, ExcsSpdInd <chr>, Hit_Run <chr>, Light_Cond <chr>, …"
  },
  {
    "objectID": "content/lectures/02-dplyr-slides.html#or-select-a-range-of-variables",
    "href": "content/lectures/02-dplyr-slides.html#or-select-a-range-of-variables",
    "title": "02-dplyr",
    "section": "or select a range of variables",
    "text": "or select a range of variables\n\nbike |>\n  select(OBJECTID:Bike_Injur)\n\n# A tibble: 5,716 × 7\n   OBJECTID AmbulanceR BikeAge_Gr Bike_Age Bike_Alc_D Bike_Dir       Bike_Injur \n      <dbl> <chr>      <chr>         <dbl> <chr>      <chr>          <chr>      \n 1       19 No         <NA>              6 No         Not Applicable C: Possibl…\n 2       30 Yes        50-59            51 No         With Traffic   C: Possibl…\n 3       34 No         <NA>             10 No         With Traffic   Injury     \n 4       36 Yes        16-19            17 No         <NA>           B: Evident…\n 5       50 No         <NA>              6 No         Facing Traffic O: No Inju…\n 6       54 Yes        50-59            52 No         With Traffic   A: Disabli…\n 7       57 Yes        16-19            18 No         <NA>           C: Possibl…\n 8       61 No         40-49            40 No         Facing Traffic B: Evident…\n 9       64 Yes        6-10              6 No         Facing Traffic B: Evident…\n10       67 Yes        6-10              7 No         <NA>           B: Evident…\n# … with 5,706 more rows"
  },
  {
    "objectID": "content/lectures/02-dplyr-slides.html#pull-to-extract-a-column-as-a-vector",
    "href": "content/lectures/02-dplyr-slides.html#pull-to-extract-a-column-as-a-vector",
    "title": "02-dplyr",
    "section": "pull to extract a column as a vector",
    "text": "pull to extract a column as a vector\n\nbike |>\n  slice(1:6) |>\n  pull(Location)\n\n[1] \"36.002743, -78.8785\"  \"35.612984, -77.39265\" \"35.595676, -77.59074\"\n[4] \"35.076767, -80.7728\"  \"35.19999, -80.75713\"  \"35.966644, -78.96749\"\n\n\n\nbike |>\n  slice(1:6) |>\n  select(Location)\n\n# A tibble: 6 × 1\n  Location            \n  <chr>               \n1 36.002743, -78.8785 \n2 35.612984, -77.39265\n3 35.595676, -77.59074\n4 35.076767, -80.7728 \n5 35.19999, -80.75713 \n6 35.966644, -78.96749"
  },
  {
    "objectID": "content/lectures/02-dplyr-slides.html#the-two-pulls-in-your-lives",
    "href": "content/lectures/02-dplyr-slides.html#the-two-pulls-in-your-lives",
    "title": "02-dplyr",
    "section": "The two pulls in your lives",
    "text": "The two pulls in your lives\n\n\n\n\n\n\n\n\nDon’t get pull happy when wrangling data! Only extract out variables if you truly need to, otherwise keep in data frame.\nBut always ⬇️ Pull before starting your work when collaborating on GitHub."
  },
  {
    "objectID": "content/lectures/02-dplyr-slides.html#rename-specific-columns",
    "href": "content/lectures/02-dplyr-slides.html#rename-specific-columns",
    "title": "02-dplyr",
    "section": "rename specific columns",
    "text": "rename specific columns\nUseful for correcting typos, and renaming to make variable names shorter and/or more informative\n\nOriginal names:\n\n\nnames(bike)\n\n [1] \"FID\"        \"OBJECTID\"   \"AmbulanceR\" \"BikeAge_Gr\" \"Bike_Age\"  \n [6] \"Bike_Alc_D\" \"Bike_Dir\"   \"Bike_Injur\" \"Bike_Pos\"   \"Bike_Race\" \n[11] \"Bike_Sex\"   \"City\"       \"County\"     \"CrashAlcoh\" \"CrashDay\"  \n[16] \"Crash_Date\" \"Crash_Grp\"  \"Crash_Hour\" \"Crash_Loc\"  \"Crash_Mont\"\n[21] \"Crash_Time\" \"Crash_Type\" \"Crash_Ty_1\" \"Crash_Year\" \"Crsh_Sevri\"\n[26] \"Developmen\" \"DrvrAge_Gr\" \"Drvr_Age\"   \"Drvr_Alc_D\" \"Drvr_EstSp\"\n[31] \"Drvr_Injur\" \"Drvr_Race\"  \"Drvr_Sex\"   \"Drvr_VehTy\" \"ExcsSpdInd\"\n[36] \"Hit_Run\"    \"Light_Cond\" \"Locality\"   \"Num_Lanes\"  \"Num_Units\" \n[41] \"Rd_Charact\" \"Rd_Class\"   \"Rd_Conditi\" \"Rd_Config\"  \"Rd_Defects\"\n[46] \"Rd_Feature\" \"Rd_Surface\" \"Region\"     \"Rural_Urba\" \"Speed_Limi\"\n[51] \"Traff_Cntr\" \"Weather\"    \"Workzone_I\" \"Location\""
  },
  {
    "objectID": "content/lectures/02-dplyr-slides.html#rename-specific-columns-1",
    "href": "content/lectures/02-dplyr-slides.html#rename-specific-columns-1",
    "title": "02-dplyr",
    "section": "rename specific columns",
    "text": "rename specific columns\n\nRename Speed_Limi to Speed_Limit:\n\n\nbike <- bike |>\n  rename(Speed_Limit = Speed_Limi)"
  },
  {
    "objectID": "content/lectures/02-dplyr-slides.html#check-before-you-move-on-1",
    "href": "content/lectures/02-dplyr-slides.html#check-before-you-move-on-1",
    "title": "02-dplyr",
    "section": "Check before you move on",
    "text": "Check before you move on\nAlways check your changes and confirm code did what you wanted it to do\n\nnames(bike)\n\n [1] \"FID\"         \"OBJECTID\"    \"AmbulanceR\"  \"BikeAge_Gr\"  \"Bike_Age\"   \n [6] \"Bike_Alc_D\"  \"Bike_Dir\"    \"Bike_Injur\"  \"Bike_Pos\"    \"Bike_Race\"  \n[11] \"Bike_Sex\"    \"City\"        \"County\"      \"CrashAlcoh\"  \"CrashDay\"   \n[16] \"Crash_Date\"  \"Crash_Grp\"   \"Crash_Hour\"  \"Crash_Loc\"   \"Crash_Mont\" \n[21] \"Crash_Time\"  \"Crash_Type\"  \"Crash_Ty_1\"  \"Crash_Year\"  \"Crsh_Sevri\" \n[26] \"Developmen\"  \"DrvrAge_Gr\"  \"Drvr_Age\"    \"Drvr_Alc_D\"  \"Drvr_EstSp\" \n[31] \"Drvr_Injur\"  \"Drvr_Race\"   \"Drvr_Sex\"    \"Drvr_VehTy\"  \"ExcsSpdInd\" \n[36] \"Hit_Run\"     \"Light_Cond\"  \"Locality\"    \"Num_Lanes\"   \"Num_Units\"  \n[41] \"Rd_Charact\"  \"Rd_Class\"    \"Rd_Conditi\"  \"Rd_Config\"   \"Rd_Defects\" \n[46] \"Rd_Feature\"  \"Rd_Surface\"  \"Region\"      \"Rural_Urba\"  \"Speed_Limit\"\n[51] \"Traff_Cntr\"  \"Weather\"     \"Workzone_I\"  \"Location\""
  },
  {
    "objectID": "content/lectures/02-dplyr-slides.html#your-turn-1",
    "href": "content/lectures/02-dplyr-slides.html#your-turn-1",
    "title": "02-dplyr",
    "section": "Your Turn",
    "text": "Your Turn\nYour boss in Cumberland County gets overwhelmed by data easily, but he wants some data from you. He wants all bike accidents from his County, but he only wants to know the road’s speed limit, the age of the biker, and to know if alcohol was involved. If you have time, mine as well make the column names very clear to your boss while you’re at it…\n\n\nPut a green sticky on the front of your computer when you’re done. Put a pink if you want help/have a question."
  },
  {
    "objectID": "content/lectures/02-dplyr-slides.html#summarize-to-reduce-variables-to-values",
    "href": "content/lectures/02-dplyr-slides.html#summarize-to-reduce-variables-to-values",
    "title": "02-dplyr",
    "section": "summarize to reduce variables to values",
    "text": "summarize to reduce variables to values\nThe values are summarized in a data frame\n\nbike |>\n  group_by(BikeAge_Gr) |>\n  summarize(crash_count = n())\n\n# A tibble: 13 × 2\n   BikeAge_Gr crash_count\n   <chr>            <int>\n 1 0-5                 60\n 2 11-15              747\n 3 16-19              605\n 4 20-24              680\n 5 25-29              430\n 6 30-39              658\n 7 40-49              920\n 8 50-59              739\n 9 6-10               421\n10 60-69              274\n11 70                  12\n12 70+                 58\n13 <NA>               112"
  },
  {
    "objectID": "content/lectures/02-dplyr-slides.html#and-arrange-to-order-rows",
    "href": "content/lectures/02-dplyr-slides.html#and-arrange-to-order-rows",
    "title": "02-dplyr",
    "section": "and arrange to order rows",
    "text": "and arrange to order rows\n\nbike |>\n  group_by(BikeAge_Gr) |>\n  summarize(crash_count = n()) |>\n  arrange(desc(crash_count))\n\n# A tibble: 13 × 2\n   BikeAge_Gr crash_count\n   <chr>            <int>\n 1 40-49              920\n 2 11-15              747\n 3 50-59              739\n 4 20-24              680\n 5 30-39              658\n 6 16-19              605\n 7 25-29              430\n 8 6-10               421\n 9 60-69              274\n10 <NA>               112\n11 0-5                 60\n12 70+                 58\n13 70                  12"
  },
  {
    "objectID": "content/lectures/02-dplyr-slides.html#count-to-group-by-then-count",
    "href": "content/lectures/02-dplyr-slides.html#count-to-group-by-then-count",
    "title": "02-dplyr",
    "section": "count to group by then count",
    "text": "count to group by then count\n\nbike |>\n  count(BikeAge_Gr)\n\n# A tibble: 13 × 2\n   BikeAge_Gr     n\n   <chr>      <int>\n 1 0-5           60\n 2 11-15        747\n 3 16-19        605\n 4 20-24        680\n 5 25-29        430\n 6 30-39        658\n 7 40-49        920\n 8 50-59        739\n 9 6-10         421\n10 60-69        274\n11 70            12\n12 70+           58\n13 <NA>         112\n\n\n   If you wanted to arrange these in ascending order what would you add to the pipe?"
  },
  {
    "objectID": "content/lectures/02-dplyr-slides.html#select-rows-with-sample_n-or-sample_frac",
    "href": "content/lectures/02-dplyr-slides.html#select-rows-with-sample_n-or-sample_frac",
    "title": "02-dplyr",
    "section": "Select rows with sample_n or sample_frac",
    "text": "Select rows with sample_n or sample_frac\n\nsample_n: randomly sample 5 observations\n\n\nbike_n5 <- bike |>\n  sample_n(5, replace = FALSE)\n\ndim(bike_n5)\n\n[1]  5 54\n\n\n\nsample_frac: randomly sample 20% of observations\n\n\nbike_perc20 <- bike |>\n  sample_frac(0.2, replace = FALSE)\n\ndim(bike_perc20)\n\n[1] 1143   54"
  },
  {
    "objectID": "content/lectures/02-dplyr-slides.html#distinct-to-filter-for-unique-rows",
    "href": "content/lectures/02-dplyr-slides.html#distinct-to-filter-for-unique-rows",
    "title": "02-dplyr",
    "section": "distinct to filter for unique rows",
    "text": "distinct to filter for unique rows\n\nbike |> \n  select(County, City) |> \n  distinct() |> \n  arrange(County, City)\n\n# A tibble: 360 × 2\n   County    City              \n   <chr>     <chr>             \n 1 Alamance  Alamance          \n 2 Alamance  Burlington        \n 3 Alamance  Elon College      \n 4 Alamance  Gibsonville       \n 5 Alamance  Graham            \n 6 Alamance  Green Level       \n 7 Alamance  Mebane            \n 8 Alamance  None - Rural Crash\n 9 Alexander None - Rural Crash\n10 Alleghany None - Rural Crash\n# … with 350 more rows"
  },
  {
    "objectID": "content/lectures/02-dplyr-slides.html#distinct-has-a-.keep_all-parameter",
    "href": "content/lectures/02-dplyr-slides.html#distinct-has-a-.keep_all-parameter",
    "title": "02-dplyr",
    "section": "distinct has a .keep_all parameter",
    "text": "distinct has a .keep_all parameter\n\nbike |> \n  distinct(County, City, .keep_all = TRUE) |> \n  arrange(County, City)\n\n# A tibble: 360 × 54\n     FID OBJEC…¹ Ambul…² BikeA…³ Bike_…⁴ Bike_…⁵ Bike_…⁶ Bike_…⁷ Bike_…⁸ Bike_…⁹\n   <dbl>   <dbl> <chr>   <chr>     <dbl> <chr>   <chr>   <chr>   <chr>   <chr>  \n 1   524     525 Yes     11-15        12 No      <NA>    B: Evi… <NA>    Black  \n 2    84      85 Yes     20-24        20 No      With T… B: Evi… Travel… White  \n 3   571     572 Yes     16-19        16 No      Not Ap… B: Evi… Non-Ro… White  \n 4   509     510 Yes     40-49        43 Yes     With T… K: Kil… Travel… Black  \n 5   855     856 Yes     30-39        30 No      With T… A: Dis… Travel… Black  \n 6     5       6 Yes     40-49        44 Yes     With T… C: Pos… Travel… Black  \n 7   163     164 Yes     30-39        35 No      Not Ap… C: Pos… <NA>    White  \n 8    96      97 Yes     30-39        36 No      With T… C: Pos… Travel… White  \n 9    46      47 Yes     50-59        53 No      With T… B: Evi… Travel… White  \n10   485     486 Yes     60-69        62 No      With T… C: Pos… Travel… White  \n# … with 350 more rows, 44 more variables: Bike_Sex <chr>, City <chr>,\n#   County <chr>, CrashAlcoh <chr>, CrashDay <chr>, Crash_Date <date>,\n#   Crash_Grp <chr>, Crash_Hour <dbl>, Crash_Loc <chr>, Crash_Mont <chr>,\n#   Crash_Time <dttm>, Crash_Type <chr>, Crash_Ty_1 <dbl>, Crash_Year <dbl>,\n#   Crsh_Sevri <chr>, Developmen <chr>, DrvrAge_Gr <chr>, Drvr_Age <dbl>,\n#   Drvr_Alc_D <chr>, Drvr_EstSp <chr>, Drvr_Injur <chr>, Drvr_Race <chr>,\n#   Drvr_Sex <chr>, Drvr_VehTy <chr>, ExcsSpdInd <chr>, Hit_Run <chr>, …"
  },
  {
    "objectID": "content/lectures/02-dplyr-slides.html#factors-1",
    "href": "content/lectures/02-dplyr-slides.html#factors-1",
    "title": "02-dplyr",
    "section": "Factors",
    "text": "Factors\nFactor objects are how R stores data for categorical variables (fixed numbers of discrete values).\n\n(x = factor(c(\"BS\", \"MS\", \"PhD\", \"MS\")))\n\n[1] BS  MS  PhD MS \nLevels: BS MS PhD\n\n\n\nglimpse(x)\n\n Factor w/ 3 levels \"BS\",\"MS\",\"PhD\": 1 2 3 2\n\n\n\ntypeof(x)\n\n[1] \"integer\""
  },
  {
    "objectID": "content/lectures/02-dplyr-slides.html#returning-to-cat-lovers",
    "href": "content/lectures/02-dplyr-slides.html#returning-to-cat-lovers",
    "title": "02-dplyr",
    "section": "Returning to: Cat lovers",
    "text": "Returning to: Cat lovers\nReading in the cat-lovers data…\n\ncat_lovers <- read_csv(\"https://raw.githubusercontent.com/COGS137/datasets/main/cat-lovers.csv\")"
  },
  {
    "objectID": "content/lectures/02-dplyr-slides.html#read-data-in-as-character-strings",
    "href": "content/lectures/02-dplyr-slides.html#read-data-in-as-character-strings",
    "title": "02-dplyr",
    "section": "Read data in as character strings",
    "text": "Read data in as character strings\n\nglimpse(cat_lovers)\n\nRows: 60\nColumns: 3\n$ name           <chr> \"Bernice Warren\", \"Woodrow Stone\", \"Willie Bass\", \"Tyro…\n$ number_of_cats <chr> \"0\", \"0\", \"1\", \"3\", \"3\", \"2\", \"1\", \"1\", \"0\", \"0\", \"0\", …\n$ handedness     <chr> \"left\", \"left\", \"left\", \"left\", \"left\", \"left\", \"left\",…"
  },
  {
    "objectID": "content/lectures/02-dplyr-slides.html#but-coerce-when-plotting",
    "href": "content/lectures/02-dplyr-slides.html#but-coerce-when-plotting",
    "title": "02-dplyr",
    "section": "But coerce when plotting",
    "text": "But coerce when plotting\n\nggplot(cat_lovers, mapping = aes(x = handedness)) +\n  geom_bar()"
  },
  {
    "objectID": "content/lectures/02-dplyr-slides.html#use-forcats-to-manipulate-factors",
    "href": "content/lectures/02-dplyr-slides.html#use-forcats-to-manipulate-factors",
    "title": "02-dplyr",
    "section": "Use forcats to manipulate factors",
    "text": "Use forcats to manipulate factors\n\ncat_lovers <- cat_lovers |>\n  mutate(handedness = fct_relevel(handedness, \n                                  \"right\", \"left\", \"ambidextrous\"))\n\n\nggplot(cat_lovers, mapping = aes(x = handedness)) +\n  geom_bar()"
  },
  {
    "objectID": "content/lectures/02-dplyr-slides.html#forcats-functionality",
    "href": "content/lectures/02-dplyr-slides.html#forcats-functionality",
    "title": "02-dplyr",
    "section": "forcats functionality ",
    "text": "forcats functionality \n\nR uses factors to handle categorical variables, variables that have a fixed and known set of possible values. Historically, factors were much easier to work with than character vectors, so many base R functions automatically convert character vectors to factors.\nfactors are still useful when you have true categorical data, and when you want to override the ordering of character vectors to improve display. The goal of the forcats package is to provide a suite of useful tools that solve common problems with factors.\n\n\n\nSource: forcats.tidyverse.org"
  },
  {
    "objectID": "content/lectures/02-dplyr-slides.html#suggested-reading",
    "href": "content/lectures/02-dplyr-slides.html#suggested-reading",
    "title": "02-dplyr",
    "section": "Suggested Reading",
    "text": "Suggested Reading\nR4DS:\n\nChapter 5: Data Transformation\nChapter 15: Factors\n\n\n\n\nhttps://cogs137.github.io/website/"
  },
  {
    "objectID": "content/lectures/02-dplyr.html",
    "href": "content/lectures/02-dplyr.html",
    "title": "02-dplyr",
    "section": "",
    "text": "Q: what does |> mean?\nA: It means “and then” and is called a “pipe.” Discussing this in more detail in today’s lecture!\n\n\nQ: I think the lab is much more harder than the lecture.\nA: This first week there is a lot to learn regarding tooling, but once you’ve got that down the “process” of completing a lab will become second nature. Then, it’s just content…and applying something is always more difficult than listening to it being explained. So, labs will be a bit harder than lecture…but that’s by design b/c 1) we grade on effort (it’s ok to be wrong in labs!) and 2) answer keys will be posted (learning from mistakes/places we struggle is a great way to learn!)\n\n\nQ: Just curious about the oral presentation portion of the final project. Will this be a requirement in the form of a recorded video (like in COGS 108), or will we be presenting our project findings live in front of the class on the due date?\nA: There are going to be two options (most likely). A recording will definitely be an option. We’re also hoping to have an option where you can come present live, to the instructional staff and any students who want to learn from one another.\n\n\nQ: I am curious about the similarities and differences between both of Python and R!\nA: Very briefly, some similarities: both are object-oriented programming languages (although R is not only object-oriented); both are great for data analysis; differences: python arguably has a simpler syntax; R is, at its core, designed for statistical analysis so I’d argue it’s better for that; Python is a general-programming language so it’s arguablly better for software development; R has an implementation of the grammar of graphics, so I’d argue it’s better for data visualization (but some would disagree).\n\n\nQ: How can I understand dataframes in R easier?\nA: With practice! Today’s lecture, this week 2 lab, and your first hw will help you get additional practice. Then, we’ll use them throughout the course and build your understanding.\n\n\nQ: For very large data sets, how would you be able to find every type coercion?\nA: Each column would have a single type. glimpse() would help you identify the type of each column. From there, you can edit any that are not what you wanted.\n\n\nQ: Where would be a good location to get some practice on most of the packages we will be using in this class?\nA: The labs and homeworks are one place. But, there are also exercises in the “textbook” for this class: https://r4ds.had.co.nz/\n\n\nQ: How do we grasp Markdown easier?\nA: Trying things out and learning the basic rules. I would recommend starting with an RMarkdown document and just typing a sentence. Then knit to see what that looks like. Then, try to bold and italicize some text. Then try to add some headers. Then, add a bulleted list. Each time knitting to see the output. With that, you’ll have most of the markdown you’ll need! reference for basics\n\n\nQ: I am still not sure whether this class focuses more on the programming aspect or the mathematical concepts\nA: Both! First 5 weeks, more programming; Last 5: combination of both are used, but new programming concepts aren’t introduced a ton, so we focus on the stats while continuing to use what we learned the first five weeks!\n\n\nQ: Is there any rules for coercion?\nA: There are rules! Summarized here\n\n\nQ: When do we use R markdown?\nA: When completing labs, homework assignments, case studies, and likely on the final project. You can also take notes in RMarkdown, but that’s up to you!\n\n\nQ: Never heard about ggplot2. I think everyone had already heard of it previously…\nA: While some students have, you’re not alone! We’ll have two lectures on this and get plenty of practice soon!\n\n\n\n\nDue Dates:\n\nLab 02 due Friday (1/20; 11:59 PM)\nHW01 due Monday (1/23; 11:59 PM)\nLecture Participation survey “due” after class\n\nNotes (1/19):\n\nLab01 Graded - see GitHub issue for comments; 2pts == full credit\n\nCommon issues:\n\nDid not knit file to HTML\nDid not include name in file\nYou do not need to version control the .RProj file\nYou should replace the “instruction” text with your explanations/interpretations\n\nIf you received a zero, you should have an email from me\n\nLab02 released\nHW01 released - let’s take a look\n\n\n\n\n\ndplyr\n\nphilosophy\npipes\ncommon operations\n\n\n\n\n\n\ndplyr is a grammar of data manipulation, providing a consistent set of verbs that help you solve the most common data manipulation challenges\n\n\n\nSource: dplyr.tidyverse.org"
  },
  {
    "objectID": "content/lectures/02-dplyr.html#the-pipe-in-baser",
    "href": "content/lectures/02-dplyr.html#the-pipe-in-baser",
    "title": "02-dplyr",
    "section": "The pipe in baseR",
    "text": "The pipe in baseR\n\n\n\n\n|> should be read as “and then”\nfor example “Wake up |> brush teeth” would be read as “wake up and then brush teeth”"
  },
  {
    "objectID": "content/lectures/02-dplyr.html#where-does-the-name-come-from",
    "href": "content/lectures/02-dplyr.html#where-does-the-name-come-from",
    "title": "02-dplyr",
    "section": "Where does the name come from?",
    "text": "Where does the name come from?\nThe pipe operator was first implemented in the package magrittr.\n\n\n\n\n\n\n\nYou will see this frequently in code online. It’s equivalent to |>."
  },
  {
    "objectID": "content/lectures/02-dplyr.html#review-how-does-a-pipe-work",
    "href": "content/lectures/02-dplyr.html#review-how-does-a-pipe-work",
    "title": "02-dplyr",
    "section": "Review: How does a pipe work?",
    "text": "Review: How does a pipe work?\n\nYou can think about the following sequence of actions - find key, unlock car, start car, drive to school, park.\n\n\n\nExpressed as a set of nested functions in R pseudocode this would look like:\n\n\npark(drive(start_car(find(\"keys\")), to = \"campus\"))\n\n\n\n\nWriting it out using pipes give it a more natural (and easier to read) structure:\n\n\nfind(\"keys\") |>\n  start_car() |>\n  drive(to = \"campus\") |>\n  park()"
  },
  {
    "objectID": "content/lectures/02-dplyr.html#nc-dot-fatal-crashes-in-north-carolina",
    "href": "content/lectures/02-dplyr.html#nc-dot-fatal-crashes-in-north-carolina",
    "title": "02-dplyr",
    "section": "NC DOT Fatal Crashes in North Carolina",
    "text": "NC DOT Fatal Crashes in North Carolina\nFrom OpenDurham’s Data Portal\n\nbike <- read_csv2(\"https://raw.githubusercontent.com/COGS137/datasets/main/nc_bike_crash.csv\", \n                  na = c(\"NA\", \"\", \".\"))"
  },
  {
    "objectID": "content/lectures/02-dplyr.html#variables",
    "href": "content/lectures/02-dplyr.html#variables",
    "title": "02-dplyr",
    "section": "Variables",
    "text": "Variables\nView the names of variables via\n\nnames(bike)\n\n [1] \"FID\"        \"OBJECTID\"   \"AmbulanceR\" \"BikeAge_Gr\" \"Bike_Age\"  \n [6] \"Bike_Alc_D\" \"Bike_Dir\"   \"Bike_Injur\" \"Bike_Pos\"   \"Bike_Race\" \n[11] \"Bike_Sex\"   \"City\"       \"County\"     \"CrashAlcoh\" \"CrashDay\"  \n[16] \"Crash_Date\" \"Crash_Grp\"  \"Crash_Hour\" \"Crash_Loc\"  \"Crash_Mont\"\n[21] \"Crash_Time\" \"Crash_Type\" \"Crash_Ty_1\" \"Crash_Year\" \"Crsh_Sevri\"\n[26] \"Developmen\" \"DrvrAge_Gr\" \"Drvr_Age\"   \"Drvr_Alc_D\" \"Drvr_EstSp\"\n[31] \"Drvr_Injur\" \"Drvr_Race\"  \"Drvr_Sex\"   \"Drvr_VehTy\" \"ExcsSpdInd\"\n[36] \"Hit_Run\"    \"Light_Cond\" \"Locality\"   \"Num_Lanes\"  \"Num_Units\" \n[41] \"Rd_Charact\" \"Rd_Class\"   \"Rd_Conditi\" \"Rd_Config\"  \"Rd_Defects\"\n[46] \"Rd_Feature\" \"Rd_Surface\" \"Region\"     \"Rural_Urba\" \"Speed_Limi\"\n[51] \"Traff_Cntr\" \"Weather\"    \"Workzone_I\" \"Location\""
  },
  {
    "objectID": "content/lectures/02-dplyr.html#viewing-your-data",
    "href": "content/lectures/02-dplyr.html#viewing-your-data",
    "title": "02-dplyr",
    "section": "Viewing your data",
    "text": "Viewing your data\n\nIn the Environment, click on the name of the data frame to view it in the data viewer (or use the View function)\nUse the glimpse function to take a peek\n\n\nglimpse(bike)\n\nRows: 5,716\nColumns: 54\n$ FID        <dbl> 18, 29, 33, 35, 49, 53, 56, 60, 63, 66, 72, 75, 82, 84, 85,…\n$ OBJECTID   <dbl> 19, 30, 34, 36, 50, 54, 57, 61, 64, 67, 73, 76, 83, 85, 86,…\n$ AmbulanceR <chr> \"No\", \"Yes\", \"No\", \"Yes\", \"No\", \"Yes\", \"Yes\", \"No\", \"Yes\", …\n$ BikeAge_Gr <chr> NA, \"50-59\", NA, \"16-19\", NA, \"50-59\", \"16-19\", \"40-49\", \"1…\n$ Bike_Age   <dbl> 6, 51, 10, 17, 6, 52, 18, 40, 6, 7, 45, 30, 17, 20, 14, 15,…\n$ Bike_Alc_D <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\",…\n$ Bike_Dir   <chr> \"Not Applicable\", \"With Traffic\", \"With Traffic\", NA, \"Faci…\n$ Bike_Injur <chr> \"C: Possible Injury\", \"C: Possible Injury\", \"Injury\", \"B: E…\n$ Bike_Pos   <chr> \"Driveway / Alley\", \"Travel Lane\", \"Travel Lane\", \"Travel L…\n$ Bike_Race  <chr> \"Black\", \"Black\", \"Black\", \"White\", \"Black\", \"White\", \"Blac…\n$ Bike_Sex   <chr> \"Female\", \"Male\", \"Male\", \"Male\", \"Male\", \"Male\", \"Female\",…\n$ City       <chr> \"Durham\", \"Greenville\", \"Farmville\", \"Charlotte\", \"Charlott…\n$ County     <chr> \"Durham\", \"Pitt\", \"Pitt\", \"Mecklenburg\", \"Mecklenburg\", \"Du…\n$ CrashAlcoh <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\",…\n$ CrashDay   <chr> \"01-01-06\", \"01-01-02\", \"01-01-07\", \"01-01-05\", NA, NA, NA,…\n$ Crash_Date <date> 2007-01-06, 2007-01-09, 2007-01-14, 2007-01-12, 2007-01-15…\n$ Crash_Grp  <chr> \"Bicyclist Failed to Yield - Midblock\", \"Crossing Paths - O…\n$ Crash_Hour <dbl> 13, 23, 16, 19, 12, 20, 19, 14, 16, 0, 17, 18, 14, 17, 19, …\n$ Crash_Loc  <chr> \"Non-Intersection\", \"Intersection-Related\", \"Intersection\",…\n$ Crash_Mont <chr> NA, NA, NA, NA, NA, \"01-04-01\", \"01-04-01\", NA, \"01-02-01\",…\n$ Crash_Time <dttm> 0001-01-01 13:17:58, 0001-01-01 23:08:58, 0001-01-01 16:44…\n$ Crash_Type <chr> \"Bicyclist Ride Out - Residential Driveway\", \"Crossing Path…\n$ Crash_Ty_1 <dbl> 353311, 211180, 111144, 119139, 112114, 311231, 119144, 132…\n$ Crash_Year <dbl> 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007,…\n$ Crsh_Sevri <chr> \"C: Possible Injury\", \"C: Possible Injury\", \"O: No Injury\",…\n$ Developmen <chr> \"Residential\", \"Commercial\", \"Residential\", \"Residential\", …\n$ DrvrAge_Gr <chr> \"60-69\", \"30-39\", \"50-59\", \"30-39\", NA, \"20-24\", \"40-49\", N…\n$ Drvr_Age   <dbl> 66, 34, 52, 33, NA, 20, 40, NA, 17, 51, NA, 64, 50, 66, 30,…\n$ Drvr_Alc_D <chr> \"No\", \"No\", \"No\", \"No\", \"Missing\", \"No\", \"No\", \"Missing\", \"…\n$ Drvr_EstSp <chr> \"11-15 mph\", \"0-5 mph\", \"21-25 mph\", \"46-50 mph\", \"16-20 mp…\n$ Drvr_Injur <chr> \"O: No Injury\", \"O: No Injury\", \"O: No Injury\", \"O: No Inju…\n$ Drvr_Race  <chr> \"Black\", \"Black\", \"White\", \"White\", \"/Missing\", \"White\", \"B…\n$ Drvr_Sex   <chr> \"Male\", \"Male\", \"Female\", \"Female\", NA, \"Female\", \"Male\", N…\n$ Drvr_VehTy <chr> \"Pickup\", \"Passenger Car\", \"Passenger Car\", \"Sport Utility\"…\n$ ExcsSpdInd <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\",…\n$ Hit_Run    <chr> \"No\", \"No\", \"No\", \"No\", \"Yes\", \"No\", \"No\", \"Yes\", \"No\", \"No…\n$ Light_Cond <chr> \"Daylight\", \"Dark - Lighted Roadway\", \"Daylight\", \"Dark - R…\n$ Locality   <chr> \"Mixed (30% To 70% Developed)\", \"Urban (>70% Developed)\", \"…\n$ Num_Lanes  <chr> \"2 lanes\", \"5 lanes\", \"2 lanes\", \"4 lanes\", \"2 lanes\", \"4 l…\n$ Num_Units  <dbl> 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,…\n$ Rd_Charact <chr> \"Straight - Level\", \"Straight - Level\", \"Straight - Level\",…\n$ Rd_Class   <chr> \"Local Street\", \"Local Street\", \"Local Street\", \"NC Route\",…\n$ Rd_Conditi <chr> \"Dry\", \"Dry\", \"Dry\", \"Dry\", \"Dry\", \"Dry\", \"Dry\", \"Dry\", \"Dr…\n$ Rd_Config  <chr> \"Two-Way, Not Divided\", \"Two-Way, Divided, Unprotected Medi…\n$ Rd_Defects <chr> \"None\", \"None\", \"None\", \"None\", \"None\", \"None\", \"None\", \"No…\n$ Rd_Feature <chr> \"No Special Feature\", \"Four-Way Intersection\", \"Four-Way In…\n$ Rd_Surface <chr> \"Smooth Asphalt\", \"Smooth Asphalt\", \"Smooth Asphalt\", \"Smoo…\n$ Region     <chr> \"Piedmont\", \"Coastal\", \"Coastal\", \"Piedmont\", \"Piedmont\", \"…\n$ Rural_Urba <chr> \"Urban\", \"Urban\", \"Rural\", \"Urban\", \"Urban\", \"Urban\", \"Urba…\n$ Speed_Limi <chr> \"20 - 25  MPH\", \"40 - 45  MPH\", \"30 - 35  MPH\", \"40 - 45  M…\n$ Traff_Cntr <chr> \"No Control Present\", \"Stop And Go Signal\", \"Stop Sign\", \"S…\n$ Weather    <chr> \"Clear\", \"Clear\", \"Clear\", \"Cloudy\", \"Clear\", \"Clear\", \"Cle…\n$ Workzone_I <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\",…\n$ Location   <chr> \"36.002743, -78.8785\", \"35.612984, -77.39265\", \"35.595676, …"
  },
  {
    "objectID": "content/lectures/02-dplyr.html#a-grammar-of-data-manipulation",
    "href": "content/lectures/02-dplyr.html#a-grammar-of-data-manipulation",
    "title": "02-dplyr",
    "section": "A Grammar of Data Manipulation",
    "text": "A Grammar of Data Manipulation\ndplyr is based on the concepts of functions as verbs that manipulate data frames.\nSingle data frame functions / verbs:\n\nfilter: pick rows matching criteria\nslice: pick rows using index(es)\nselect: pick columns by name\npull: grab a column as a vector\nrename: rename specific columns\narrange: reorder rows\nmutate: add new variables\ntransmute: create new data frame with variables\ndistinct: filter for unique rows\nsample_n / sample_frac: randomly sample rows\nsummarize: reduce variables to values\n… (many more)"
  },
  {
    "objectID": "content/lectures/02-dplyr.html#dplyr-rules-for-functions",
    "href": "content/lectures/02-dplyr.html#dplyr-rules-for-functions",
    "title": "02-dplyr",
    "section": "dplyr rules for functions",
    "text": "dplyr rules for functions\n\nFirst argument is always a data frame\nSubsequent arguments say what to do with that data frame\nAlways return a data frame\nDo not modify in place\nPerformance via lazy evaluation"
  },
  {
    "objectID": "content/lectures/02-dplyr.html#filter-rows-with-filter",
    "href": "content/lectures/02-dplyr.html#filter-rows-with-filter",
    "title": "02-dplyr",
    "section": "Filter rows with filter",
    "text": "Filter rows with filter\n\nSelect a subset of rows in a data frame.\nEasily filter for many conditions at once."
  },
  {
    "objectID": "content/lectures/02-dplyr.html#filter",
    "href": "content/lectures/02-dplyr.html#filter",
    "title": "02-dplyr",
    "section": "filter",
    "text": "filter\nfor crashes in Durham County\n\nbike |>\n  filter(County == \"Durham\")\n\n# A tibble: 253 × 54\n     FID OBJEC…¹ Ambul…² BikeA…³ Bike_…⁴ Bike_…⁵ Bike_…⁶ Bike_…⁷ Bike_…⁸ Bike_…⁹\n   <dbl>   <dbl> <chr>   <chr>     <dbl> <chr>   <chr>   <chr>   <chr>   <chr>  \n 1    18      19 No      <NA>          6 No      Not Ap… C: Pos… Drivew… Black  \n 2    53      54 Yes     50-59        52 No      With T… A: Dis… Travel… White  \n 3    56      57 Yes     16-19        18 No      <NA>    C: Pos… Travel… Black  \n 4   209     210 No      16-19        16 No      Facing… C: Pos… <NA>    Black  \n 5   228     229 Yes     40-49        40 No      With T… B: Evi… Bike L… Black  \n 6   620     621 Yes     50-59        55 No      With T… B: Evi… Travel… White  \n 7   667     668 Yes     60-69        61 No      Not Ap… B: Evi… Sidewa… Black  \n 8   458     459 Yes     60-69        62 No      With T… B: Evi… Travel… White  \n 9   576     577 No      40-49        49 No      With T… C: Pos… Travel… Black  \n10   618     619 No      20-24        23 No      With T… C: Pos… Travel… Asian  \n# … with 243 more rows, 44 more variables: Bike_Sex <chr>, City <chr>,\n#   County <chr>, CrashAlcoh <chr>, CrashDay <chr>, Crash_Date <date>,\n#   Crash_Grp <chr>, Crash_Hour <dbl>, Crash_Loc <chr>, Crash_Mont <chr>,\n#   Crash_Time <dttm>, Crash_Type <chr>, Crash_Ty_1 <dbl>, Crash_Year <dbl>,\n#   Crsh_Sevri <chr>, Developmen <chr>, DrvrAge_Gr <chr>, Drvr_Age <dbl>,\n#   Drvr_Alc_D <chr>, Drvr_EstSp <chr>, Drvr_Injur <chr>, Drvr_Race <chr>,\n#   Drvr_Sex <chr>, Drvr_VehTy <chr>, ExcsSpdInd <chr>, Hit_Run <chr>, …"
  },
  {
    "objectID": "content/lectures/02-dplyr.html#filter-1",
    "href": "content/lectures/02-dplyr.html#filter-1",
    "title": "02-dplyr",
    "section": "filter",
    "text": "filter\nfor crashes in Durham County where biker was < 10 yrs old\n\nbike |>\n  filter(County == \"Durham\", Bike_Age < 10)\n\n# A tibble: 20 × 54\n     FID OBJEC…¹ Ambul…² BikeA…³ Bike_…⁴ Bike_…⁵ Bike_…⁶ Bike_…⁷ Bike_…⁸ Bike_…⁹\n   <dbl>   <dbl> <chr>   <chr>     <dbl> <chr>   <chr>   <chr>   <chr>   <chr>  \n 1    18      19 No      <NA>          6 No      Not Ap… C: Pos… Drivew… Black  \n 2    47      48 No      10-Jun        9 No      Not Ap… O: No … Non-Ro… Black  \n 3   124     125 Yes     10-Jun        8 No      With T… C: Pos… Travel… Black  \n 4   531     532 Yes     10-Jun        7 No      With T… C: Pos… Travel… Black  \n 5   704     705 Yes     10-Jun        9 No      Not Ap… C: Pos… Non-Ro… Black  \n 6    42      43 No      10-Jun        8 No      With T… O: No … Travel… Black  \n 7   392     393 Yes     0-5           2 No      Not Ap… B: Evi… Drivew… Black  \n 8   941     942 No      10-Jun        9 No      With T… C: Pos… Travel… Black  \n 9   436     437 Yes     10-Jun        6 No      Not Ap… O: No … Drivew… Black  \n10   160     161 Yes     10-Jun        7 No      With T… C: Pos… Travel… Black  \n11   273     274 Yes     10-Jun        7 No      Facing… C: Pos… Travel… Black  \n12    78      79 Yes     10-Jun        7 No      With T… C: Pos… Travel… Black  \n13   422     423 No      10-Jun        9 No      Not Ap… O: No … Drivew… Black  \n14   570     571 No      <NA>          0 Missing Not Ap… Injury  Non-Ro… /Missi…\n15   683     684 Yes     10-Jun        8 No      Not Ap… C: Pos… Non-Ro… Black  \n16    62      63 Yes     10-Jun        7 No      With T… C: Pos… Travel… Black  \n17   248     249 No      0-5           4 No      Not Ap… O: No … Drivew… Hispan…\n18   306     307 Yes     10-Jun        8 No      With T… C: Pos… <NA>    Black  \n19   231     232 Yes     10-Jun        8 No      With T… C: Pos… Travel… Black  \n20   361     362 Yes     10-Jun        9 No      With T… B: Evi… Travel… Hispan…\n# … with 44 more variables: Bike_Sex <chr>, City <chr>, County <chr>,\n#   CrashAlcoh <chr>, CrashDay <chr>, Crash_Date <date>, Crash_Grp <chr>,\n#   Crash_Hour <dbl>, Crash_Loc <chr>, Crash_Mont <chr>, Crash_Time <dttm>,\n#   Crash_Type <chr>, Crash_Ty_1 <dbl>, Crash_Year <dbl>, Crsh_Sevri <chr>,\n#   Developmen <chr>, DrvrAge_Gr <chr>, Drvr_Age <dbl>, Drvr_Alc_D <chr>,\n#   Drvr_EstSp <chr>, Drvr_Injur <chr>, Drvr_Race <chr>, Drvr_Sex <chr>,\n#   Drvr_VehTy <chr>, ExcsSpdInd <chr>, Hit_Run <chr>, Light_Cond <chr>, …"
  },
  {
    "objectID": "content/lectures/02-dplyr.html#aside-real-data-is-messy",
    "href": "content/lectures/02-dplyr.html#aside-real-data-is-messy",
    "title": "02-dplyr",
    "section": "Aside: real data is messy!",
    "text": "Aside: real data is messy!\n   What in the world does a BikeAge_gr of 10-Jun or 15-Nov mean?\n\nbike |>\n  group_by(BikeAge_Gr) |>\n  summarize(crash_count = n())\n\n# A tibble: 13 × 2\n   BikeAge_Gr crash_count\n   <chr>            <int>\n 1 0-5                 60\n 2 10-Jun             421\n 3 15-Nov             747\n 4 16-19              605\n 5 20-24              680\n 6 25-29              430\n 7 30-39              658\n 8 40-49              920\n 9 50-59              739\n10 60-69              274\n11 70                  12\n12 70+                 58\n13 <NA>               112"
  },
  {
    "objectID": "content/lectures/02-dplyr.html#careful-data-scientists-clean-up-their-data-first",
    "href": "content/lectures/02-dplyr.html#careful-data-scientists-clean-up-their-data-first",
    "title": "02-dplyr",
    "section": "Careful data scientists clean up their data first!",
    "text": "Careful data scientists clean up their data first!\n\nWe’re going to need to do some text parsing to clean up these data\n\n10-Jun should be 6-10\n15-Nov should be 11-15"
  },
  {
    "objectID": "content/lectures/02-dplyr.html#correct-and-overwrite-mutate",
    "href": "content/lectures/02-dplyr.html#correct-and-overwrite-mutate",
    "title": "02-dplyr",
    "section": "Correct and overwrite mutate",
    "text": "Correct and overwrite mutate\n\nRemember we want to do the following in the BikeAge_Gr variable\n\n10-Jun should be 6-10\n15-Nov should be 11-15\n\n\n\nbike <- bike |>\n  mutate(\n    BikeAge_Gr = case_when(\n      BikeAge_Gr == \"10-Jun\" ~ \"6-10\",\n      BikeAge_Gr == \"15-Nov\" ~ \"11-15\",\n      TRUE                   ~ BikeAge_Gr     # everything else\n    )\n  )\n\n\nNote that we’re overwriting existing data and columns, so be careful!\n\nBut remember, it’s easy to revert if you make a mistake since we didn’t touch the raw data, we can always reload it and start over"
  },
  {
    "objectID": "content/lectures/02-dplyr.html#check-before-you-move-on",
    "href": "content/lectures/02-dplyr.html#check-before-you-move-on",
    "title": "02-dplyr",
    "section": "Check before you move on",
    "text": "Check before you move on\nAlways check your changes and confirm code did what you wanted it to do\n\nbike |>\n  group_by(BikeAge_Gr) |>\n  summarize(count = n())\n\n# A tibble: 13 × 2\n   BikeAge_Gr count\n   <chr>      <int>\n 1 0-5           60\n 2 11-15        747\n 3 16-19        605\n 4 20-24        680\n 5 25-29        430\n 6 30-39        658\n 7 40-49        920\n 8 50-59        739\n 9 6-10         421\n10 60-69        274\n11 70            12\n12 70+           58\n13 <NA>         112"
  },
  {
    "objectID": "content/lectures/02-dplyr.html#mutate-to-add-new-variables",
    "href": "content/lectures/02-dplyr.html#mutate-to-add-new-variables",
    "title": "02-dplyr",
    "section": "mutate to add new variables",
    "text": "mutate to add new variables\n   How is the new alcohol variable determined?\n\nbike |>\n  mutate(alcohol = case_when(\n    Bike_Alc_D == \"No\" & Drvr_Alc_D == \"No\"      ~ \"No\",\n    Bike_Alc_D == \"Yes\" | Drvr_Alc_D == \"Yes\"    ~ \"Yes\",\n    Bike_Alc_D == \"Missing\" & Drvr_Alc_D == \"No\" ~ \"Missing\",\n    Bike_Alc_D == \"No\" & Drvr_Alc_D == \"Missing\" ~ \"Missing\"\n  ))"
  },
  {
    "objectID": "content/lectures/02-dplyr.html#save-when-you-mutate",
    "href": "content/lectures/02-dplyr.html#save-when-you-mutate",
    "title": "02-dplyr",
    "section": "“Save” when you mutate",
    "text": "“Save” when you mutate\nMost often when you define a new variable with mutate you’ll also want to save the resulting data frame, often by writing over the original data frame.\n\nbike <- bike |>\n  mutate(alcohol = case_when(\n    Bike_Alc_D == \"No\" & Drvr_Alc_D == \"No\"      ~ \"No\",\n    Bike_Alc_D == \"Yes\" | Drvr_Alc_D == \"Yes\"    ~ \"Yes\",\n    Bike_Alc_D == \"Missing\" & Drvr_Alc_D == \"No\" ~ \"Missing\",\n    Bike_Alc_D == \"No\" & Drvr_Alc_D == \"Missing\" ~ \"Missing\"\n  ))"
  },
  {
    "objectID": "content/lectures/02-dplyr.html#transmute-to-create-a-new-dataset",
    "href": "content/lectures/02-dplyr.html#transmute-to-create-a-new-dataset",
    "title": "02-dplyr",
    "section": "transmute to create a new dataset",
    "text": "transmute to create a new dataset\nYou’ll use this much less often than mutate but when you need it, you need it.\n\nbike |> \n  transmute(ID = paste(FID, OBJECTID, sep = \"-\"))\n\n# A tibble: 5,716 × 1\n   ID   \n   <chr>\n 1 18-19\n 2 29-30\n 3 33-34\n 4 35-36\n 5 49-50\n 6 53-54\n 7 56-57\n 8 60-61\n 9 63-64\n10 66-67\n# … with 5,706 more rows"
  },
  {
    "objectID": "content/lectures/02-dplyr.html#mutate-vs.-transmute",
    "href": "content/lectures/02-dplyr.html#mutate-vs.-transmute",
    "title": "02-dplyr",
    "section": "mutate vs. transmute",
    "text": "mutate vs. transmute\n\nmutate adds new and keeps original\ntransmute adds new; drops existing"
  },
  {
    "objectID": "content/lectures/02-dplyr.html#your-turn",
    "href": "content/lectures/02-dplyr.html#your-turn",
    "title": "02-dplyr",
    "section": "Your Turn",
    "text": "Your Turn\nHow many accidents in our dataset required an ambulance ride (AmbulanceR) and had the Crash_Type “Bicyclist Lost Control - Mechanical Problems”?\n\n\nPut a green sticky on the front of your computer when you’re done. Put a pink if you want help/have a question."
  },
  {
    "objectID": "content/lectures/02-dplyr.html#slice-for-certain-row-numbers",
    "href": "content/lectures/02-dplyr.html#slice-for-certain-row-numbers",
    "title": "02-dplyr",
    "section": "slice for certain row numbers",
    "text": "slice for certain row numbers\nFirst five\n\nbike |>\n  slice(1:5)\n\n# A tibble: 5 × 54\n    FID OBJECTID Ambul…¹ BikeA…² Bike_…³ Bike_…⁴ Bike_…⁵ Bike_…⁶ Bike_…⁷ Bike_…⁸\n  <dbl>    <dbl> <chr>   <chr>     <dbl> <chr>   <chr>   <chr>   <chr>   <chr>  \n1    18       19 No      <NA>          6 No      Not Ap… C: Pos… Drivew… Black  \n2    29       30 Yes     50-59        51 No      With T… C: Pos… Travel… Black  \n3    33       34 No      <NA>         10 No      With T… Injury  Travel… Black  \n4    35       36 Yes     16-19        17 No      <NA>    B: Evi… Travel… White  \n5    49       50 No      <NA>          6 No      Facing… O: No … Travel… Black  \n# … with 44 more variables: Bike_Sex <chr>, City <chr>, County <chr>,\n#   CrashAlcoh <chr>, CrashDay <chr>, Crash_Date <date>, Crash_Grp <chr>,\n#   Crash_Hour <dbl>, Crash_Loc <chr>, Crash_Mont <chr>, Crash_Time <dttm>,\n#   Crash_Type <chr>, Crash_Ty_1 <dbl>, Crash_Year <dbl>, Crsh_Sevri <chr>,\n#   Developmen <chr>, DrvrAge_Gr <chr>, Drvr_Age <dbl>, Drvr_Alc_D <chr>,\n#   Drvr_EstSp <chr>, Drvr_Injur <chr>, Drvr_Race <chr>, Drvr_Sex <chr>,\n#   Drvr_VehTy <chr>, ExcsSpdInd <chr>, Hit_Run <chr>, Light_Cond <chr>, …"
  },
  {
    "objectID": "content/lectures/02-dplyr.html#slice-for-certain-row-numbers-1",
    "href": "content/lectures/02-dplyr.html#slice-for-certain-row-numbers-1",
    "title": "02-dplyr",
    "section": "slice for certain row numbers",
    "text": "slice for certain row numbers\nLast five\n\nlast_row <- nrow(bike)\nbike |>\n  slice((last_row - 4):last_row)\n\n# A tibble: 5 × 54\n    FID OBJECTID Ambul…¹ BikeA…² Bike_…³ Bike_…⁴ Bike_…⁵ Bike_…⁶ Bike_…⁷ Bike_…⁸\n  <dbl>    <dbl> <chr>   <chr>     <dbl> <chr>   <chr>   <chr>   <chr>   <chr>  \n1   460      461 Yes     6-10          7 No      Not Ap… C: Pos… Drivew… Black  \n2   474      475 Yes     50-59        50 No      With T… B: Evi… Travel… White  \n3   479      480 Yes     16-19        16 No      Not Ap… C: Pos… Sidewa… White  \n4   487      488 No      40-49        47 Yes     With T… C: Pos… Travel… White  \n5   488      489 Yes     30-39        35 No      Facing… C: Pos… Travel… Black  \n# … with 44 more variables: Bike_Sex <chr>, City <chr>, County <chr>,\n#   CrashAlcoh <chr>, CrashDay <chr>, Crash_Date <date>, Crash_Grp <chr>,\n#   Crash_Hour <dbl>, Crash_Loc <chr>, Crash_Mont <chr>, Crash_Time <dttm>,\n#   Crash_Type <chr>, Crash_Ty_1 <dbl>, Crash_Year <dbl>, Crsh_Sevri <chr>,\n#   Developmen <chr>, DrvrAge_Gr <chr>, Drvr_Age <dbl>, Drvr_Alc_D <chr>,\n#   Drvr_EstSp <chr>, Drvr_Injur <chr>, Drvr_Race <chr>, Drvr_Sex <chr>,\n#   Drvr_VehTy <chr>, ExcsSpdInd <chr>, Hit_Run <chr>, Light_Cond <chr>, …"
  },
  {
    "objectID": "content/lectures/02-dplyr.html#select-to-keep-only-the-variables-you-mention",
    "href": "content/lectures/02-dplyr.html#select-to-keep-only-the-variables-you-mention",
    "title": "02-dplyr",
    "section": "select to keep only the variables you mention",
    "text": "select to keep only the variables you mention\n\nbike |>\n  select(Crash_Loc, Hit_Run) |>\n  table()\n\n                      Hit_Run\nCrash_Loc                No  Yes\n  Intersection         2223  275\n  Intersection-Related  252   42\n  Location                3    7\n  Non-Intersection     2213  462\n  Non-Roadway           205   30"
  },
  {
    "objectID": "content/lectures/02-dplyr.html#or-select-to-exclude-variables",
    "href": "content/lectures/02-dplyr.html#or-select-to-exclude-variables",
    "title": "02-dplyr",
    "section": "or select to exclude variables",
    "text": "or select to exclude variables\n\nbike |>\n  select(-OBJECTID)\n\n# A tibble: 5,716 × 53\n     FID Ambul…¹ BikeA…² Bike_…³ Bike_…⁴ Bike_…⁵ Bike_…⁶ Bike_…⁷ Bike_…⁸ Bike_…⁹\n   <dbl> <chr>   <chr>     <dbl> <chr>   <chr>   <chr>   <chr>   <chr>   <chr>  \n 1    18 No      <NA>          6 No      Not Ap… C: Pos… Drivew… Black   Female \n 2    29 Yes     50-59        51 No      With T… C: Pos… Travel… Black   Male   \n 3    33 No      <NA>         10 No      With T… Injury  Travel… Black   Male   \n 4    35 Yes     16-19        17 No      <NA>    B: Evi… Travel… White   Male   \n 5    49 No      <NA>          6 No      Facing… O: No … Travel… Black   Male   \n 6    53 Yes     50-59        52 No      With T… A: Dis… Travel… White   Male   \n 7    56 Yes     16-19        18 No      <NA>    C: Pos… Travel… Black   Female \n 8    60 No      40-49        40 No      Facing… B: Evi… Sidewa… Hispan… Male   \n 9    63 Yes     6-10          6 No      Facing… B: Evi… Travel… White   Male   \n10    66 Yes     6-10          7 No      <NA>    B: Evi… Non-Ro… Black   Female \n# … with 5,706 more rows, 43 more variables: City <chr>, County <chr>,\n#   CrashAlcoh <chr>, CrashDay <chr>, Crash_Date <date>, Crash_Grp <chr>,\n#   Crash_Hour <dbl>, Crash_Loc <chr>, Crash_Mont <chr>, Crash_Time <dttm>,\n#   Crash_Type <chr>, Crash_Ty_1 <dbl>, Crash_Year <dbl>, Crsh_Sevri <chr>,\n#   Developmen <chr>, DrvrAge_Gr <chr>, Drvr_Age <dbl>, Drvr_Alc_D <chr>,\n#   Drvr_EstSp <chr>, Drvr_Injur <chr>, Drvr_Race <chr>, Drvr_Sex <chr>,\n#   Drvr_VehTy <chr>, ExcsSpdInd <chr>, Hit_Run <chr>, Light_Cond <chr>, …"
  },
  {
    "objectID": "content/lectures/02-dplyr.html#or-select-a-range-of-variables",
    "href": "content/lectures/02-dplyr.html#or-select-a-range-of-variables",
    "title": "02-dplyr",
    "section": "or select a range of variables",
    "text": "or select a range of variables\n\nbike |>\n  select(OBJECTID:Bike_Injur)\n\n# A tibble: 5,716 × 7\n   OBJECTID AmbulanceR BikeAge_Gr Bike_Age Bike_Alc_D Bike_Dir       Bike_Injur \n      <dbl> <chr>      <chr>         <dbl> <chr>      <chr>          <chr>      \n 1       19 No         <NA>              6 No         Not Applicable C: Possibl…\n 2       30 Yes        50-59            51 No         With Traffic   C: Possibl…\n 3       34 No         <NA>             10 No         With Traffic   Injury     \n 4       36 Yes        16-19            17 No         <NA>           B: Evident…\n 5       50 No         <NA>              6 No         Facing Traffic O: No Inju…\n 6       54 Yes        50-59            52 No         With Traffic   A: Disabli…\n 7       57 Yes        16-19            18 No         <NA>           C: Possibl…\n 8       61 No         40-49            40 No         Facing Traffic B: Evident…\n 9       64 Yes        6-10              6 No         Facing Traffic B: Evident…\n10       67 Yes        6-10              7 No         <NA>           B: Evident…\n# … with 5,706 more rows"
  },
  {
    "objectID": "content/lectures/02-dplyr.html#pull-to-extract-a-column-as-a-vector",
    "href": "content/lectures/02-dplyr.html#pull-to-extract-a-column-as-a-vector",
    "title": "02-dplyr",
    "section": "pull to extract a column as a vector",
    "text": "pull to extract a column as a vector\n\nbike |>\n  slice(1:6) |>\n  pull(Location)\n\n[1] \"36.002743, -78.8785\"  \"35.612984, -77.39265\" \"35.595676, -77.59074\"\n[4] \"35.076767, -80.7728\"  \"35.19999, -80.75713\"  \"35.966644, -78.96749\"\n\n\n\nbike |>\n  slice(1:6) |>\n  select(Location)\n\n# A tibble: 6 × 1\n  Location            \n  <chr>               \n1 36.002743, -78.8785 \n2 35.612984, -77.39265\n3 35.595676, -77.59074\n4 35.076767, -80.7728 \n5 35.19999, -80.75713 \n6 35.966644, -78.96749"
  },
  {
    "objectID": "content/lectures/02-dplyr.html#the-two-pulls-in-your-lives",
    "href": "content/lectures/02-dplyr.html#the-two-pulls-in-your-lives",
    "title": "02-dplyr",
    "section": "The two pulls in your lives",
    "text": "The two pulls in your lives\n\n\n\n\n\n\n\n\nDon’t get pull happy when wrangling data! Only extract out variables if you truly need to, otherwise keep in data frame.\nBut always ⬇️ Pull before starting your work when collaborating on GitHub."
  },
  {
    "objectID": "content/lectures/02-dplyr.html#rename-specific-columns",
    "href": "content/lectures/02-dplyr.html#rename-specific-columns",
    "title": "02-dplyr",
    "section": "rename specific columns",
    "text": "rename specific columns\nUseful for correcting typos, and renaming to make variable names shorter and/or more informative\n\nOriginal names:\n\n\nnames(bike)\n\n [1] \"FID\"        \"OBJECTID\"   \"AmbulanceR\" \"BikeAge_Gr\" \"Bike_Age\"  \n [6] \"Bike_Alc_D\" \"Bike_Dir\"   \"Bike_Injur\" \"Bike_Pos\"   \"Bike_Race\" \n[11] \"Bike_Sex\"   \"City\"       \"County\"     \"CrashAlcoh\" \"CrashDay\"  \n[16] \"Crash_Date\" \"Crash_Grp\"  \"Crash_Hour\" \"Crash_Loc\"  \"Crash_Mont\"\n[21] \"Crash_Time\" \"Crash_Type\" \"Crash_Ty_1\" \"Crash_Year\" \"Crsh_Sevri\"\n[26] \"Developmen\" \"DrvrAge_Gr\" \"Drvr_Age\"   \"Drvr_Alc_D\" \"Drvr_EstSp\"\n[31] \"Drvr_Injur\" \"Drvr_Race\"  \"Drvr_Sex\"   \"Drvr_VehTy\" \"ExcsSpdInd\"\n[36] \"Hit_Run\"    \"Light_Cond\" \"Locality\"   \"Num_Lanes\"  \"Num_Units\" \n[41] \"Rd_Charact\" \"Rd_Class\"   \"Rd_Conditi\" \"Rd_Config\"  \"Rd_Defects\"\n[46] \"Rd_Feature\" \"Rd_Surface\" \"Region\"     \"Rural_Urba\" \"Speed_Limi\"\n[51] \"Traff_Cntr\" \"Weather\"    \"Workzone_I\" \"Location\""
  },
  {
    "objectID": "content/lectures/02-dplyr.html#rename-specific-columns-1",
    "href": "content/lectures/02-dplyr.html#rename-specific-columns-1",
    "title": "02-dplyr",
    "section": "rename specific columns",
    "text": "rename specific columns\n\nRename Speed_Limi to Speed_Limit:\n\n\nbike <- bike |>\n  rename(Speed_Limit = Speed_Limi)"
  },
  {
    "objectID": "content/lectures/02-dplyr.html#check-before-you-move-on-1",
    "href": "content/lectures/02-dplyr.html#check-before-you-move-on-1",
    "title": "02-dplyr",
    "section": "Check before you move on",
    "text": "Check before you move on\nAlways check your changes and confirm code did what you wanted it to do\n\nnames(bike)\n\n [1] \"FID\"         \"OBJECTID\"    \"AmbulanceR\"  \"BikeAge_Gr\"  \"Bike_Age\"   \n [6] \"Bike_Alc_D\"  \"Bike_Dir\"    \"Bike_Injur\"  \"Bike_Pos\"    \"Bike_Race\"  \n[11] \"Bike_Sex\"    \"City\"        \"County\"      \"CrashAlcoh\"  \"CrashDay\"   \n[16] \"Crash_Date\"  \"Crash_Grp\"   \"Crash_Hour\"  \"Crash_Loc\"   \"Crash_Mont\" \n[21] \"Crash_Time\"  \"Crash_Type\"  \"Crash_Ty_1\"  \"Crash_Year\"  \"Crsh_Sevri\" \n[26] \"Developmen\"  \"DrvrAge_Gr\"  \"Drvr_Age\"    \"Drvr_Alc_D\"  \"Drvr_EstSp\" \n[31] \"Drvr_Injur\"  \"Drvr_Race\"   \"Drvr_Sex\"    \"Drvr_VehTy\"  \"ExcsSpdInd\" \n[36] \"Hit_Run\"     \"Light_Cond\"  \"Locality\"    \"Num_Lanes\"   \"Num_Units\"  \n[41] \"Rd_Charact\"  \"Rd_Class\"    \"Rd_Conditi\"  \"Rd_Config\"   \"Rd_Defects\" \n[46] \"Rd_Feature\"  \"Rd_Surface\"  \"Region\"      \"Rural_Urba\"  \"Speed_Limit\"\n[51] \"Traff_Cntr\"  \"Weather\"     \"Workzone_I\"  \"Location\""
  },
  {
    "objectID": "content/lectures/02-dplyr.html#your-turn-1",
    "href": "content/lectures/02-dplyr.html#your-turn-1",
    "title": "02-dplyr",
    "section": "Your Turn",
    "text": "Your Turn\nYour boss in Cumberland County gets overwhelmed by data easily, but he wants some data from you. He wants all bike accidents from his County, but he only wants to know the road’s speed limit, the age of the biker, and to know if alcohol was involved. If you have time, mine as well make the column names very clear to your boss while you’re at it…\n\n\nPut a green sticky on the front of your computer when you’re done. Put a pink if you want help/have a question."
  },
  {
    "objectID": "content/lectures/02-dplyr.html#summarize-to-reduce-variables-to-values",
    "href": "content/lectures/02-dplyr.html#summarize-to-reduce-variables-to-values",
    "title": "02-dplyr",
    "section": "summarize to reduce variables to values",
    "text": "summarize to reduce variables to values\nThe values are summarized in a data frame\n\nbike |>\n  group_by(BikeAge_Gr) |>\n  summarize(crash_count = n())\n\n# A tibble: 13 × 2\n   BikeAge_Gr crash_count\n   <chr>            <int>\n 1 0-5                 60\n 2 11-15              747\n 3 16-19              605\n 4 20-24              680\n 5 25-29              430\n 6 30-39              658\n 7 40-49              920\n 8 50-59              739\n 9 6-10               421\n10 60-69              274\n11 70                  12\n12 70+                 58\n13 <NA>               112"
  },
  {
    "objectID": "content/lectures/02-dplyr.html#and-arrange-to-order-rows",
    "href": "content/lectures/02-dplyr.html#and-arrange-to-order-rows",
    "title": "02-dplyr",
    "section": "and arrange to order rows",
    "text": "and arrange to order rows\n\nbike |>\n  group_by(BikeAge_Gr) |>\n  summarize(crash_count = n()) |>\n  arrange(desc(crash_count))\n\n# A tibble: 13 × 2\n   BikeAge_Gr crash_count\n   <chr>            <int>\n 1 40-49              920\n 2 11-15              747\n 3 50-59              739\n 4 20-24              680\n 5 30-39              658\n 6 16-19              605\n 7 25-29              430\n 8 6-10               421\n 9 60-69              274\n10 <NA>               112\n11 0-5                 60\n12 70+                 58\n13 70                  12"
  },
  {
    "objectID": "content/lectures/02-dplyr.html#count-to-group-by-then-count",
    "href": "content/lectures/02-dplyr.html#count-to-group-by-then-count",
    "title": "02-dplyr",
    "section": "count to group by then count",
    "text": "count to group by then count\n\nbike |>\n  count(BikeAge_Gr)\n\n# A tibble: 13 × 2\n   BikeAge_Gr     n\n   <chr>      <int>\n 1 0-5           60\n 2 11-15        747\n 3 16-19        605\n 4 20-24        680\n 5 25-29        430\n 6 30-39        658\n 7 40-49        920\n 8 50-59        739\n 9 6-10         421\n10 60-69        274\n11 70            12\n12 70+           58\n13 <NA>         112\n\n\n   If you wanted to arrange these in ascending order what would you add to the pipe?"
  },
  {
    "objectID": "content/lectures/02-dplyr.html#select-rows-with-sample_n-or-sample_frac",
    "href": "content/lectures/02-dplyr.html#select-rows-with-sample_n-or-sample_frac",
    "title": "02-dplyr",
    "section": "Select rows with sample_n or sample_frac",
    "text": "Select rows with sample_n or sample_frac\n\nsample_n: randomly sample 5 observations\n\n\nbike_n5 <- bike |>\n  sample_n(5, replace = FALSE)\n\ndim(bike_n5)\n\n[1]  5 54\n\n\n\nsample_frac: randomly sample 20% of observations\n\n\nbike_perc20 <- bike |>\n  sample_frac(0.2, replace = FALSE)\n\ndim(bike_perc20)\n\n[1] 1143   54"
  },
  {
    "objectID": "content/lectures/02-dplyr.html#distinct-to-filter-for-unique-rows",
    "href": "content/lectures/02-dplyr.html#distinct-to-filter-for-unique-rows",
    "title": "02-dplyr",
    "section": "distinct to filter for unique rows",
    "text": "distinct to filter for unique rows\n\nbike |> \n  select(County, City) |> \n  distinct() |> \n  arrange(County, City)\n\n# A tibble: 360 × 2\n   County    City              \n   <chr>     <chr>             \n 1 Alamance  Alamance          \n 2 Alamance  Burlington        \n 3 Alamance  Elon College      \n 4 Alamance  Gibsonville       \n 5 Alamance  Graham            \n 6 Alamance  Green Level       \n 7 Alamance  Mebane            \n 8 Alamance  None - Rural Crash\n 9 Alexander None - Rural Crash\n10 Alleghany None - Rural Crash\n# … with 350 more rows"
  },
  {
    "objectID": "content/lectures/02-dplyr.html#distinct-has-a-.keep_all-parameter",
    "href": "content/lectures/02-dplyr.html#distinct-has-a-.keep_all-parameter",
    "title": "02-dplyr",
    "section": "distinct has a .keep_all parameter",
    "text": "distinct has a .keep_all parameter\n\nbike |> \n  distinct(County, City, .keep_all = TRUE) |> \n  arrange(County, City)\n\n# A tibble: 360 × 54\n     FID OBJEC…¹ Ambul…² BikeA…³ Bike_…⁴ Bike_…⁵ Bike_…⁶ Bike_…⁷ Bike_…⁸ Bike_…⁹\n   <dbl>   <dbl> <chr>   <chr>     <dbl> <chr>   <chr>   <chr>   <chr>   <chr>  \n 1   524     525 Yes     11-15        12 No      <NA>    B: Evi… <NA>    Black  \n 2    84      85 Yes     20-24        20 No      With T… B: Evi… Travel… White  \n 3   571     572 Yes     16-19        16 No      Not Ap… B: Evi… Non-Ro… White  \n 4   509     510 Yes     40-49        43 Yes     With T… K: Kil… Travel… Black  \n 5   855     856 Yes     30-39        30 No      With T… A: Dis… Travel… Black  \n 6     5       6 Yes     40-49        44 Yes     With T… C: Pos… Travel… Black  \n 7   163     164 Yes     30-39        35 No      Not Ap… C: Pos… <NA>    White  \n 8    96      97 Yes     30-39        36 No      With T… C: Pos… Travel… White  \n 9    46      47 Yes     50-59        53 No      With T… B: Evi… Travel… White  \n10   485     486 Yes     60-69        62 No      With T… C: Pos… Travel… White  \n# … with 350 more rows, 44 more variables: Bike_Sex <chr>, City <chr>,\n#   County <chr>, CrashAlcoh <chr>, CrashDay <chr>, Crash_Date <date>,\n#   Crash_Grp <chr>, Crash_Hour <dbl>, Crash_Loc <chr>, Crash_Mont <chr>,\n#   Crash_Time <dttm>, Crash_Type <chr>, Crash_Ty_1 <dbl>, Crash_Year <dbl>,\n#   Crsh_Sevri <chr>, Developmen <chr>, DrvrAge_Gr <chr>, Drvr_Age <dbl>,\n#   Drvr_Alc_D <chr>, Drvr_EstSp <chr>, Drvr_Injur <chr>, Drvr_Race <chr>,\n#   Drvr_Sex <chr>, Drvr_VehTy <chr>, ExcsSpdInd <chr>, Hit_Run <chr>, …"
  },
  {
    "objectID": "content/lectures/02-dplyr.html#factors-1",
    "href": "content/lectures/02-dplyr.html#factors-1",
    "title": "02-dplyr",
    "section": "Factors",
    "text": "Factors\nFactor objects are how R stores data for categorical variables (fixed numbers of discrete values).\n\n(x = factor(c(\"BS\", \"MS\", \"PhD\", \"MS\")))\n\n[1] BS  MS  PhD MS \nLevels: BS MS PhD\n\n\n\nglimpse(x)\n\n Factor w/ 3 levels \"BS\",\"MS\",\"PhD\": 1 2 3 2\n\n\n\ntypeof(x)\n\n[1] \"integer\""
  },
  {
    "objectID": "content/lectures/02-dplyr.html#returning-to-cat-lovers",
    "href": "content/lectures/02-dplyr.html#returning-to-cat-lovers",
    "title": "02-dplyr",
    "section": "Returning to: Cat lovers",
    "text": "Returning to: Cat lovers\nReading in the cat-lovers data…\n\ncat_lovers <- read_csv(\"https://raw.githubusercontent.com/COGS137/datasets/main/cat-lovers.csv\")"
  },
  {
    "objectID": "content/lectures/02-dplyr.html#read-data-in-as-character-strings",
    "href": "content/lectures/02-dplyr.html#read-data-in-as-character-strings",
    "title": "02-dplyr",
    "section": "Read data in as character strings",
    "text": "Read data in as character strings\n\nglimpse(cat_lovers)\n\nRows: 60\nColumns: 3\n$ name           <chr> \"Bernice Warren\", \"Woodrow Stone\", \"Willie Bass\", \"Tyro…\n$ number_of_cats <chr> \"0\", \"0\", \"1\", \"3\", \"3\", \"2\", \"1\", \"1\", \"0\", \"0\", \"0\", …\n$ handedness     <chr> \"left\", \"left\", \"left\", \"left\", \"left\", \"left\", \"left\",…"
  },
  {
    "objectID": "content/lectures/02-dplyr.html#but-coerce-when-plotting",
    "href": "content/lectures/02-dplyr.html#but-coerce-when-plotting",
    "title": "02-dplyr",
    "section": "But coerce when plotting",
    "text": "But coerce when plotting\n\nggplot(cat_lovers, mapping = aes(x = handedness)) +\n  geom_bar()"
  },
  {
    "objectID": "content/lectures/02-dplyr.html#use-forcats-to-manipulate-factors",
    "href": "content/lectures/02-dplyr.html#use-forcats-to-manipulate-factors",
    "title": "02-dplyr",
    "section": "Use forcats to manipulate factors",
    "text": "Use forcats to manipulate factors\n\ncat_lovers <- cat_lovers |>\n  mutate(handedness = fct_relevel(handedness, \n                                  \"right\", \"left\", \"ambidextrous\"))\n\n\nggplot(cat_lovers, mapping = aes(x = handedness)) +\n  geom_bar()"
  },
  {
    "objectID": "content/lectures/02-dplyr.html#forcats-functionality",
    "href": "content/lectures/02-dplyr.html#forcats-functionality",
    "title": "02-dplyr",
    "section": "forcats functionality ",
    "text": "forcats functionality \n\nR uses factors to handle categorical variables, variables that have a fixed and known set of possible values. Historically, factors were much easier to work with than character vectors, so many base R functions automatically convert character vectors to factors.\nfactors are still useful when you have true categorical data, and when you want to override the ordering of character vectors to improve display. The goal of the forcats package is to provide a suite of useful tools that solve common problems with factors.\n\n\n\nSource: forcats.tidyverse.org"
  },
  {
    "objectID": "content/lectures/02-dplyr.html#suggested-reading",
    "href": "content/lectures/02-dplyr.html#suggested-reading",
    "title": "02-dplyr",
    "section": "Suggested Reading",
    "text": "Suggested Reading\nR4DS:\n\nChapter 5: Data Transformation\nChapter 15: Factors"
  },
  {
    "objectID": "content/lectures/01-intro-to-r-slides.html#ad-calpirg",
    "href": "content/lectures/01-intro-to-r-slides.html#ad-calpirg",
    "title": "01-intro-to-r",
    "section": "[ad] CALPIRG",
    "text": "[ad] CALPIRG\n\nAPPLY NOW: Volunteer or Intern to fight plastic pollution or turn out the vote on campus!\nCALPIRG Students is a student organization on campus that works to protect the environment, address food insecurity, and promote civic engagement. We helped nearly 10,000 students register to vote in California and got the UCs to release new policy to phase out single-use plastics to protect our oceans! Get involved to protect our oceans!\n\nThis Winter, we’re working to protect our oceans. They give us food, provide most of the oxygen we breathe, and are home to awesome biodiversity like whales and sea turtles, but our oceans are at risk from things like overfishing, oil drilling, and pollution. That’s why we’re calling on Governor Newsom to increase protections for marine areas in California!\nWe’re also working on campaigns addressing hunger & homelessness, fighting plastic pollution, and promoting voter participation.\nAs a volunteer or intern with CALPIRG you can:\n\nBuild grassroots support\nWork with the media and help organize press conferences with experts and elected officials\nLobby elected officials\nPlan big events like rallies or a benefit concert\nLearn key nonprofit management and fundraising skills\n\nLearn skills, build your resume, and work with issues that matter. Apply today."
  },
  {
    "objectID": "content/lectures/01-intro-to-r-slides.html#qa",
    "href": "content/lectures/01-intro-to-r-slides.html#qa",
    "title": "01-intro-to-r",
    "section": "Q&A",
    "text": "Q&A\n\nQ: Curious about why we’re using RStudio on DataHub instead of running it locally. Are there tasks that require the hardware used in DataHub or can most of the tasks be also done on a laptop?\nA: You could run this whole class locally and are free to do so! The one place where you would run into issues is that I assume packages (which have been installed on datahub) are installed. So, you would just have to install those packages before proceeding.\n\n\nQ: How exactly do students make appointments for the Wednesday office hour? Is it simply through email or is there a separate form?\nA: I use Calendly for this. The link to sign up is on Canvas!\n\n\nQ: I am still not sure how to clone GitHub code into datahub.\nA: This will be covered in lab this week!\n\n\nQ: How will we submit the lab. What will the lab being release and when will it due?\nA: Labs, homework, and exams will all be “submitted” by pushing to GitHub (covered in lab on Friday). Once it’s on GitHub, it’s submitted! This weeks lab will be released today. Typically, each week’s lab will be released on Monday of the week it’s due.\n\n\nQ: Do we need to bring our own computer to lab?\nA: Good question! I should have covered this. Lab is in the same room as lecture, so you will need your own computer. If you don’t have one, please reach out to me or campus resources (listed in the syllabus) and I’ll see what I can do!\n\n\nQ: After class today, I am a little confused on how we will be writing code for assignments. Will we be doing everything through RStudio once we have opened DataHub, or will there be a cell format similar to Jupyter Notebooks when using Python? In other words, can we expect all of our assignments to be conducted in RStudio as we did today?\nA: The code you submit will typically be in R Markdown documents (discussing more today!) These are similar to Jupyter Notebooks. And yes, everything can be done in RStudio as demo-ed on Tuesday.\n\n\nQ: I know you mentioned R has changed since you last used it. Would it be possible for you to share any resources or materials that you and other R practitioners find useful. I.E. Frameworks/Conventions/Blogs. A: Ah, so I meant to say that R has changed since I first used it many years ago. I have continued to use and learn R since then! I’ve never stopped using R. That said, I have/know of TONS of resources. Two big compilations I can recommend are: learnr4free and the Big Book of R. If there’s something specific you’re interested, feel free to let me know and I can point to more specific resources!\n\n\nQ: I’m anxious to learn Github - have put it off for most of my programming life. It seems so complicated! :(\nA: It is complicated, but that’s b/c it’s doing something REALLY hard. That said, the basics are not too complicated. So this course will force you to learn the basics, and then you’ll be on your way to learn the harder stuff!\n\n\nQ: Could you talk about the prevalence of R in industry (use cases / types of jobs / etc.)? My general understanding of it is that it’s kind of out the door when compared to Python.\nA: Yes! I’ll try to discuss this more throughout the course, but R is super popular among data scientists, particularly those who have a focus in statistics, biological data (bioinformatics), econometrics, data analysis, and/or data journalism. If you’re trying to do data engineering, you likely won’t see/use R, but if you’re analyzing and visualizing data in your job, you’re likely to encounter R. That said, Python is certainly a more popular language. That’s why I/we teach it in our intro programming course!"
  },
  {
    "objectID": "content/lectures/01-intro-to-r-slides.html#course-announcements",
    "href": "content/lectures/01-intro-to-r-slides.html#course-announcements",
    "title": "01-intro-to-r",
    "section": "Course Announcements",
    "text": "Course Announcements\nDue Dates:\n\nLab 01 due tomorrow (Friday) 11:59 PM\nLecture Participation survey “due” after class (both Tu and today’s lectures available)\nStudent survey “due” Sunday (1/15) 11:59 PM\n\n\nUpdate: Lab will be podcast but restricted to UCSD students and will not be archived."
  },
  {
    "objectID": "content/lectures/01-intro-to-r-slides.html#agenda",
    "href": "content/lectures/01-intro-to-r-slides.html#agenda",
    "title": "01-intro-to-r",
    "section": "Agenda",
    "text": "Agenda\n\nVariables\nOperators\nData in R\nRMarkdown"
  },
  {
    "objectID": "content/lectures/01-intro-to-r-slides.html#variables-assignment-1",
    "href": "content/lectures/01-intro-to-r-slides.html#variables-assignment-1",
    "title": "01-intro-to-r",
    "section": "Variables & Assignment",
    "text": "Variables & Assignment\nVariables are how we store information so that we can access it later.\n\nVariables are created and stored using the assignment operator <- 1\n\nfirst_variable <- 3\n\nThe above stores the value 3 in the variable first_variable\n\n\nThis means that if we ever want to reference the information stored in that variable later, we can “call” (mean, type in our code) the variable’s name:\n\nfirst_variable\n\n[1] 3\n\n\n\nOther programming languages use = for assignment. R also uses that for assignment, but it is more typical to see <- in R code, so we’ll stick with that."
  },
  {
    "objectID": "content/lectures/01-intro-to-r-slides.html#variable-type",
    "href": "content/lectures/01-intro-to-r-slides.html#variable-type",
    "title": "01-intro-to-r",
    "section": "Variable Type",
    "text": "Variable Type\n\nEvery variable you create in R will be of a specific type.\n\n\n\nThe type of the variable is determined dynamically on assignment.\n\n\n\n\nDetermining the type of a variable with class():\n\n\nclass(first_variable)\n\n[1] \"numeric\""
  },
  {
    "objectID": "content/lectures/01-intro-to-r-slides.html#basic-variable-types",
    "href": "content/lectures/01-intro-to-r-slides.html#basic-variable-types",
    "title": "01-intro-to-r",
    "section": "Basic Variable Types",
    "text": "Basic Variable Types\n\n\n\n\n\n\n\n\nVariable Type\nExplanation\nExample\n\n\n\n\ncharacter\nstores a string\n\"cogs137\", \"hi!\"\n\n\nnumeric\nstores whole numbers and decimals\n9, 9.29\n\n\ninteger\nspecifies integer\n9L (the L specifies this is an integer)\n\n\nlogical\nBooleans\nTRUE, FALSE\n\n\nlist\nstore multiple elements\nlist(7, \"a\", TRUE)\n\n\n\n\n\nThere are many more. We’ll get to some but not all in this course."
  },
  {
    "objectID": "content/lectures/01-intro-to-r-slides.html#logical-character",
    "href": "content/lectures/01-intro-to-r-slides.html#logical-character",
    "title": "01-intro-to-r",
    "section": "logical & character",
    "text": "logical & character\nlogical - Boolean values TRUE and FALSE\n\nclass(TRUE)\n\n[1] \"logical\"\n\n\n\ncharacter - character strings\n\nclass(\"hello\")\n\n[1] \"character\"\n\nclass('students') # equivalent...but we'll use double quotes!\n\n[1] \"character\""
  },
  {
    "objectID": "content/lectures/01-intro-to-r-slides.html#numeric-double-integer",
    "href": "content/lectures/01-intro-to-r-slides.html#numeric-double-integer",
    "title": "01-intro-to-r",
    "section": "numeric: double & integer",
    "text": "numeric: double & integer\ndouble - floating point numerical values (default numerical type)\n\nclass(1.335)\n\n[1] \"numeric\"\n\nclass(7)\n\n[1] \"numeric\"\n\n\n\ninteger - integer numerical values (indicated with an L)\n\nclass(7L)\n\n[1] \"integer\""
  },
  {
    "objectID": "content/lectures/01-intro-to-r-slides.html#lists",
    "href": "content/lectures/01-intro-to-r-slides.html#lists",
    "title": "01-intro-to-r",
    "section": "lists",
    "text": "lists\nSo far, every variable has been an atomic vector, meaning it only stores a single piece of information.\n\nLists are 1d objects that can contain any combination of R objects\n\n\n\nmylist <- list(\"A\", 7L, TRUE, 18.4)\nmylist\n\n[[1]]\n[1] \"A\"\n\n[[2]]\n[1] 7\n\n[[3]]\n[1] TRUE\n\n[[4]]\n[1] 18.4\n\n\n\n\nstr(mylist)\n\nList of 4\n $ : chr \"A\"\n $ : int 7\n $ : logi TRUE\n $ : num 18.4"
  },
  {
    "objectID": "content/lectures/01-intro-to-r-slides.html#your-turn",
    "href": "content/lectures/01-intro-to-r-slides.html#your-turn",
    "title": "01-intro-to-r",
    "section": "Your Turn",
    "text": "Your Turn\nDefine variables of each of the following types: charachter, numeric, integer, logical, list\n\n\nPut a green sticky on the front of your computer when you’re done. Put a pink if you want help/have a question."
  },
  {
    "objectID": "content/lectures/01-intro-to-r-slides.html#functions",
    "href": "content/lectures/01-intro-to-r-slides.html#functions",
    "title": "01-intro-to-r",
    "section": "Functions",
    "text": "Functions\n\nclass() (and View() & median()) were our first functions…but we’ll show a few more.\n\n\n\nFunctions are (most often) verbs, followed by what they will be applied to in parentheses.\n\n\n\nFunctions are:\n\navailable from base R\navailable from packages you import\ndefined by you\n\n\n\nWe’ll start by getting comfortable with available functions, but in a few days, you’ll learn how to write your own!"
  },
  {
    "objectID": "content/lectures/01-intro-to-r-slides.html#helpful-functions",
    "href": "content/lectures/01-intro-to-r-slides.html#helpful-functions",
    "title": "01-intro-to-r",
    "section": "Helpful Functions",
    "text": "Helpful Functions\n\n\n\nclass() - determine high-level variable type\n\n\nclass(mylist)\n\n[1] \"list\"\n\n\n\nlength()- determine how long an object is\n\n\n# contains 4 elements\nlength(mylist)\n\n[1] 4\n\n\n\n\nstr() - display the structure of an R object\n\n\nstr(mylist)\n\nList of 4\n $ : chr \"A\"\n $ : int 7\n $ : logi TRUE\n $ : num 18.4"
  },
  {
    "objectID": "content/lectures/01-intro-to-r-slides.html#coercion",
    "href": "content/lectures/01-intro-to-r-slides.html#coercion",
    "title": "01-intro-to-r",
    "section": "Coercion",
    "text": "Coercion\nR is a dynamically typed language – it will happily convert between the various types without complaint.\n\nc(1, \"Hello\")\n\n[1] \"1\"     \"Hello\"\n\nc(FALSE, 3L)\n\n[1] 0 3\n\nc(1.2, 3L)\n\n[1] 1.2 3.0"
  },
  {
    "objectID": "content/lectures/01-intro-to-r-slides.html#missing-values",
    "href": "content/lectures/01-intro-to-r-slides.html#missing-values",
    "title": "01-intro-to-r",
    "section": "Missing Values",
    "text": "Missing Values\nR uses NA to represent missing values in its data structures.\n\nclass(NA)\n\n[1] \"logical\"\n\n\n\nOther Special Values\nNaN | Not a number\nInf | Positive infinity\n-Inf | Negative infinity"
  },
  {
    "objectID": "content/lectures/01-intro-to-r-slides.html#activity",
    "href": "content/lectures/01-intro-to-r-slides.html#activity",
    "title": "01-intro-to-r",
    "section": "Activity",
    "text": "Activity\nWhat is the type of the following vectors? Chat about why they have that type.\n\nc(1, NA+1L, \"C\")\nc(1L / 0, NA)\nc(1:3, 5)\nc(3L, NaN+1L)\nc(NA, TRUE)\n\n\n\nPut a green sticky on the front of your computer when you’re done. Put a pink if you want help/have a question."
  },
  {
    "objectID": "content/lectures/01-intro-to-r-slides.html#operators-1",
    "href": "content/lectures/01-intro-to-r-slides.html#operators-1",
    "title": "01-intro-to-r",
    "section": "Operators",
    "text": "Operators\nAt its simplest, R is a calculator. To carry out mathematical operations, R uses operators."
  },
  {
    "objectID": "content/lectures/01-intro-to-r-slides.html#arithmetic-operators",
    "href": "content/lectures/01-intro-to-r-slides.html#arithmetic-operators",
    "title": "01-intro-to-r",
    "section": "Arithmetic Operators",
    "text": "Arithmetic Operators\n\n\n\nOperator\nDescription\n\n\n\n\n+\naddition\n\n\n-\nsubtraction\n\n\n*\nmultiplication\n\n\n/\ndivision\n\n\n^ or **\nexponentiation\n\n\nx %% y\nmodulus (x mod y) 9%%2 is 1\n\n\nx %/% y\ninteger division 9%/%2 is 4"
  },
  {
    "objectID": "content/lectures/01-intro-to-r-slides.html#arithmetic-operators-examples",
    "href": "content/lectures/01-intro-to-r-slides.html#arithmetic-operators-examples",
    "title": "01-intro-to-r",
    "section": "Arithmetic Operators: Examples",
    "text": "Arithmetic Operators: Examples\n\n7 + 6  \n\n[1] 13\n\n2 - 3\n\n[1] -1\n\n4 * 2\n\n[1] 8\n\n9 / 2\n\n[1] 4.5"
  },
  {
    "objectID": "content/lectures/01-intro-to-r-slides.html#reminder",
    "href": "content/lectures/01-intro-to-r-slides.html#reminder",
    "title": "01-intro-to-r",
    "section": "Reminder",
    "text": "Reminder\nOutput can be stored to a variable\n\nmy_addition <- 7 + 6\n\n\n\nmy_addition\n\n[1] 13"
  },
  {
    "objectID": "content/lectures/01-intro-to-r-slides.html#comparison-operators",
    "href": "content/lectures/01-intro-to-r-slides.html#comparison-operators",
    "title": "01-intro-to-r",
    "section": "Comparison Operators",
    "text": "Comparison Operators\nThese operators return a Boolean.\n\n\n\nOperator\nDescription\n\n\n\n\n<\nless than\n\n\n<=\nless than or equal to\n\n\n>\ngreater than\n\n\n>=\ngreater than or equal to\n\n\n==\nexactly equal to\n\n\n!=\nnot equal to"
  },
  {
    "objectID": "content/lectures/01-intro-to-r-slides.html#comparison-operators-examples",
    "href": "content/lectures/01-intro-to-r-slides.html#comparison-operators-examples",
    "title": "01-intro-to-r",
    "section": "Comparison Operators: Examples",
    "text": "Comparison Operators: Examples\n\n4 < 12\n\n[1] TRUE\n\n4 >= 3\n\n[1] TRUE\n\n6 == 6\n\n[1] TRUE\n\n7 != 6\n\n[1] TRUE"
  },
  {
    "objectID": "content/lectures/01-intro-to-r-slides.html#your-turn-1",
    "href": "content/lectures/01-intro-to-r-slides.html#your-turn-1",
    "title": "01-intro-to-r",
    "section": "Your Turn",
    "text": "Your Turn\nUse arithmetic and comparison operators to store the value 30 in the variable var_30 and TRUE in the variable true_var.\n\n\nPut a green sticky on the front of your computer when you’re done. Put a pink if you want help/have a question."
  },
  {
    "objectID": "content/lectures/01-intro-to-r-slides.html#packages",
    "href": "content/lectures/01-intro-to-r-slides.html#packages",
    "title": "01-intro-to-r",
    "section": "Packages",
    "text": "Packages\n\nPackages are installed with the install.packages function and loaded with the library function, once per session:\n\n\ninstall.packages(\"package_name\")\nlibrary(package_name)\n\n\nIn this course, most packages we’ll use have been installed for you already on datahub, so you will only have to load the package in (using library)."
  },
  {
    "objectID": "content/lectures/01-intro-to-r-slides.html#data-sets-in-r",
    "href": "content/lectures/01-intro-to-r-slides.html#data-sets-in-r",
    "title": "01-intro-to-r",
    "section": "Data “sets” in R",
    "text": "Data “sets” in R\n\n“set” is in quotation marks because it is not a formal data class\nA tidy data “set” can be one of the following types:\n\ntibble\ndata.frame\n\nWe’ll often work with tibbles:\n\nreadr package (e.g. read_csv function) loads data as a tibble by default\ntibbles are part of the tidyverse, so they work well with other packages we are using\nthey make minimal assumptions about your data, so are less likely to cause hard to track bugs in your code"
  },
  {
    "objectID": "content/lectures/01-intro-to-r-slides.html#data-frames",
    "href": "content/lectures/01-intro-to-r-slides.html#data-frames",
    "title": "01-intro-to-r",
    "section": "Data frames",
    "text": "Data frames\n\nA data frame is the most commonly used data structure in R, they are list of equal length vectors (usually atomic, but can be generic). Each vector is treated as a column and elements of the vectors as rows.\nA tibble is a type of data frame that … makes your life (i.e. data analysis) easier.\nMost often a data frame will be constructed by reading in from a file, but we can create them from scratch.\n\n\ndf <- tibble(x = 1:3, y = c(\"a\", \"b\", \"c\"))\nclass(df)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\nglimpse(df)\n\nRows: 3\nColumns: 2\n$ x <int> 1, 2, 3\n$ y <chr> \"a\", \"b\", \"c\""
  },
  {
    "objectID": "content/lectures/01-intro-to-r-slides.html#data-frames-cont.",
    "href": "content/lectures/01-intro-to-r-slides.html#data-frames-cont.",
    "title": "01-intro-to-r",
    "section": "Data frames (cont.)",
    "text": "Data frames (cont.)\n\nattributes(df)\n\n$class\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n$row.names\n[1] 1 2 3\n\n$names\n[1] \"x\" \"y\"\n\n\n\nColumns (variables) in data frames are accessed with $:\n\ndataframe$var_name\n\n\n\n\nclass(df$x)  # access variable type for column\n\n[1] \"integer\"\n\nclass(df$y)  \n\n[1] \"character\""
  },
  {
    "objectID": "content/lectures/01-intro-to-r-slides.html#variable-types",
    "href": "content/lectures/01-intro-to-r-slides.html#variable-types",
    "title": "01-intro-to-r",
    "section": "Variable Types",
    "text": "Variable Types\nData stored in columns can include different kinds of information…which would require a different type (class) of variable to be used in R.\n\n\n\n\nR Data Types:\n\nContinuous: numeric, integer\nDiscrete: factors (we haven’t talked about these yet, but will today!)\n\n\n\n\n\nArtwork by @allison_horst"
  },
  {
    "objectID": "content/lectures/01-intro-to-r-slides.html#variable-types-cont.",
    "href": "content/lectures/01-intro-to-r-slides.html#variable-types-cont.",
    "title": "01-intro-to-r",
    "section": "Variable Types (cont.)",
    "text": "Variable Types (cont.)\nSometimes data are non-numeric and store words. Even when that is the case, the data can be conveying different information.\n\n\n\n\nR Data Types:\n\nNominal: character\nOrdinal: factors\nBinary: logical OR numeric OR factors 😱\n\n\n\n\n\nArtwork by @allison_horst"
  },
  {
    "objectID": "content/lectures/01-intro-to-r-slides.html#example-cat-lovers",
    "href": "content/lectures/01-intro-to-r-slides.html#example-cat-lovers",
    "title": "01-intro-to-r",
    "section": "Example: Cat lovers",
    "text": "Example: Cat lovers\nA survey asked respondents their name and number of cats. The instructions said to enter the number of cats as a numerical value.\n\n🚨 There is code ahead that we’re not going to discuss in detail today, but we will in coming lectures.\n\ncat_lovers <- read_csv(\"https://raw.githubusercontent.com/COGS137/datasets/main/cat-lovers.csv\")"
  },
  {
    "objectID": "content/lectures/01-intro-to-r-slides.html#the-data",
    "href": "content/lectures/01-intro-to-r-slides.html#the-data",
    "title": "01-intro-to-r",
    "section": "The Data",
    "text": "The Data\n\ncat_lovers |>\n  datatable()"
  },
  {
    "objectID": "content/lectures/01-intro-to-r-slides.html#the-question",
    "href": "content/lectures/01-intro-to-r-slides.html#the-question",
    "title": "01-intro-to-r",
    "section": "The Question",
    "text": "The Question\nHow many respondents have a below average number of cats?\n\nGiving it a first shot…\n\ncat_lovers |>\n  summarise(mean = mean(number_of_cats))\n\n# A tibble: 1 × 1\n   mean\n  <dbl>\n1    NA\n\n\n\n\n💡 maybe there is missing data in the number_of_cats column!\nOh why will you still not work??!!\n\ncat_lovers |>\n  summarise(mean_cats = mean(number_of_cats, na.rm = TRUE))\n\n# A tibble: 1 × 1\n  mean_cats\n      <dbl>\n1        NA\n\n\n\n\n💡What is the type of the number_of_cats variable?"
  },
  {
    "objectID": "content/lectures/01-intro-to-r-slides.html#take-a-breath-and-look-at-your-data",
    "href": "content/lectures/01-intro-to-r-slides.html#take-a-breath-and-look-at-your-data",
    "title": "01-intro-to-r",
    "section": "Take a breath and look at your data",
    "text": "Take a breath and look at your data\n\n\nglimpse(cat_lovers)\n\nRows: 60\nColumns: 3\n$ name           <chr> \"Bernice Warren\", \"Woodrow Stone\", \"Willie Bass\", \"Tyro…\n$ number_of_cats <chr> \"0\", \"0\", \"1\", \"3\", \"3\", \"2\", \"1\", \"1\", \"0\", \"0\", \"0\", …\n$ handedness     <chr> \"left\", \"left\", \"left\", \"left\", \"left\", \"left\", \"left\",…"
  },
  {
    "objectID": "content/lectures/01-intro-to-r-slides.html#lets-take-another-look",
    "href": "content/lectures/01-intro-to-r-slides.html#lets-take-another-look",
    "title": "01-intro-to-r",
    "section": "Let’s take another look",
    "text": "Let’s take another look"
  },
  {
    "objectID": "content/lectures/01-intro-to-r-slides.html#sometimes-you-need-to-babysit-your-respondents",
    "href": "content/lectures/01-intro-to-r-slides.html#sometimes-you-need-to-babysit-your-respondents",
    "title": "01-intro-to-r",
    "section": "Sometimes you need to babysit your respondents",
    "text": "Sometimes you need to babysit your respondents\n\ncat_lovers |>\n  mutate(number_of_cats = case_when(\n    name == \"Ginger Clark\" ~ 2,\n    name == \"Doug Bass\"    ~ 3,\n    TRUE                   ~ as.numeric(number_of_cats))) \n\n# A tibble: 60 × 3\n   name           number_of_cats handedness\n   <chr>                   <dbl> <chr>     \n 1 Bernice Warren              0 left      \n 2 Woodrow Stone               0 left      \n 3 Willie Bass                 1 left      \n 4 Tyrone Estrada              3 left      \n 5 Alex Daniels                3 left      \n 6 Jane Bates                  2 left      \n 7 Latoya Simpson              1 left      \n 8 Darin Woods                 1 left      \n 9 Agnes Cobb                  0 left      \n10 Tabitha Grant               0 left      \n# … with 50 more rows"
  },
  {
    "objectID": "content/lectures/01-intro-to-r-slides.html#always-respect-check-data-types",
    "href": "content/lectures/01-intro-to-r-slides.html#always-respect-check-data-types",
    "title": "01-intro-to-r",
    "section": "Always respect (& check!) data types",
    "text": "Always respect (& check!) data types\n\ncat_lovers |>\n  mutate(number_of_cats = case_when(\n         name == \"Ginger Clark\" ~ \"2\",\n         name == \"Doug Bass\"    ~ \"3\",\n         TRUE                   ~ number_of_cats),\n         number_of_cats = as.numeric(number_of_cats)) |>\n  summarise(mean_cats = mean(number_of_cats))\n\n# A tibble: 1 × 1\n  mean_cats\n      <dbl>\n1     0.817"
  },
  {
    "objectID": "content/lectures/01-intro-to-r-slides.html#now-that-we-know-what-were-doing",
    "href": "content/lectures/01-intro-to-r-slides.html#now-that-we-know-what-were-doing",
    "title": "01-intro-to-r",
    "section": "Now that we know what we’re doing…",
    "text": "Now that we know what we’re doing…\n\ncat_lovers <- cat_lovers |>\n  mutate(number_of_cats = case_when(\n         name == \"Ginger Clark\" ~ \"2\",\n         name == \"Doug Bass\"    ~ \"3\",\n         TRUE                   ~ number_of_cats),\n         number_of_cats = as.numeric(number_of_cats))\n\n… store your data in a variable (here we’re overwriting the old cat_lovers tibble)."
  },
  {
    "objectID": "content/lectures/01-intro-to-r-slides.html#moral-of-the-story",
    "href": "content/lectures/01-intro-to-r-slides.html#moral-of-the-story",
    "title": "01-intro-to-r",
    "section": "Moral of the story",
    "text": "Moral of the story\n\nIf your data does not behave how you expect it to, type coercion upon reading in the data might be the reason.\nGo in and investigate your data, apply the fix, save your data, live happily ever after."
  },
  {
    "objectID": "content/lectures/01-intro-to-r-slides.html#r-markdown-tour",
    "href": "content/lectures/01-intro-to-r-slides.html#r-markdown-tour",
    "title": "01-intro-to-r",
    "section": "R Markdown: tour",
    "text": "R Markdown: tour\n\n[DEMO]\n\nBefore we move on…\n   What is the Bechdel test?\n\nThe Bechdel test asks whether a work of fiction features at least two women who talk to each other about something other than a man, and there must be two women named characters.\n\n\nConcepts introduced:\n\nKnitting documents\nR Markdown and (some) R syntax"
  },
  {
    "objectID": "content/lectures/01-intro-to-r-slides.html#giving-the-demo-a-go",
    "href": "content/lectures/01-intro-to-r-slides.html#giving-the-demo-a-go",
    "title": "01-intro-to-r",
    "section": "Giving the demo a go…",
    "text": "Giving the demo a go…\n\nNavigate to the demo URL (on Canvas)\nAccept the “assignment” (this is NOT graded)\nClone the repo\nEdit the document\nKnit the document\nPush your changes\n\nTry to play around with this after finishing your lab tomorrow!"
  },
  {
    "objectID": "content/lectures/01-intro-to-r-slides.html#recap",
    "href": "content/lectures/01-intro-to-r-slides.html#recap",
    "title": "01-intro-to-r",
    "section": "Recap",
    "text": "Recap\n\nAlways best to think of data as part of a tibble\n\nThis plays nicely with the tidyverse as well\nRows are observations, columns are variables\n\nWhat are the common variable types in R\n\nHow do I create a variable of each type?\nWhen would I use each one?\n\nDo I know how to determine the class/type of a variable?\nCan I explain dynamic typing?\nCan I operate on variables and values using…\n\narithmetic operators?\ncomparison operators?\n\nWhat are dataframes/tibbles? and why are they useful?\nWhat is the difference between installing and loading a package?\nWhat are the components of an R Markdown file?\n\n\n\n\nhttps://cogs137.github.io/website/"
  },
  {
    "objectID": "content/lectures/01-intro-to-r.html",
    "href": "content/lectures/01-intro-to-r.html",
    "title": "01-intro-to-r",
    "section": "",
    "text": "APPLY NOW: Volunteer or Intern to fight plastic pollution or turn out the vote on campus!\nCALPIRG Students is a student organization on campus that works to protect the environment, address food insecurity, and promote civic engagement. We helped nearly 10,000 students register to vote in California and got the UCs to release new policy to phase out single-use plastics to protect our oceans! Get involved to protect our oceans!\n\nThis Winter, we’re working to protect our oceans. They give us food, provide most of the oxygen we breathe, and are home to awesome biodiversity like whales and sea turtles, but our oceans are at risk from things like overfishing, oil drilling, and pollution. That’s why we’re calling on Governor Newsom to increase protections for marine areas in California!\nWe’re also working on campaigns addressing hunger & homelessness, fighting plastic pollution, and promoting voter participation.\nAs a volunteer or intern with CALPIRG you can:\n\nBuild grassroots support\nWork with the media and help organize press conferences with experts and elected officials\nLobby elected officials\nPlan big events like rallies or a benefit concert\nLearn key nonprofit management and fundraising skills\n\nLearn skills, build your resume, and work with issues that matter. Apply today.\n\n\n\n\n\nQ: Curious about why we’re using RStudio on DataHub instead of running it locally. Are there tasks that require the hardware used in DataHub or can most of the tasks be also done on a laptop?\nA: You could run this whole class locally and are free to do so! The one place where you would run into issues is that I assume packages (which have been installed on datahub) are installed. So, you would just have to install those packages before proceeding.\n\n\nQ: How exactly do students make appointments for the Wednesday office hour? Is it simply through email or is there a separate form?\nA: I use Calendly for this. The link to sign up is on Canvas!\n\n\nQ: I am still not sure how to clone GitHub code into datahub.\nA: This will be covered in lab this week!\n\n\nQ: How will we submit the lab. What will the lab being release and when will it due?\nA: Labs, homework, and exams will all be “submitted” by pushing to GitHub (covered in lab on Friday). Once it’s on GitHub, it’s submitted! This weeks lab will be released today. Typically, each week’s lab will be released on Monday of the week it’s due.\n\n\nQ: Do we need to bring our own computer to lab?\nA: Good question! I should have covered this. Lab is in the same room as lecture, so you will need your own computer. If you don’t have one, please reach out to me or campus resources (listed in the syllabus) and I’ll see what I can do!\n\n\nQ: After class today, I am a little confused on how we will be writing code for assignments. Will we be doing everything through RStudio once we have opened DataHub, or will there be a cell format similar to Jupyter Notebooks when using Python? In other words, can we expect all of our assignments to be conducted in RStudio as we did today?\nA: The code you submit will typically be in R Markdown documents (discussing more today!) These are similar to Jupyter Notebooks. And yes, everything can be done in RStudio as demo-ed on Tuesday.\n\n\nQ: I know you mentioned R has changed since you last used it. Would it be possible for you to share any resources or materials that you and other R practitioners find useful. I.E. Frameworks/Conventions/Blogs. A: Ah, so I meant to say that R has changed since I first used it many years ago. I have continued to use and learn R since then! I’ve never stopped using R. That said, I have/know of TONS of resources. Two big compilations I can recommend are: learnr4free and the Big Book of R. If there’s something specific you’re interested, feel free to let me know and I can point to more specific resources!\n\n\nQ: I’m anxious to learn Github - have put it off for most of my programming life. It seems so complicated! :(\nA: It is complicated, but that’s b/c it’s doing something REALLY hard. That said, the basics are not too complicated. So this course will force you to learn the basics, and then you’ll be on your way to learn the harder stuff!\n\n\nQ: Could you talk about the prevalence of R in industry (use cases / types of jobs / etc.)? My general understanding of it is that it’s kind of out the door when compared to Python.\nA: Yes! I’ll try to discuss this more throughout the course, but R is super popular among data scientists, particularly those who have a focus in statistics, biological data (bioinformatics), econometrics, data analysis, and/or data journalism. If you’re trying to do data engineering, you likely won’t see/use R, but if you’re analyzing and visualizing data in your job, you’re likely to encounter R. That said, Python is certainly a more popular language. That’s why I/we teach it in our intro programming course!\n\n\n\n\nDue Dates:\n\nLab 01 due tomorrow (Friday) 11:59 PM\nLecture Participation survey “due” after class (both Tu and today’s lectures available)\nStudent survey “due” Sunday (1/15) 11:59 PM\n\n\nUpdate: Lab will be podcast but restricted to UCSD students and will not be archived.\n\n\n\n\n\nVariables\nOperators\nData in R\nRMarkdown"
  },
  {
    "objectID": "content/lectures/01-intro-to-r.html#variables-assignment-1",
    "href": "content/lectures/01-intro-to-r.html#variables-assignment-1",
    "title": "01-intro-to-r",
    "section": "Variables & Assignment",
    "text": "Variables & Assignment\nVariables are how we store information so that we can access it later.\n\nVariables are created and stored using the assignment operator <- 1\n\nfirst_variable <- 3\n\nThe above stores the value 3 in the variable first_variable\n\n\nThis means that if we ever want to reference the information stored in that variable later, we can “call” (mean, type in our code) the variable’s name:\n\nfirst_variable\n\n[1] 3"
  },
  {
    "objectID": "content/lectures/01-intro-to-r.html#variable-type",
    "href": "content/lectures/01-intro-to-r.html#variable-type",
    "title": "01-intro-to-r",
    "section": "Variable Type",
    "text": "Variable Type\n\nEvery variable you create in R will be of a specific type.\n\n\n\nThe type of the variable is determined dynamically on assignment.\n\n\n\n\nDetermining the type of a variable with class():\n\n\nclass(first_variable)\n\n[1] \"numeric\""
  },
  {
    "objectID": "content/lectures/01-intro-to-r.html#basic-variable-types",
    "href": "content/lectures/01-intro-to-r.html#basic-variable-types",
    "title": "01-intro-to-r",
    "section": "Basic Variable Types",
    "text": "Basic Variable Types\n\n\n\n\n\n\n\n\nVariable Type\nExplanation\nExample\n\n\n\n\ncharacter\nstores a string\n\"cogs137\", \"hi!\"\n\n\nnumeric\nstores whole numbers and decimals\n9, 9.29\n\n\ninteger\nspecifies integer\n9L (the L specifies this is an integer)\n\n\nlogical\nBooleans\nTRUE, FALSE\n\n\nlist\nstore multiple elements\nlist(7, \"a\", TRUE)\n\n\n\n\n\nThere are many more. We’ll get to some but not all in this course."
  },
  {
    "objectID": "content/lectures/01-intro-to-r.html#logical-character",
    "href": "content/lectures/01-intro-to-r.html#logical-character",
    "title": "01-intro-to-r",
    "section": "logical & character",
    "text": "logical & character\nlogical - Boolean values TRUE and FALSE\n\nclass(TRUE)\n\n[1] \"logical\"\n\n\n\ncharacter - character strings\n\nclass(\"hello\")\n\n[1] \"character\"\n\nclass('students') # equivalent...but we'll use double quotes!\n\n[1] \"character\""
  },
  {
    "objectID": "content/lectures/01-intro-to-r.html#numeric-double-integer",
    "href": "content/lectures/01-intro-to-r.html#numeric-double-integer",
    "title": "01-intro-to-r",
    "section": "numeric: double & integer",
    "text": "numeric: double & integer\ndouble - floating point numerical values (default numerical type)\n\nclass(1.335)\n\n[1] \"numeric\"\n\nclass(7)\n\n[1] \"numeric\"\n\n\n\ninteger - integer numerical values (indicated with an L)\n\nclass(7L)\n\n[1] \"integer\""
  },
  {
    "objectID": "content/lectures/01-intro-to-r.html#lists",
    "href": "content/lectures/01-intro-to-r.html#lists",
    "title": "01-intro-to-r",
    "section": "lists",
    "text": "lists\nSo far, every variable has been an atomic vector, meaning it only stores a single piece of information.\n\nLists are 1d objects that can contain any combination of R objects\n\n\n\nmylist <- list(\"A\", 7L, TRUE, 18.4)\nmylist\n\n[[1]]\n[1] \"A\"\n\n[[2]]\n[1] 7\n\n[[3]]\n[1] TRUE\n\n[[4]]\n[1] 18.4\n\n\n\n\nstr(mylist)\n\nList of 4\n $ : chr \"A\"\n $ : int 7\n $ : logi TRUE\n $ : num 18.4"
  },
  {
    "objectID": "content/lectures/01-intro-to-r.html#your-turn",
    "href": "content/lectures/01-intro-to-r.html#your-turn",
    "title": "01-intro-to-r",
    "section": "Your Turn",
    "text": "Your Turn\nDefine variables of each of the following types: charachter, numeric, integer, logical, list\n\n\nPut a green sticky on the front of your computer when you’re done. Put a pink if you want help/have a question."
  },
  {
    "objectID": "content/lectures/01-intro-to-r.html#functions",
    "href": "content/lectures/01-intro-to-r.html#functions",
    "title": "01-intro-to-r",
    "section": "Functions",
    "text": "Functions\n\nclass() (and View() & median()) were our first functions…but we’ll show a few more.\n\n\n\nFunctions are (most often) verbs, followed by what they will be applied to in parentheses.\n\n\n\nFunctions are:\n\navailable from base R\navailable from packages you import\ndefined by you\n\n\n\nWe’ll start by getting comfortable with available functions, but in a few days, you’ll learn how to write your own!"
  },
  {
    "objectID": "content/lectures/01-intro-to-r.html#helpful-functions",
    "href": "content/lectures/01-intro-to-r.html#helpful-functions",
    "title": "01-intro-to-r",
    "section": "Helpful Functions",
    "text": "Helpful Functions\n\n\n\nclass() - determine high-level variable type\n\n\nclass(mylist)\n\n[1] \"list\"\n\n\n\nlength()- determine how long an object is\n\n\n# contains 4 elements\nlength(mylist)\n\n[1] 4\n\n\n\n\nstr() - display the structure of an R object\n\n\nstr(mylist)\n\nList of 4\n $ : chr \"A\"\n $ : int 7\n $ : logi TRUE\n $ : num 18.4"
  },
  {
    "objectID": "content/lectures/01-intro-to-r.html#coercion",
    "href": "content/lectures/01-intro-to-r.html#coercion",
    "title": "01-intro-to-r",
    "section": "Coercion",
    "text": "Coercion\nR is a dynamically typed language – it will happily convert between the various types without complaint.\n\nc(1, \"Hello\")\n\n[1] \"1\"     \"Hello\"\n\nc(FALSE, 3L)\n\n[1] 0 3\n\nc(1.2, 3L)\n\n[1] 1.2 3.0"
  },
  {
    "objectID": "content/lectures/01-intro-to-r.html#missing-values",
    "href": "content/lectures/01-intro-to-r.html#missing-values",
    "title": "01-intro-to-r",
    "section": "Missing Values",
    "text": "Missing Values\nR uses NA to represent missing values in its data structures.\n\nclass(NA)\n\n[1] \"logical\"\n\n\n\n\nOther Special Values\nNaN | Not a number\nInf | Positive infinity\n-Inf | Negative infinity"
  },
  {
    "objectID": "content/lectures/01-intro-to-r.html#activity",
    "href": "content/lectures/01-intro-to-r.html#activity",
    "title": "01-intro-to-r",
    "section": "Activity",
    "text": "Activity\nWhat is the type of the following vectors? Chat about why they have that type.\n\nc(1, NA+1L, \"C\")\nc(1L / 0, NA)\nc(1:3, 5)\nc(3L, NaN+1L)\nc(NA, TRUE)\n\n\n\nPut a green sticky on the front of your computer when you’re done. Put a pink if you want help/have a question."
  },
  {
    "objectID": "content/lectures/01-intro-to-r.html#operators-1",
    "href": "content/lectures/01-intro-to-r.html#operators-1",
    "title": "01-intro-to-r",
    "section": "Operators",
    "text": "Operators\nAt its simplest, R is a calculator. To carry out mathematical operations, R uses operators."
  },
  {
    "objectID": "content/lectures/01-intro-to-r.html#arithmetic-operators",
    "href": "content/lectures/01-intro-to-r.html#arithmetic-operators",
    "title": "01-intro-to-r",
    "section": "Arithmetic Operators",
    "text": "Arithmetic Operators\n\n\n\nOperator\nDescription\n\n\n\n\n+\naddition\n\n\n-\nsubtraction\n\n\n*\nmultiplication\n\n\n/\ndivision\n\n\n^ or **\nexponentiation\n\n\nx %% y\nmodulus (x mod y) 9%%2 is 1\n\n\nx %/% y\ninteger division 9%/%2 is 4"
  },
  {
    "objectID": "content/lectures/01-intro-to-r.html#arithmetic-operators-examples",
    "href": "content/lectures/01-intro-to-r.html#arithmetic-operators-examples",
    "title": "01-intro-to-r",
    "section": "Arithmetic Operators: Examples",
    "text": "Arithmetic Operators: Examples\n\n7 + 6  \n\n[1] 13\n\n2 - 3\n\n[1] -1\n\n4 * 2\n\n[1] 8\n\n9 / 2\n\n[1] 4.5"
  },
  {
    "objectID": "content/lectures/01-intro-to-r.html#reminder",
    "href": "content/lectures/01-intro-to-r.html#reminder",
    "title": "01-intro-to-r",
    "section": "Reminder",
    "text": "Reminder\nOutput can be stored to a variable\n\nmy_addition <- 7 + 6\n\n\n\nmy_addition\n\n[1] 13"
  },
  {
    "objectID": "content/lectures/01-intro-to-r.html#comparison-operators",
    "href": "content/lectures/01-intro-to-r.html#comparison-operators",
    "title": "01-intro-to-r",
    "section": "Comparison Operators",
    "text": "Comparison Operators\nThese operators return a Boolean.\n\n\n\nOperator\nDescription\n\n\n\n\n<\nless than\n\n\n<=\nless than or equal to\n\n\n>\ngreater than\n\n\n>=\ngreater than or equal to\n\n\n==\nexactly equal to\n\n\n!=\nnot equal to"
  },
  {
    "objectID": "content/lectures/01-intro-to-r.html#comparison-operators-examples",
    "href": "content/lectures/01-intro-to-r.html#comparison-operators-examples",
    "title": "01-intro-to-r",
    "section": "Comparison Operators: Examples",
    "text": "Comparison Operators: Examples\n\n4 < 12\n\n[1] TRUE\n\n4 >= 3\n\n[1] TRUE\n\n6 == 6\n\n[1] TRUE\n\n7 != 6\n\n[1] TRUE"
  },
  {
    "objectID": "content/lectures/01-intro-to-r.html#your-turn-1",
    "href": "content/lectures/01-intro-to-r.html#your-turn-1",
    "title": "01-intro-to-r",
    "section": "Your Turn",
    "text": "Your Turn\nUse arithmetic and comparison operators to store the value 30 in the variable var_30 and TRUE in the variable true_var.\n\n\nPut a green sticky on the front of your computer when you’re done. Put a pink if you want help/have a question."
  },
  {
    "objectID": "content/lectures/01-intro-to-r.html#packages",
    "href": "content/lectures/01-intro-to-r.html#packages",
    "title": "01-intro-to-r",
    "section": "Packages",
    "text": "Packages\n\nPackages are installed with the install.packages function and loaded with the library function, once per session:\n\n\ninstall.packages(\"package_name\")\nlibrary(package_name)\n\n\nIn this course, most packages we’ll use have been installed for you already on datahub, so you will only have to load the package in (using library)."
  },
  {
    "objectID": "content/lectures/01-intro-to-r.html#data-sets-in-r",
    "href": "content/lectures/01-intro-to-r.html#data-sets-in-r",
    "title": "01-intro-to-r",
    "section": "Data “sets” in R",
    "text": "Data “sets” in R\n\n“set” is in quotation marks because it is not a formal data class\nA tidy data “set” can be one of the following types:\n\ntibble\ndata.frame\n\nWe’ll often work with tibbles:\n\nreadr package (e.g. read_csv function) loads data as a tibble by default\ntibbles are part of the tidyverse, so they work well with other packages we are using\nthey make minimal assumptions about your data, so are less likely to cause hard to track bugs in your code"
  },
  {
    "objectID": "content/lectures/01-intro-to-r.html#data-frames",
    "href": "content/lectures/01-intro-to-r.html#data-frames",
    "title": "01-intro-to-r",
    "section": "Data frames",
    "text": "Data frames\n\nA data frame is the most commonly used data structure in R, they are list of equal length vectors (usually atomic, but can be generic). Each vector is treated as a column and elements of the vectors as rows.\nA tibble is a type of data frame that … makes your life (i.e. data analysis) easier.\nMost often a data frame will be constructed by reading in from a file, but we can create them from scratch.\n\n\ndf <- tibble(x = 1:3, y = c(\"a\", \"b\", \"c\"))\nclass(df)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\nglimpse(df)\n\nRows: 3\nColumns: 2\n$ x <int> 1, 2, 3\n$ y <chr> \"a\", \"b\", \"c\""
  },
  {
    "objectID": "content/lectures/01-intro-to-r.html#data-frames-cont.",
    "href": "content/lectures/01-intro-to-r.html#data-frames-cont.",
    "title": "01-intro-to-r",
    "section": "Data frames (cont.)",
    "text": "Data frames (cont.)\n\nattributes(df)\n\n$class\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n$row.names\n[1] 1 2 3\n\n$names\n[1] \"x\" \"y\"\n\n\n\nColumns (variables) in data frames are accessed with $:\n\ndataframe$var_name\n\n\n\n\nclass(df$x)  # access variable type for column\n\n[1] \"integer\"\n\nclass(df$y)  \n\n[1] \"character\""
  },
  {
    "objectID": "content/lectures/01-intro-to-r.html#variable-types",
    "href": "content/lectures/01-intro-to-r.html#variable-types",
    "title": "01-intro-to-r",
    "section": "Variable Types",
    "text": "Variable Types\nData stored in columns can include different kinds of information…which would require a different type (class) of variable to be used in R.\n\n\n\n\nR Data Types:\n\nContinuous: numeric, integer\nDiscrete: factors (we haven’t talked about these yet, but will today!)\n\n\n\n\n\nArtwork by @allison_horst"
  },
  {
    "objectID": "content/lectures/01-intro-to-r.html#variable-types-cont.",
    "href": "content/lectures/01-intro-to-r.html#variable-types-cont.",
    "title": "01-intro-to-r",
    "section": "Variable Types (cont.)",
    "text": "Variable Types (cont.)\nSometimes data are non-numeric and store words. Even when that is the case, the data can be conveying different information.\n\n\n\n\nR Data Types:\n\nNominal: character\nOrdinal: factors\nBinary: logical OR numeric OR factors 😱\n\n\n\n\n\nArtwork by @allison_horst"
  },
  {
    "objectID": "content/lectures/01-intro-to-r.html#example-cat-lovers",
    "href": "content/lectures/01-intro-to-r.html#example-cat-lovers",
    "title": "01-intro-to-r",
    "section": "Example: Cat lovers",
    "text": "Example: Cat lovers\nA survey asked respondents their name and number of cats. The instructions said to enter the number of cats as a numerical value.\n\n🚨 There is code ahead that we’re not going to discuss in detail today, but we will in coming lectures.\n\ncat_lovers <- read_csv(\"https://raw.githubusercontent.com/COGS137/datasets/main/cat-lovers.csv\")"
  },
  {
    "objectID": "content/lectures/01-intro-to-r.html#the-data",
    "href": "content/lectures/01-intro-to-r.html#the-data",
    "title": "01-intro-to-r",
    "section": "The Data",
    "text": "The Data\n\ncat_lovers |>\n  datatable()"
  },
  {
    "objectID": "content/lectures/01-intro-to-r.html#the-question",
    "href": "content/lectures/01-intro-to-r.html#the-question",
    "title": "01-intro-to-r",
    "section": "The Question",
    "text": "The Question\nHow many respondents have a below average number of cats?\n\nGiving it a first shot…\n\ncat_lovers |>\n  summarise(mean = mean(number_of_cats))\n\nWarning in mean.default(number_of_cats): argument is not numeric or logical:\nreturning NA\n\n\n# A tibble: 1 × 1\n   mean\n  <dbl>\n1    NA\n\n\n\n\n💡 maybe there is missing data in the number_of_cats column!\nOh why will you still not work??!!\n\ncat_lovers |>\n  summarise(mean_cats = mean(number_of_cats, na.rm = TRUE))\n\nWarning in mean.default(number_of_cats, na.rm = TRUE): argument is not numeric\nor logical: returning NA\n\n\n# A tibble: 1 × 1\n  mean_cats\n      <dbl>\n1        NA\n\n\n\n\n💡What is the type of the number_of_cats variable?"
  },
  {
    "objectID": "content/lectures/01-intro-to-r.html#take-a-breath-and-look-at-your-data",
    "href": "content/lectures/01-intro-to-r.html#take-a-breath-and-look-at-your-data",
    "title": "01-intro-to-r",
    "section": "Take a breath and look at your data",
    "text": "Take a breath and look at your data\n\n\nglimpse(cat_lovers)\n\nRows: 60\nColumns: 3\n$ name           <chr> \"Bernice Warren\", \"Woodrow Stone\", \"Willie Bass\", \"Tyro…\n$ number_of_cats <chr> \"0\", \"0\", \"1\", \"3\", \"3\", \"2\", \"1\", \"1\", \"0\", \"0\", \"0\", …\n$ handedness     <chr> \"left\", \"left\", \"left\", \"left\", \"left\", \"left\", \"left\",…"
  },
  {
    "objectID": "content/lectures/01-intro-to-r.html#lets-take-another-look",
    "href": "content/lectures/01-intro-to-r.html#lets-take-another-look",
    "title": "01-intro-to-r",
    "section": "Let’s take another look",
    "text": "Let’s take another look"
  },
  {
    "objectID": "content/lectures/01-intro-to-r.html#sometimes-you-need-to-babysit-your-respondents",
    "href": "content/lectures/01-intro-to-r.html#sometimes-you-need-to-babysit-your-respondents",
    "title": "01-intro-to-r",
    "section": "Sometimes you need to babysit your respondents",
    "text": "Sometimes you need to babysit your respondents\n\ncat_lovers |>\n  mutate(number_of_cats = case_when(\n    name == \"Ginger Clark\" ~ 2,\n    name == \"Doug Bass\"    ~ 3,\n    TRUE                   ~ as.numeric(number_of_cats))) \n\nWarning in eval_tidy(pair$rhs, env = default_env): NAs introduced by coercion\n\n\n# A tibble: 60 × 3\n   name           number_of_cats handedness\n   <chr>                   <dbl> <chr>     \n 1 Bernice Warren              0 left      \n 2 Woodrow Stone               0 left      \n 3 Willie Bass                 1 left      \n 4 Tyrone Estrada              3 left      \n 5 Alex Daniels                3 left      \n 6 Jane Bates                  2 left      \n 7 Latoya Simpson              1 left      \n 8 Darin Woods                 1 left      \n 9 Agnes Cobb                  0 left      \n10 Tabitha Grant               0 left      \n# … with 50 more rows"
  },
  {
    "objectID": "content/lectures/01-intro-to-r.html#always-respect-check-data-types",
    "href": "content/lectures/01-intro-to-r.html#always-respect-check-data-types",
    "title": "01-intro-to-r",
    "section": "Always respect (& check!) data types",
    "text": "Always respect (& check!) data types\n\ncat_lovers |>\n  mutate(number_of_cats = case_when(\n         name == \"Ginger Clark\" ~ \"2\",\n         name == \"Doug Bass\"    ~ \"3\",\n         TRUE                   ~ number_of_cats),\n         number_of_cats = as.numeric(number_of_cats)) |>\n  summarise(mean_cats = mean(number_of_cats))\n\n# A tibble: 1 × 1\n  mean_cats\n      <dbl>\n1     0.817"
  },
  {
    "objectID": "content/lectures/01-intro-to-r.html#now-that-we-know-what-were-doing",
    "href": "content/lectures/01-intro-to-r.html#now-that-we-know-what-were-doing",
    "title": "01-intro-to-r",
    "section": "Now that we know what we’re doing…",
    "text": "Now that we know what we’re doing…\n\ncat_lovers <- cat_lovers |>\n  mutate(number_of_cats = case_when(\n         name == \"Ginger Clark\" ~ \"2\",\n         name == \"Doug Bass\"    ~ \"3\",\n         TRUE                   ~ number_of_cats),\n         number_of_cats = as.numeric(number_of_cats))\n\n… store your data in a variable (here we’re overwriting the old cat_lovers tibble)."
  },
  {
    "objectID": "content/lectures/01-intro-to-r.html#moral-of-the-story",
    "href": "content/lectures/01-intro-to-r.html#moral-of-the-story",
    "title": "01-intro-to-r",
    "section": "Moral of the story",
    "text": "Moral of the story\n\nIf your data does not behave how you expect it to, type coercion upon reading in the data might be the reason.\nGo in and investigate your data, apply the fix, save your data, live happily ever after."
  },
  {
    "objectID": "content/lectures/01-intro-to-r.html#r-markdown-tour",
    "href": "content/lectures/01-intro-to-r.html#r-markdown-tour",
    "title": "01-intro-to-r",
    "section": "R Markdown: tour",
    "text": "R Markdown: tour\n\n[DEMO]\n\nBefore we move on…\n   What is the Bechdel test?\n\nThe Bechdel test asks whether a work of fiction features at least two women who talk to each other about something other than a man, and there must be two women named characters.\n\n\nConcepts introduced:\n\nKnitting documents\nR Markdown and (some) R syntax"
  },
  {
    "objectID": "content/lectures/01-intro-to-r.html#giving-the-demo-a-go",
    "href": "content/lectures/01-intro-to-r.html#giving-the-demo-a-go",
    "title": "01-intro-to-r",
    "section": "Giving the demo a go…",
    "text": "Giving the demo a go…\n\nNavigate to the demo URL (on Canvas)\nAccept the “assignment” (this is NOT graded)\nClone the repo\nEdit the document\nKnit the document\nPush your changes\n\nTry to play around with this after finishing your lab tomorrow!"
  },
  {
    "objectID": "content/lectures/01-intro-to-r.html#recap",
    "href": "content/lectures/01-intro-to-r.html#recap",
    "title": "01-intro-to-r",
    "section": "Recap",
    "text": "Recap\n\nAlways best to think of data as part of a tibble\n\nThis plays nicely with the tidyverse as well\nRows are observations, columns are variables\n\nWhat are the common variable types in R\n\nHow do I create a variable of each type?\nWhen would I use each one?\n\nDo I know how to determine the class/type of a variable?\nCan I explain dynamic typing?\nCan I operate on variables and values using…\n\narithmetic operators?\ncomparison operators?\n\nWhat are dataframes/tibbles? and why are they useful?\nWhat is the difference between installing and loading a package?\nWhat are the components of an R Markdown file?"
  },
  {
    "objectID": "content/lectures/04-ggplot2-slides.html#qa",
    "href": "content/lectures/04-ggplot2-slides.html#qa",
    "title": "04-ggplot2",
    "section": "Q&A",
    "text": "Q&A\n\nQ:Can we have a demo in class on how to clone our repo and check if our Github submissions submitted properly? I am having trouble doing this.\nA: Yes! Let’s do that today.\n\n\nQ: Does left_join(a, b) = right_join(b, a)?\nA: No. The total information would be equivalent but the order of columns would differ. In the left join, the columns from a would be first and in the right join, the colums from b would be listed first. But the actual rows that are joined/included would be the same.\n\n\nQ: I would still like to know if there is a way to save data sets more often when using functions on them, such as filter. I see we only saved data sets when we use functions like mutate, but why not other functions?\nA: You’re allowed to store variables into a new data frame whenever you’d like! Now, the more variables you create, the more to keep track of, so I would encourage you to store your output any time you make a “substantial” change to your data. So, say you do a filter, selection, and mutate to get your data into the format for analysis. I wouldn’t store after each step, but I would store it after I wrote the pipe doing all three. Follow up if this doesn’t clarify!\n\n\nQ: I think the left_join, right_join, and full_join was pretty confusing.\nA: You’re right! It is confusing. We’ll go through more examples and get more practice!"
  },
  {
    "objectID": "content/lectures/04-ggplot2-slides.html#course-announcements",
    "href": "content/lectures/04-ggplot2-slides.html#course-announcements",
    "title": "04-ggplot2",
    "section": "Course Announcements",
    "text": "Course Announcements\nDue Dates:\n\nLab 03 due Friday (1/27; 11:59 PM)\nLecture Participation survey “due” after class\n\nCourse Announcements:\n\nHappy New Year!\nGitHub assignment clone + submission demo\nLab02 Notes:\n\nLook at the answer key:\ngrouping by name and year\ncan add text outside of code chunks; discuss variable reference\nsolutions to optional exercises"
  },
  {
    "objectID": "content/lectures/04-ggplot2-slides.html#ggplot2-in-tidyverse",
    "href": "content/lectures/04-ggplot2-slides.html#ggplot2-in-tidyverse",
    "title": "04-ggplot2",
    "section": "ggplot2 \\(\\in\\) tidyverse",
    "text": "ggplot2 \\(\\in\\) tidyverse\n\n\n\n\n\n\n\n\n\nggplot2 is tidyverse’s data visualization package\nStructure of the code for plots can be summarized as\n\n\nggplot(data = [dataset], \n       mapping = aes(x = [x-variable], \n                     y = [y-variable])) +\n   geom_xxx() +\n   other options"
  },
  {
    "objectID": "content/lectures/04-ggplot2-slides.html#data-palmer-penguins",
    "href": "content/lectures/04-ggplot2-slides.html#data-palmer-penguins",
    "title": "04-ggplot2",
    "section": "Data: Palmer Penguins",
    "text": "Data: Palmer Penguins\nMeasurements for penguin species, island in Palmer Archipelago, size (flipper length, body mass, bill dimensions), and sex.\n\n\n\n\n\n\n\n\n\n# install.packages(\"palmerpenguins\")\nlibrary(palmerpenguins)\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           <fct> Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel…\n$ island            <fct> Torgersen, Torgersen, Torgersen, Torgersen, Torgerse…\n$ bill_length_mm    <dbl> 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, …\n$ bill_depth_mm     <dbl> 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, …\n$ flipper_length_mm <int> 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186…\n$ body_mass_g       <int> 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, …\n$ sex               <fct> male, female, female, NA, female, male, female, male…\n$ year              <int> 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007…\n\n\n\n\n\n\nArtwork by @allison_horst"
  },
  {
    "objectID": "content/lectures/04-ggplot2-slides.html#the-data",
    "href": "content/lectures/04-ggplot2-slides.html#the-data",
    "title": "04-ggplot2",
    "section": "The Data",
    "text": "The Data\n\npenguins |>\n  datatable()"
  },
  {
    "objectID": "content/lectures/04-ggplot2-slides.html#a-plot",
    "href": "content/lectures/04-ggplot2-slides.html#a-plot",
    "title": "04-ggplot2",
    "section": "A Plot",
    "text": "A Plot\n\n\nggplot(data = penguins, \n       mapping = aes(x = bill_depth_mm, y = bill_length_mm,\n                     color = species)) +\n  geom_point() +\n  labs(title = \"Bill depth and length\",\n       subtitle = \"Dimensions for Adelie, Chinstrap, and Gentoo Penguins\",\n       x = \"Bill depth (mm)\", y = \"Bill length (mm)\",\n       color = \"Species\") +\n  scale_color_viridis_d()"
  },
  {
    "objectID": "content/lectures/04-ggplot2-slides.html#section",
    "href": "content/lectures/04-ggplot2-slides.html#section",
    "title": "04-ggplot2",
    "section": "",
    "text": "Start with the penguins data frame\n\n\n\nggplot(data = penguins)"
  },
  {
    "objectID": "content/lectures/04-ggplot2-slides.html#section-1",
    "href": "content/lectures/04-ggplot2-slides.html#section-1",
    "title": "04-ggplot2",
    "section": "",
    "text": "Start with the penguins data frame, map bill depth to the x-axis\n\n\n\nggplot(data = penguins,\n       mapping = aes(x = bill_depth_mm))"
  },
  {
    "objectID": "content/lectures/04-ggplot2-slides.html#section-2",
    "href": "content/lectures/04-ggplot2-slides.html#section-2",
    "title": "04-ggplot2",
    "section": "",
    "text": "Start with the penguins data frame, map bill depth to the x-axis and map bill length to the y-axis.\n\n\n\nggplot(data = penguins,\n       mapping = aes(x = bill_depth_mm,\n                     y = bill_length_mm))"
  },
  {
    "objectID": "content/lectures/04-ggplot2-slides.html#section-3",
    "href": "content/lectures/04-ggplot2-slides.html#section-3",
    "title": "04-ggplot2",
    "section": "",
    "text": "Start with the penguins data frame, map bill depth to the x-axis and map bill length to the y-axis. Represent each observation with a point\n\n\n\nggplot(data = penguins,\n       mapping = aes(x = bill_depth_mm,\n                     y = bill_length_mm)) + \n  geom_point()"
  },
  {
    "objectID": "content/lectures/04-ggplot2-slides.html#section-4",
    "href": "content/lectures/04-ggplot2-slides.html#section-4",
    "title": "04-ggplot2",
    "section": "",
    "text": "Start with the penguins data frame, map bill depth to the x-axis and map bill length to the y-axis. Represent each observation with a point and map species to the color of each point.\n\n\n\nggplot(data = penguins,\n       mapping = aes(x = bill_depth_mm,\n                     y = bill_length_mm,\n                     color = species)) + \n  geom_point()"
  },
  {
    "objectID": "content/lectures/04-ggplot2-slides.html#section-5",
    "href": "content/lectures/04-ggplot2-slides.html#section-5",
    "title": "04-ggplot2",
    "section": "",
    "text": "Start with the penguins data frame, map bill depth to the x-axis and map bill length to the y-axis. Represent each observation with a point and map species to the color of each point. Title the plot “Bill depth and length”\n\n\n\nggplot(data = penguins,\n       mapping = aes(x = bill_depth_mm,\n                     y = bill_length_mm,\n                     color = species)) +\n  geom_point() +\n  labs(title = \"Bill depth and length\")"
  },
  {
    "objectID": "content/lectures/04-ggplot2-slides.html#section-6",
    "href": "content/lectures/04-ggplot2-slides.html#section-6",
    "title": "04-ggplot2",
    "section": "",
    "text": "Start with the penguins data frame, map bill depth to the x-axis and map bill length to the y-axis. Represent each observation with a point and map species to the color of each point. Title the plot “Bill depth and length”, add the subtitle “Dimensions for Adelie, Chinstrap, and Gentoo Penguins”\n\n\n\nggplot(data = penguins,\n       mapping = aes(x = bill_depth_mm,\n                     y = bill_length_mm,\n                     color = species)) +\n  geom_point() +\n  labs(title = \"Bill depth and length\",\n       subtitle = \"Dimensions for Adelie, Chinstrap, and Gentoo Penguins\")"
  },
  {
    "objectID": "content/lectures/04-ggplot2-slides.html#section-7",
    "href": "content/lectures/04-ggplot2-slides.html#section-7",
    "title": "04-ggplot2",
    "section": "",
    "text": "Start with the penguins data frame, map bill depth to the x-axis and map bill length to the y-axis. Represent each observation with a point and map species to the color of each point. Title the plot “Bill depth and length”, add the subtitle “Dimensions for Adelie, Chinstrap, and Gentoo Penguins”, label the x and y axes as “Bill depth (mm)” and “Bill length (mm)”, respectively\n\n\n\nggplot(data = penguins,\n       mapping = aes(x = bill_depth_mm,\n                     y = bill_length_mm,\n                     color = species)) +\n  geom_point() +\n  labs(title = \"Bill depth and length\",\n       subtitle = \"Dimensions for Adelie, Chinstrap, and Gentoo Penguins\",\n       x = \"Bill depth (mm)\", y = \"Bill length (mm)\")"
  },
  {
    "objectID": "content/lectures/04-ggplot2-slides.html#section-8",
    "href": "content/lectures/04-ggplot2-slides.html#section-8",
    "title": "04-ggplot2",
    "section": "",
    "text": "Start with the penguins data frame, map bill depth to the x-axis and map bill length to the y-axis. Represent each observation with a point and map species to the color of each point. Title the plot “Bill depth and length”, add the subtitle “Dimensions for Adelie, Chinstrap, and Gentoo Penguins”, label the x and y axes as “Bill depth (mm)” and “Bill length (mm)”, respectively, label the legend “Species”\n\n\n\nggplot(data = penguins,\n       mapping = aes(x = bill_depth_mm,\n                     y = bill_length_mm,\n                     color = species)) +\n  geom_point() +\n  labs(title = \"Bill depth and length\",\n       subtitle = \"Dimensions for Adelie, Chinstrap, and Gentoo Penguins\",\n       x = \"Bill depth (mm)\", y = \"Bill length (mm)\",\n       color = \"Species\")"
  },
  {
    "objectID": "content/lectures/04-ggplot2-slides.html#section-9",
    "href": "content/lectures/04-ggplot2-slides.html#section-9",
    "title": "04-ggplot2",
    "section": "",
    "text": "Start with the penguins data frame, map bill depth to the x-axis and map bill length to the y-axis. Represent each observation with a point and map species to the color of each point. Title the plot “Bill depth and length”, add the subtitle “Dimensions for Adelie, Chinstrap, and Gentoo Penguins”, label the x and y axes as “Bill depth (mm)” and “Bill length (mm)”, respectively, label the legend “Species”, and add a caption for the data source.\n\n\n\nggplot(data = penguins,\n       mapping = aes(x = bill_depth_mm,\n                     y = bill_length_mm,\n                     color = species)) +\n  geom_point() +\n  labs(title = \"Bill depth and length\",\n       subtitle = \"Dimensions for Adelie, Chinstrap, and Gentoo Penguins\",\n       x = \"Bill depth (mm)\", y = \"Bill length (mm)\",\n       color = \"Species\",\n       caption = \"Source: Palmer Station LTER / palmerpenguins package\")"
  },
  {
    "objectID": "content/lectures/04-ggplot2-slides.html#section-10",
    "href": "content/lectures/04-ggplot2-slides.html#section-10",
    "title": "04-ggplot2",
    "section": "",
    "text": "Start with the penguins data frame, map bill depth to the x-axis and map bill length to the y-axis. Represent each observation with a point and map species to the color of each point. Title the plot “Bill depth and length”, add the subtitle “Dimensions for Adelie, Chinstrap, and Gentoo Penguins”, label the x and y axes as “Bill depth (mm)” and “Bill length (mm)”, respectively, label the legend “Species”, and add a caption for the data source. Finally, use a discrete color scale that is designed to be perceived by viewers with common forms of color blindness.\n\n\n\nggplot(data = penguins,\n       mapping = aes(x = bill_depth_mm,\n                     y = bill_length_mm,\n                     color = species)) +\n  geom_point() +\n  labs(title = \"Bill depth and length\",\n       subtitle = \"Dimensions for Adelie, Chinstrap, and Gentoo Penguins\",\n       x = \"Bill depth (mm)\", y = \"Bill length (mm)\",\n       color = \"Species\",\n       caption = \"Source: Palmer Station LTER / palmerpenguins package\") +\n  scale_color_viridis_d()"
  },
  {
    "objectID": "content/lectures/04-ggplot2-slides.html#coding-out-loud-1",
    "href": "content/lectures/04-ggplot2-slides.html#coding-out-loud-1",
    "title": "04-ggplot2",
    "section": "Coding out loud",
    "text": "Coding out loud\n\nCodePlotNarrative\n\n\n\nggplot(data = penguins,\n       mapping = aes(x = bill_depth_mm,\n                     y = bill_length_mm,\n                     color = species)) +\n  geom_point() +\n  labs(title = \"Bill depth and length\",\n       subtitle = \"Dimensions for Adelie, Chinstrap, and Gentoo Penguins\",\n       x = \"Bill depth (mm)\", y = \"Bill length (mm)\",\n       color = \"Species\",\n       caption = \"Source: Palmer Station LTER / palmerpenguins package\") +\n  scale_color_viridis_d()\n\n\n\n\n\n\n\n\n\n\nStart with the penguins data frame, map bill depth to the x-axis and map bill length to the y-axis.\nRepresent each observation with a point and map species to the color of each point.\nTitle the plot “Bill depth and length”, add the subtitle “Dimensions for Adelie, Chinstrap, and Gentoo Penguins”, label the x and y axes as “Bill depth (mm)” and “Bill length (mm)”, respectively, label the legend “Species”, and add a caption for the data source.\nFinally, use a discrete color scale that is designed to be perceived by viewers with common forms of color blindness."
  },
  {
    "objectID": "content/lectures/04-ggplot2-slides.html#argument-names",
    "href": "content/lectures/04-ggplot2-slides.html#argument-names",
    "title": "04-ggplot2",
    "section": "Argument names",
    "text": "Argument names\n\n\n\n\n\n\nTip\n\n\nYou can omit the names of first two arguments when building plots with ggplot().\n\n\n\n\n\n\nggplot(data = penguins, \n       mapping = aes(x = bill_depth_mm,  \n                     y = bill_length_mm,\n                     color = species)) +\n  geom_point() +\n  scale_color_viridis_d()\n\n\n\nggplot(penguins, \n       aes(x = bill_depth_mm, \n           y = bill_depth_mm,\n           color = species)) +\n  geom_point() +\n  scale_color_viridis_d()"
  },
  {
    "objectID": "content/lectures/04-ggplot2-slides.html#your-turn",
    "href": "content/lectures/04-ggplot2-slides.html#your-turn",
    "title": "04-ggplot2",
    "section": "Your Turn",
    "text": "Your Turn\nGenerate a basic plot in ggplot2 using different variables than those in the last example (last example: bill_depth_mm & bill_depth_mm).\n\n\nPut a green sticky on the front of your computer when you’re done. Put a pink if you want help/have a question."
  },
  {
    "objectID": "content/lectures/04-ggplot2-slides.html#aesthetics-options",
    "href": "content/lectures/04-ggplot2-slides.html#aesthetics-options",
    "title": "04-ggplot2",
    "section": "Aesthetics options",
    "text": "Aesthetics options\nCommonly used characteristics of plotting characters that can be mapped to a specific variable in the data are\n\ncolor\nshape\nsize\nalpha (transparency)"
  },
  {
    "objectID": "content/lectures/04-ggplot2-slides.html#color",
    "href": "content/lectures/04-ggplot2-slides.html#color",
    "title": "04-ggplot2",
    "section": "Color",
    "text": "Color\n\nggplot(penguins,\n       aes(x = bill_depth_mm, \n           y = bill_length_mm,\n           color = species)) + \n  geom_point() +\n  scale_color_viridis_d()"
  },
  {
    "objectID": "content/lectures/04-ggplot2-slides.html#shape",
    "href": "content/lectures/04-ggplot2-slides.html#shape",
    "title": "04-ggplot2",
    "section": "Shape",
    "text": "Shape\nMapped to a different variable than color\n\nggplot(penguins,\n       aes(x = bill_depth_mm, \n           y = bill_length_mm,\n           color = species,\n           shape = island)) + \n  geom_point() +\n  scale_color_viridis_d()"
  },
  {
    "objectID": "content/lectures/04-ggplot2-slides.html#shape-1",
    "href": "content/lectures/04-ggplot2-slides.html#shape-1",
    "title": "04-ggplot2",
    "section": "Shape",
    "text": "Shape\nMapped to same variable as color\n\nggplot(penguins,\n       aes(x = bill_depth_mm, \n           y = bill_length_mm,\n           color = species,\n           shape = species)) + \n  geom_point() +\n  scale_color_viridis_d()"
  },
  {
    "objectID": "content/lectures/04-ggplot2-slides.html#size",
    "href": "content/lectures/04-ggplot2-slides.html#size",
    "title": "04-ggplot2",
    "section": "Size",
    "text": "Size\n\nggplot(penguins,\n       aes(x = bill_depth_mm, \n           y = bill_length_mm,\n           color = species,\n           shape = species,\n           size = body_mass_g)) + \n  geom_point() +\n  scale_color_viridis_d()"
  },
  {
    "objectID": "content/lectures/04-ggplot2-slides.html#alpha",
    "href": "content/lectures/04-ggplot2-slides.html#alpha",
    "title": "04-ggplot2",
    "section": "Alpha",
    "text": "Alpha\n\nggplot(penguins,\n       aes(x = bill_depth_mm, \n           y = bill_length_mm,\n           color = species,\n           shape = species,\n           size = body_mass_g,\n           alpha = flipper_length_mm)) + \n  geom_point() +\n  scale_color_viridis_d()"
  },
  {
    "objectID": "content/lectures/04-ggplot2-slides.html#mapping-vs.-setting",
    "href": "content/lectures/04-ggplot2-slides.html#mapping-vs.-setting",
    "title": "04-ggplot2",
    "section": "Mapping vs. setting",
    "text": "Mapping vs. setting\n\nMapping: Determine the size, alpha, etc. of points based on the values of a variable in the data\n\ngoes into aes()\n\nSetting: Determine the size, alpha, etc. of points not based on the values of a variable in the data\n\ngoes into geom_*() (this was geom_point() in the previous example, but we’ll learn about other geoms soon!)"
  },
  {
    "objectID": "content/lectures/04-ggplot2-slides.html#mapping-vs.-setting-example",
    "href": "content/lectures/04-ggplot2-slides.html#mapping-vs.-setting-example",
    "title": "04-ggplot2",
    "section": "Mapping vs. Setting (example)",
    "text": "Mapping vs. Setting (example)\n\n\nMapping\n\nggplot(penguins,\n       aes(x = bill_depth_mm,\n           y = bill_length_mm,\n           size = body_mass_g, \n           alpha = flipper_length_mm)) + \n  geom_point()\n\n\n\n\n\nSetting\n\nggplot(penguins,\n       aes(x = bill_depth_mm,\n           y = bill_length_mm)) + \n  geom_point(size = 2, alpha = 0.5)"
  },
  {
    "objectID": "content/lectures/04-ggplot2-slides.html#your-turn-1",
    "href": "content/lectures/04-ggplot2-slides.html#your-turn-1",
    "title": "04-ggplot2",
    "section": "Your Turn",
    "text": "Your Turn\nEdit the basic plot you created earlier to change something about its aesthetics.\n\n\nPut a green sticky on the front of your computer when you’re done. Put a pink if you want help/have a question."
  },
  {
    "objectID": "content/lectures/04-ggplot2-slides.html#faceting-1",
    "href": "content/lectures/04-ggplot2-slides.html#faceting-1",
    "title": "04-ggplot2",
    "section": "Faceting",
    "text": "Faceting\n\nSmaller plots that display different subsets of the data\nUseful for exploring conditional relationships and large data\n\n\n\n\n\n\n\n\nggplot(penguins, aes(x = bill_depth_mm, y = bill_length_mm)) + \n  geom_point() +\n  facet_grid(species ~ island)"
  },
  {
    "objectID": "content/lectures/04-ggplot2-slides.html#various-ways-to-facet",
    "href": "content/lectures/04-ggplot2-slides.html#various-ways-to-facet",
    "title": "04-ggplot2",
    "section": "Various ways to facet",
    "text": "Various ways to facet\n🧠 In the next few slides describe what each plot displays. Think about how the code relates to the output.\n\n\n\n\n\n\nWarning\n\n\nThe plots in the next few slides do not have proper titles, axis labels, etc. because we want you to figure out what’s happening in the plots. But you should always label your plots!"
  },
  {
    "objectID": "content/lectures/04-ggplot2-slides.html#section-11",
    "href": "content/lectures/04-ggplot2-slides.html#section-11",
    "title": "04-ggplot2",
    "section": "",
    "text": "ggplot(penguins, aes(x = bill_depth_mm, y = bill_length_mm)) + \n  geom_point() +\n  facet_grid(species ~ sex)"
  },
  {
    "objectID": "content/lectures/04-ggplot2-slides.html#section-12",
    "href": "content/lectures/04-ggplot2-slides.html#section-12",
    "title": "04-ggplot2",
    "section": "",
    "text": "ggplot(penguins, aes(x = bill_depth_mm, y = bill_length_mm)) + \n  geom_point() +\n  facet_grid(sex ~ species)"
  },
  {
    "objectID": "content/lectures/04-ggplot2-slides.html#section-13",
    "href": "content/lectures/04-ggplot2-slides.html#section-13",
    "title": "04-ggplot2",
    "section": "",
    "text": "ggplot(penguins, aes(x = bill_depth_mm, y = bill_length_mm)) + \n  geom_point() +\n  facet_wrap(~ species)"
  },
  {
    "objectID": "content/lectures/04-ggplot2-slides.html#section-14",
    "href": "content/lectures/04-ggplot2-slides.html#section-14",
    "title": "04-ggplot2",
    "section": "",
    "text": "ggplot(penguins, aes(x = bill_depth_mm, y = bill_length_mm)) + \n  geom_point() +\n  facet_grid(. ~ species)"
  },
  {
    "objectID": "content/lectures/04-ggplot2-slides.html#section-15",
    "href": "content/lectures/04-ggplot2-slides.html#section-15",
    "title": "04-ggplot2",
    "section": "",
    "text": "ggplot(penguins, aes(x = bill_depth_mm, y = bill_length_mm)) + \n  geom_point() +\n  facet_wrap(~ species, ncol = 2)"
  },
  {
    "objectID": "content/lectures/04-ggplot2-slides.html#faceting-summary",
    "href": "content/lectures/04-ggplot2-slides.html#faceting-summary",
    "title": "04-ggplot2",
    "section": "Faceting summary",
    "text": "Faceting summary\n\nfacet_grid():\n\n2d grid\nrows ~ cols\nuse . for no split\n\nfacet_wrap(): 1d ribbon wrapped according to number of rows and columns specified or available plotting area"
  },
  {
    "objectID": "content/lectures/04-ggplot2-slides.html#facet-and-color",
    "href": "content/lectures/04-ggplot2-slides.html#facet-and-color",
    "title": "04-ggplot2",
    "section": "Facet and color",
    "text": "Facet and color\n\nggplot(\n  penguins, \n  aes(x = bill_depth_mm, \n      y = bill_length_mm, \n      color = species)) + \n  geom_point() +\n  facet_grid(species ~ sex) +\n  scale_color_viridis_d()"
  },
  {
    "objectID": "content/lectures/04-ggplot2-slides.html#face-and-color-no-legend",
    "href": "content/lectures/04-ggplot2-slides.html#face-and-color-no-legend",
    "title": "04-ggplot2",
    "section": "Face and color, no legend",
    "text": "Face and color, no legend\n\nggplot(\n  penguins, \n  aes(x = bill_depth_mm, \n      y = bill_length_mm, \n      color = species)) +\n  geom_point() +\n  facet_grid(species ~ sex) +\n  scale_color_viridis_d() +\n  guides(color = FALSE)"
  },
  {
    "objectID": "content/lectures/04-ggplot2-slides.html#common-geoms",
    "href": "content/lectures/04-ggplot2-slides.html#common-geoms",
    "title": "04-ggplot2",
    "section": "Common geoms",
    "text": "Common geoms\n\n\n\ngeom 1\nDescription 2\n\n\n\n\ngeom_point\nscatterplot\n\n\ngeom_bar\nbarplot\n\n\ngeom_line\nline plot\n\n\ngeom_density\ndensityplot\n\n\ngeom_histogram\nhistogram\n\n\ngeom_boxplot\nboxplot\n\n\n\nggplot2 geoms listed hereWhen each visualization is appropriate here"
  },
  {
    "objectID": "content/lectures/04-ggplot2-slides.html#your-turn-2",
    "href": "content/lectures/04-ggplot2-slides.html#your-turn-2",
    "title": "04-ggplot2",
    "section": "Your Turn",
    "text": "Your Turn\nGenerate a plot in ggplot2 using a different geom than what you did previously. Customize as much as you can before time is “up.”\n\n\nPut a green sticky on the front of your computer when you’re done. Put a pink if you want help/have a question."
  },
  {
    "objectID": "content/lectures/04-ggplot2-slides.html#suggested-reading",
    "href": "content/lectures/04-ggplot2-slides.html#suggested-reading",
    "title": "04-ggplot2",
    "section": "Suggested Reading",
    "text": "Suggested Reading\n\nR4DS Chapter 3: Data Visualization\nData to Viz: https://www.data-to-viz.com/\n\n\n\n\nhttps://cogs137.github.io/website/"
  },
  {
    "objectID": "content/lectures/04-ggplot2.html",
    "href": "content/lectures/04-ggplot2.html",
    "title": "04-ggplot2",
    "section": "",
    "text": "Q:Can we have a demo in class on how to clone our repo and check if our Github submissions submitted properly? I am having trouble doing this.\nA: Yes! Let’s do that today.\n\n\nQ: Does left_join(a, b) = right_join(b, a)?\nA: No. The total information would be equivalent but the order of columns would differ. In the left join, the columns from a would be first and in the right join, the colums from b would be listed first. But the actual rows that are joined/included would be the same.\n\n\nQ: I would still like to know if there is a way to save data sets more often when using functions on them, such as filter. I see we only saved data sets when we use functions like mutate, but why not other functions?\nA: You’re allowed to store variables into a new data frame whenever you’d like! Now, the more variables you create, the more to keep track of, so I would encourage you to store your output any time you make a “substantial” change to your data. So, say you do a filter, selection, and mutate to get your data into the format for analysis. I wouldn’t store after each step, but I would store it after I wrote the pipe doing all three. Follow up if this doesn’t clarify!\n\n\nQ: I think the left_join, right_join, and full_join was pretty confusing.\nA: You’re right! It is confusing. We’ll go through more examples and get more practice!\n\n\n\n\nDue Dates:\n\nLab 03 due Friday (1/27; 11:59 PM)\nLecture Participation survey “due” after class\n\nCourse Announcements:\n\nHappy New Year!\nGitHub assignment clone + submission demo\nLab02 Notes:\n\nLook at the answer key:\ngrouping by name and year\ncan add text outside of code chunks; discuss variable reference\nsolutions to optional exercises\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot2 is tidyverse’s data visualization package\nStructure of the code for plots can be summarized as\n\n\nggplot(data = [dataset], \n       mapping = aes(x = [x-variable], \n                     y = [y-variable])) +\n   geom_xxx() +\n   other options\n\n\n\n\n\n\nMeasurements for penguin species, island in Palmer Archipelago, size (flipper length, body mass, bill dimensions), and sex.\n\n\n\n\n\n\n\n\n\n# install.packages(\"palmerpenguins\")\nlibrary(palmerpenguins)\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           <fct> Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel…\n$ island            <fct> Torgersen, Torgersen, Torgersen, Torgersen, Torgerse…\n$ bill_length_mm    <dbl> 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, …\n$ bill_depth_mm     <dbl> 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, …\n$ flipper_length_mm <int> 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186…\n$ body_mass_g       <int> 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, …\n$ sex               <fct> male, female, female, NA, female, male, female, male…\n$ year              <int> 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007…\n\n\n\n\n\n\nArtwork by @allison_horst \n\n\n\n\npenguins |>\n  datatable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = penguins, \n       mapping = aes(x = bill_depth_mm, y = bill_length_mm,\n                     color = species)) +\n  geom_point() +\n  labs(title = \"Bill depth and length\",\n       subtitle = \"Dimensions for Adelie, Chinstrap, and Gentoo Penguins\",\n       x = \"Bill depth (mm)\", y = \"Bill length (mm)\",\n       color = \"Species\") +\n  scale_color_viridis_d()\n\nWarning: Removed 2 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "content/lectures/04-ggplot2.html#section",
    "href": "content/lectures/04-ggplot2.html#section",
    "title": "04-ggplot2",
    "section": "",
    "text": "Start with the penguins data frame\n\n\nggplot(data = penguins)"
  },
  {
    "objectID": "content/lectures/04-ggplot2.html#section-1",
    "href": "content/lectures/04-ggplot2.html#section-1",
    "title": "04-ggplot2",
    "section": "",
    "text": "Start with the penguins data frame, map bill depth to the x-axis\n\n\nggplot(data = penguins,\n       mapping = aes(x = bill_depth_mm))"
  },
  {
    "objectID": "content/lectures/04-ggplot2.html#section-2",
    "href": "content/lectures/04-ggplot2.html#section-2",
    "title": "04-ggplot2",
    "section": "",
    "text": "Start with the penguins data frame, map bill depth to the x-axis and map bill length to the y-axis.\n\n\nggplot(data = penguins,\n       mapping = aes(x = bill_depth_mm,\n                     y = bill_length_mm))"
  },
  {
    "objectID": "content/lectures/04-ggplot2.html#section-3",
    "href": "content/lectures/04-ggplot2.html#section-3",
    "title": "04-ggplot2",
    "section": "",
    "text": "Start with the penguins data frame, map bill depth to the x-axis and map bill length to the y-axis. Represent each observation with a point\n\n\nggplot(data = penguins,\n       mapping = aes(x = bill_depth_mm,\n                     y = bill_length_mm)) + \n  geom_point()"
  },
  {
    "objectID": "content/lectures/04-ggplot2.html#section-4",
    "href": "content/lectures/04-ggplot2.html#section-4",
    "title": "04-ggplot2",
    "section": "",
    "text": "Start with the penguins data frame, map bill depth to the x-axis and map bill length to the y-axis. Represent each observation with a point and map species to the color of each point.\n\n\nggplot(data = penguins,\n       mapping = aes(x = bill_depth_mm,\n                     y = bill_length_mm,\n                     color = species)) + \n  geom_point()"
  },
  {
    "objectID": "content/lectures/04-ggplot2.html#section-5",
    "href": "content/lectures/04-ggplot2.html#section-5",
    "title": "04-ggplot2",
    "section": "",
    "text": "Start with the penguins data frame, map bill depth to the x-axis and map bill length to the y-axis. Represent each observation with a point and map species to the color of each point. Title the plot “Bill depth and length”\n\n\nggplot(data = penguins,\n       mapping = aes(x = bill_depth_mm,\n                     y = bill_length_mm,\n                     color = species)) +\n  geom_point() +\n  labs(title = \"Bill depth and length\")"
  },
  {
    "objectID": "content/lectures/04-ggplot2.html#section-6",
    "href": "content/lectures/04-ggplot2.html#section-6",
    "title": "04-ggplot2",
    "section": "",
    "text": "Start with the penguins data frame, map bill depth to the x-axis and map bill length to the y-axis. Represent each observation with a point and map species to the color of each point. Title the plot “Bill depth and length”, add the subtitle “Dimensions for Adelie, Chinstrap, and Gentoo Penguins”\n\n\nggplot(data = penguins,\n       mapping = aes(x = bill_depth_mm,\n                     y = bill_length_mm,\n                     color = species)) +\n  geom_point() +\n  labs(title = \"Bill depth and length\",\n       subtitle = \"Dimensions for Adelie, Chinstrap, and Gentoo Penguins\")"
  },
  {
    "objectID": "content/lectures/04-ggplot2.html#section-7",
    "href": "content/lectures/04-ggplot2.html#section-7",
    "title": "04-ggplot2",
    "section": "",
    "text": "Start with the penguins data frame, map bill depth to the x-axis and map bill length to the y-axis. Represent each observation with a point and map species to the color of each point. Title the plot “Bill depth and length”, add the subtitle “Dimensions for Adelie, Chinstrap, and Gentoo Penguins”, label the x and y axes as “Bill depth (mm)” and “Bill length (mm)”, respectively\n\n\nggplot(data = penguins,\n       mapping = aes(x = bill_depth_mm,\n                     y = bill_length_mm,\n                     color = species)) +\n  geom_point() +\n  labs(title = \"Bill depth and length\",\n       subtitle = \"Dimensions for Adelie, Chinstrap, and Gentoo Penguins\",\n       x = \"Bill depth (mm)\", y = \"Bill length (mm)\")"
  },
  {
    "objectID": "content/lectures/04-ggplot2.html#section-8",
    "href": "content/lectures/04-ggplot2.html#section-8",
    "title": "04-ggplot2",
    "section": "",
    "text": "Start with the penguins data frame, map bill depth to the x-axis and map bill length to the y-axis. Represent each observation with a point and map species to the color of each point. Title the plot “Bill depth and length”, add the subtitle “Dimensions for Adelie, Chinstrap, and Gentoo Penguins”, label the x and y axes as “Bill depth (mm)” and “Bill length (mm)”, respectively, label the legend “Species”\n\n\nggplot(data = penguins,\n       mapping = aes(x = bill_depth_mm,\n                     y = bill_length_mm,\n                     color = species)) +\n  geom_point() +\n  labs(title = \"Bill depth and length\",\n       subtitle = \"Dimensions for Adelie, Chinstrap, and Gentoo Penguins\",\n       x = \"Bill depth (mm)\", y = \"Bill length (mm)\",\n       color = \"Species\")"
  },
  {
    "objectID": "content/lectures/04-ggplot2.html#section-9",
    "href": "content/lectures/04-ggplot2.html#section-9",
    "title": "04-ggplot2",
    "section": "",
    "text": "Start with the penguins data frame, map bill depth to the x-axis and map bill length to the y-axis. Represent each observation with a point and map species to the color of each point. Title the plot “Bill depth and length”, add the subtitle “Dimensions for Adelie, Chinstrap, and Gentoo Penguins”, label the x and y axes as “Bill depth (mm)” and “Bill length (mm)”, respectively, label the legend “Species”, and add a caption for the data source.\n\n\nggplot(data = penguins,\n       mapping = aes(x = bill_depth_mm,\n                     y = bill_length_mm,\n                     color = species)) +\n  geom_point() +\n  labs(title = \"Bill depth and length\",\n       subtitle = \"Dimensions for Adelie, Chinstrap, and Gentoo Penguins\",\n       x = \"Bill depth (mm)\", y = \"Bill length (mm)\",\n       color = \"Species\",\n       caption = \"Source: Palmer Station LTER / palmerpenguins package\")"
  },
  {
    "objectID": "content/lectures/04-ggplot2.html#section-10",
    "href": "content/lectures/04-ggplot2.html#section-10",
    "title": "04-ggplot2",
    "section": "",
    "text": "Start with the penguins data frame, map bill depth to the x-axis and map bill length to the y-axis. Represent each observation with a point and map species to the color of each point. Title the plot “Bill depth and length”, add the subtitle “Dimensions for Adelie, Chinstrap, and Gentoo Penguins”, label the x and y axes as “Bill depth (mm)” and “Bill length (mm)”, respectively, label the legend “Species”, and add a caption for the data source. Finally, use a discrete color scale that is designed to be perceived by viewers with common forms of color blindness.\n\n\nggplot(data = penguins,\n       mapping = aes(x = bill_depth_mm,\n                     y = bill_length_mm,\n                     color = species)) +\n  geom_point() +\n  labs(title = \"Bill depth and length\",\n       subtitle = \"Dimensions for Adelie, Chinstrap, and Gentoo Penguins\",\n       x = \"Bill depth (mm)\", y = \"Bill length (mm)\",\n       color = \"Species\",\n       caption = \"Source: Palmer Station LTER / palmerpenguins package\") +\n  scale_color_viridis_d()"
  },
  {
    "objectID": "content/lectures/04-ggplot2.html#coding-out-loud-1",
    "href": "content/lectures/04-ggplot2.html#coding-out-loud-1",
    "title": "04-ggplot2",
    "section": "Coding out loud",
    "text": "Coding out loud\n\nCodePlotNarrative\n\n\n\nggplot(data = penguins,\n       mapping = aes(x = bill_depth_mm,\n                     y = bill_length_mm,\n                     color = species)) +\n  geom_point() +\n  labs(title = \"Bill depth and length\",\n       subtitle = \"Dimensions for Adelie, Chinstrap, and Gentoo Penguins\",\n       x = \"Bill depth (mm)\", y = \"Bill length (mm)\",\n       color = \"Species\",\n       caption = \"Source: Palmer Station LTER / palmerpenguins package\") +\n  scale_color_viridis_d()\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\nStart with the penguins data frame, map bill depth to the x-axis and map bill length to the y-axis.\nRepresent each observation with a point and map species to the color of each point.\nTitle the plot “Bill depth and length”, add the subtitle “Dimensions for Adelie, Chinstrap, and Gentoo Penguins”, label the x and y axes as “Bill depth (mm)” and “Bill length (mm)”, respectively, label the legend “Species”, and add a caption for the data source.\nFinally, use a discrete color scale that is designed to be perceived by viewers with common forms of color blindness."
  },
  {
    "objectID": "content/lectures/04-ggplot2.html#argument-names",
    "href": "content/lectures/04-ggplot2.html#argument-names",
    "title": "04-ggplot2",
    "section": "Argument names",
    "text": "Argument names\n\n\n\n\n\n\nTip\n\n\n\nYou can omit the names of first two arguments when building plots with ggplot().\n\n\n\n\n\nggplot(data = penguins, \n       mapping = aes(x = bill_depth_mm,  \n                     y = bill_length_mm,\n                     color = species)) +\n  geom_point() +\n  scale_color_viridis_d()\n\n\n\nggplot(penguins, \n       aes(x = bill_depth_mm, \n           y = bill_depth_mm,\n           color = species)) +\n  geom_point() +\n  scale_color_viridis_d()"
  },
  {
    "objectID": "content/lectures/04-ggplot2.html#your-turn",
    "href": "content/lectures/04-ggplot2.html#your-turn",
    "title": "04-ggplot2",
    "section": "Your Turn",
    "text": "Your Turn\nGenerate a basic plot in ggplot2 using different variables than those in the last example (last example: bill_depth_mm & bill_depth_mm).\n\n\nPut a green sticky on the front of your computer when you’re done. Put a pink if you want help/have a question."
  },
  {
    "objectID": "content/lectures/04-ggplot2.html#aesthetics-options",
    "href": "content/lectures/04-ggplot2.html#aesthetics-options",
    "title": "04-ggplot2",
    "section": "Aesthetics options",
    "text": "Aesthetics options\nCommonly used characteristics of plotting characters that can be mapped to a specific variable in the data are\n\ncolor\nshape\nsize\nalpha (transparency)"
  },
  {
    "objectID": "content/lectures/04-ggplot2.html#color",
    "href": "content/lectures/04-ggplot2.html#color",
    "title": "04-ggplot2",
    "section": "Color",
    "text": "Color\n\nggplot(penguins,\n       aes(x = bill_depth_mm, \n           y = bill_length_mm,\n           color = species)) + \n  geom_point() +\n  scale_color_viridis_d()"
  },
  {
    "objectID": "content/lectures/04-ggplot2.html#shape",
    "href": "content/lectures/04-ggplot2.html#shape",
    "title": "04-ggplot2",
    "section": "Shape",
    "text": "Shape\nMapped to a different variable than color\n\nggplot(penguins,\n       aes(x = bill_depth_mm, \n           y = bill_length_mm,\n           color = species,\n           shape = island)) + \n  geom_point() +\n  scale_color_viridis_d()"
  },
  {
    "objectID": "content/lectures/04-ggplot2.html#shape-1",
    "href": "content/lectures/04-ggplot2.html#shape-1",
    "title": "04-ggplot2",
    "section": "Shape",
    "text": "Shape\nMapped to same variable as color\n\nggplot(penguins,\n       aes(x = bill_depth_mm, \n           y = bill_length_mm,\n           color = species,\n           shape = species)) + \n  geom_point() +\n  scale_color_viridis_d()"
  },
  {
    "objectID": "content/lectures/04-ggplot2.html#size",
    "href": "content/lectures/04-ggplot2.html#size",
    "title": "04-ggplot2",
    "section": "Size",
    "text": "Size\n\nggplot(penguins,\n       aes(x = bill_depth_mm, \n           y = bill_length_mm,\n           color = species,\n           shape = species,\n           size = body_mass_g)) + \n  geom_point() +\n  scale_color_viridis_d()"
  },
  {
    "objectID": "content/lectures/04-ggplot2.html#alpha",
    "href": "content/lectures/04-ggplot2.html#alpha",
    "title": "04-ggplot2",
    "section": "Alpha",
    "text": "Alpha\n\nggplot(penguins,\n       aes(x = bill_depth_mm, \n           y = bill_length_mm,\n           color = species,\n           shape = species,\n           size = body_mass_g,\n           alpha = flipper_length_mm)) + \n  geom_point() +\n  scale_color_viridis_d()"
  },
  {
    "objectID": "content/lectures/04-ggplot2.html#mapping-vs.-setting",
    "href": "content/lectures/04-ggplot2.html#mapping-vs.-setting",
    "title": "04-ggplot2",
    "section": "Mapping vs. setting",
    "text": "Mapping vs. setting\n\nMapping: Determine the size, alpha, etc. of points based on the values of a variable in the data\n\ngoes into aes()\n\nSetting: Determine the size, alpha, etc. of points not based on the values of a variable in the data\n\ngoes into geom_*() (this was geom_point() in the previous example, but we’ll learn about other geoms soon!)"
  },
  {
    "objectID": "content/lectures/04-ggplot2.html#mapping-vs.-setting-example",
    "href": "content/lectures/04-ggplot2.html#mapping-vs.-setting-example",
    "title": "04-ggplot2",
    "section": "Mapping vs. Setting (example)",
    "text": "Mapping vs. Setting (example)\n\n\nMapping\n\nggplot(penguins,\n       aes(x = bill_depth_mm,\n           y = bill_length_mm,\n           size = body_mass_g, \n           alpha = flipper_length_mm)) + \n  geom_point()\n\n\n\n\n\nSetting\n\nggplot(penguins,\n       aes(x = bill_depth_mm,\n           y = bill_length_mm)) + \n  geom_point(size = 2, alpha = 0.5)"
  },
  {
    "objectID": "content/lectures/04-ggplot2.html#your-turn-1",
    "href": "content/lectures/04-ggplot2.html#your-turn-1",
    "title": "04-ggplot2",
    "section": "Your Turn",
    "text": "Your Turn\nEdit the basic plot you created earlier to change something about its aesthetics.\n\n\nPut a green sticky on the front of your computer when you’re done. Put a pink if you want help/have a question."
  },
  {
    "objectID": "content/lectures/04-ggplot2.html#faceting-1",
    "href": "content/lectures/04-ggplot2.html#faceting-1",
    "title": "04-ggplot2",
    "section": "Faceting",
    "text": "Faceting\n\nSmaller plots that display different subsets of the data\nUseful for exploring conditional relationships and large data\n\n\n\n\n\n\n\n\nggplot(penguins, aes(x = bill_depth_mm, y = bill_length_mm)) + \n  geom_point() +\n  facet_grid(species ~ island) \n\nWarning: Removed 2 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "content/lectures/04-ggplot2.html#various-ways-to-facet",
    "href": "content/lectures/04-ggplot2.html#various-ways-to-facet",
    "title": "04-ggplot2",
    "section": "Various ways to facet",
    "text": "Various ways to facet\n🧠 In the next few slides describe what each plot displays. Think about how the code relates to the output.\n\n\n\n\n\n\nWarning\n\n\n\nThe plots in the next few slides do not have proper titles, axis labels, etc. because we want you to figure out what’s happening in the plots. But you should always label your plots!"
  },
  {
    "objectID": "content/lectures/04-ggplot2.html#section-11",
    "href": "content/lectures/04-ggplot2.html#section-11",
    "title": "04-ggplot2",
    "section": "",
    "text": "ggplot(penguins, aes(x = bill_depth_mm, y = bill_length_mm)) + \n  geom_point() +\n  facet_grid(species ~ sex)"
  },
  {
    "objectID": "content/lectures/04-ggplot2.html#section-12",
    "href": "content/lectures/04-ggplot2.html#section-12",
    "title": "04-ggplot2",
    "section": "",
    "text": "ggplot(penguins, aes(x = bill_depth_mm, y = bill_length_mm)) + \n  geom_point() +\n  facet_grid(sex ~ species)"
  },
  {
    "objectID": "content/lectures/04-ggplot2.html#section-13",
    "href": "content/lectures/04-ggplot2.html#section-13",
    "title": "04-ggplot2",
    "section": "",
    "text": "ggplot(penguins, aes(x = bill_depth_mm, y = bill_length_mm)) + \n  geom_point() +\n  facet_wrap(~ species)"
  },
  {
    "objectID": "content/lectures/04-ggplot2.html#section-14",
    "href": "content/lectures/04-ggplot2.html#section-14",
    "title": "04-ggplot2",
    "section": "",
    "text": "ggplot(penguins, aes(x = bill_depth_mm, y = bill_length_mm)) + \n  geom_point() +\n  facet_grid(. ~ species)"
  },
  {
    "objectID": "content/lectures/04-ggplot2.html#section-15",
    "href": "content/lectures/04-ggplot2.html#section-15",
    "title": "04-ggplot2",
    "section": "",
    "text": "ggplot(penguins, aes(x = bill_depth_mm, y = bill_length_mm)) + \n  geom_point() +\n  facet_wrap(~ species, ncol = 2)"
  },
  {
    "objectID": "content/lectures/04-ggplot2.html#faceting-summary",
    "href": "content/lectures/04-ggplot2.html#faceting-summary",
    "title": "04-ggplot2",
    "section": "Faceting summary",
    "text": "Faceting summary\n\nfacet_grid():\n\n2d grid\nrows ~ cols\nuse . for no split\n\nfacet_wrap(): 1d ribbon wrapped according to number of rows and columns specified or available plotting area"
  },
  {
    "objectID": "content/lectures/04-ggplot2.html#facet-and-color",
    "href": "content/lectures/04-ggplot2.html#facet-and-color",
    "title": "04-ggplot2",
    "section": "Facet and color",
    "text": "Facet and color\n\nggplot(\n  penguins, \n  aes(x = bill_depth_mm, \n      y = bill_length_mm, \n      color = species)) + \n  geom_point() +\n  facet_grid(species ~ sex) +\n  scale_color_viridis_d()"
  },
  {
    "objectID": "content/lectures/04-ggplot2.html#face-and-color-no-legend",
    "href": "content/lectures/04-ggplot2.html#face-and-color-no-legend",
    "title": "04-ggplot2",
    "section": "Face and color, no legend",
    "text": "Face and color, no legend\n\nggplot(\n  penguins, \n  aes(x = bill_depth_mm, \n      y = bill_length_mm, \n      color = species)) +\n  geom_point() +\n  facet_grid(species ~ sex) +\n  scale_color_viridis_d() +\n  guides(color = FALSE)"
  },
  {
    "objectID": "content/lectures/04-ggplot2.html#common-geoms",
    "href": "content/lectures/04-ggplot2.html#common-geoms",
    "title": "04-ggplot2",
    "section": "Common geoms",
    "text": "Common geoms\n\n\n\ngeom 1\nDescription 2\n\n\n\n\ngeom_point\nscatterplot\n\n\ngeom_bar\nbarplot\n\n\ngeom_line\nline plot\n\n\ngeom_density\ndensityplot\n\n\ngeom_histogram\nhistogram\n\n\ngeom_boxplot\nboxplot"
  },
  {
    "objectID": "content/lectures/04-ggplot2.html#your-turn-2",
    "href": "content/lectures/04-ggplot2.html#your-turn-2",
    "title": "04-ggplot2",
    "section": "Your Turn",
    "text": "Your Turn\nGenerate a plot in ggplot2 using a different geom than what you did previously. Customize as much as you can before time is “up.”\n\n\nPut a green sticky on the front of your computer when you’re done. Put a pink if you want help/have a question."
  },
  {
    "objectID": "content/lectures/04-ggplot2.html#suggested-reading",
    "href": "content/lectures/04-ggplot2.html#suggested-reading",
    "title": "04-ggplot2",
    "section": "Suggested Reading",
    "text": "Suggested Reading\n\nR4DS Chapter 3: Data Visualization\nData to Viz: https://www.data-to-viz.com/"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "COGS 137: Practical Data Science in R",
    "section": "",
    "text": "Course Info\nPractical Data Science in R focuses on teaching students how to think rigorously throughout the data science process. To this end, through interaction with unique data sets and interesting questions, this course helps students 1) gain fluency in the R programming language, 2) effectively explore & visualize data, 3) use statistical thinking to analyze data and rigorously evaluate their conclusions, and 4) effectively communicate their results. Course objectives are accomplished through hands-on practice, using real-world data to learn via case studies, and project-based learning.\n\nDays & Times\n\n\n\n\n\n Lecture: Tu/Th 2-3:20 (Peterson Hall 104)\n Lab: Fri 1-1:50 (Peterson Hall 104)\n\nInstructional Staff & Office Hours\n\n\n\nInstructor\nShannon Ellis\nsellis@ucsd.edu\nWed 2-3\nVirtual (see canvas)\n\n\n\n\n\nTh 12:50-1:50 PM\nCSB 243\n\n\nTA\nShubham Kulkarni\n\nF 12-1PM\nCSB 114\n\n\nIAs\nChristian Kim\n\nTh 11AM-12PM\nCSB 114\n\n\n\n\n\n\n\nCourse Objectives\n\nProgram at the introductory level in the R statistical programming language\nEmploy the tidyverse suite of packages to interact with, wrangle, visualize, and model data\nExplain & apply statistical concepts (estimation, linear regression, logistic regression, etc.) for data analysis\nCommunicate data science projects through effective visualization, oral presentation, and written reports\n\n\n\nTexts\nTexts are freely available online:\n\n\n\nIntroduction to Modern Statistics\nÇetinkaya-Rundel and Hardin\nOpenIntro, 1st Edition, 2021\n\n\nR for Data Science\nGrolemund and Wickham\nO’Reilly, 1st edition, 2016\n\n\n\n\n\nMaterials\nYou should have access to a laptop and bring it to every class, fully charged (as possible).\nNote: If you do not have consistent access to the technology needed, please use this form to request a loaner laptop. (For any issues that you may have, please email vcsa@ucsd.edu, and they will work to assist you.)\n\n\nAcknowledgements\nI want to first recognize Dr. Mine Çetinkaya-Rundeland for her unparalleled efforts in support of education and educators in data science, statistics, and R programming. This course website was adapted from her course website. These course slides/labs/homework…also adapted from Mine’s course and the related datascienceinabox. I am so *very* indebted to Mine! I also want to thank the Open Case Studies team for their tireless work in putting together interesting and topical case studies, a handful of which we use throughout the course. And, finally, thanks to Allison Horst, whose artwork is inspiring, educational, and fun…and is used throughout this course. Further, thanks to the R (education) community generally; planning this course was really fun because I had so many awesome resources to choose from. Having these materials made course prep and planning is just another example of what sets the R community apart!"
  },
  {
    "objectID": "policies.html",
    "href": "policies.html",
    "title": "COGS 137",
    "section": "",
    "text": "Class\nClass will include short lectures as well as interactive activities. The goal of lecture is to introduce the topics and information needed for the course. The goal of your time outside of lecture is to practice with topics that are introduced and deepen your understanding of material presented in class. Since so much of programming and statistical analysis is learned best by doing, we’ll prioritize that throughout the course, both in and outside of the classroom.\n\n\nDiversity & Inclusion\nMy goal is that every student, regardless of their background or perspective, will be well-served by this course. My philosophy is that the diversity of students in this class is a huge asset to our learning community; our differences provide opportunities for learning and understanding. I intend to present course materials that are conscious of and respectful to diversity (gender identity, sexuality, disability, age, socioeconomic status, ethnicity, race, nationality, religion, politics, and culture); however, if I ever fall short or if you ever have suggestions for improvement, please do share with me! This feedback is always welcomed, and I am always in the process of learning and improving to this end. If you would like to provide that feedback anonymously, please use the anonymous Google Form.*\n\nWhat should you call me?\nMost students call me Professor/Prof Ellis, and that’s great! This is how I typically sign emails to students. I’m also totally OK with you addressing me as Shannon or Dr. Ellis.\n\n\nWhat I should call you?\nI should call you by your preferred name, with the correct pronunciation. Please correct me (in the moment or via email/Campuswire after the fact…however you’re most comfortable) if I ever make a mistake.\n\n\n\nDisability Access\nStudents requesting accommodations due to a disability should provide a current Authorization for Accommodation (AFA) letter. These letters are issued by the Office for Students with Disabilities (OSD), which is located in University Center 202 behind Center Hall. If you are struggling to get necessary accommodations or want to further discuss your accommodations, please feel free to reach out to Professor Ellis directly.\nContacting the OSD can help you further:\n858.534.4382 (phone)\nosd@ucsd.edu (email)\nhttp://disabilities.ucsd.edu\n\n\nHow to get help\nIt’s great that we have so many ways to communicate, but it can get tricky to figure out who to contact or where your question belongs or when to expect a response. These guidelines are to help you get your question answered as quickly as possible and to ensure that we’re able to get to everyone’s questions.\nThat said, to ensure that we’re respecting their time, TAs and IAs have been instructed they’re only encouraged to answer questions between standard working hours (M-F 9AM-5PM). Professor Ellis is also going to do her best to stick to these working hours and only go on Campuswire M-F each week. However, we know that’s not necessarily when you may be doing your work. So, please feel free to post whenever is best for you while knowing that if you post late at night or on a weekend, you may not get a response until the next weekday. As such, do your best not to wait until the last minute to ask a question.\nIf you have:\n\nquestions about course content - these are awesome! We want everyone to see them and have their questions answered too, so post these to Campuswire!\na technical assignment question - come to office hours (or post to Campuswire). Answering technical questions is often best accomplished ‘in person’ where we can discuss the question and talk through ideas. However, if that is not possible, post your question to Campuswire. Be as specific as you can in the question you ask. And, for those answering, help your classmates as much as you can without just giving the answer. Help guide them, point them in a direction, provide pseudo code, but do not provide code that answers assignment questions.\nbeen stuck on something for a while (>30min) and aren’t even really sure where to start - Programming can be frustrating and it may not always be obvious what is going wrong or why something isn’t working. That’s OK - we’ve all been there! If you are stuck, you can and should reach out for help, even if you aren’t exactly sure what your specific question is. To determine when to reach out, consider the 2-hour rule. This rule states that if you are stuck, work on that problem for an hour. Then, take a 30 minute break and do something else. When you come back after your break, try for another 30 minutes or so to solve your problem. If you are still completely stuck, stop and contact us (office hours, post on Campuswire). If you don’t have a specific question, include the information you have (what you’re stuck on, the code you’ve been trying that hasn’t been happening, and/or the error messages you’ve been getting).\nquestions about course logistics - first, check the course website. If you can’t find the answer there, first ask a classmate. If still unsure, post on Campuswire.\nquestions about a grade - Post on Campuswire with “regrades” tag in a private post to “Instructors & TAs”.\nsomething super cool to share related to class or want to talk about a topic in further depth - feel free to email Professor Ellis (sellis@ucsd.edu) or come to office hours. Please include COGS137 in the email subject line.\nsome feedback about the course you want to share anonymously - If you’ve been offended by an example in class, really liked or disliked a lesson, or wish there were something covered in class that wasn’t but would rather not share this publicly, etc., please fill out the anonymous Google Form*\n\n*This form can be taken down at any time if it’s not being used for its intended purpose; however, you all will be notified should that happen.\n\n\nAcademic integrity\nDon’t cheat.\nYou are generally encouraged to work together and help one another in this course. However, you are personally responsible for the work you submit. A helpful heuristic can b to ask yourself “Can I explain each piece of code and each analysis carried out in what I’m submitting? Could I reproduce this code/analysis on my own?”; you should be able to answer “Yes” to both questions for everything you submit in this course. For labs and assignments, you are allowed and encouraged to work together, but it is your responsibility to ensure you understand everything you’ve submitted. (For exams, all work has to be completed individually and communication with others about the exam is not allowed; this will be discussed more explicitly before exams.)\nA note on sharing / reusing code: The Internet is an excellent resource; there will be many times you find helpful information online. You should use available resources (e.g. StackOverflow), but you must explicitly cite any code you use directly or any code you use as inspiration. This can be done by including the URL/reference to the source directly in your code (as a code comment) or in accompanying text for a given assignment/exam/lab. You should never share code directly (e.g. copy + paste; share an send an answer to a classmate), but you can discuss code and work together on everything other than take-home exams.\nPlease review UCSD’s academic integrity policies here.\nCheating and plagiarism have been and will be strongly penalized. If, for whatever reason, Canvas or DataHub is down or something else prohibits you from being able to turn in an assignment on time, immediately contact Professor Ellis by emailing your assignment (sellis@ucsd.edu), or else it will be graded as late.\n\n\nCourse components\n\nLecture\nLectures will be your introduction to course topics and material. Lectures will be interactive, and you will be given time to practice with the lecture concepts during class. Attendance is not required, but is encouraged if you’re feeling well. To help incentivize coming to class, there will be a daily participation survey that will open at the end of lecture and close shortly after each Tues/Thurs lecture. Each time you fill out the lecture survey, you get a small % of credit toward your final project Completion of all surveys can provide up to 3.5% extra credit on your final project (not your final course grade).\n\nReadings\nReadings will be assigned for some class days and are best completed prior to the day’s lecture. These are meant to provide background and additional context for the upcoming day’s lecture topics. These can also be a good source after class when studying or reviewing topics discussed in class.\n\n\nPodcast\nIn case you miss class or would like to review the material covered in class, you can view the podcasts here.\n\n\n\nLabs (16%)\nLabs are meant to give you deeper understanding and hands-on experience with the technical and statistical topics introduced during lecture in a low-stakes environment. Lab sections will typically comprise of a short review and explanation of the lab and then time for you to complete the assigned weekly lab. Labs are submitted individually, but you are encouraged to work together during lab. You are free to ask and answer each others’ questions and discuss your work. Instructional staff will be present during lab to help further your understanding.\nLabs are graded for concerted effort. This is because when we learn something new, mistakes are going to happen! In fact, we learn a lot from the mistakes we make during the learning process. If your submission reflects ~50 min of work/effort, you will receive full credit for the week’s lab.\nLab attendance is not required, but is definitely encouraged if you are feeling well. While slides used are shared, lab sessions are not recorded, so being present is the best way to fully engage in the course.\n\n\nHomework (32%)\nAfter practice in lecture and labs, homework assignments are meant to demonstrate your solidified understanding of the course material. These are typically 2-4x longer and more involved than labs. Homework assignments are completed and submitted individually and are marked for correctness. You are allowed to work together on homework assignments, but academic integrity must be upheld.\n\n\nMidterm (15%)\nThere will be a single take-home exam due in week 4, and you will have at least 48 hours to complete it. This exam is meant to assess your understanding of the R programming language prior to us moving into focusing on case studies and full analyses. The exam will be completed individually and will be open-notes and open-Internet; however, you will not be permitted to ask questions of one another, the Internet, nor instructional staff while completing the take-home exam.\n\n\nTeams\nThere will be two case study mini-projects and a final project. Teams will be randomly assigned for the mini-projects but you will choose your final project groups. (By working with teammates throughout the course, you will also be able to use one another as a resource during labs and assignments.)\n\n\nCase Study Mini-projects (20%)\nStarting week 5, we will transition to a project-based course. This will allow us to use case studies to focus on deepening statistical knowledge and carrying out interesting analyses. In this, specific case studies and statistics topics will be discussed in class. In your teams and for each of the case studies, you will: 1) extend the analysis from class and 2) write up a full report of the case study for your team project.\n\n\nFinal Project (17%)\nThe final project will be completed in groups. There will be two different general final projects from which your group can choose, but the idea is that whichever you choose, you will be able to tackle it using and building upon the tools and techniques discussed in class. Briefly here, the two options will be: 1. Create a technical presentation on a statistics topic and/or an R package. 2. Carry out a data analysis.\nEach will require a written report and an oral presentation, but the specific requirements will differ between the two.\nFinal Projects will be due on Th 3/23 of finals week at 11:59 PM.\n\n\n\nGrading\nYour final grade will be comprised of the following:\n\n\n\nLabs (8)\n16%\n\n\nHomework (4)\n32%\n\n\nMidterm (1)\n16%\n\n\nCase Study Projects* (2)\n20%\n\n\nFinal Project(*) (1)\n17%\n\n\n\n* indicates group submission\n\nFinal Grades\nTo calculate final grades, I use the standard grading scale and do not round grades up (given the numerous extra credit opportunities offered):\n\n\n\n97-100%\nA+\n\n\n93-96%\nA\n\n\n90-92%\nA-\n\n\n87-89%\nB+\n\n\n83-86%\nB\n\n\n80-82%\nB-\n\n\n77-79%\nC+\n\n\n73-76%\nC\n\n\n70-72%\nC-\n\n\n67-69%\nD+\n\n\n63-66%\nD\n\n\n60-62%\nD-\n\n\n<60%\nF\n\n\n\n\n\n\nLate / missed work\nLate homework assignments and case study projects will be accepted up to 3 days (72 hours) after the assigned deadline. Late submissions will receive a 25% deduction.\nThere are no late deadlines for labs, the exam, or the final project.\nNote: Prof Ellis is a reasonable person; reach out to her if you have an extenuating circumstance at any point in the quarter.\n\n\nRegrade requests\nWe will work hard to grade everyone fairly and return assignments quickly. And, we know you also work hard and want you to receive the grade you’ve earned. Occasionally, grading mistakes do happen, and it’s important to us to correct them. If you think there is a mistake in your grade on an assignment, post privately on Campuswire to “Instructors” using the “regrades” tag within 72 hours. This post should include evidence of why you think your answer was correct and should point to the specific part of the assignment in question.\n\n\nProfessionalism\nPlease refrain from texting or using your computer for anything other than coursework during class. Not only is this distracting to you, but it can also be distracting to those around you. (Note that there is no consequence associated with this. I know it can be difficult, but I ask that you try your best!)"
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "COGS 137",
    "section": "",
    "text": "Week\nDate\nTitle\nType\n\n\n\n\n1\nTu Jan 10\nWelcome & Tooling\nLecture\n\n\n1\nTh Jan 12\nIntro to R\nLecture\n\n\n1\nFri Jan 13\nLab 01: Intro to R\nLab\n\n\n2\nTu Jan 17\nData Wrangling: dplyr\nLecture\n\n\n2\nTh Jan 19\nData Wrangling: tidyr\nLecture\n\n\n2\nFri Jan 20\nLab 02: Data Wrangling\nLab\n\n\n3\nMon Jan 23\nHW01 due (11:59 PM)\nHW\n\n\n3\nTu Jan 24\nData Visualization: ggplot2 (day 1)\nLecture\n\n\n3\nTh Jan 26\nData Visualization: ggplot2 (day 2)\nLecture\n\n\n3\nFri Jan 27\nLab 03: Data Visualization\nLab\n\n\n4\nTu Jan 31\nData Analysis & Modeling\nLecture\n\n\n4\nTh Feb 2\nLinear Models Review\nLecture\n\n\n4\nFri Feb 3\nLab 04: Modeling\nLab\n\n\n5\nMon Feb 6\nHW02 due (11:59 PM)\nHW\n\n\n5\nTu Feb 7\nEffective Communication\nLecture\n\n\n5\nTh Feb 9\nCase Study & Final Project Info\nLecture\n\n\n5\nFri Feb 10\nLab used for midterm review\nLab\n\n\n6\nMon Feb 13\nMIDTERM EXAM (due 11:59 PM) \nExam\n\n\n6\nTu Feb 14\nMultiple Linear Regression\nLecture\n\n\n6\nTh Feb 16\nCase Study 01: Right to Carry (day 1)\nLecture\n\n\n6\nFri Feb 17\nLab 05: Multiple Linear Regression\nLab\n\n\n7\nTu Feb 21\nCase Study 01: Right to Carry (day 2)\nLecture\n\n\n7\nTh Feb 23\nCase Study 01: Right to Carry (day 3)\nLecture\n\n\n7\nFri Feb 24\nLab 06: CS01\nLab\n\n\n8\nMon Feb 27\nHW03 due (11:59 PM)\nHW\n\n\n8\nTu Feb 28\nLogistic Regression (day 1)\nLecture\n\n\n8\nTh Mar 2\nLogistic Regression (day 2)\nLecture\n\n\n8\nFri Mar 3\nLab 07: Logistic Regression\nLab\n\n\n9\nMon Mar 6\nCS01 Due (11:59 PM)\nCase Study\n\n\n9\nTu Mar 7\nCase Study 02: Vaping (day 1)\nLecture\n\n\n9\nTh Mar 9\nCase Study 02: Vaping (day 2)\nLecture\n\n\n9\nFri Mar 10\nLab 08: CS02\nLab\n\n\n10\nMon Mar 13\nHW04 due (11:59 PM)\nHW\n\n\n10\nTu Mar 14\nFinal Project Brainstorming\nLecture\n\n\n10\nTh Mar 16\nNext Steps\nLecture\n\n\n10\nFri Mar 17\nLab used for Final Project\nLab\n\n\nFinals\nMon Mar 20\nCS02 Due\nCase Study\n\n\nFinals\nTh Mar 23\nFinal Project Due (11:59 PM)\nLecture"
  }
]