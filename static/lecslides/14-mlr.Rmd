---
title: "Multiple linear regression + Model selection"
author: "Prof Ellis"
date: "2021-11-02"
output:
  xaringan::moon_reader:
    css: "slides.css"
    logo: img/cogs137-logo-hex.png
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r packages, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(tidymodels)
library(broom)
library(knitr)
library(DT)
library(googlesheets4)
library(plotly)
library(widgetframe)
library(patchwork)
library(RColorBrewer)
# For nonsese...
library(emo)

set.seed(1234)
options(dplyr.print_min = 10, dplyr.print_max = 6)
# Set dpi and height for images
opts_chunk$set(fig.height = 2.5, fig.width = 5, dpi = 300, warning=FALSE, message=FALSE) 


options(gargle_oauth_email = "sellis@ucsd.edu")
```

```{r child = "setup.Rmd"}
```


## Course Announcements

- hw02 grades posted; (grades on Canvas; comments in issue on GitHub)
- cs01 due Monday

--

- mid-course survey
  - Thanks to those who completed! (N=39; 75% response rate)
  - EC has been posted
  
---

### Time Spent

```{r, echo=FALSE, warning=FALSE, message=FALSE, out.width = "100%"}
survey <- read_sheet('1BORwAZ3V1tTR1hsqlaSxMyFJd7g42JwgmoV5TPPLiVQ')

hw01 <- ggplot(survey, aes(x=`Approximately how many hours did you spend completing hw01?`)) + geom_histogram(binwidth=0.5) + theme_classic(base_size = 8) + geom_vline(xintercept = median(survey$`Approximately how many hours did you spend completing hw01?`), col='#92a86a', size=1) + labs(title = 'Most students spent ~2.5h completing hw01', x='Hours spent completing hw01') + scale_x_continuous(n.breaks=14) + theme(plot.title.position = 'plot')

hw02 <- ggplot(survey, aes(x=`Approximately how many hours did you spend completing hw02?`)) + geom_histogram(binwidth=0.5) + theme_classic(base_size = 8) + geom_vline(xintercept = median(survey$`Approximately how many hours did you spend completing hw02?`), col='#92a86a', size=1) + labs(title = 'Most students spent ~2-6h completing hw02', x='Hours spent completing hw02') + scale_x_continuous(n.breaks=14) + theme(plot.title.position = 'plot', axis.title.y = element_blank()) 

midterm_complete <- ggplot(survey, aes(x=`Approximately how many hours did you spend completing the midterm?`)) + geom_histogram(binwidth=0.5) + theme_classic(base_size = 8) + geom_vline(xintercept = median(survey$`Approximately how many hours did you spend completing the midterm?`), col='#92a86a', size=1) + labs(title = 'Most students spent  ~6h completing the midterm', x='Hours spent completing the midterm') + scale_x_continuous(n.breaks=14) + theme(plot.title.position = 'plot', axis.title.y = element_blank())

midterm_study <- ggplot(survey, aes(x=`Approximately how many hours did you spend studying for the midterm?`)) + geom_histogram(binwidth=0.5) + theme_classic(base_size = 8) + geom_vline(xintercept = median(survey$`Approximately how many hours did you spend studying for the midterm?`), col='#92a86a', size=1) + labs(title = 'Most students spent  ~2h studying for the midterm', x='Hours spent studying for the midterm') + theme(plot.title.position = 'plot')

hw01 + hw02 + midterm_study + midterm_complete
```

---

### Difficulty

```{r, echo=FALSE, out.width = "100%"}
response_levels <- c("Very Easy", "Fairly Easy", "About Right", "Fairly Hard", "Very Hard")
pal<-rev(c('#ca0020', '#f4a582', '#f7f7f7', '#92c5de', '#0571b0'))


survey$hw01 <- fct_relevel(factor(survey$`How difficult did you find... [hw01]`, levels = response_levels))
survey$hw02 <- fct_relevel(factor(survey$`How difficult did you find... [hw02]`, levels = response_levels))
survey$midterm <- fct_relevel(factor(survey$`How difficult did you find... [midterm]`, levels = response_levels))


hw01 <- ggplot(survey, aes(x=hw01, fill=hw01)) + geom_bar(color = "black") + scale_x_discrete(drop=FALSE) + scale_fill_manual(values = rev(c('#ca0020', '#f4a582', '#f7f7f7', '#92c5de', '#0571b0'))) +  theme_classic(base_size = 9) + labs(title = 'Students did not find hw01 to be particularly difficult') + theme(plot.title.position = 'plot', axis.title.x = element_blank(), axis.text.x = element_blank(), legend.position = "none")

hw02 <- ggplot(survey, aes(x=hw02, fill=hw02)) + geom_bar(color = "black") + scale_x_discrete(drop=FALSE) + scale_fill_manual(values = rev(c('#ca0020', '#f4a582', '#f7f7f7', '#92c5de'))) +  theme_classic(base_size = 9) + labs(title = 'Students found hw02 to be more difficult than hw01') + theme(plot.title.position = 'plot', axis.title.x = element_blank(), axis.text.x = element_blank(), legend.position = "none")

midterm <- ggplot(survey, aes(x=midterm, fill=midterm)) + geom_bar(color = "black") + scale_x_discrete(drop=FALSE) + scale_fill_manual(values = rev(c('#ca0020', '#f4a582', '#f7f7f7', '#92c5de'))) +  theme_classic(base_size = 9) + labs(title = 'Students found the midterm most difficult of all') + theme(plot.title.position = 'plot', axis.title.x = element_blank(),   legend.position = "none")


hw01 / hw02 / midterm
```

---

### What would you change?

.very-small[

```{r, echo=FALSE}
DT::datatable(survey |> 
                filter(!is.na(`Optional: If you were in charge and could change one thing about COGS 137, what would it be?`)) |> select(`Optional: If you were in charge and could change one thing about COGS 137, what would it be?`)) 
```
]
---

### Follow up to what you would change

.small[
- **Labs**: take a long time
  - We make them long so that nobody is bored in lab, *but* you typically don't have to do *everything*
  - Going to **push lab due date back to Sunday night (11:59 PM)** to take some of the pressure off.
  - *But* this does NOT mean we're expecting you to complete. Just giving additional time
  - If you feel like you're putting in ~1h of work and NOT getting full credit, reach out to Prof (DM on Campuswire or email)
]
--
.small[
- release CS earlier (I totally agree. will work on this.)
- power outlets (I also agree. I don't have a solution :( )
]
--
.small[
- need more zoom office hours
  - **new zoom office hours**: by appt. only
  - 10 min slots on Thursdays 3-4 PM 
  - see Canvas for link to sign up
]

---

## Packages & Data

```{r, eval=FALSE}
library(tidyverse)
library(tidymodels)
library(broom)
```

```{r load-pp, message=FALSE}
pp <- read_csv("data/paris_paintings.csv",
               na = c("n/a", "", "NA")) |>
  mutate(log_price = log(price))
```


.small[
File also available at URL: 
- "https://raw.githubusercontent.com/COGS137/datasets/main/paris_paintings.csv"
]

---

class: middle

# Two numerical predictors

---

## Multiple predictors

- Response variable: `log_price` 
- Explanatory variables: Width and height

```{r model-price-width-height}
pp_fit <- linear_reg() |>
  set_engine("lm") |>
  fit(log_price ~ Width_in + Height_in, data = pp)
tidy(pp_fit)
```

---

##  Linear model with multiple predictors

```{r model-price-width-height-tidy, echo=FALSE}
tidy(pp_fit)
```

<br>

$$\widehat{log\_price} = 4.77 + 0.0269 \times width - 0.0133 \times height$$

---

## Visualizing models with multiple predictors

.panelset[
.panel[.panel-name[Plot]
.pull-left-wide[
```{r plotly-plot, echo = FALSE, fig.align="center", warning=FALSE}
p <- plot_ly(pp,
  x = ~Width_in, y = ~Height_in, z = ~log_price,
  marker = list(size = 3, color = "lightgray", alpha = 0.5, 
                line = list(color = "gray", width = 2))) |>
  add_markers() |>
  plotly::layout(scene = list(
    xaxis = list(title = "Width (in)"),
    yaxis = list(title = "Height (in)"),
    zaxis = list(title = "log_price")
  )) |>
  config(displayModeBar = FALSE)
frameWidget(p)
```
]
]
.panel[.panel-name[Code]
```{r plotly-code, eval=FALSE}
p <- plot_ly(pp,
  x = ~Width_in, y = ~Height_in, z = ~log_price,
  marker = list(size = 3, color = "lightgray", alpha = 0.5, 
                line = list(color = "gray", width = 2))) |>
  add_markers() |>
  plotly::layout(scene = list(
    xaxis = list(title = "Width (in)"),
    yaxis = list(title = "Height (in)"),
    zaxis = list(title = "log_price")
  )) |>
  config(displayModeBar = FALSE)
frameWidget(p)
```
]
]

---

class: middle

# Numerical and categorical predictors

---

## Price, surface area, and living artist

- Explore the relationship between price of paintings and surface area, conditioned 
on whether or not the artist is still living
- First visualize and explore, then model
- But first, prep the data

.midi[
```{r}
pp <- pp |>
  mutate(artistliving = if_else(artistliving == 0, "Deceased", "Living"))

pp |>
  count(artistliving)
```
]

---

## Typical surface area

.panelset[
.panel[.panel-name[Plot]
.pull-left-narrow[
Typical surface area appears to be less than 1000 square inches (~ 80cm x 80cm). There are very few paintings that have surface area above 5000 square inches.
]
.pull-right-wide[
```{r ref.label = "viz-surf-artistliving", echo = FALSE, warning = FALSE, out.width="90%"}
```
]
]
.panel[.panel-name[Code]
```{r viz-surf-artistliving, fig.show = "hide"}
ggplot(data = pp, aes(x = Surface, fill = artistliving)) +
  geom_histogram(binwidth = 500) + 
  facet_grid(artistliving ~ .) +
  scale_fill_manual(values = c("#E48957", "#071381")) +
  guides(fill = "none") +
  labs(x = "Surface area", y = NULL) +
  geom_vline(xintercept = 1000) +
  geom_vline(xintercept = 5000, linetype = "dashed", color = "gray")
```
]
]

---

## Narrowing the scope

.panelset[
.panel[.panel-name[Plot]
For simplicity let's focus on the paintings with `Surface < 5000`:

```{r ref.label = "viz-surf-lt-5000-artistliving", echo = FALSE, warning = FALSE, out.width = "55%"}
```
]
.panel[.panel-name[Code]
```{r viz-surf-lt-5000-artistliving, fig.show = "hide"}
pp_Surf_lt_5000 <- pp |>
  filter(Surface < 5000)

ggplot(data = pp_Surf_lt_5000, 
       aes(y = log_price, x = Surface, color = artistliving, shape = artistliving)) +
  geom_point(alpha = 0.5) +
  labs(color = "Artist", shape = "Artist") +
  scale_color_manual(values = c("#E48957", "#071381"))
```
]
]

---

## Facet to get a better look

.panelset[
.panel[.panel-name[Plot]
```{r ref.label = "viz-surf-lt-5000-artistliving-facet", echo = FALSE, warning = FALSE, out.width = "80%", fig.asp = 0.5}
```
]
.panel[.panel-name[Code]
```{r viz-surf-lt-5000-artistliving-facet, fig.show = "hide"}
ggplot(data = pp_Surf_lt_5000, 
       aes(y = log_price, x = Surface, color = artistliving, shape = artistliving)) +
  geom_point(alpha = 0.5) +
  facet_wrap(~artistliving) +
  scale_color_manual(values = c("#E48957", "#071381")) +
  labs(color = "Artist", shape = "Artist")
```
]
]

---

## Two ways to model

- **Main effects:** Assuming relationship between surface and logged price 
**does not vary** by whether or not the artist is living.
- **Interaction effects:** Assuming relationship between surface and logged 
price **varies** by whether or not the artist is living.

---

## Interacting explanatory variables

- Including an interaction effect in the model allows for different slopes, i.e. 
nonparallel lines.
- This implies that the regression coefficient for an explanatory variable would 
change as another explanatory variable changes.
- This can be accomplished by adding an interaction variable: the product of two 
explanatory variables.

---

## Two ways to model

.pull-left-narrow[
- **Main effects:** Assuming relationship between surface and logged price **does not vary** by whether or not the artist is living
- **Interaction effects:** Assuming relationship between surface and logged price **varies** by whether or not the artist is living
]
.pull-right-wide[
```{r pp-main-int-viz, echo=FALSE, out.width="70%", fig.asp = 0.9}
pp_main_fit <- linear_reg() |>
  set_engine("lm") |>
  fit(log_price ~ Surface + artistliving, data = pp_Surf_lt_5000)
pp_main_fit_aug <- augment(pp_main_fit$fit)

pp_int_fit <- linear_reg() |>
  set_engine("lm") |>
  fit(log_price ~ Surface * artistliving, data = pp_Surf_lt_5000)
pp_int_fit_aug <- augment(pp_int_fit$fit)

p_main <- ggplot(
  pp_main_fit_aug,
  aes(y = log_price, x = Surface, color = artistliving)
) +
  geom_point(aes(shape = artistliving), alpha = 0.5) +
  scale_x_continuous(breaks = c(0, 2500, 5000)) +
  scale_color_manual(values = c("#E48957", "#071381")) +
  geom_line(aes(y = .fitted), size = 1.5) +
  labs(y = "log_price", title = "Main effects", color = "Artist", shape = "Artist")

p_int <- ggplot(
  pp_int_fit_aug,
  aes(y = log_price, x = Surface, color = artistliving)
) +
  geom_point(aes(shape = artistliving), alpha = 0.5) +
  scale_x_continuous(breaks = c(0, 2500, 5000)) +
  scale_color_manual(values = c("#E48957", "#071381")) +
  geom_line(aes(y = .fitted), size = 1.5) +
  labs(y = "log_price", title = "Interaction effects", color = "Artist", shape = "Artist")

p_main /
  p_int  + 
  plot_layout(guides = "collect") & theme(legend.position = "bottom")
```
]

---

## Fit model with main effects

- Response variable: `log_price`
- Explanatory variables: `Surface` area and `artistliving`

.midi[
```{r model-main-effects}
pp_main_fit <- linear_reg() |>
  set_engine("lm") |>
  fit(log_price ~ Surface + artistliving, data = pp_Surf_lt_5000)
tidy(pp_main_fit)
```
]

--

$$\widehat{log\_price} = 4.88 + 0.000265 \times surface + 0.137 \times artistliving$$

---

## Solving the model

- Non-living artist: Plug in 0 for `artistliving`

$\widehat{log\_price} = 4.88 + 0.000265 \times surface + 0.137 \times 0$  
$= 4.88 + 0.000265 \times surface$

--
- Living artist: Plug in 1 for `artistliving`

$\widehat{log\_price} = 4.88 + 0.000265 \times surface + 0.137 \times 1$   
$= 5.017 + 0.000265 \times surface$

---

## Visualizing main effects

.pull-left-narrow[
- **Same slope:** Rate of change in price as the surface area increases does 
not vary between paintings by living and non-living artists.
- **Different intercept:** Paintings by living artists are consistently more 
expensive than paintings by non-living artists.
]
.pull-right-wide[
```{r out.width="100%", echo = FALSE}
p_main
```
]

---

## Interpreting main effects

.midi[
```{r exp-coefs}
tidy(pp_main_fit) |> 
  mutate(exp_estimate = exp(estimate)) |>
  select(term, estimate, exp_estimate)
```
]

- All else held constant, for each additional square inch in painting's surface area, the price of the painting is predicted, on average, to be higher by a factor of 1.
- All else held constant, paintings by a living artist are predicted, on average, to be higher by a factor of 1.15 compared to paintings by an artist who is no longer alive.
- Paintings that are by an artist who is not alive and that have a surface area of 0 square inches are predicted, on average, to be 132 livres.

---

## Main vs. interaction effects

- The way we specified our main effects model only lets `artistliving` affect the intercept.
- Model implicitly assumes that paintings with living and deceased artists have the *same slope* and only allows for *different intercepts*.  

.question[
What seems more appropriate in this case?
+ Same slope and same intercept for both colours
+ Same slope and different intercept for both colours
+ Different slope and different intercept for both colours
]

---

## Interaction: `Surface * artistliving`

```{r out.width="60%", echo = FALSE}
p_int
```

---

## Fit model with interaction effects

- Response variable: log_price
- Explanatory variables: `Surface` area, `artistliving`, and their interaction

.midi[
```{r model-interaction-effects}
pp_int_fit <- linear_reg() |>
  set_engine("lm") |>
  fit(log_price ~ Surface * artistliving, data = pp_Surf_lt_5000)
tidy(pp_int_fit)
```
]

---

## Linear model with interaction effects

.midi[
```{r model-interaction-effects-tidy, echo=FALSE}
tidy(pp_int_fit)
```
]

$$\widehat{log\_price} = 4.91 + 0.00021 \times surface - 0.126 \times artistliving$$
$$+ ~ 0.00048 \times surface * artistliving$$

---

## Interpretation of interaction effects

- Rate of change in price as the surface area of the painting increases does 
vary between paintings by living and non-living artists (different slopes), 
- Some paintings by living artists are more expensive than paintings by
non-living artists, and some are not (different intercept).

.small[
.pull-left[
- Non-living artist: 
$\widehat{log\_price} = 4.91 + 0.00021 \times surface$
$- 0.126 \times 0 + 0.00048 \times surface \times 0$
$= 4.91 + 0.00021 \times surface$
- Living artist: 
$\widehat{log\_price} = 4.91 + 0.00021 \times surface$
$- 0.126 \times 1 + 0.00048 \times surface \times 1$
$= 4.91 + 0.00021 \times surface$
$- 0.126 + 0.00048 \times surface$
$= 4.784 + 0.00069 \times surface$
]
.pull-right[
```{r viz-interaction-effects2, out.width="80%", echo = FALSE}
p_int
```
]
]

---

## Comparing models

---

## R-squared

- $R^2$ is the percentage of variability in the response variable explained by 
the regression model.

```{r}
glance(pp_main_fit)$r.squared
glance(pp_int_fit)$r.squared
```

--
- Clearly the model with interactions has a higher $R^2$.

--
- However using $R^2$ for model selection in models with multiple explanatory variables is not a good idea as $R^2$ increases when **any** variable is added to the model.

---

## Adjusted R-squared

It appears that adding the interaction actually increased adjusted $R^2$, so we 
should indeed use the model with the interactions.

```{r}
glance(pp_main_fit)$adj.r.squared
glance(pp_int_fit)$adj.r.squared
```

---

## Third order interactions

- Can you? Yes
- Should you? Probably not if you want to interpret these interactions in context
of the data.

---

## In pursuit of Occam's razor

- Occam's Razor states that among competing hypotheses that predict equally well, the one with the fewest assumptions should be selected.

--
- Model selection follows this principle.

--
- We only want to add another variable to the model if the addition of that variable brings something valuable in terms of predictive power to the model.

--
- In other words, we prefer the simplest best model, i.e. **parsimonious** model.

